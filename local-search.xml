<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>golang面试-麦都</title>
    <link href="/2023/08/15/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%95-%E9%BA%A6%E9%83%BD/"/>
    <url>/2023/08/15/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%95-%E9%BA%A6%E9%83%BD/</url>
    
    <content type="html"><![CDATA[<ol><li><p>gRPC需不需要限制带宽，限制gRPC的流量</p><p>可以使用gRPC的服务配置选项来限制gRPC流量，包括设置每个客户端可以并发打开的流数量、每个流可以发送和接收的消息数量、每个消息的最大字节数量等。此外，还可以使用网络代理程序或负载均衡器来限制gRPC流量。gRPC的服务配置选项通常可以在服务端的gRPC配置文件中配置，也可以通过使用环境变量和代码API来动态配置。</p></li><li><p>怎么进行SQL优化的？</p></li><li><p>context包的使用，并发的去查询orm和redis，需不要进行处理</p></li><li><p>敏感词算法，怎么实现的匹配机制</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>五一假期计划</title>
    <link href="/2023/04/14/05.%E9%9A%8F%E7%AC%94/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F/"/>
    <url>/2023/04/14/05.%E9%9A%8F%E7%AC%94/%E4%BA%94%E4%B8%80%E5%81%87%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<h1>五一假期计划</h1><h2 id="4月29日-深圳">4月29日 深圳</h2><p><strong>路线</strong>：</p><ul><li>早茶（未定）</li><li>10 点平安大厦</li><li>10:30 去东山码头 路程一个半小时</li><li>预计12点到达吃饭</li><li>13点出发海钓</li><li>17点回码头，休息后回福田</li><li>晚上可以去福田的清吧坐一下</li></ul><p>准备晕船药、太阳镜、遮阳帽</p><h2 id="4月30日-香港">4月30日 香港</h2><p><strong>路线</strong>：</p><ul><li>过福田口岸</li><li>港铁 落马洲站 -&gt; 尖沙咀地铁站</li><li>星光大道</li><li>太平山缆车登顶</li><li>维多利亚港</li><li>回口岸</li></ul><h2 id="5月1日-珠海">5月1日 珠海</h2><p>湾仔旅游码头</p><h2 id="5月2日-澳门">5月2日 澳门</h2>]]></content>
    
    
    <categories>
      
      <category>五一假期计划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>五一假期计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常见面试题</title>
    <link href="/2023/04/06/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/03.redis/01.redis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2023/04/06/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/03.redis/01.redis%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><h2 id="1-redis和memcached的区别">1. redis和memcached的区别</h2><p>redis支持的类型更丰富，有string，hash，list，set，zset等类型，而memcached只有key-value一种模式；</p><p>redis支持数据的持久化，可以把内存中的数据保存到磁盘，所以在重启之后能够加载原来的数据，而memcached的数据都保存在内存中，如果重启或者挂掉，数据就没了；</p><p>redis原生就支持集群，memcached没有原生的集群模式，需要依靠客户端来实现往集群中的分片写入；</p><p>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</p><h2 id="2-redis的数据结构">2. redis的数据结构</h2><h3 id="2-1-redis是数据类型及使用场景">2.1 redis是数据类型及使用场景</h3><p>String</p><p>List</p><p>Set</p><p>Hash</p><p>Zset</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kafka消息积压</title>
    <link href="/2023/03/17/02.%E8%AE%B0%E5%BD%95/01.%E7%94%9F%E4%BA%A7%E4%BA%8B%E6%95%85/01-Kafka%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B/"/>
    <url>/2023/03/17/02.%E8%AE%B0%E5%BD%95/01.%E7%94%9F%E4%BA%A7%E4%BA%8B%E6%95%85/01-Kafka%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B/</url>
    
    <content type="html"><![CDATA[<h1>一、事故现场</h1><p>当天风和日丽，正在开(chou)开(mei)心(ku)心(lian)的排查bug，客户突然告警，某个引擎需要下发的数据没有推送，由于刚巧重启过服务，事故日志未保留，本地也未持久化相关日志，导致事故现场未保留，也不知道具体原因。</p><h1>二、解决方案</h1><ol><li>由于此引擎作用为从Kafka消费消息，然后通过http或者Kafka的方式推送给下游，导致事故发生时积压了很多数据，因为决定先增加日志并重启服务，消费数据，观测有没有其他原因。</li><li>重启后发现消息消费一部分后阻塞，于是扩充资源，怀疑是资源引起的服务down掉，扩充资源后，服务正常。</li></ol><h1>三、事故总结</h1><p>由于日志未备份，且刚好随意操作，导致事故日志未保留，这存在很大的隐患，无法确定当时事故发生的具体原因，经过考虑，可能是由于某个协程泄漏或者是内存逃逸导致，后续将会对这一服务进行压测，确定在大流量情况下是否还有类似情况发生，并确定资源阈值。</p>]]></content>
    
    
    
    <tags>
      
      <tag>事故排查</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>超时控制</title>
    <link href="/2023/03/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/6.%E8%B6%85%E6%97%B6%E6%8E%A7%E5%88%B6/"/>
    <url>/2023/03/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/6.%E8%B6%85%E6%97%B6%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1>一、原因</h1><p>如果没有超时控制，当一个节点故障后，其他节点也会受到影响导致故障，所以单节点不容易被打死，才不会引起其他控制。</p><p>不希望不等到断开的实例知道超时，尽量控制返回时间，如果是无响应界面，用户体验是很差的。</p><p>服务调用链是串联的，很有可能导致超时叠加，最终导致请求堆积，无法被消费。</p><p>网络传递具有不确定性。</p><p>客户端和服务端不一致的超时策略导致资源浪费，当上游超时时间较短时，会导致上游超时后下游仍在执行。</p><p>默认值策略，比如redis和mysql，永不超时，所以设计时要考虑主动超时。</p><p>超时控制是微服务可用性的第一道关，良好的超时策略，可以尽可能的让服务不堆积请求，尽快清空高延迟的请求，释放goroutine。</p>]]></content>
    
    
    <categories>
      
      <category>微服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zed-web框架</title>
    <link href="/2023/03/08/03.github%E9%A1%B9%E7%9B%AE/01.web/"/>
    <url>/2023/03/08/03.github%E9%A1%B9%E7%9B%AE/01.web/</url>
    
    <content type="html"><![CDATA[<h1>一、简介</h1><p>在使用过beego、gin、kratos等常用框架后，他们的设计理念和提供的功能有很多共性，为了更好提高自己的一些理解，决定简单的写一个web框架。</p><h1>二、编写</h1><h2 id="1-路由">1. 路由</h2><p>参考gin框架，我们先写一个engine，将路由和对应的执行方法利用map的方式绑定起来，并且把engine的生成方法收束起来由框架控制。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> zed<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-comment">// HandlerFunc defines the request handler used by zed</span><br><span class="hljs-keyword">type</span> HandlerFunc <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(http.ResponseWriter, *http.Request)</span></span><br><br><span class="hljs-comment">// Engine implement the interface of ServeHTTP</span><br><span class="hljs-keyword">type</span> Engine <span class="hljs-keyword">struct</span> &#123;<br>router <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">ServeHTTP</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;<br>key := req.Method + <span class="hljs-string">&quot;-&quot;</span> + req.URL.Path<br><span class="hljs-keyword">if</span> handler, ok := engine.router[key]; ok &#123;<br>handler(w, req)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>fmt.Fprintf(w, <span class="hljs-string">&quot;404 not found:%s\n&quot;</span>, req.URL)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">Run</span><span class="hljs-params">(addr <span class="hljs-keyword">string</span>)</span> <span class="hljs-params">(err error)</span></span> &#123;<br><span class="hljs-keyword">return</span> http.ListenAndServe(addr, engine)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">addRoute</span><span class="hljs-params">(method <span class="hljs-keyword">string</span>, pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>key := method + <span class="hljs-string">&quot;-&quot;</span> + pattern<br>engine.router[key] = handler<br>&#125;<br><br><span class="hljs-comment">// GET defines the method to add GET request.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">GET</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>engine.addRoute(<span class="hljs-string">&quot;GET&quot;</span>, pattern, handler)<br>&#125;<br><br><span class="hljs-comment">// POST defines the method to add POST request.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">POST</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>engine.addRoute(<span class="hljs-string">&quot;POST&quot;</span>, pattern, handler)<br>&#125;<br><br><span class="hljs-comment">// New is the constructor of zed.Engine</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">()</span> *<span class="hljs-title">Engine</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;Engine&#123;router: <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc&#123;&#125;&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>这样一个简单的路由方法就写好了，这样有什么问题呢，首先，在高并发的场景下，可能有大量的请求不会马上返回，这时候我们就需要一个超时控制，其次，在原生的net/http中每个请求都需要对它的header进行设置，代码繁杂，初次之外，对于框架来说，可能还要支撑一些其他功能，例如中间件，那么中间件的消息怎么传递呢，这时候我们就需要context。</p><h2 id="2-context">2. context</h2><p>新增了一个Context的结构体，把请求参数和返回参数都放到里面，另外再封装一些常用信息和方法，这样可以给用户一些简洁的写法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> zed<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;encoding/json&quot;</span><br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> H <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">interface</span>&#123;&#125;<br><br><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">//origin objects</span><br>Writer http.ResponseWriter<br>Req    *http.Request<br><br>Method <span class="hljs-keyword">string</span><br>Path   <span class="hljs-keyword">string</span><br><br>StatusCode <span class="hljs-keyword">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newContext</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span> *<span class="hljs-title">Context</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;Context&#123;<br>Writer: w,<br>Req:    req,<br>Method: req.Method,<br>Path:   req.URL.Path,<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">PostForm</span><span class="hljs-params">(key <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">return</span> c.Req.FormValue(key)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">Query</span><span class="hljs-params">(key <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">return</span> c.Req.URL.Query().Get(key)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">Status</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>)</span></span> &#123;<br>c.StatusCode = code<br>c.Writer.WriteHeader(code)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">SetHeader</span><span class="hljs-params">(key <span class="hljs-keyword">string</span>, value <span class="hljs-keyword">string</span>)</span></span> &#123;<br>c.Writer.Header().Set(key, value)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">String</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>, format <span class="hljs-keyword">string</span>, value ...<span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br>c.SetHeader(<span class="hljs-string">&quot;Content-Type&quot;</span>, <span class="hljs-string">&quot;text/plain&quot;</span>)<br>c.Status(code)<br>c.Writer.Write([]<span class="hljs-keyword">byte</span>(fmt.Sprintf(format, value...)))<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">JSON</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>, obj <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br>c.SetHeader(<span class="hljs-string">&quot;Content-Type&quot;</span>, <span class="hljs-string">&quot;application/json&quot;</span>)<br>c.Status(code)<br>encoder := json.NewEncoder(c.Writer)<br>err := encoder.Encode(obj)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>http.Error(c.Writer, err.Error(), <span class="hljs-number">500</span>)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">Data</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>, data []<span class="hljs-keyword">byte</span>)</span></span> &#123;<br>c.Status(code)<br>c.Writer.Write(data)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">HTML</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>, html <span class="hljs-keyword">string</span>)</span></span> &#123;<br>c.SetHeader(<span class="hljs-string">&quot;Content-Type&quot;</span>, <span class="hljs-string">&quot;text/html&quot;</span>)<br>c.Status(code)<br>c.Writer.Write([]<span class="hljs-keyword">byte</span>(html))<br>&#125;<br></code></pre></td></tr></table></figure><p>同时重新封装一下路由，为后面路由的扩展做准备</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> zed<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;log&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> router <span class="hljs-keyword">struct</span> &#123;<br>handlers <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newRouter</span><span class="hljs-params">()</span> *<span class="hljs-title">router</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;router&#123;handlers: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc)&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">addRoute</span><span class="hljs-params">(method <span class="hljs-keyword">string</span>, pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>log.Printf(<span class="hljs-string">&quot;Route %4s - %s&quot;</span>, method, pattern)<br>key := method + <span class="hljs-string">&quot;-&quot;</span> + pattern<br>r.handlers[key] = handler<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">handle</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>key := c.Method + <span class="hljs-string">&quot;-&quot;</span> + c.Path<br><span class="hljs-keyword">if</span> handler, ok := r.handlers[key]; ok &#123;<br>handler(c)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>c.String(http.StatusNotFound, <span class="hljs-string">&quot;404 NOT FOUND: %s\n&quot;</span>, c.Path)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-前缀树路由">3. 前缀树路由</h2><ul><li><p>使用 Trie 树实现动态路由(dynamic route)解析。</p></li><li><p>支持两种模式<code>:name</code>和<code>*filepath</code>。</p></li></ul><h3 id="Trie树">Trie树</h3><p>之前使用的是map的方式用来匹配路由，虽然索引很高效，但是这种方式不够灵活，只能检索动态路由。</p><p>实现动态路由最常用的数据结构，被称为前缀树，每一个节点的所有的子节点都拥有相同的前缀。而HTTP的请求路径是由<code>/</code>分隔开的，每一段都可以作为一个前缀树的节点，我们通过树结构查询，如果某一层的节点都不满足条件，就说明没有匹配到的路由，查询结束。</p><h3 id="实现">实现</h3><p>首先我们需要设计树节点上应该存储那些信息。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> node <span class="hljs-keyword">struct</span> &#123;<br>pattern  <span class="hljs-keyword">string</span> <span class="hljs-comment">// 待匹配路由，例如 /p/:lang</span><br>part     <span class="hljs-keyword">string</span> <span class="hljs-comment">// 路由中的一部分，例如 :lang</span><br>children []*node <span class="hljs-comment">// 子节点，例如 [doc, tutorial, intro]</span><br>isWild   <span class="hljs-keyword">bool</span> <span class="hljs-comment">// 是否精确匹配，part 含有 : 或 * 时为true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>与普通的树不同，为了实现动态路由匹配，加上了<code>isWild</code>这个参数。即当我们匹配 <code>/p/go/doc/</code>这个路由时，第一层节点，<code>p</code>精准匹配到了<code>p</code>，第二层节点，<code>go</code>模糊匹配到<code>:lang</code>，那么将会把<code>lang</code>这个参数赋值为<code>go</code>，继续下一层匹配。我们将匹配的逻辑，包装为一个辅助函数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 第一个匹配成功的节点，用于插入</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span> <span class="hljs-title">matchChild</span><span class="hljs-params">(part <span class="hljs-keyword">string</span>)</span> *<span class="hljs-title">node</span></span> &#123;<br><span class="hljs-keyword">for</span> _, child := <span class="hljs-keyword">range</span> n.children &#123;<br><span class="hljs-keyword">if</span> child.part == part || child.isWild &#123;<br><span class="hljs-keyword">return</span> child<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-comment">// 所有匹配成功的节点，用于查找</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span> <span class="hljs-title">matchChildren</span><span class="hljs-params">(part <span class="hljs-keyword">string</span>)</span> []*<span class="hljs-title">node</span></span> &#123;<br>nodes := <span class="hljs-built_in">make</span>([]*node, <span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> _, child := <span class="hljs-keyword">range</span> n.children &#123;<br><span class="hljs-keyword">if</span> child.part == part || child.isWild &#123;<br>nodes = <span class="hljs-built_in">append</span>(nodes, child)<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> nodes<br>&#125;<br></code></pre></td></tr></table></figure><p>对于路由来说，最重要的当然是注册与匹配了。开发服务时，注册路由规则，映射handler；访问时，匹配路由规则，查找到对应的handler。因此，Trie 树需要支持节点的插入与查询。插入功能很简单，递归查找每一层的节点，如果没有匹配到当前<code>part</code>的节点，则新建一个，有一点需要注意，<code>/p/:lang/doc</code>只有在第三层节点，即<code>doc</code>节点，<code>pattern</code>才会设置为<code>/p/:lang/doc</code>。<code>p</code>和<code>:lang</code>节点的<code>pattern</code>属性皆为空。因此，当匹配结束时，我们可以使用<code>n.pattern == &quot;&quot;</code>来判断路由规则是否匹配成功。例如，<code>/p/python</code>虽能成功匹配到<code>:lang</code>，但<code>:lang</code>的<code>pattern</code>值为空，因此匹配失败。查询功能，同样也是递归查询每一层的节点，退出规则是，匹配到了<code>*</code>，匹配失败，或者匹配到了第<code>len(parts)</code>层节点。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span> <span class="hljs-title">insert</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>, parts []<span class="hljs-keyword">string</span>, height <span class="hljs-keyword">int</span>)</span></span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(parts) == height &#123;<br>n.pattern = pattern<br><span class="hljs-keyword">return</span><br>&#125;<br><br>part := parts[height]<br>child := n.matchChild(part)<br><span class="hljs-keyword">if</span> child == <span class="hljs-literal">nil</span> &#123;<br>child = &amp;node&#123;part: part, isWild: part[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;:&#x27;</span> || part[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;*&#x27;</span>&#125;<br>n.children = <span class="hljs-built_in">append</span>(n.children, child)<br>&#125;<br>child.insert(pattern, parts, height+<span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span> <span class="hljs-title">search</span><span class="hljs-params">(parts []<span class="hljs-keyword">string</span>, height <span class="hljs-keyword">int</span>)</span> *<span class="hljs-title">node</span></span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(parts) == height || strings.HasPrefix(n.part, <span class="hljs-string">&quot;*&quot;</span>) &#123;<br><span class="hljs-keyword">if</span> n.pattern == <span class="hljs-string">&quot;&quot;</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">return</span> n<br>&#125;<br><br>part := parts[height]<br>children := n.matchChildren(part)<br><br><span class="hljs-keyword">for</span> _, child := <span class="hljs-keyword">range</span> children &#123;<br>result := child.search(parts, height+<span class="hljs-number">1</span>)<br><span class="hljs-keyword">if</span> result != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> result<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Router">Router</h3><p>Trie 树的插入与查找都成功实现了，接下来我们将 Trie 树应用到路由中去吧。我们使用 roots 来存储每种请求方式的Trie 树根节点。使用 handlers 存储每种请求方式的 HandlerFunc 。getRoute 函数中，还解析了<code>:</code>和<code>*</code>两种匹配符的参数，返回一个 map 。例如<code>/p/go/doc</code>匹配到<code>/p/:lang/doc</code>，解析结果为：<code>&#123;lang: &quot;go&quot;&#125;</code>，<code>/static/css/geektutu.css</code>匹配到<code>/static/*filepath</code>，解析结果为<code>&#123;filepath: &quot;css/geektutu.css&quot;&#125;</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> router <span class="hljs-keyword">struct</span> &#123;<br>roots    <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*node<br>handlers <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc<br>&#125;<br><br><span class="hljs-comment">// roots key eg, roots[&#x27;GET&#x27;] roots[&#x27;POST&#x27;]</span><br><span class="hljs-comment">// handlers key eg, handlers[&#x27;GET-/p/:lang/doc&#x27;], handlers[&#x27;POST-/p/book&#x27;]</span><br>    <br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newRouter</span><span class="hljs-params">()</span> *<span class="hljs-title">router</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;router&#123;<br>roots:    <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*node),<br>handlers: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]HandlerFunc),<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// Only one * is allowed</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">parsePattern</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>)</span> []<span class="hljs-title">string</span></span> &#123;<br>vs := strings.Split(pattern, <span class="hljs-string">&quot;/&quot;</span>)<br><br>parts := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">string</span>, <span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> _, item := <span class="hljs-keyword">range</span> vs &#123;<br><span class="hljs-keyword">if</span> item != <span class="hljs-string">&quot;&quot;</span> &#123;<br>parts = <span class="hljs-built_in">append</span>(parts, item)<br><span class="hljs-keyword">if</span> item[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;*&#x27;</span> &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> parts<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">addRoute</span><span class="hljs-params">(method <span class="hljs-keyword">string</span>, pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>parts := parsePattern(pattern)<br><br>key := method + <span class="hljs-string">&quot;-&quot;</span> + pattern<br>_, ok := r.roots[method]<br><span class="hljs-keyword">if</span> !ok &#123;<br>r.roots[method] = &amp;node&#123;&#125;<br>&#125;<br>r.roots[method].insert(pattern, parts, <span class="hljs-number">0</span>)<br>r.handlers[key] = handler<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">getRoute</span><span class="hljs-params">(method <span class="hljs-keyword">string</span>, path <span class="hljs-keyword">string</span>)</span> <span class="hljs-params">(*node, <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">string</span>)</span></span> &#123;<br>searchParts := parsePattern(path)<br>params := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">string</span>)<br>root, ok := r.roots[method]<br><br><span class="hljs-keyword">if</span> !ok &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>&#125;<br><br>n := root.search(searchParts, <span class="hljs-number">0</span>)<br><br><span class="hljs-keyword">if</span> n != <span class="hljs-literal">nil</span> &#123;<br>parts := parsePattern(n.pattern)<br><span class="hljs-keyword">for</span> index, part := <span class="hljs-keyword">range</span> parts &#123;<br><span class="hljs-keyword">if</span> part[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;:&#x27;</span> &#123;<br>params[part[<span class="hljs-number">1</span>:]] = searchParts[index]<br>&#125;<br><span class="hljs-keyword">if</span> part[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;*&#x27;</span> &amp;&amp; <span class="hljs-built_in">len</span>(part) &gt; <span class="hljs-number">1</span> &#123;<br>params[part[<span class="hljs-number">1</span>:]] = strings.Join(searchParts[index:], <span class="hljs-string">&quot;/&quot;</span>)<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> n, params<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Context与handle的变化">Context与handle的变化</h3><p>在 HandlerFunc 中，希望能够访问到解析的参数，因此，需要对 Context 对象增加一个属性和方法，来提供对路由参数的访问。我们将解析后的参数存储到<code>Params</code>中，通过<code>c.Param(&quot;lang&quot;)</code>的方式获取到对应的值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// origin objects</span><br>Writer http.ResponseWriter<br>Req    *http.Request<br><span class="hljs-comment">// request info</span><br>Path   <span class="hljs-keyword">string</span><br>Method <span class="hljs-keyword">string</span><br>Params <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">string</span><br><span class="hljs-comment">// response info</span><br>StatusCode <span class="hljs-keyword">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">Param</span><span class="hljs-params">(key <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<br>value, _ := c.Params[key]<br><span class="hljs-keyword">return</span> value<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">handle</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>n, params := r.getRoute(c.Method, c.Path)<br><span class="hljs-keyword">if</span> n != <span class="hljs-literal">nil</span> &#123;<br>c.Params = params<br>key := c.Method + <span class="hljs-string">&quot;-&quot;</span> + n.pattern<br>r.handlers[key](c)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>c.String(http.StatusNotFound, <span class="hljs-string">&quot;404 NOT FOUND: %s\n&quot;</span>, c.Path)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>router.go</code>的变化比较小，比较重要的一点是，在调用匹配到的<code>handler</code>前，将解析出来的路由参数赋值给了<code>c.Params</code>。这样就能够在<code>handler</code>中，通过<code>Context</code>对象访问到具体的值了。</p><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p><h2 id="4-实现路由分组控制-Route-Group-Control">4. 实现路由分组控制(Route Group Control)</h2><p>=======</p><h2 id="4-分组控制">4. 分组控制</h2><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>ba26a3a9458192af5af8922514b11e1b18dc576b</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><h3 id="分组的意义">分组的意义</h3><p>分组控制(Group Control)是 Web 框架应提供的基础功能之一。所谓分组，是指路由的分组。如果没有路由分组，我们需要针对每一个路由进行控制。但是真实的业务场景中，往往某一组路由需要相似的处理。例如：</p><ul><li>以<code>/post</code>开头的路由匿名可访问。</li><li>以<code>/admin</code>开头的路由需要鉴权。</li><li>以<code>/api</code>开头的路由是 RESTful 接口，可以对接第三方平台，需要三方平台鉴权。</li></ul><p>大部分情况下的路由分组，是以相同的前缀来区分的。因此，我们今天实现的分组控制也是以前缀来区分，并且支持分组的嵌套。例如<code>/post</code>是一个分组，<code>/post/a</code>和<code>/post/b</code>可以是该分组下的子分组。作用在<code>/post</code>分组上的中间件(middleware)，也都会作用在子分组，子分组还可以应用自己特有的中间件。</p><p>中间件可以给框架提供无限的扩展能力，应用在分组上，可以使得分组控制的收益更为明显，而不是共享相同的路由前缀这么简单。例如<code>/admin</code>的分组，可以应用鉴权中间件；<code>/</code>分组应用日志中间件，<code>/</code>是默认的最顶层的分组，也就意味着给所有的路由，即整个框架增加了记录日志的能力。</p><h3 id="分组嵌套">分组嵌套</h3><p>一个 Group 对象需要具备哪些属性呢？首先是前缀(prefix)，比如<code>/</code>，或者<code>/api</code>；要支持分组嵌套，那么需要知道当前分组的父亲(parent)是谁；当然了，按照我们一开始的分析，中间件是应用在分组上的，那还需要存储应用在该分组上的中间件(middlewares)。还记得，我们之前调用函数<code>(*Engine).addRoute()</code>来映射所有的路由规则和 Handler 。如果Group对象需要直接映射路由规则的话，比如我们想在使用框架时，这么调用：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>z := zed.New()<br>v1 := z.Group(<span class="hljs-string">&quot;/v1&quot;</span>)<br>v1.GET(<span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *zed.Context)</span></span> &#123;<br>   c.HTML(http.StatusOK, <span class="hljs-string">&quot;&lt;h1&gt;Hello zed&lt;/h1&gt;&quot;</span>)<br>=======<br>r := gee.New()<br>v1 := r.Group(<span class="hljs-string">&quot;/v1&quot;</span>)<br>v1.GET(<span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gee.Context)</span></span> &#123;<br>c.HTML(http.StatusOK, <span class="hljs-string">&quot;&lt;h1&gt;Hello Gee&lt;/h1&gt;&quot;</span>)<br>&gt;&gt;&gt;&gt;&gt;&gt;&gt; ba26a3a9458192af5af8922514b11e1b18dc576b<br>&#125;)<br></code></pre></td></tr></table></figure><p>那么Group对象，还需要有访问<code>Router</code>的能力，为了方便，我们可以在Group中，保存一个指针，指向<code>Engine</code>，整个框架的所有资源都是由<code>Engine</code>统一协调的，那么就可以通过<code>Engine</code>间接地访问各种接口了。</p><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><br><span class="hljs-keyword">type</span> RouterGroup <span class="hljs-keyword">struct</span> &#123;<br>=======<br>所以，最后的 Group 的定义是这样的：<br><br><span class="hljs-string">``</span><span class="hljs-string">`go</span><br><span class="hljs-string">RouterGroup struct &#123;</span><br><span class="hljs-string">&gt;&gt;&gt;&gt;&gt;&gt;&gt; ba26a3a9458192af5af8922514b11e1b18dc576b</span><br><span class="hljs-string">prefix      string</span><br><span class="hljs-string">middlewares []HandlerFunc // support middleware</span><br><span class="hljs-string">parent      *RouterGroup  // support nesting</span><br><span class="hljs-string">engine      *Engine       // all groups share a Engine instance</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="hljs-string"></span><br><span class="hljs-string">// HandlerFunc defines the request handler used by zed</span><br><span class="hljs-string">type HandlerFunc func(ctx *Context)</span><br><span class="hljs-string"></span><br><span class="hljs-string">// Engine implement the interface of ServeHTTP</span><br><span class="hljs-string">type Engine struct &#123;</span><br><span class="hljs-string">=======</span><br></code></pre></td></tr></table></figure><p>我们还可以进一步地抽象，将<code>Engine</code>作为最顶层的分组，也就是说<code>Engine</code>拥有<code>RouterGroup</code>所有的能力。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">Engine <span class="hljs-keyword">struct</span> &#123;<br>&gt;&gt;&gt;&gt;&gt;&gt;&gt; ba26a3a9458192af5af8922514b11e1b18dc576b<br>*RouterGroup<br>router *router<br>groups []*RouterGroup <span class="hljs-comment">// store all groups</span><br>&#125;<br>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br><br><span class="hljs-comment">// New is the constructor of zed.Engine</span><br>=======<br></code></pre></td></tr></table></figure><p>那我们就可以将和路由有关的函数，都交给<code>RouterGroup</code>实现了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// New is the constructor of gee.Engine</span><br>&gt;&gt;&gt;&gt;&gt;&gt;&gt; ba26a3a9458192af5af8922514b11e1b18dc576b<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">()</span> *<span class="hljs-title">Engine</span></span> &#123;<br>engine := &amp;Engine&#123;router: newRouter()&#125;<br>engine.RouterGroup = &amp;RouterGroup&#123;engine: engine&#125;<br>engine.groups = []*RouterGroup&#123;engine.RouterGroup&#125;<br><span class="hljs-keyword">return</span> engine<br>&#125;<br><br>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD<br>=======<br><span class="hljs-comment">// Group is defined to create a new RouterGroup</span><br><span class="hljs-comment">// remember all groups share the same Engine instance</span><br>&gt;&gt;&gt;&gt;&gt;&gt;&gt; ba26a3a9458192af5af8922514b11e1b18dc576b<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">Group</span><span class="hljs-params">(prefix <span class="hljs-keyword">string</span>)</span> *<span class="hljs-title">RouterGroup</span></span> &#123;<br>engine := group.engine<br>newGroup := &amp;RouterGroup&#123;<br>prefix: group.prefix + prefix,<br>parent: group,<br>engine: engine,<br>&#125;<br>engine.groups = <span class="hljs-built_in">append</span>(engine.groups, newGroup)<br><span class="hljs-keyword">return</span> newGroup<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">addRoute</span><span class="hljs-params">(method <span class="hljs-keyword">string</span>, comp <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>pattern := group.prefix + comp<br>log.Printf(<span class="hljs-string">&quot;Route %4s - %s&quot;</span>, method, pattern)<br>group.engine.router.addRoute(method, pattern, handler)<br>&#125;<br><br><span class="hljs-comment">// GET defines the method to add GET request</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">GET</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>group.addRoute(<span class="hljs-string">&quot;GET&quot;</span>, pattern, handler)<br>&#125;<br><br><span class="hljs-comment">// POST defines the method to add POST request</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">POST</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>, handler HandlerFunc)</span></span> &#123;<br>group.addRoute(<span class="hljs-string">&quot;POST&quot;</span>, pattern, handler)<br>&#125;<br></code></pre></td></tr></table></figure><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p><h2 id="5-中间件">5. 中间件</h2><p>=======<br>可以仔细观察下<code>addRoute</code>函数，调用了<code>group.engine.router.addRoute</code>来实现了路由的映射。由于<code>Engine</code>从某种意义上继承了<code>RouterGroup</code>的所有属性和方法，因为 (*Engine).engine 是指向自己的。这样实现，我们既可以像原来一样添加路由，也可以通过分组添加路由。</p><h2 id="5-中间件-2">5. 中间件</h2><h3 id="中间件是什么">中间件是什么</h3><p>中间件(middlewares)，简单说，就是非业务的技术类组件。Web 框架本身不可能去理解所有的业务，因而不可能实现所有的功能。因此，框架需要有一个插口，允许用户自己定义功能，嵌入到框架中，仿佛这个功能是框架原生支持的一样。因此，对中间件而言，需要考虑2个比较关键的点：</p><ul><li>插入点在哪？使用框架的人并不关心底层逻辑的具体实现，如果插入点太底层，中间件逻辑就会非常复杂。如果插入点离用户太近，那和用户直接定义一组函数，每次在 Handler 中手工调用没有多大的优势了。</li><li>中间件的输入是什么？中间件的输入，决定了扩展能力。暴露的参数太少，用户发挥空间有限。</li></ul><p>那对于一个 Web 框架而言，中间件应该设计成什么样呢？接下来的实现，基本参考了 Gin 框架。</p><h3 id="中间件设计">中间件设计</h3><p>Gee 的中间件的定义与路由映射的 Handler 一致，处理的输入是<code>Context</code>对象。插入点是框架接收到请求初始化<code>Context</code>对象后，允许用户使用自己定义的中间件做一些额外的处理，例如记录日志等，以及对<code>Context</code>进行二次加工。另外通过调用<code>(*Context).Next()</code>函数，中间件可等待用户自己定义的 <code>Handler</code>处理结束后，再做一些额外的操作，例如计算本次处理所用时间等。即 Gee 的中间件支持用户在请求被处理的前后，做一些额外的操作。举个例子，我们希望最终能够支持如下定义的中间件，<code>c.Next()</code>表示等待执行其他的中间件或用户的<code>Handler</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Logger</span><span class="hljs-params">()</span> <span class="hljs-title">HandlerFunc</span></span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Context)</span></span> &#123;<br><span class="hljs-comment">// Start timer</span><br>t := time.Now()<br><span class="hljs-comment">// Process request</span><br>c.Next()<br><span class="hljs-comment">// Calculate resolution time</span><br>log.Printf(<span class="hljs-string">&quot;[%d] %s in %v&quot;</span>, c.StatusCode, c.Req.RequestURI, time.Since(t))<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>另外，支持设置多个中间件，依次进行调用。</p><p>我们在分组控制 Group Control中讲到，中间件是应用在<code>RouterGroup</code>上的，应用在最顶层的 Group，相当于作用于全局，所有的请求都会被中间件处理。那为什么不作用在每一条路由规则上呢？作用在某条路由规则，那还不如用户直接在 Handler 中调用直观。只作用在某条路由规则的功能通用性太差，不适合定义为中间件。</p><p>我们之前的框架设计是这样的，当接收到请求后，匹配路由，该请求的所有信息都保存在<code>Context</code>中。中间件也不例外，接收到请求后，应查找所有应作用于该路由的中间件，保存在<code>Context</code>中，依次进行调用。为什么依次调用后，还需要在<code>Context</code>中保存呢？因为在设计中，中间件不仅作用在处理流程前，也可以作用在处理流程后，即在用户定义的 Handler 处理完毕后，还可以执行剩下的操作。</p><p>为此，我们给<code>Context</code>添加了2个参数，定义了<code>Next</code>方法：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// origin objects</span><br>Writer http.ResponseWriter<br>Req    *http.Request<br><span class="hljs-comment">// request info</span><br>Path   <span class="hljs-keyword">string</span><br>Method <span class="hljs-keyword">string</span><br>Params <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">string</span><br><span class="hljs-comment">// response info</span><br>StatusCode <span class="hljs-keyword">int</span><br><span class="hljs-comment">// middleware</span><br>handlers []HandlerFunc<br>index    <span class="hljs-keyword">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newContext</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span> *<span class="hljs-title">Context</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;Context&#123;<br>Path:   req.URL.Path,<br>Method: req.Method,<br>Req:    req,<br>Writer: w,<br>index:  <span class="hljs-number">-1</span>,<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">Next</span><span class="hljs-params">()</span></span> &#123;<br>c.index++<br>s := <span class="hljs-built_in">len</span>(c.handlers)<br><span class="hljs-keyword">for</span> ; c.index &lt; s; c.index++ &#123;<br>c.handlers[c.index](c)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>index</code>是记录当前执行到第几个中间件，当在中间件中调用<code>Next</code>方法时，控制权交给了下一个中间件，直到调用到最后一个中间件，然后再从后往前，调用每个中间件在<code>Next</code>方法之后定义的部分。如果我们将用户在映射路由时定义的<code>Handler</code>添加到<code>c.handlers</code>列表中，结果会怎么样呢？想必你已经猜到了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">A</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>    part1<br>    c.Next()<br>    part2<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">B</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>    part3<br>    c.Next()<br>    part4<br>&#125;<br></code></pre></td></tr></table></figure><p>假设我们应用了中间件 A 和 B，和路由映射的 Handler。<code>c.handlers</code>是这样的[A, B, Handler]，<code>c.index</code>初始化为-1。调用<code>c.Next()</code>，接下来的流程是这样的：</p><ul><li>c.index++，c.index 变为 0</li><li>0 &lt; 3，调用 c.handlers[0]，即 A</li><li>执行 part1，调用 c.Next()</li><li>c.index++，c.index 变为 1</li><li>1 &lt; 3，调用 c.handlers[1]，即 B</li><li>执行 part3，调用 c.Next()</li><li>c.index++，c.index 变为 2</li><li>2 &lt; 3，调用 c.handlers[2]，即Handler</li><li>Handler 调用完毕，返回到 B 中的 part4，执行 part4</li><li>part4 执行完毕，返回到 A 中的 part2，执行 part2</li><li>part2 执行完毕，结束。</li></ul><p>一句话说清楚重点，最终的顺序是<code>part1 -&gt; part3 -&gt; Handler -&gt; part 4 -&gt; part2</code>。恰恰满足了我们对中间件的要求，接下来看调用部分的代码，就能全部串起来了。</p><h3 id="代码实现">代码实现</h3><ul><li>定义<code>Use</code>函数，将中间件应用到某个 Group 。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Use is defined to add middleware to the group</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">Use</span><span class="hljs-params">(middlewares ...HandlerFunc)</span></span> &#123;<br>group.middlewares = <span class="hljs-built_in">append</span>(group.middlewares, middlewares...)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">ServeHTTP</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;<br><span class="hljs-keyword">var</span> middlewares []HandlerFunc<br><span class="hljs-keyword">for</span> _, group := <span class="hljs-keyword">range</span> engine.groups &#123;<br><span class="hljs-keyword">if</span> strings.HasPrefix(req.URL.Path, group.prefix) &#123;<br>middlewares = <span class="hljs-built_in">append</span>(middlewares, group.middlewares...)<br>&#125;<br>&#125;<br>c := newContext(w, req)<br>c.handlers = middlewares<br>engine.router.handle(c)<br>&#125;<br></code></pre></td></tr></table></figure><p>ServeHTTP 函数也有变化，当我们接收到一个具体请求时，要判断该请求适用于哪些中间件，在这里我们简单通过 URL 的前缀来判断。得到中间件列表后，赋值给 <code>c.handlers</code>。</p><ul><li>handle 函数中，将从路由匹配得到的 Handler 添加到 <code>c.handlers</code>列表中，执行<code>c.Next()</code>。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(r *router)</span> <span class="hljs-title">handle</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>n, params := r.getRoute(c.Method, c.Path)<br><br><span class="hljs-keyword">if</span> n != <span class="hljs-literal">nil</span> &#123;<br>key := c.Method + <span class="hljs-string">&quot;-&quot;</span> + n.pattern<br>c.Params = params<br>c.handlers = <span class="hljs-built_in">append</span>(c.handlers, r.handlers[key])<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>c.handlers = <span class="hljs-built_in">append</span>(c.handlers, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>c.String(http.StatusNotFound, <span class="hljs-string">&quot;404 NOT FOUND: %s\n&quot;</span>, c.Path)<br>&#125;)<br>&#125;<br>c.Next()<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="6-模板">6. 模板</h2><h3 id="服务端渲染">服务端渲染</h3><p>现在越来越流行前后端分离的开发模式，即 Web 后端提供 RESTful 接口，返回结构化的数据(通常为 JSON 或者 XML)。前端使用 AJAX 技术请求到所需的数据，利用 JavaScript 进行渲染。Vue/React 等前端框架持续火热，这种开发模式前后端解耦，优势非常突出。后端童鞋专心解决资源利用，并发，数据库等问题，只需要考虑数据如何生成；前端童鞋专注于界面设计实现，只需要考虑拿到数据后如何渲染即可。使用 JSP 写过网站的童鞋，应该能感受到前后端耦合的痛苦。JSP 的表现力肯定是远不如 Vue/React 等专业做前端渲染的框架的。而且前后端分离在当前还有另外一个不可忽视的优势。因为后端只关注于数据，接口返回值是结构化的，与前端解耦。同一套后端服务能够同时支撑小程序、移动APP、PC端 Web 页面，以及对外提供的接口。随着前端工程化的不断地发展，Webpack，gulp 等工具层出不穷，前端技术越来越自成体系了。</p><p>但前后分离的一大问题在于，页面是在客户端渲染的，比如浏览器，这对于爬虫并不友好。Google 爬虫已经能够爬取渲染后的网页，但是短期内爬取服务端直接渲染的 HTML 页面仍是主流。</p><p>今天的内容便是介绍 Web 框架如何支持服务端渲染的场景。</p><h3 id="静态文件-Serve-Static-Files">静态文件(Serve Static Files)</h3><p>网页的三剑客，JavaScript、CSS 和 HTML。要做到服务端渲染，第一步便是要支持 JS、CSS 等静态文件。还记得我们之前设计动态路由的时候，支持通配符<code>*</code>匹配多级子路径。比如路由规则<code>/assets/*filepath</code>，可以匹配<code>/assets/</code>开头的所有的地址。例如<code>/assets/js/geektutu.js</code>，匹配后，参数<code>filepath</code>就赋值为<code>js/geektutu.js</code>。</p><p>那如果我么将所有的静态文件放在<code>/usr/web</code>目录下，那么<code>filepath</code>的值即是该目录下文件的相对地址。映射到真实的文件后，将文件返回，静态服务器就实现了。</p><p>找到文件后，如何返回这一步，<code>net/http</code>库已经实现了。因此，gee 框架要做的，仅仅是解析请求的地址，映射到服务器上文件的真实地址，交给<code>http.FileServer</code>处理就好了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// create static handler</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">createStaticHandler</span><span class="hljs-params">(relativePath <span class="hljs-keyword">string</span>, fs http.FileSystem)</span> <span class="hljs-title">HandlerFunc</span></span> &#123;<br>absolutePath := path.Join(group.prefix, relativePath)<br>fileServer := http.StripPrefix(absolutePath, http.FileServer(fs))<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Context)</span></span> &#123;<br>file := c.Param(<span class="hljs-string">&quot;filepath&quot;</span>)<br><span class="hljs-comment">// Check if file exists and/or if we have permission to access it</span><br><span class="hljs-keyword">if</span> _, err := fs.Open(file); err != <span class="hljs-literal">nil</span> &#123;<br>c.Status(http.StatusNotFound)<br><span class="hljs-keyword">return</span><br>&#125;<br><br>fileServer.ServeHTTP(c.Writer, c.Req)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// serve static files</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(group *RouterGroup)</span> <span class="hljs-title">Static</span><span class="hljs-params">(relativePath <span class="hljs-keyword">string</span>, root <span class="hljs-keyword">string</span>)</span></span> &#123;<br>handler := group.createStaticHandler(relativePath, http.Dir(root))<br>urlPattern := path.Join(relativePath, <span class="hljs-string">&quot;/*filepath&quot;</span>)<br><span class="hljs-comment">// Register GET handlers</span><br>group.GET(urlPattern, handler)<br>&#125;<br></code></pre></td></tr></table></figure><p>我们给<code>RouterGroup</code>添加了2个方法，<code>Static</code>这个方法是暴露给用户的。用户可以将磁盘上的某个文件夹<code>root</code>映射到路由<code>relativePath</code>。例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">z := zed.New()<br>z.Static(<span class="hljs-string">&quot;/assets&quot;</span>, <span class="hljs-string">&quot;/usr/geektutu/blog/static&quot;</span>)<br><span class="hljs-comment">// 或相对路径 z.Static(&quot;/assets&quot;, &quot;./static&quot;)</span><br>z.Run(<span class="hljs-string">&quot;:9999&quot;</span>)<br></code></pre></td></tr></table></figure><p>用户访问<code>localhost:9999/assets/js/zed.js</code>，最终返回<code>/usr/geektutu/blog/static/js/zed.js</code>。</p><h3 id="HTML-模板渲染">HTML 模板渲染</h3><p>Go语言内置了<code>text/template</code>和<code>html/template</code>2个模板标准库，其中html/template为 HTML 提供了较为完整的支持。包括普通变量渲染、列表渲染、对象渲染等。gee 框架的模板渲染直接使用了<code>html/template</code>提供的能力。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go">Engine <span class="hljs-keyword">struct</span> &#123;<br>*RouterGroup<br>router        *router<br>groups        []*RouterGroup     <span class="hljs-comment">// store all groups</span><br>htmlTemplates *template.Template <span class="hljs-comment">// for html render</span><br>funcMap       template.FuncMap   <span class="hljs-comment">// for html render</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">SetFuncMap</span><span class="hljs-params">(funcMap template.FuncMap)</span></span> &#123;<br>engine.funcMap = funcMap<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">LoadHTMLGlob</span><span class="hljs-params">(pattern <span class="hljs-keyword">string</span>)</span></span> &#123;<br>engine.htmlTemplates = template.Must(template.New(<span class="hljs-string">&quot;&quot;</span>).Funcs(engine.funcMap).ParseGlob(pattern))<br>&#125;<br></code></pre></td></tr></table></figure><p>首先为 Engine 示例添加了 <code>*template.Template</code> 和 <code>template.FuncMap</code>对象，前者将所有的模板加载进内存，后者是所有的自定义模板渲染函数。</p><p>另外，给用户分别提供了设置自定义渲染函数<code>funcMap</code>和加载模板的方法。</p><p>接下来，对原来的 <code>(*Context).HTML()</code>方法做了些小修改，使之支持根据模板文件名选择模板进行渲染。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-comment">// ...</span><br><span class="hljs-comment">// engine pointer</span><br>engine *Engine<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span> <span class="hljs-title">HTML</span><span class="hljs-params">(code <span class="hljs-keyword">int</span>, name <span class="hljs-keyword">string</span>, data <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br>c.SetHeader(<span class="hljs-string">&quot;Content-Type&quot;</span>, <span class="hljs-string">&quot;text/html&quot;</span>)<br>c.Status(code)<br><span class="hljs-keyword">if</span> err := c.engine.htmlTemplates.ExecuteTemplate(c.Writer, name, data); err != <span class="hljs-literal">nil</span> &#123;<br>c.Fail(<span class="hljs-number">500</span>, err.Error())<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们在 <code>Context</code> 中添加了成员变量 <code>engine *Engine</code>，这样就能够通过 Context 访问 Engine 中的 HTML 模板。实例化 Context 时，还需要给 <code>c.engine</code> 赋值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span> <span class="hljs-title">ServeHTTP</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;<br><span class="hljs-comment">// ...</span><br>c := newContext(w, req)<br>c.handlers = middlewares<br>c.engine = engine<br>engine.router.handle(c)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="7-错误恢复">7. 错误恢复</h2><h3 id="panic">panic</h3><p>Go 语言中，比较常见的错误处理方法是返回 error，由调用者决定后续如何处理。但是如果是无法恢复的错误，可以手动触发 panic，当然如果在程序运行过程中出现了类似于数组越界的错误，panic 也会被触发。panic 会中止当前执行的程序，退出。</p><p>下面是主动触发的例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// hello.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;before panic&quot;</span>)<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;crash&quot;</span>)<br>fmt.Println(<span class="hljs-string">&quot;after panic&quot;</span>)<br>&#125;<br>$ <span class="hljs-keyword">go</span> run hello.<span class="hljs-keyword">go</span><br><br>before <span class="hljs-built_in">panic</span><br><span class="hljs-built_in">panic</span>: crash<br><br>goroutine <span class="hljs-number">1</span> [running]:<br>main.main()<br>        ~/go_demo/hello/hello.<span class="hljs-keyword">go</span>:<span class="hljs-number">7</span> +<span class="hljs-number">0x95</span><br>exit status <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>下面是数组越界触发的 panic</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// hello.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>arr := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br>fmt.Println(arr[<span class="hljs-number">4</span>])<br>&#125;<br>$ <span class="hljs-keyword">go</span> run hello.<span class="hljs-keyword">go</span><br><span class="hljs-built_in">panic</span>: runtime error: index out of <span class="hljs-keyword">range</span> [<span class="hljs-number">4</span>] with length <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h3 id="defer">defer</h3><p>panic 会导致程序被中止，但是在退出前，会先处理完当前协程上已经defer 的任务，执行完成后再退出。效果类似于 java 语言的 <code>try...catch</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// hello.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;defer func&quot;</span>)<br>&#125;()<br><br>arr := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br>fmt.Println(arr[<span class="hljs-number">4</span>])<br>&#125;<br>$ <span class="hljs-keyword">go</span> run hello.<span class="hljs-keyword">go</span> <br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span></span><br><span class="hljs-built_in">panic</span>: runtime error: index out of <span class="hljs-keyword">range</span> [<span class="hljs-number">4</span>] with length <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>可以 defer 多个任务，在同一个函数中 defer 多个任务，会逆序执行。即先执行最后 defer 的任务。</p><p>在这里，defer 的任务执行完成之后，panic 还会继续被抛出，导致程序非正常结束。</p><h3 id="recover">recover</h3><p>Go 语言还提供了 recover 函数，可以避免因为 panic 发生而导致整个程序终止，recover 函数只在 defer 中生效。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// hello.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">test_recover</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;defer func&quot;</span>)<br><span class="hljs-keyword">if</span> err := <span class="hljs-built_in">recover</span>(); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;recover success&quot;</span>)<br>&#125;<br>&#125;()<br><br>arr := []<span class="hljs-keyword">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br>fmt.Println(arr[<span class="hljs-number">4</span>])<br>fmt.Println(<span class="hljs-string">&quot;after panic&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>test_recover()<br>fmt.Println(<span class="hljs-string">&quot;after recover&quot;</span>)<br>&#125;<br>$ <span class="hljs-keyword">go</span> run hello.<span class="hljs-keyword">go</span> <br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span></span><br><span class="hljs-built_in">recover</span> success<br>after <span class="hljs-built_in">recover</span><br></code></pre></td></tr></table></figure><p>我们可以看到，recover 捕获了 panic，程序正常结束。<em>test_recover()</em> 中的 <em>after panic</em> 没有打印，这是正确的，当 panic 被触发时，控制权就被交给了 defer 。就像在 java 中，<code>try</code>代码块中发生了异常，控制权交给了 <code>catch</code>，接下来执行 catch 代码块中的代码。而在 <em>main()</em> 中打印了 <em>after recover</em>，说明程序已经恢复正常，继续往下执行直到结束。</p><h3 id="zed-的错误处理机制">zed 的错误处理机制</h3><p>对一个 Web 框架而言，错误处理机制是非常必要的。可能是框架本身没有完备的测试，导致在某些情况下出现空指针异常等情况。也有可能用户不正确的参数，触发了某些异常，例如数组越界，空指针等。如果因为这些原因导致系统宕机，必然是不可接受的。</p><p>今天，我们将在 zed中添加一个非常简单的错误处理机制，即在此类错误发生时，向用户返回 <em>Internal Server Error</em>，并且在日志中打印必要的错误信息，方便进行错误定位。</p><p>我们之前实现了中间件机制，错误处理也可以作为一个中间件，增强 zed框架的能力，在zed中实现中间件 <code>Recovery</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Recovery</span><span class="hljs-params">()</span> <span class="hljs-title">HandlerFunc</span></span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Context)</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> err := <span class="hljs-built_in">recover</span>(); err != <span class="hljs-literal">nil</span> &#123;<br>message := fmt.Sprintf(<span class="hljs-string">&quot;%s&quot;</span>, err)<br>log.Printf(<span class="hljs-string">&quot;%s\n\n&quot;</span>, trace(message))<br>c.Fail(http.StatusInternalServerError, <span class="hljs-string">&quot;Internal Server Error&quot;</span>)<br>&#125;<br>&#125;()<br><br>c.Next()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Recovery</code> 的实现非常简单，使用 defer 挂载上错误恢复的函数，在这个函数中调用 <em>recover()</em>，捕获 panic，并且将堆栈信息打印在日志中，向用户返回 <em>Internal Server Error</em>。</p><p>你可能注意到，这里有一个 <em>trace()</em> 函数，这个函数是用来获取触发 panic 的堆栈信息，完整代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gee<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;log&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br><span class="hljs-string">&quot;runtime&quot;</span><br><span class="hljs-string">&quot;strings&quot;</span><br>)<br><br><span class="hljs-comment">// print stack trace for debug</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">trace</span><span class="hljs-params">(message <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">var</span> pcs [<span class="hljs-number">32</span>]<span class="hljs-keyword">uintptr</span><br>n := runtime.Callers(<span class="hljs-number">3</span>, pcs[:]) <span class="hljs-comment">// skip first 3 caller</span><br><br><span class="hljs-keyword">var</span> str strings.Builder<br>str.WriteString(message + <span class="hljs-string">&quot;\nTraceback:&quot;</span>)<br><span class="hljs-keyword">for</span> _, pc := <span class="hljs-keyword">range</span> pcs[:n] &#123;<br>fn := runtime.FuncForPC(pc)<br>file, line := fn.FileLine(pc)<br>str.WriteString(fmt.Sprintf(<span class="hljs-string">&quot;\n\t%s:%d&quot;</span>, file, line))<br>&#125;<br><span class="hljs-keyword">return</span> str.String()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Recovery</span><span class="hljs-params">()</span> <span class="hljs-title">HandlerFunc</span></span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Context)</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> err := <span class="hljs-built_in">recover</span>(); err != <span class="hljs-literal">nil</span> &#123;<br>message := fmt.Sprintf(<span class="hljs-string">&quot;%s&quot;</span>, err)<br>log.Printf(<span class="hljs-string">&quot;%s\n\n&quot;</span>, trace(message))<br>c.Fail(http.StatusInternalServerError, <span class="hljs-string">&quot;Internal Server Error&quot;</span>)<br>&#125;<br>&#125;()<br><br>c.Next()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 <em>trace()</em> 中，调用了 <code>runtime.Callers(3, pcs[:])</code>，Callers 用来返回调用栈的程序计数器, 第 0 个 Caller 是 Callers 本身，第 1 个是上一层 trace，第 2 个是再上一层的 <code>defer func</code>。因此，为了日志简洁一点，我们跳过了前 3 个 Caller。</p><p>接下来，通过 <code>runtime.FuncForPC(pc)</code> 获取对应的函数，在通过 <code>fn.FileLine(pc)</code> 获取到调用该函数的文件名和行号，打印在日志中。</p><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>ba26a3a9458192af5af8922514b11e1b18dc576b</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote>]]></content>
    
    
    <categories>
      
      <category>Zed系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Zed系列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>隔离</title>
    <link href="/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/5.%E9%9A%94%E7%A6%BB/"/>
    <url>/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/5.%E9%9A%94%E7%A6%BB/</url>
    
    <content type="html"><![CDATA[<h1>隔离</h1><p>隔离，本质上是对系统或者资源进行分割，从而实现当系统发生故障时能够限定传播范围和影响范围，即发生故障后只有出问题的服务不可用，保证其他服务仍然可用。</p><h2 id="1-服务隔离">1. 服务隔离</h2><h3 id="1-1-动静隔离">1.1 动静隔离</h3><p>小到CPU的cacheline，false sharing、数据库mysql表设计中避免bufferpool频繁过期，隔离动静表，大到架构设计中的图片、静态资源等缓存加速。本质上都体现的一样的思路，即加速、缓存访问变换频次小的。比如CDN场景中，将静态资源和动态API分离。</p><h3 id="1-2-服务隔离">1.2 服务隔离</h3><p>把少量更新的表和频繁更新的表分割开，MySQL BufferPool是用于缓存DataPage的，DataPage可以理解为缓存了表的行，那么如果频繁更新DataPage不断会置换，导致命中率下降。</p><h3 id="1-3-轻重隔离">1.3 轻重隔离</h3><p>核心隔离，业务按照level进行资源池划分（L0/L1/L2）</p><ul><li>核心和非核心的故障与的差异隔离</li><li>多集群，通过冗余资源来提升吞吐和容灾能力</li></ul><h3 id="1-4-快慢隔离">1.4 快慢隔离</h3><p>可以把服务的吞吐想象成一个池子，当洪峰进来时，池子需要一定时间才能排放完，这时候其他的支流在池子中的时间取决于前面的排放能力，就会变慢。</p><h3 id="1-5-物理隔离">1.5 物理隔离</h3><p>Java中，线程池可能被耗尽，但是go中goroutine是托管给runtime，而且线程不会阻塞，但是goroutine最终越来越多，最终oom掉。</p><p>主要通过线程池进行隔离，也是实现服务隔离的基础，把业务进行分类并交给不同的线程池处理，这样当某一个业务出现故障时，不会影响到其他故障。</p><h3 id="1-6-进程隔离">1.6 进程隔离</h3><p>每个容器只运行一个进程</p><h3 id="Case">Case:</h3><h4 id="转码集群被超大视频攻击，导致转码大量延迟">转码集群被超大视频攻击，导致转码大量延迟</h4><p>某用户制造了一个大视频，上传后处理时间变长，大量同类似视频上传后，转码器服务被堵住，导致小视频转码被阻塞。</p><p>按照大视频和小视频进行集群隔离，大视频走A集群，小视频走B集群，这样就不会互相干扰。</p><h4 id="缩略图服务，被大图实时缩略图吃完所有CPU，导致正常小图缩略图被丢弃，大量503">缩略图服务，被大图实时缩略图吃完所有CPU，导致正常小图缩略图被丢弃，大量503</h4><p>缩略gif图片时，耗时更长，导致其他图片缩略阻塞，思路也按照上一个case处理，把全局故障转换为局部故障</p><h4 id="数据库实例cgroup未隔离，导致大SQL引起的集体故障">数据库实例cgroup未隔离，导致大SQL引起的集体故障</h4><p>由于mysql没有上容器，部署了多个数据库端口到物理机上，有一个大SQL导致某一个MYSQL CPU突然飚高，导致所有的mysqld全部变慢</p><h4 id="INFO日志量变大，导致ERROR日志采集延迟">INFO日志量变大，导致ERROR日志采集延迟</h4><p>发版后，搜索Error看不到，原因是其他服务打印了一个超级大的request body，导致报错日志采集延迟，发版时未检索到，误以为发版正常，导致大量请求报错，这时候我们就需要把日志进行topic和文件的隔离，分别进行采集。</p>]]></content>
    
    
    <categories>
      
      <category>微服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>内存模型</title>
    <link href="/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/10.%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
    <url>/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/10.%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1>一、场景</h1><p>如何保证在一个goroutine中看到另一个goroutine修改的变量的值，如果程序中修改数据时，有其他goroutine同时读取，那么必须将读取串行化。</p><h2 id="Happen-Before">Happen-Before</h2><p>在一个goroutine中，读和写时按照一定顺序执行的，由于goroutine的重排，他的执行顺序可能是不确定的。</p><h2 id="Memory-Reordering">Memory Reordering</h2><p>为了提高读写效率，编译器会对读写指令进行重新排列，这就是所谓得内存重排，英文为MemoryReordering。</p><h1>二、内存分配原理</h1><h2 id="1-堆和栈的定义">1. 堆和栈的定义</h2><p>Go有两个地方分配内存：</p><ul><li>全局堆：用来动态分配内存。</li><li>goroutine栈：每个goroutine都有自身的栈空间。</li></ul><p>其中，栈的内存一般由编译器自动进行分配和释放，其中存储了函数的入参和局部变量，这些参数会随着函数的创建而创建，会随着函数的返回而销毁。</p><p>为什么会有堆这个概念呢？因为goroutine栈空间是隔离的，无法访问到别人的栈空间。</p><p>堆内存一般由编译器和工程师自己共同管理分配，交给runtime gc释放，堆上分配必须找到一个足够大的内存来分配变量数据，后续释放时，垃圾回收器扫描堆空间寻找不再被使用的对象。</p><p><strong>变量存在堆还是栈？</strong></p><p>变量存在堆还是栈跟语义无关，由编译器决定是在堆上还是在栈上。</p><h2 id="2-内存逃逸">2. 内存逃逸</h2><h3 id="什么是逃逸？"><strong>什么是逃逸？</strong></h3><p>变量的作用域超过了他所在的栈。</p><p>作用：减少GC压力，随着函数退出直接回收；减少内存碎片的产生；减轻分配堆内存的开销，提高运行速度。</p><h3 id="内存逃逸分析">内存逃逸分析</h3><p><code>Go</code>语言的逃逸分析总共实现了两个版本：</p><ul><li>1.13版本前是第一版</li><li>1.13版本后是第二版</li></ul><p>粗略看了一下逃逸分析的代码，大概有<code>1500+</code>行（go1.15.7）。代码我倒是没仔细看，注释我倒是仔细看了一遍，注释写的还是很详细的，代码路径：src/cmd/compile/internal/gc/escape.go，大家可以自己看一遍注释，其逃逸分析原理如下：</p><ul><li><code>pointers to stack objects cannot be stored in the heap</code>：指向栈对象的指针不能存储在堆中</li><li><code>pointers to a stack object cannot outlive that object</code>：指向栈对象的指针不能超过该对象的存活期，也就说指针不能在栈对象被销毁后依旧存活。（例子：声明的函数返回并销毁了对象的栈帧，或者它在循环迭代中被重复用于逻辑上不同的变量）</li></ul><p>我们大概知道它的分析准则是什么就好了，具体逃逸分析是怎么做的，感兴趣的同学可以根据源码自行研究。</p><p>既然逃逸分析是在编译阶段进行的，那我们就可以通过<code>go build -gcflags '-m -l'</code>命令查看到逃逸分析的结果，我们之前在分析内联优化时使用的<code>-gcflags '-m -m'</code>，能看到所有的编译器优化，这里使用<code>-l</code>禁用掉内联优化，只关注逃逸优化就好了。</p><p>现在我们也知道了逃逸分析，接下来我们就看几个逃逸分析的例子。</p><h3 id="分析方法">分析方法</h3><ol><li>压测</li><li>使用pprof确定是那一个方法内存消耗高，另外可以确定分配了几个内存出去</li><li>使用go build --gcflag -m -l 来确定是哪一个内存逃逸</li><li>如果有内存逃逸的现象，会提示escape to heap</li></ol><h3 id="2-1-函数返回局部指针变量">2.1  函数返回局部指针变量</h3><p>先看例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Add</span><span class="hljs-params">(x,y <span class="hljs-keyword">int</span>)</span> *<span class="hljs-title">int</span></span> &#123;<br>res := <span class="hljs-number">0</span><br>res = x + y<br><span class="hljs-keyword">return</span> &amp;res<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>  &#123;<br>Add(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>查看逃逸分析结果：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> build -gcflags=<span class="hljs-string">&quot;-m -l&quot;</span> ./test1.<span class="hljs-keyword">go</span><br># command-line-arguments<br>./test1.<span class="hljs-keyword">go</span>:<span class="hljs-number">6</span>:<span class="hljs-number">9</span>: &amp;res escapes to heap<br>./test1.<span class="hljs-keyword">go</span>:<span class="hljs-number">6</span>:<span class="hljs-number">9</span>:         from ~r2 (<span class="hljs-keyword">return</span>) at ./test1.<span class="hljs-keyword">go</span>:<span class="hljs-number">6</span>:<span class="hljs-number">2</span><br>./test1.<span class="hljs-keyword">go</span>:<span class="hljs-number">4</span>:<span class="hljs-number">2</span>: moved to heap: res<br>复制代码<br></code></pre></td></tr></table></figure><p>分析结果很明了，函数返回的局部变量是一个指针变量，当函数<code>Add</code>执行结束后，对应的栈桢就会被销毁，但是引用已经返回到函数之外，如果我们在外部解引用地址，就会导致程序访问非法内存，就像上面的<code>C</code>语言的例子一样，所以编译器经过逃逸分析后将其在堆上分配内存。</p><h3 id="2-2-interface类型逃逸">2.2  interface类型逃逸</h3><p>先看一个例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>  &#123;<br>str := <span class="hljs-string">&quot;asong太帅了吧&quot;</span><br>fmt.Printf(<span class="hljs-string">&quot;%v&quot;</span>,str)<br>&#125;<br></code></pre></td></tr></table></figure><p>查看逃逸分析结果：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> build -gcflags=<span class="hljs-string">&quot;-m -m -l&quot;</span> ./test2.<span class="hljs-keyword">go</span> <br># command-line-arguments<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span>: str escapes to heap<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span>:        from ... argument (arg to ...) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span>:        from *(... argument) (indirection) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span>:        from ... argument (passed to call[argument content escapes]) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">13</span>: main ... argument does not escape<br></code></pre></td></tr></table></figure><p><code>str</code>是<code>main</code>函数中的一个局部变量，传递给<code>fmt.Println()</code>函数后发生了逃逸，这是因为<code>fmt.Println()</code>函数的入参是一个<code>interface&#123;&#125;</code>类型，如果函数参数为<code>interface&#123;&#125;</code>，那么在编译期间就很难确定其参数的具体类型，也会发送逃逸。</p><p>观察这个分析结果，我们可以看到没有<code>moved to heap: str</code>，这也就是说明<code>str</code>变量并没有在堆上进行分配，只是它存储的值逃逸到堆上了，也就说任何被<code>str</code>引用的对象必须分配在堆上。如果我们把代码改成这样：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>  &#123;<br>str := <span class="hljs-string">&quot;asong太帅了吧&quot;</span><br>fmt.Printf(<span class="hljs-string">&quot;%p&quot;</span>,&amp;str)<br>&#125;<br></code></pre></td></tr></table></figure><p>查看逃逸分析结果：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> build -gcflags=<span class="hljs-string">&quot;-m -m -l&quot;</span> ./test2.<span class="hljs-keyword">go</span><br># command-line-arguments<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>: &amp;str escapes to heap<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from ... argument (arg to ...) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from *(... argument) (indirection) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from ... argument (passed to call[argument content escapes]) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>: &amp;str escapes to heap<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from &amp;str (<span class="hljs-keyword">interface</span>-converted) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from ... argument (arg to ...) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from *(... argument) (indirection) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">18</span>:        from ... argument (passed to call[argument content escapes]) at ./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span><br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">8</span>:<span class="hljs-number">2</span>: moved to heap: str<br>./test2.<span class="hljs-keyword">go</span>:<span class="hljs-number">9</span>:<span class="hljs-number">12</span>: main ... argument does not escape<br></code></pre></td></tr></table></figure><p>这回<code>str</code>也逃逸到了堆上，在堆上进行内存分配，这是因为我们访问<code>str</code>的地址，因为入参是<code>interface</code>类型，所以变量<code>str</code>的地址以实参的形式传入<code>fmt.Printf</code>后被装箱到一个<code>interface&#123;&#125;</code>形参变量中，装箱的形参变量的值要在堆上分配，但是还要存储一个栈上的地址，也就是<code>str</code>的地址，堆上的对象不能存储一个栈上的地址，所以<code>str</code>也逃逸到堆上，在堆上分配内存。（<strong>这里注意一个知识点：Go语言的参数传递只有值传递</strong>）。</p><h1>三、内存管理</h1><p>TCMalloc 是 Thread Cache Malloc 的简称，是Go 内存管理的起源，Go的内存管理是借鉴了TCMalloc：</p><p>内存碎片：随着内存不断的申请和释放，内存上会存在大量的碎片，降低内存的使用率。为了解决内存碎片，可以将2个连续的未使用的内存块合并，减少碎片。</p><p>大锁：同一进程下的所有线程共享相同的内存空间，它们申请内存时需要加锁，如果不加锁就存在同一块内存被2个线程同时访问的问题。</p><h2 id="主要概念">主要概念</h2><p>page: 内存页, 一块 8K 大小的内存空间. Go 与 OS之间的内存申请和释放都是以page 为单位的。</p><p>span: 内存块, 一个或多个连续的 page 组成一个span. 如果把 page 比喻成工人, span可以看成是小队, 工人被分成若干个队伍, 不同队伍干不同的(sizeclass)活。</p><p>sizeclass: 空间规格, 每个 span 都带有一个 sizeclass , 标记着该 span 中的 page 应该如何使用. 标志着 span 是一个什么样的队伍。</p><p>object: 对象, 用来存储一个变量数据内存空间, 一个 span 在初始化时,会被切割成一堆等大的object. 假设 object 的大小是 16B, span 大小是 8K, 那么就会把span中的 page 就会被初始化 8K / 16B = 512 个 object . 所谓内存分配, 就是分配一个 object 出去。</p><h2 id="主要分区">主要分区</h2><p><strong>mcache</strong>：</p><p>当程序里发生了 32kb 以下的小块内存申请时，Go 会从一个叫做的 <em>mcache</em> 的本地缓存给程序分配内存。这样的一个内存块里叫做 <em>mspan</em>，它是要给程序分配内存时的分配单元。</p><p>在 Go 的调度器模型里，每个线程 M 会绑定给一个处理器 P，在单一粒度的时间里只能做多处理运行一个 goroutine，每个 P 都会绑定一个上面说的本地缓存 mcache。当需要进行内存分配时，当前运行的 goroutine 会从 mcache 中查找可用的 mspan。从本地 mcache 里分配内存时不需要加锁，这种分配策略效率更高。</p><p><strong>mcentral</strong>：</p><p>程序申请内存的时候，mcache 里已经没有合适的空闲 mspan了，那么工作线程就会像下图这样去 <em>mcentral</em> 里去申请。mcache 从 <em>mcentral</em> 获取和归还 mspan 的流程：</p><p>• <em>获取加锁；从 nonempty 链表找到一个可用的mspan；并将其从 nonempty 链表删除；将取出的 mspan 加入到 empty 链表；将 mspan 返回给工作线程；解锁。</em></p><p>•<em>归还加锁；将 mspan 从 empty 链表删除；将mspan 加入到 nonempty 链表；解锁。</em></p><p><em>mcentral</em> <em>是</em> <em>sizeclass</em> <em>相同的</em> <em>span</em> <em>会以链表的形式组织在一起</em>*,* <em>就是指该</em> <em>span</em> <em>用来存储哪种大小的对象</em>*。*</p><p><strong>mheap</strong>：</p><p>当 mcentral 没有空闲的 mspan 时，会向 <em>mheap</em> 申请。而 <em>mheap</em> 没有资源时，会向操作系统申请新内存。<em>mheap</em> 主要用于大对象的内存分配，以及管理未切割的 mspan，用于给 mcentral 切割成小对象。</p><p><em>mheap 中含有所有规格的 mcentral，所以当一个 mcache 从 mcentral 申请 mspan 时，只需要在独立的 mcentral 中使用锁，并不会影响申请其他规格的 mspan。</em></p><h2 id="内存分配">内存分配</h2><p>所有 mcentral 的集合则是存放于 <em>mheap</em> 中的。 <em>mheap</em> 里的 <em>arena</em> 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象。运行时使用二维的 <em>runtime.heapArena</em> 数组管理所有的内存，每个 <em>runtime.heapArena</em> 都会管理 64MB 的内存。</p><p>*如果 arena 区域没有足够的空间，会调用 runtime.mheap.sysAlloc 从操作系统中申请更多的内存。（如下图：*<em>Go 1.11</em> <em>前的内存布局）</em></p><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5Cimage-20230322165035180.png" alt="image-20230322165035180"></p><h2 id="根据大小分配">根据大小分配</h2><p><strong>小于32kb内存分配</strong></p><p>在mcache中选定指定大小的span进行分配</p><p><strong>小于16b</strong></p><p>对于小于16字节的对象(且无指针)，Go 语言将其划分为了<em>tiny</em> 对象。划分 <em>tiny</em> 对象的主要目的是为了处理极小的字符串和独立的转义变量。对 json 的基准测试表明，使用 <em>tiny</em> 对象减少了12%的分配次数和20%的堆大小。tiny 对象会被放入class 为2的 span 中。</p><p>•首先查看之前分配的元素中是否有空余的空间</p><p>•如果当前要分配的大小不够，例如要分配16字节的大小，这时就需要找到下一个空闲的元素</p><p>tiny 分配的第一步是尝试利用分配过的前一个元素的空间，达到节约内存的目的。</p><p><strong>大于32K</strong></p><p>对于小于16字节的对象(且无指针)，Go 语言将其划分为了<em>tiny</em> 对象。划分 <em>tiny</em> 对象的主要目的是为了处理极小的字符串和独立的转义变量。对 json 的基准测试表明，使用 <em>tiny</em> 对象减少了12%的分配次数和20%的堆大小。tiny 对象会被放入class 为2的 span 中。</p><p>•首先查看之前分配的元素中是否有空余的空间</p><p>•如果当前要分配的大小不够，例如要分配16字节的大小，这时就需要找到下一个空闲的元素</p><p>tiny 分配的第一步是尝试利用分配过的前一个元素的空间，达到节约内存的目的。</p><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5Cimage-20230322165521965.png" alt="image-20230322165521965"></p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并行编程</title>
    <link href="/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/09.%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B/"/>
    <url>/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/09.%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1>并行设计原则</h1><h2 id="Keep-yourself-busy-or-do-the-work-yourself">Keep yourself busy or do the work yourself</h2><p>如果依赖于协程的结果返回，不如直接由自己操作</p><h2 id="Leave-concurrency-to-the-caller">Leave concurrency to the caller</h2><p>让并行让调用者去控制</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ListDirectory</span><span class="hljs-params">(dir <span class="hljs-keyword">string</span>)</span><span class="hljs-params">([]<span class="hljs-keyword">string</span>, error)</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ListDirectory</span><span class="hljs-params">(dir <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">chan</span> <span class="hljs-title">string</span></span><br></code></pre></td></tr></table></figure><p>第一种方式是同步调用，会导致阻塞，如果目录很大，可能会导致读取时间很长，并且分配一个很大的空间。</p><p>第二种方式返回chan string，将通过该chan传递目录。当通道关闭时，这表示不在读取目录。由于在ListDirectory返回后发生通道的填充，ListDirectory可能内部启动goroutine填充通道。但是也有两个问题</p><ol><li><p>无法区分空目录和错误</p></li><li><p>调用者必须从中读取数据，即使它可能已经有了想要的答案<br>解决方案</p></li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ListDirectory</span><span class="hljs-params">(dir <span class="hljs-keyword">string</span>, fn <span class="hljs-keyword">func</span>(<span class="hljs-keyword">string</span>)</span>)</span><br></code></pre></td></tr></table></figure><p>防止goroutine的泄漏，将异步执行函数的决定权交给该函数的调用方。</p><h2 id="Never-start-a-goroutine-without-knowing-when-it-will-stop">Never start a goroutine without knowing when it will stop</h2><p>协程泄漏案例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">search</span><span class="hljs-params">(term <span class="hljs-keyword">string</span>)</span> <span class="hljs-params">(<span class="hljs-keyword">string</span>, error)</span></span> &#123;<br>time.Sleep(<span class="hljs-number">200</span> * time.Millisecond)<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;some value&quot;</span>, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">process</span><span class="hljs-params">(term <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">error</span></span> &#123;<br><span class="hljs-keyword">var</span> ctx context.Context<br><span class="hljs-keyword">var</span> ch = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> result)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>record, err := search(term)<br>ch &lt;- result&#123;record, err&#125;<br>&#125;()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br><span class="hljs-keyword">return</span> errors.New(<span class="hljs-string">&quot;canceled&quot;</span>)<br><span class="hljs-keyword">case</span> result := &lt;-ch:<br><span class="hljs-keyword">if</span> result.err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> result.err<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>当ctx.Done()先执行后，如果ch不是buffer channel，没有任何人获取到ch上的内容，这样会导致协程的阻塞。</p><p>开启一个协程后，必须要思考：</p><ol><li>他什么时候会结束</li><li>有没有办法结束它</li></ol><p>要保证创建的goroutine的声明周期，写的人停止channel</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>error</title>
    <link href="/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/07.error/"/>
    <url>/2023/03/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/07.error/</url>
    
    <content type="html"><![CDATA[<h1>基础构造</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// The error built-in interface type is the conventional interface for representing an error condition, with the nil value representing no error.</span><br><span class="hljs-keyword">type</span> error <span class="hljs-keyword">interface</span> &#123;<br>Error() <span class="hljs-keyword">string</span><br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// New returns an error that formats as the given text. Each call to New returns a distinct error value even if the text is identical.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">(text <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">error</span></span> &#123;<br><span class="hljs-keyword">return</span> &amp;errorString&#123;text&#125;<br>&#125;<br><br><span class="hljs-comment">// errorString is a trivial implementation of error.</span><br><span class="hljs-keyword">type</span> errorString <span class="hljs-keyword">struct</span> &#123;<br>s <span class="hljs-keyword">string</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e *errorString)</span> <span class="hljs-title">Error</span><span class="hljs-params">()</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">return</span> e.s<br>&#125;<br></code></pre></td></tr></table></figure><p>规范：errors.New(&quot;packageName： error info &quot;)</p><p>errors.New()返回的是一个地址，因为如果直接返回结构体，如果两个error的内容相同，可能==会是ture</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>net/http</title>
    <link href="/2023/03/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/05.nethttp/"/>
    <url>/2023/03/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/05.nethttp/</url>
    
    <content type="html"><![CDATA[<h1>1. http</h1><ol><li><p>request读取body的时候，只能读一次，如果需要读两次，需要进行一次copy，将原始数据copy到一个新的变量。</p></li><li><p>GetBody()原则上是可以多次读取，但是在原生的http.Request里面，这是个nil。</p></li><li><p>r.URL.Query()能获取url中携带的参数</p></li><li><p>header需要注意go会自动把key首字符改成大写</p></li><li><p>ParseForm()后的值，存在r.Form里面</p></li></ol><h1>2.http server</h1><h2 id="1-优雅退出">1. 优雅退出</h2><ol start="0"><li>摘掉流量</li><li>拒绝新的请求</li><li>等待当前的请求处理完毕</li><li>释放资源</li><li>关闭服务器</li><li>如果这中间超时，我们要强制关闭（再次受到关闭请求，强制退出）</li></ol><h2 id="2-监听系统信号">2.监听系统信号</h2><p>使用select channel监听</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>context</title>
    <link href="/2023/03/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/04.context/"/>
    <url>/2023/03/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/04.context/</url>
    
    <content type="html"><![CDATA[<h1>一、应用场景</h1><p>在 Go http 包的 Server 中，每一个请求在都有一个对应的<code>goroutine</code>去处理。请求处理函数通常会启动额外的<code>goroutine</code>用来访问后端服务，比如数据库和 RPC 服务。用来处理一个请求的<code>goroutine</code>通常需要访问一些与请求特定的数据，比如终端用户的身份认证信息、验证相关的 token、请求的截止时间。当一个请求被取消或超时时，所有用来处理该请求的<code>goroutine</code>都应该迅速退出，然后系统才能释放这些<code>goroutine</code>占用的资源。</p><h1>二、Context 原理</h1><p>Context的调用是链式的，通过<code>WithCancel</code>，<code>WithDeadline</code>，<code>WithTimeout</code>或<code>WithValue</code>派生出新的 Context。当父 Context 被取消时，其派生的所有 Context 都将取消。</p><p>通过<code>context.WithXXX</code>都将返回新的 Context 和 CancelFunc。调用 CancelFunc 将取消子代，移除父代对子代的引用，并且停止所有定时器。未能调用 CancelFunc 将泄漏子代，直到父代被取消或定时器触发。<code>go vet</code>工具检查所有流程控制路径上使用 CancelFuncs。</p><h1>三、遵循规则</h1><p>遵循以下规则，以保持包之间的接口一致，并启用静态分析工具以检查上下文传播。</p><ol><li>不要将 Contexts 放入结构体，相反<code>context</code>应该作为第一个参数传入，命名为<code>ctx</code>。 <code>func DoSomething（ctx context.Context，arg Arg）error &#123; // ... use ctx ... &#125;</code></li><li>即使函数允许，也不要传入<code>nil</code>的 Context。如果不知道用哪种 Context，可以使用<code>context.TODO()</code>。</li><li>使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数</li><li>相同的 Context 可以传递给在不同的<code>goroutine</code>；Context 是并发安全的。</li></ol><h1>四、Context 包</h1><h2 id="4-1-Context-结构体">4.1 Context 结构体</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A Context carries a deadline, cancelation signal, and request-scoped values</span><br><span class="hljs-comment">// across API boundaries. Its methods are safe for simultaneous use by multiple</span><br><span class="hljs-comment">// goroutines.</span><br><span class="hljs-keyword">type</span> Context <span class="hljs-keyword">interface</span> &#123;<br>    <span class="hljs-comment">// Done returns a channel that is closed when this Context is canceled</span><br>    <span class="hljs-comment">// or times out.</span><br>    Done() &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br><br>    <span class="hljs-comment">// Err indicates why this context was canceled, after the Done channel</span><br>    <span class="hljs-comment">// is closed.</span><br>    Err() error<br><br>    <span class="hljs-comment">// Deadline returns the time when this Context will be canceled, if any.</span><br>    Deadline() (deadline time.Time, ok <span class="hljs-keyword">bool</span>)<br><br>    <span class="hljs-comment">// Value returns the value associated with key or nil if none.</span><br>    Value(key <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-keyword">interface</span>&#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="4-2-所有方法">4.2 所有方法</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Background</span><span class="hljs-params">()</span> <span class="hljs-title">Context</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TODO</span><span class="hljs-params">()</span> <span class="hljs-title">Context</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithCancel</span><span class="hljs-params">(parent Context)</span> <span class="hljs-params">(ctx Context, cancel CancelFunc)</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithDeadline</span><span class="hljs-params">(parent Context, deadline time.Time)</span> <span class="hljs-params">(Context, CancelFunc)</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithTimeout</span><span class="hljs-params">(parent Context, timeout time.Duration)</span> <span class="hljs-params">(Context, CancelFunc)</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithValue</span><span class="hljs-params">(parent Context, key, val <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">Context</span></span><br></code></pre></td></tr></table></figure><p>上面可以看到Context是一个接口，想要使用就得实现其方法。在context包内部已经为我们实现好了两个空的Context，可以通过调用Background()和TODO()方法获取。一般的将它们作为Context的根，往下派生。</p><h3 id="4-2-1-WithCancel">4.2.1 WithCancel</h3><p>WithCancel 以一个新的 Done channel 返回一个父 Context 的拷贝。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithCancel</span><span class="hljs-params">(parent Context)</span> <span class="hljs-params">(ctx Context, cancel CancelFunc)</span></span> &#123;<br>    c := newCancelCtx(parent)<br>    propagateCancel(parent, &amp;c)<br>    <span class="hljs-keyword">return</span> &amp;c, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123; c.cancel(<span class="hljs-literal">true</span>, Canceled) &#125;<br>&#125;<br><br><span class="hljs-comment">// newCancelCtx returns an initialized cancelCtx.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newCancelCtx</span><span class="hljs-params">(parent Context)</span> <span class="hljs-title">cancelCtx</span></span> &#123;<br>    <span class="hljs-keyword">return</span> cancelCtx&#123;<br>        Context: parent,<br>        done:    <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;),<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>此示例演示使用一个可取消的上下文，以防止 goroutine 泄漏。示例函数结束时，defer 调用 cancel 方法，gen goroutine 将返回而不泄漏。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;fmt&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// gen generates integers in a separate goroutine and</span><br>    <span class="hljs-comment">// sends them to the returned channel.</span><br>    <span class="hljs-comment">// The callers of gen need to cancel the context once</span><br>    <span class="hljs-comment">// they are done consuming generated integers not to leak</span><br>    <span class="hljs-comment">// the internal goroutine started by gen.</span><br>    gen := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span> &lt;-<span class="hljs-title">chan</span> <span class="hljs-title">int</span></span> &#123;<br>        dst := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">int</span>)<br>        n := <span class="hljs-number">1</span><br>        <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>            <span class="hljs-keyword">for</span> &#123;<br>                <span class="hljs-keyword">select</span> &#123;<br>                <span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>                    <span class="hljs-keyword">return</span> <span class="hljs-comment">// returning not to leak the goroutine</span><br>                <span class="hljs-keyword">case</span> dst &lt;- n:<br>                    n++<br>                &#125;<br>            &#125;<br>        &#125;()<br>        <span class="hljs-keyword">return</span> dst<br>    &#125;<br><br>    ctx, cancel := context.WithCancel(context.Background())<br>    <span class="hljs-keyword">defer</span> cancel() <span class="hljs-comment">// cancel when we are finished consuming integers</span><br><br>    <span class="hljs-keyword">for</span> n := <span class="hljs-keyword">range</span> gen(ctx) &#123;<br>        fmt.Println(n)<br>        <span class="hljs-keyword">if</span> n == <span class="hljs-number">5</span> &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-2-WithDeadline">4.2.2 WithDeadline</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithDeadline</span><span class="hljs-params">(parent Context, deadline time.Time)</span> <span class="hljs-params">(Context, CancelFunc)</span></span> &#123;<br>    <span class="hljs-keyword">if</span> cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(deadline) &#123;<br>        <span class="hljs-comment">// The current deadline is already sooner than the new one.</span><br>        <span class="hljs-keyword">return</span> WithCancel(parent)<br>    &#125;<br>    c := &amp;timerCtx&#123;<br>        cancelCtx: newCancelCtx(parent),<br>        deadline:  deadline,<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>可以清晰的看到，当派生出的子 Context 的deadline在父Context之后，直接返回了一个父Context的拷贝。故语义上等效为父。</p><p>WithDeadline 的最后期限调整为不晚于 d 返回父上下文的副本。如果父母的截止日期已经早于 d，WithDeadline （父，d） 是在语义上等效为父。返回的上下文完成的通道关闭的最后期限期满后，返回的取消函数调用时，或当父上下文完成的通道关闭，以先发生者为准。</p><p>看看官方例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;time&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    d := time.Now().Add(<span class="hljs-number">50</span> * time.Millisecond)<br>    ctx, cancel := context.WithDeadline(context.Background(), d)<br><br>    <span class="hljs-comment">// Even though ctx will be expired, it is good practice to call its</span><br>    <span class="hljs-comment">// cancelation function in any case. Failure to do so may keep the</span><br>    <span class="hljs-comment">// context and its parent alive longer than necessary.</span><br>    <span class="hljs-keyword">defer</span> cancel()<br><br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> &lt;-time.After(<span class="hljs-number">1</span> * time.Second):<br>        fmt.Println(<span class="hljs-string">&quot;overslept&quot;</span>)<br>    <span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>        fmt.Println(ctx.Err())<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-3-WithTimeout">4.2.3 WithTimeout</h3><p>WithTimeout 返回 WithDeadline(parent, time.Now().Add(timeout))。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithTimeout</span><span class="hljs-params">(parent Context, timeout time.Duration)</span> <span class="hljs-params">(Context, CancelFunc)</span></span> &#123;<br>    <span class="hljs-keyword">return</span> WithDeadline(parent, time.Now().Add(timeout))<br>&#125;<br></code></pre></td></tr></table></figure><p>看看官方例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;time&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// Pass a context with a timeout to tell a blocking function that it</span><br>    <span class="hljs-comment">// should abandon its work after the timeout elapses.</span><br>    ctx, cancel := context.WithTimeout(context.Background(), <span class="hljs-number">50</span>*time.Millisecond)<br>    <span class="hljs-keyword">defer</span> cancel()<br><br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> &lt;-time.After(<span class="hljs-number">1</span> * time.Second):<br>        fmt.Println(<span class="hljs-string">&quot;overslept&quot;</span>)<br>    <span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>        fmt.Println(ctx.Err()) <span class="hljs-comment">// prints &quot;context deadline exceeded&quot;</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-4-WithValue">4.2.4 WithValue</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithValue</span><span class="hljs-params">(parent Context, key, val <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">Context</span></span> &#123;<br>    <span class="hljs-keyword">if</span> key == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;nil key&quot;</span>)<br>    &#125;<br>    <span class="hljs-keyword">if</span> !reflect.TypeOf(key).Comparable() &#123;<br>        <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;key is not comparable&quot;</span>)<br>    &#125;<br>    <span class="hljs-keyword">return</span> &amp;valueCtx&#123;parent, key, val&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>WithValue 返回的父与键关联的值在 val 的副本。</p><p>使用上下文值仅为过渡进程和 Api 的请求范围的数据，而不是将可选参数传递给函数。</p><p>提供的键必须是可比性和应该不是字符串类型或任何其他内置的类型以避免包使用的上下文之间的碰撞。WithValue 用户应该定义自己的键的类型。为了避免分配分配给接口 {} 时，上下文键经常有具体类型结构 {}。另外，导出的上下文关键变量静态类型应该是一个指针或接口。</p><p>每次都是返回一个新的context，最后构成一个链式结构，因为context是并发安全的，如果不这样做，上层context可能会开个新的goroutine，导致原有的context被污染，不适合大量被调用。</p><p>看看官方例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;fmt&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-keyword">type</span> favContextKey <span class="hljs-keyword">string</span><br><br>    f := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context, k favContextKey)</span></span> &#123;<br>        <span class="hljs-keyword">if</span> v := ctx.Value(k); v != <span class="hljs-literal">nil</span> &#123;<br>            fmt.Println(<span class="hljs-string">&quot;found value:&quot;</span>, v)<br>            <span class="hljs-keyword">return</span><br>        &#125;<br>        fmt.Println(<span class="hljs-string">&quot;key not found:&quot;</span>, k)<br>    &#125;<br><br>    k := favContextKey(<span class="hljs-string">&quot;language&quot;</span>)<br>    ctx := context.WithValue(context.Background(), k, <span class="hljs-string">&quot;Go&quot;</span>)<br><br>    f(ctx, k)<br>    f(ctx, favContextKey(<span class="hljs-string">&quot;color&quot;</span>))<br>&#125;<br></code></pre></td></tr></table></figure><h1>五、使用场景</h1><h2 id="5-1-RPC调用">5.1 RPC调用</h2><p>在主goroutine上有4个RPC，RPC2/3/4是并行请求的，我们这里希望在RPC2请求失败之后，直接返回错误，并且让RPC3/4停止继续计算。这个时候，就使用的到Context。</p><p>这个的具体实现如下面的代码。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;context&quot;</span><br><span class="hljs-string">&quot;sync&quot;</span><br><span class="hljs-string">&quot;github.com/pkg/errors&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Rpc</span><span class="hljs-params">(ctx context.Context, url <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">error</span></span> &#123;<br>result := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">int</span>)<br>err := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> error)<br><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-comment">// 进行RPC调用，并且返回是否成功，成功通过result传递成功信息，错误通过error传递错误信息</span><br>isSuccess := <span class="hljs-literal">true</span><br><span class="hljs-keyword">if</span> isSuccess &#123;<br>result &lt;- <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>err &lt;- errors.New(<span class="hljs-string">&quot;some error happen&quot;</span>)<br>&#125;<br>&#125;()<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;- ctx.Done():<br><span class="hljs-comment">// 其他RPC调用调用失败</span><br><span class="hljs-keyword">return</span> ctx.Err()<br><span class="hljs-keyword">case</span> e := &lt;- err:<br><span class="hljs-comment">// 本RPC调用失败，返回错误信息</span><br><span class="hljs-keyword">return</span> e<br><span class="hljs-keyword">case</span> &lt;- result:<br><span class="hljs-comment">// 本RPC调用成功，不返回错误信息</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>ctx, cancel := context.WithCancel(context.Background())<br><br><span class="hljs-comment">// RPC1调用</span><br>err := Rpc(ctx, <span class="hljs-string">&quot;http://rpc_1_url&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>wg := sync.WaitGroup&#123;&#125;<br><br><span class="hljs-comment">// RPC2调用</span><br>wg.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-keyword">defer</span> wg.Done()<br>err := Rpc(ctx, <span class="hljs-string">&quot;http://rpc_2_url&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>cancel()<br>&#125;<br>&#125;()<br><br><span class="hljs-comment">// RPC3调用</span><br>wg.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-keyword">defer</span> wg.Done()<br>err := Rpc(ctx, <span class="hljs-string">&quot;http://rpc_3_url&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>cancel()<br>&#125;<br>&#125;()<br><br><span class="hljs-comment">// RPC4调用</span><br>wg.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-keyword">defer</span> wg.Done()<br>err := Rpc(ctx, <span class="hljs-string">&quot;http://rpc_4_url&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>cancel()<br>&#125;<br>&#125;()<br><br>wg.Wait()<br>&#125;<br></code></pre></td></tr></table></figure><p>当然我这里使用了waitGroup来保证main函数在所有RPC调用完成之后才退出。</p><p>在Rpc函数中，第一个参数是一个CancelContext, 这个Context形象的说，就是一个传话筒，在创建CancelContext的时候，返回了一个听声器（ctx）和话筒（cancel函数）。所有的goroutine都拿着这个听声器（ctx），当主goroutine想要告诉所有goroutine要结束的时候，通过cancel函数把结束的信息告诉给所有的goroutine。当然所有的goroutine都需要内置处理这个听声器结束信号的逻辑（ctx-&gt;Done()）。我们可以看Rpc函数内部，通过一个select来判断ctx的done和当前的rpc调用哪个先结束。</p><p>这个waitGroup和其中一个RPC调用就通知所有RPC的逻辑，其实有一个包已经帮我们做好了。<a href="https://godoc.org/golang.org/x/sync/errgroup">errorGroup</a>。具体这个errorGroup包的使用可以看这个包的test例子。</p><p>有人可能会担心我们这里的cancel()会被多次调用，context包的cancel调用是幂等的。可以放心多次调用。</p><p>我们这里不妨品一下，这里的Rpc函数，实际上我们的这个例子里面是一个“阻塞式”的请求，这个请求如果是使用http.Get或者http.Post来实现，实际上Rpc函数的Goroutine结束了，内部的那个实际的http.Get却没有结束。所以，需要理解下，这里的函数最好是“非阻塞”的，<a href="http://xn--http-f96g426d76i.Do">比如是http.Do</a>，然后可以通过某种方式进行中断。比如像这篇文章<a href="https://medium.com/@ferencfbin/golang-cancel-http-request-using-context-1f45aeba6464">Cancel http.Request using Context</a>中的这个例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">httpRequest</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">  ctx context.Context,</span></span><br><span class="hljs-params"><span class="hljs-function">  client *http.Client,</span></span><br><span class="hljs-params"><span class="hljs-function">  req *http.Request,</span></span><br><span class="hljs-params"><span class="hljs-function">  respChan <span class="hljs-keyword">chan</span> []<span class="hljs-keyword">byte</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">  errChan <span class="hljs-keyword">chan</span> error</span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span> &#123;<br>  req = req.WithContext(ctx)<br>  tr := &amp;http.Transport&#123;&#125;<br>  client.Transport = tr<br>  <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>    resp, err := client.Do(req)<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      errChan &lt;- err<br>    &#125;<br>    <span class="hljs-keyword">if</span> resp != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">defer</span> resp.Body.Close()<br>      respData, err := ioutil.ReadAll(resp.Body)<br>      <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        errChan &lt;- err<br>      &#125;<br>      respChan &lt;- respData<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      errChan &lt;- errors.New(<span class="hljs-string">&quot;HTTP request failed&quot;</span>)<br>    &#125;<br>  &#125;()<br>  <span class="hljs-keyword">for</span> &#123;<br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>      tr.CancelRequest(req)<br>      errChan &lt;- errors.New(<span class="hljs-string">&quot;HTTP request cancelled&quot;</span>)<br>      <span class="hljs-keyword">return</span><br>    <span class="hljs-keyword">case</span> &lt;-errChan:<br>      tr.CancelRequest(req)<br>      <span class="hljs-keyword">return</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><a href="http://xn--http-ps5fo5cg49bv20c.Client.Do">它使用了http.Client.Do</a>，然后接收到ctx.Done的时候，通过调用transport.CancelRequest来进行结束。<br>我们还可以参考<a href="https://tip.golang.org/src/net/dial.go?s=11446:11534#L351">net/dail/DialContext</a><br>换而言之，如果你希望你实现的包是“可中止/可控制”的，那么你在你包实现的函数里面，最好是能接收一个Context函数，并且处理了Context.Done。</p><h2 id="5-2-PipeLine">5.2 PipeLine</h2><p>Pipeline模式就是流水线模型，流水线上的几个工人，有n个产品，一个一个产品进行组装。其实pipeline模型的实现和Context并无关系，没有context我们也能用chan实现pipeline模型。但是对于整条流水线的控制，则是需要使用上Context的。这篇文章<a href="https://medium.com/statuscode/pipeline-patterns-in-go-a37bb3a7e61d">Pipeline Patterns in Go</a>的<a href="https://gist.github.com/claudiofahey/3afcf4f4fb3d8d3b35cadb100d4fb9b7">例子</a>是非常好的说明。这里就大致对这个代码进行下说明。</p><p>runSimplePipeline的流水线工人有三个，lineListSource负责将参数一个个分割进行传输，lineParser负责将字符串处理成int64,sink根据具体的值判断这个数据是否可用。他们所有的返回值基本上都有两个chan，一个用于传递数据，一个用于传递错误。（&lt;-chan string, &lt;-chan error）输入基本上也都有两个值，一个是Context，用于传声控制的，一个是(in &lt;-chan)输入产品的。</p><p>我们可以看到，这三个工人的具体函数里面，都使用switch处理了case &lt;-ctx.Done()。这个就是生产线上的命令控制。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">lineParser</span><span class="hljs-params">(ctx context.Context, base <span class="hljs-keyword">int</span>, in &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">string</span>)</span> <span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">&lt;-<span class="hljs-keyword">chan</span> <span class="hljs-keyword">int64</span>, &lt;-<span class="hljs-keyword">chan</span> error, error)</span></span> &#123;<br>...<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-built_in">close</span>(out)<br><span class="hljs-keyword">defer</span> <span class="hljs-built_in">close</span>(errc)<br><br><span class="hljs-keyword">for</span> line := <span class="hljs-keyword">range</span> in &#123;<br><br>n, err := strconv.ParseInt(line, base, <span class="hljs-number">64</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>errc &lt;- err<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> out &lt;- n:<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br>&#125;()<br><span class="hljs-keyword">return</span> out, errc, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="5-3-超时请求">5.3 超时请求</h2><p>我们发送RPC请求的时候，往往希望对这个请求进行一个超时的限制。当一个RPC请求超过10s的请求，自动断开。当然我们使用CancelContext，也能实现这个功能（开启一个新的goroutine，这个goroutine拿着cancel函数，当时间到了，就调用cancel函数）。</p><p>鉴于这个需求是非常常见的，context包也实现了这个需求：timerCtx。具体实例化的方法是 WithDeadline 和 WithTimeout。</p><p>具体的timerCtx里面的逻辑也就是通过time.AfterFunc来调用ctx.cancel的。</p><p>官方的例子：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs css">package <span class="hljs-selector-tag">main</span><br><br>import (<br>    &quot;context&quot;<br>    &quot;fmt&quot;<br>    &quot;<span class="hljs-selector-tag">time</span>&quot;<br>)<br><br>func <span class="hljs-selector-tag">main</span>() &#123;<br>    ctx, cancel := context.<span class="hljs-built_in">WithTimeout</span>(context.<span class="hljs-built_in">Background</span>(), <span class="hljs-number">50</span>*time.Millisecond)<br>    defer <span class="hljs-built_in">cancel</span>()<br><br>    select &#123;<br>    case &lt;-time.<span class="hljs-built_in">After</span>(<span class="hljs-number">1</span> * time.Second):<br>        fmt.<span class="hljs-built_in">Println</span>(<span class="hljs-string">&quot;overslept&quot;</span>)<br>    case &lt;-ctx.<span class="hljs-built_in">Done</span>():<br>        fmt.<span class="hljs-built_in">Println</span>(ctx.<span class="hljs-built_in">Err</span>()) // prints <span class="hljs-string">&quot;context deadline exceeded&quot;</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在http的客户端里面加上timeout也是一个常见的办法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go">uri := <span class="hljs-string">&quot;https://httpbin.org/delay/3&quot;</span><br>req, err := http.NewRequest(<span class="hljs-string">&quot;GET&quot;</span>, uri, <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;http.NewRequest() failed with &#x27;%s&#x27;\n&quot;</span>, err)<br>&#125;<br><br>ctx, _ := context.WithTimeout(context.Background(), time.Millisecond*<span class="hljs-number">100</span>)<br>req = req.WithContext(ctx)<br><br>resp, err := http.DefaultClient.Do(req)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Fatalf(<span class="hljs-string">&quot;http.DefaultClient.Do() failed with:\n&#x27;%s&#x27;\n&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">defer</span> resp.Body.Close()<br></code></pre></td></tr></table></figure><p>在http服务端设置一个timeout如何做呢？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;net/http&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">test</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>time.Sleep(<span class="hljs-number">20</span> * time.Second)<br>w.Write([]<span class="hljs-keyword">byte</span>(<span class="hljs-string">&quot;test&quot;</span>))<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>http.HandleFunc(<span class="hljs-string">&quot;/&quot;</span>, test)<br>timeoutHandler := http.TimeoutHandler(http.DefaultServeMux, <span class="hljs-number">5</span> * time.Second, <span class="hljs-string">&quot;timeout&quot;</span>)<br>http.ListenAndServe(<span class="hljs-string">&quot;:8080&quot;</span>, timeoutHandler)<br>&#125;<br></code></pre></td></tr></table></figure><p>我们看看TimeoutHandler的内部，本质上也是通过context.WithTimeout来做处理。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(h *timeoutHandler)</span> <span class="hljs-title">ServeHTTP</span><span class="hljs-params">(w ResponseWriter, r *Request)</span></span> &#123;<br>  ...<br>ctx, cancelCtx = context.WithTimeout(r.Context(), h.dt)<br><span class="hljs-keyword">defer</span> cancelCtx()<br>...<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>    ...<br>h.handler.ServeHTTP(tw, r)<br>&#125;()<br><span class="hljs-keyword">select</span> &#123;<br>    ...<br><span class="hljs-keyword">case</span> &lt;-ctx.Done():<br>...<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="5-4-HTTP服务器的request互相传递数据">5.4 HTTP服务器的request互相传递数据</h2><p>context还提供了valueCtx的数据结构。</p><p>这个valueCtx最经常使用的场景就是在一个http服务器中，在request中传递一个特定值，比如有一个中间件，做cookie验证，然后把验证后的用户名存放在request中。</p><p>我们可以看到，官方的request里面是包含了Context的，并且提供了WithContext的方法进行context的替换。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;net/http&quot;</span><br><span class="hljs-string">&quot;context&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> FooKey <span class="hljs-keyword">string</span><br><br><span class="hljs-keyword">var</span> UserName = FooKey(<span class="hljs-string">&quot;user-name&quot;</span>)<br><span class="hljs-keyword">var</span> UserId = FooKey(<span class="hljs-string">&quot;user-id&quot;</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">(next http.HandlerFunc)</span> <span class="hljs-title">http</span>.<span class="hljs-title">HandlerFunc</span></span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>ctx := context.WithValue(r.Context(), UserId, <span class="hljs-string">&quot;1&quot;</span>)<br>ctx2 := context.WithValue(ctx, UserName, <span class="hljs-string">&quot;yejianfeng&quot;</span>)<br>next(w, r.WithContext(ctx2))<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetUserName</span><span class="hljs-params">(context context.Context)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">if</span> ret, ok := context.Value(UserName).(<span class="hljs-keyword">string</span>); ok &#123;<br><span class="hljs-keyword">return</span> ret<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetUserId</span><span class="hljs-params">(context context.Context)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">if</span> ret, ok := context.Value(UserId).(<span class="hljs-keyword">string</span>); ok &#123;<br><span class="hljs-keyword">return</span> ret<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">test</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>w.Write([]<span class="hljs-keyword">byte</span>(<span class="hljs-string">&quot;welcome: &quot;</span>))<br>w.Write([]<span class="hljs-keyword">byte</span>(GetUserId(r.Context())))<br>w.Write([]<span class="hljs-keyword">byte</span>(<span class="hljs-string">&quot; &quot;</span>))<br>w.Write([]<span class="hljs-keyword">byte</span>(GetUserName(r.Context())))<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>http.Handle(<span class="hljs-string">&quot;/&quot;</span>, foo(test))<br>http.ListenAndServe(<span class="hljs-string">&quot;:8080&quot;</span>, <span class="hljs-literal">nil</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>在使用ValueCtx的时候需要注意一点，这里的key不应该设置成为普通的String或者Int类型，为了防止不同的中间件对这个key的覆盖。最好的情况是每个中间件使用一个自定义的key类型，比如这里的FooKey，而且获取Value的逻辑尽量也抽取出来作为一个函数，放在这个middleware的同包中。这样，就会有效避免不同包设置相同的key的冲突问题了。</p><h1>六、优化</h1><p>使用sync.Pool创建context的变量池</p><p>Do not store Contexts inside a struct type.</p><p>不要轻易修改value的值，如果修改，deep copy 再重新生成一个</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面经2</title>
    <link href="/2023/03/01/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%952/"/>
    <url>/2023/03/01/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%952/</url>
    
    <content type="html"><![CDATA[<ol><li>自我介绍</li><li>设计模式 - 装饰器模式</li><li>对于kratos的了解</li><li>怎么去学习新技术的</li><li>代码风格</li></ol>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面经3</title>
    <link href="/2023/03/01/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/%E4%BA%91%E5%AD%98%E5%82%A8%E9%9D%A2%E8%AF%95/"/>
    <url>/2023/03/01/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/%E4%BA%91%E5%AD%98%E5%82%A8%E9%9D%A2%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<ol><li><p>gRPC使用过程中遇到了什么问题？一个长连接</p></li><li><p>context 发起两个协程，一个是gorm，一个是redis，子context退出时需要立马退出吗</p></li><li><p>线上协程泄漏问题</p></li><li><p>敏感字怎么实现的，匹配机制是怎么样</p></li><li><p>线上有没有排查过网络问题</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将hexo部署到个人服务器</title>
    <link href="/2023/02/28/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/hexo/%E9%83%A8%E7%BD%B2%E5%88%B0%E4%B8%AA%E4%BA%BA%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <url>/2023/02/28/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/hexo/%E9%83%A8%E7%BD%B2%E5%88%B0%E4%B8%AA%E4%BA%BA%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1>一、背景</h1><p>在把hexo部署到github并绑定域名后，因为github的不稳定性，刚好受伤有一台闲置电脑，决定把这个电脑作为服务器，把hexo博客部署到服务器上。</p><h1>二、部署</h1><h2 id="1-安装git和nginx">1. 安装git和nginx</h2><p>首先安装git仓库和nginx：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt-get update<br>sudo x install git nginx -y<br></code></pre></td></tr></table></figure><p>创建文件路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo mkdir /var/repo<br></code></pre></td></tr></table></figure><p>修改文件夹权限：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">chown -R $USER:$USER /var/repo/<br>chmod -R 755 /var/repo/<br></code></pre></td></tr></table></figure><p>创建远程git仓库：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /var/repo<br>git init --bare &#123;自定义仓库名name&#125;.git<br></code></pre></td></tr></table></figure><p><strong>待续</strong></p>]]></content>
    
    
    <categories>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面经1</title>
    <link href="/2023/02/27/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%951/"/>
    <url>/2023/02/27/04.%E9%9D%A2%E8%AF%95/01.%E9%9D%A2%E7%BB%8F/golang%E9%9D%A2%E8%AF%951/</url>
    
    <content type="html"><![CDATA[<ol><li>自我介绍</li><li>说说对协程的理解（GMP机制）</li><li>在主协程和子协程间，有什么方式可以实现通信？（channel，context）</li><li>sync.Pool的理解</li><li>你对gin框架的理解，为什么会这么快</li><li>gRPC使用的协议是什么，二进制通信使用的是什么协议</li><li>K8S master节点上主要的组件有哪些</li><li>就绪指针</li><li>Pod 和 container的关系</li><li>container之间是怎么通信的 cluster IP</li><li>K8S apply创建容器的过程</li><li>pod 是怎么把一个实例扩充成两个实例，修改replicas后更新过程会发生什么</li></ol><p>总结：面试难度不高，但是回答的逻辑有问题，没有突出问题重点，同时说话方式嗫嚅含糊，眼神飘忽，是缺少自信的表现。</p>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>问题记录</title>
    <link href="/2022/12/01/02.%E8%AE%B0%E5%BD%95/03.%E9%97%AE%E9%A2%98/01.%E6%9C%AA%E8%A7%A3%E7%AD%94%E9%97%AE%E9%A2%98/"/>
    <url>/2022/12/01/02.%E8%AE%B0%E5%BD%95/03.%E9%97%AE%E9%A2%98/01.%E6%9C%AA%E8%A7%A3%E7%AD%94%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="问题记录">问题记录</h2><ol><li>redis的强一致性怎么保证？</li></ol>]]></content>
    
    
    <categories>
      
      <category>记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>问题记录</title>
    <link href="/2022/12/01/02.%E8%AE%B0%E5%BD%95/02.%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/01.%E8%AE%B0%E5%BD%95/"/>
    <url>/2022/12/01/02.%E8%AE%B0%E5%BD%95/02.%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/01.%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>问题一：</p><p>二分查找，有个bug，有一个边界条件没有处理好，导致在死循环，go runtime的Machine无法把G切出来，只吃一个核，CPU打满。</p>]]></content>
    
    
    <categories>
      
      <category>记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>问题记录</title>
    <link href="/2022/12/01/02.%E8%AE%B0%E5%BD%95/02.%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/02.git/"/>
    <url>/2022/12/01/02.%E8%AE%B0%E5%BD%95/02.%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/02.git/</url>
    
    <content type="html"><![CDATA[<h2 id="问题一">问题一</h2><h3 id="问题描述">问题描述</h3><p>git clone时提示“fatal: remote error: Git repository not found”</p><h3 id="原因：">原因：</h3><p>下载时，使用的是电脑原同事的git账号</p><h3 id="解决方案：">解决方案：</h3><p>win凭据管理中删除原来的凭据即可</p><h2 id="问题二">问题二</h2><h3 id="问题描述-2">问题描述</h3><p>使用 kratos proto server 命令时报错<br>[!avater]</p><h3 id="原因">原因</h3><p>缺少了工具</p><h3 id="解决方案">解决方案</h3><p>手动把上方get包install<br>go install</p><h2 id="问题三">问题三</h2><h3 id="生成ssh">生成ssh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd ~/.ssh<br>ssh-keygen -t rsa -C &quot;757135670@qq.com&quot;<br>cat id_rsa.pub<br></code></pre></td></tr></table></figure><h2 id="问题四">问题四</h2><h3 id="问题描述-3">问题描述</h3><p><img src="../../image/%E9%97%AE%E9%A2%98/image-20230216100306598.png" alt="image-20230216100306598"></p><h3 id="原因-2">原因</h3><p>原因是在2022年3月15日之后，github不再支持SHA-1的加密方式了。</p><h3 id="解决方法">解决方法</h3><p>将SHA-1的加密方式修改为<code>ECDSA</code>的方式，并把公钥加入到github中，具体操作步骤如下。</p><ol><li><p>生成<code>ECDSA</code>密钥</p><p>执行如下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd ~/.ssh<br>ssh-keygen -t ecdsa -b 521 -C &quot;757135670@qq.com&quot;<br>ssh-keygen -t ed25519 -C &quot;757135670@qq.com&quot;<br></code></pre></td></tr></table></figure></li><li><p>重新把公钥放到github的setting中</p></li></ol><h2 id="问题五">问题五</h2><h3 id="问题描述-4">问题描述</h3><p>在goland中，执行go mod tidy失败，但是手动git clone能够下载代码</p><h3 id="解决方法-2">解决方法</h3><p>清除提示报错信息的cache目录下的缓存，重新tidy</p>]]></content>
    
    
    <categories>
      
      <category>记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gRPC</title>
    <link href="/2022/12/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/3.gRPC/"/>
    <url>/2022/12/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/3.gRPC/</url>
    
    <content type="html"><![CDATA[<h1>一、使用</h1><h2 id="1-安装">1. 安装</h2><h3 id="1-1-安装golang中的gRPC库">1.1 安装golang中的gRPC库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">go get -u google.golang.org/grpc<br></code></pre></td></tr></table></figure><h3 id="1-2-安装工具">1.2 安装工具</h3><p>安装编译器最简单的方式是去<a href="https://link.zhihu.com/?target=https%3A//github.com/protocolbuffers/protobuf/releases">protobuf仓库地址</a>下载预编译好的 protoc 二进制文件，仓库中可以找到每个平台对应的编译器二进制文件，下载解压后配置到环境变量，查看是否成功。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">protoc --version<br></code></pre></td></tr></table></figure><h3 id="1-3-安装插件">1.3 安装插件</h3><p>安装 protoc 之外还需要安装各个语言对应的编译插件，这里我们用的Go 语言，所以还需要安装一个 Go 语言的编译插件。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">go</span> install github.<span class="hljs-keyword">com</span>/golang/protobuf/protoc-gen-<span class="hljs-keyword">go</span><br></code></pre></td></tr></table></figure><h2 id="2-DEMO">2. DEMO</h2><p>gRPC主要有4种请求和响应模式，分别是简单模式(Simple RPC)、服务端流式（Server-side streaming RPC）、客户端流式（Client-side streaming RPC）、和双向流式（Bidirectional streaming RPC）。</p><ul><li>简单模式(Simple RPC)：客户端发起请求并等待服务端响应。</li><li>服务端流式（Server-side streaming RPC）：客户端发送请求到服务器，拿到一个流去读取返回的消息序列。 客户端读取返回的流，直到里面没有任何消息。</li><li>客户端流式（Client-side streaming RPC）：与服务端数据流模式相反，这次是客户端源源不断的向服务端发送数据流，而在发送结束后，由服务端返回一个响应。</li><li>双向流式（Bidirectional streaming RPC）：双方使用读写流去发送一个消息序列，两个流独立操作，双方可以同时发送和同时接收。</li></ul><h3 id="2-1-简单模式">2.1 简单模式</h3><p>本demo项目结构如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">helloworld/<br>├── client.go - 客户端代码<br>├── go.mod  - go模块配置文件<br>├── proto     - 协议目录<br>│   ├── helloworld.pb.go - rpc协议go版本代码<br>│   └── helloworld.proto - rpc协议文件<br>└── server.go  - rpc服务端代码<br></code></pre></td></tr></table></figure><p>初始化命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text"># 创建项目目录<br>mkdir helloworld<br># 切换到项目目录<br>cd helloworld<br># 创建RPC协议目录<br>mkdir proto<br># 初始化go模块配置，用来管理第三方依赖<br>go mod init <br></code></pre></td></tr></table></figure><h4 id="2-1-1-定义服务">2.1.1 定义服务</h4><p>其实就是通过protobuf语法定义语言平台无关的接口。 文件: helloworld/proto/helloworld.proto</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs text">syntax = &quot;proto3&quot;;<br><br>//option go_package = &quot;path;name&quot;;<br>//path 表示生成的go文件的存放地址，会自动生成目录的。<br>//name 表示生成的go文件所属的包名<br>option go_package=&quot;./;proto&quot;;<br>// 定义包名<br>package proto;<br><br>// 定义Greeter服务<br>service Greeter &#123;<br>  // 定义SayHello方法，接受HelloRequest消息， 并返回HelloReply消息<br>  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;<br>&#125;<br><br>// 定义HelloRequest消息<br>message HelloRequest &#123;<br>  // name字段<br>  string name = 1;<br>&#125;<br><br>// 定义HelloReply消息<br>message HelloReply &#123;<br>  // message字段<br>  string message = 1;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-1-2-编译命令">2.1.2 <strong>编译命令</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> protoc --proto_path=IMPORT_PATH  --go_out=OUT_DIR  --go_opt=paths=source_relative path/to/file.proto</span><br></code></pre></td></tr></table></figure><p>这里简单介绍一下 golang 的编译姿势:</p><ul><li><p>proto_path或者-I ：指定 import 路径，可以指定多个参数，编译时按顺序查找，不指定时默认查找当前目录。</p></li><li><ul><li>proto 文件中也可以引入其他 .proto 文件，这里主要用于指定被引入文件的位置。</li></ul></li><li><p>go_out：golang编译支持，指定输出文件路径</p></li><li><p>go_opt：指定参数，比如–go_opt=paths=source_relative就是表明生成文件输出使用相对路径。</p></li><li><p>path/to/file.proto ：被编译的 .proto 文件放在最后面</p></li></ul><p>上面通过proto定义的接口，没法直接在代码中使用，因此需要通过protoc编译器，将proto协议文件，编译成go语言代码。 在我们的demo中,按如下命令进行编译:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">protoc -I proto/ --go_out=plugins=grpc:proto proto/helloworld.proto<br></code></pre></td></tr></table></figure><h4 id="2-1-3-实现服务端代码">2.1.3 <strong>实现服务端代码</strong></h4><p>文件:helloworld/server.go</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs text">package main<br><br>import (<br> &quot;log&quot;<br> &quot;net&quot;<br><br> &quot;golang.org/x/net/context&quot;<br> // 导入grpc包<br> &quot;google.golang.org/grpc&quot;<br> // 导入刚才我们生成的代码所在的proto包。<br>  pb &quot;helloworld/proto&quot;<br> &quot;google.golang.org/grpc/reflection&quot;<br>)<br><br><br>// 定义server，用来实现proto文件，里面实现的Greeter服务里面的接口<br>type server struct&#123;&#125;<br><br>// 实现SayHello接口<br>// 第一个参数是上下文参数，所有接口默认都要必填<br>// 第二个参数是我们定义的HelloRequest消息<br>// 返回值是我们定义的HelloReply消息，error返回值也是必须的。<br>func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123;<br> // 创建一个HelloReply消息，设置Message字段，然后直接返回。<br> return &amp;pb.HelloReply&#123;Message: &quot;Hello &quot; + in.Name&#125;, nil<br>&#125;<br><br>func main() &#123;<br> // 监听127.0.0.1:50051地址<br> lis, err := net.Listen(&quot;tcp&quot;, &quot;127.0.0.1:50051&quot;)<br> if err != nil &#123;<br>  log.Fatalf(&quot;failed to listen: %v&quot;, err)<br> &#125;<br><br> // 实例化grpc服务端<br> s := grpc.NewServer()<br><br>        // 注册Greeter服务<br> pb.RegisterGreeterServer(s, &amp;server&#123;&#125;)<br><br> // 往grpc服务端注册反射服务<br> reflection.Register(s)<br><br>        // 启动grpc服务<br> if err := s.Serve(lis); err != nil &#123;<br>     log.Fatalf(&quot;failed to serve: %v&quot;, err)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text"># 切换到项目根目录，运行命令<br>go run server.go<br></code></pre></td></tr></table></figure><h4 id="2-1-4-客户端代码">2.1.4 <strong>客户端代码</strong></h4><p>文件：helloworld/client.go</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs text">package main<br><br>import (<br> &quot;log&quot;<br> &quot;os&quot;<br> &quot;time&quot;<br><br> &quot;golang.org/x/net/context&quot;<br> // 导入grpc包<br> &quot;google.golang.org/grpc&quot;<br> // 导入刚才我们生成的代码所在的proto包。<br>  pb &quot;helloworld/proto&quot;<br>)<br><br>const (<br> defaultName = &quot;world&quot;<br>)<br><br>func main() &#123;<br> // 连接grpc服务器<br> conn, err := grpc.Dial(&quot;localhost:50051&quot;, grpc.WithInsecure())<br> if err != nil &#123;<br>  log.Fatalf(&quot;did not connect: %v&quot;, err)<br> &#125;<br> // 延迟关闭连接<br> defer conn.Close()<br><br> // 初始化Greeter服务客户端<br> c := pb.NewGreeterClient(conn)<br><br> // 初始化上下文，设置请求超时时间为1秒<br> ctx, cancel := context.WithTimeout(context.Background(), time.Second)<br> // 延迟关闭请求会话<br> defer cancel()<br><br> // 调用SayHello接口，发送一条消息<br> r, err := c.SayHello(ctx, &amp;pb.HelloRequest&#123;Name: &quot;world&quot;&#125;)<br> if err != nil &#123;<br>  log.Fatalf(&quot;could not greet: %v&quot;, err)<br> &#125;<br><br> // 打印服务的返回的消息<br> log.Printf(&quot;Greeting: %s&quot;, r.Message)<br>&#125;<br></code></pre></td></tr></table></figure><p>运行:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text"># 切换到项目根目录，运行命令<br>go run client.go<br></code></pre></td></tr></table></figure><h3 id="2-2-服务端流式RPC">2.2 <strong>服务端流式RPC</strong></h3><p>上面的DEMO介绍了简单模式RPC，当数据量大或者需要不断传输数据时候，我们应该使用流式RPC，它允许我们边处理边传输数据。本节先介绍服务端流式RPC。</p><p><strong>服务端流式RPC</strong>：客户端发送请求到服务器，拿到一个流去读取返回的消息序列。 客户端读取返回的流，直到里面没有任何消息。</p><p><strong>情景模拟：实时获取股票走势。</strong></p><ul><li>客户端要获取某原油股的实时走势，客户端发送一个请求</li><li>服务端实时返回该股票的走势</li></ul><h4 id="2-2-1-新建proto文件">2.2.1 <strong>新建proto文件</strong></h4><p>新建server_stream.proto文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs text">// 定义发送请求信息<br>message SimpleRequest&#123;<br>    // 定义发送的参数，采用驼峰命名方式，小写加下划线，如：student_name<br>    // 请求参数<br>    string data = 1;<br>&#125;<br><br>// 定义流式响应信息<br>message StreamResponse&#123;<br>    // 流式响应数据<br>    string stream_value = 1;<br>&#125;<br><br>//服务端流式rpc，只要在响应数据前添加stream即可<br>// 定义我们的服务（可定义多个服务,每个服务可定义多个接口）<br>service StreamServer&#123;<br>    // 服务端流式rpc，在响应数据前添加stream<br>    rpc ListValue(SimpleRequest)returns(stream StreamResponse)&#123;&#125;;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译参考demo部分的编译命令</p><h4 id="2-2-2-创建server端">2.2.2 <strong>创建server端</strong></h4><p>定义我们的服务，并实现ListValue方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs text">// SimpleService 定义我们的服务<br>type StreamService struct&#123;&#125;<br>// ListValue 实现ListValue方法<br>func (s *StreamService) ListValue(req *pb.SimpleRequest, srv pb.StreamServer_ListValueServer) error &#123;<br> for n := 0; n &lt; 5; n++ &#123;<br>  // 向流中发送消息， 默认每次send送消息最大长度为`math.MaxInt32`bytes<br>  err := srv.Send(&amp;pb.StreamResponse&#123;<br>   StreamValue: req.Data + strconv.Itoa(n),<br>  &#125;)<br>  if err != nil &#123;<br>   return err<br>  &#125;<br> &#125;<br> return nil<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC服务器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs text">const (<br> // Address 监听地址<br> Address string = &quot;:8000&quot;<br> // Network 网络通信协议<br> Network string = &quot;tcp&quot;<br>)<br><br>func main() &#123;<br> // 监听本地端口<br> listener, err := net.Listen(Network, Address)<br> if err != nil &#123;<br>  log.Fatalf(&quot;net.Listen err: %v&quot;, err)<br> &#125;<br> log.Println(Address + &quot; net.Listing...&quot;)<br> // 新建gRPC服务器实例<br> // 默认单次接收最大消息长度为`1024*1024*4`bytes(4M)，单次发送消息最大长度为`math.MaxInt32`bytes<br> // grpcServer := grpc.NewServer(grpc.MaxRecvMsgSize(1024*1024*4), grpc.MaxSendMsgSize(math.MaxInt32))<br> grpcServer := grpc.NewServer()<br> // 在gRPC服务器注册我们的服务<br> pb.RegisterStreamServerServer(grpcServer, &amp;StreamService&#123;&#125;)<br><br> //用服务器 Serve() 方法以及我们的端口信息区实现阻塞等待，直到进程被杀死或者 Stop() 被调用<br> err = grpcServer.Serve(listener)<br> if err != nil &#123;<br>  log.Fatalf(&quot;grpcServer.Serve err: %v&quot;, err)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs she">go run server.go<br></code></pre></td></tr></table></figure><h4 id="2-2-3-创建client端">2.2.3 <strong>创建client端</strong></h4><p>创建调用服务端ListValue方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// listValue 调用服务端的ListValue方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">listValue</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">// 创建发送结构体</span><br> req := pb.SimpleRequest&#123;<br>  Data: <span class="hljs-string">&quot;stream server grpc &quot;</span>,<br> &#125;<br> <span class="hljs-comment">// 调用我们的服务(ListValue方法)</span><br> stream, err := grpcClient.ListValue(context.Background(), &amp;req)<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;Call ListStr err: %v&quot;</span>, err)<br> &#125;<br> <span class="hljs-keyword">for</span> &#123;<br>  <span class="hljs-comment">//Recv() 方法接收服务端消息，默认每次Recv()最大消息长度为`1024*1024*4`bytes(4M)</span><br>  res, err := stream.Recv()<br>  <span class="hljs-comment">// 判断消息流是否已经结束</span><br>  <span class="hljs-keyword">if</span> err == io.EOF &#123;<br>   <span class="hljs-keyword">break</span><br>  &#125;<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   log.Fatalf(<span class="hljs-string">&quot;ListStr get stream err: %v&quot;</span>, err)<br>  &#125;<br>  <span class="hljs-comment">// 打印返回值</span><br>  log.Println(res.StreamValue)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC客户端</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Address 连接地址</span><br><span class="hljs-keyword">const</span> Address <span class="hljs-keyword">string</span> = <span class="hljs-string">&quot;:8000&quot;</span><br><br><span class="hljs-keyword">var</span> grpcClient pb.StreamServerClient<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">// 连接服务器</span><br> conn, err := grpc.Dial(Address, grpc.WithInsecure())<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;net.Connect err: %v&quot;</span>, err)<br> &#125;<br> <span class="hljs-keyword">defer</span> conn.Close()<br><br> <span class="hljs-comment">// 建立gRPC连接</span><br> grpcClient = pb.NewStreamServerClient(conn)<br> listValue()<br>&#125;<br></code></pre></td></tr></table></figure><p>运行客户端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">go run client.go<br>stream server grpc 0<br>stream server grpc 1<br>stream server grpc 2<br>stream server grpc 3<br>stream server grpc 4<br></code></pre></td></tr></table></figure><blockquote><p>客户端不断从服务端获取数据</p></blockquote><h3 id="2-3-客户端流式RPC">2.3 <strong>客户端流式RPC</strong></h3><p>上一节介绍了服务端流式RPC，客户端发送请求到服务器，拿到一个流去读取返回的消息序列。 客户端读取返回的流的数据。本节将介绍客户端流式RPC。</p><p><strong>客户端流式RPC</strong>：与服务端流式RPC相反，客户端不断的向服务端发送数据流，而在发送结束后，由服务端返回一个响应。</p><p><strong>情景模拟</strong>：客户端大量数据上传到服务端。</p><h4 id="2-3-1-新建proto文件">2.3.1 <strong>新建proto文件</strong></h4><p>新建client_stream.proto文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs text">// 定义流式请求信息<br>message StreamRequest&#123;<br>    //流式请求参数<br>    string stream_data = 1;<br>&#125;<br><br>// 定义响应信息<br>message SimpleResponse&#123;<br>    //响应码<br>    int32 code = 1;<br>    //响应值<br>    string value = 2;<br>&#125;<br><br><br>//客户端流式rpc，只要在请求的参数前添加stream即可<br>service StreamClient&#123;<br>    // 客户端流式rpc，在请求的参数前添加stream<br>    rpc RouteList (stream StreamRequest) returns (SimpleResponse)&#123;&#125;;<br>&#125;<br></code></pre></td></tr></table></figure><p>参照demo进行编译。</p><h4 id="2-3-2-创建Server端">2.3.2 <strong>创建Server端</strong></h4><p>定义我们的服务，并实现RouteList方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// SimpleService 定义我们的服务</span><br><span class="hljs-keyword">type</span> SimpleService <span class="hljs-keyword">struct</span>&#123;&#125;<br><span class="hljs-comment">// RouteList 实现RouteList方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *SimpleService)</span> <span class="hljs-title">RouteList</span><span class="hljs-params">(srv pb.StreamClient_RouteListServer)</span> <span class="hljs-title">error</span></span> &#123;<br> <span class="hljs-keyword">for</span> &#123;<br>  <span class="hljs-comment">//从流中获取消息</span><br>  res, err := srv.Recv()<br>  <span class="hljs-keyword">if</span> err == io.EOF &#123;<br>   <span class="hljs-comment">//发送结果，并关闭</span><br>   <span class="hljs-keyword">return</span> srv.SendAndClose(&amp;pb.SimpleResponse&#123;Value: <span class="hljs-string">&quot;ok&quot;</span>&#125;)<br>  &#125;<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>  &#125;<br>  log.Println(res.StreamData)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC服务器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs text">const (<br> // Address 监听地址<br> Address string = &quot;:8000&quot;<br> // Network 网络通信协议<br> Network string = &quot;tcp&quot;<br>)<br><br>func main() &#123;<br> // 监听本地端口<br> listener, err := net.Listen(Network, Address)<br> if err != nil &#123;<br>  log.Fatalf(&quot;net.Listen err: %v&quot;, err)<br> &#125;<br> log.Println(Address + &quot; net.Listing...&quot;)<br> // 新建gRPC服务器实例<br> grpcServer := grpc.NewServer()<br> // 在gRPC服务器注册我们的服务<br> pb.RegisterStreamClientServer(grpcServer, &amp;SimpleService&#123;&#125;)<br><br> //用服务器 Serve() 方法以及我们的端口信息区实现阻塞等待，直到进程被杀死或者 Stop() 被调用<br> err = grpcServer.Serve(listener)<br> if err != nil &#123;<br>  log.Fatalf(&quot;grpcServer.Serve err: %v&quot;, err)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行服务端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">go run server.go<br></code></pre></td></tr></table></figure><h4 id="2-3-3-创建客户端">2.3.3 <strong>创建客户端</strong></h4><p>创建调用服务端RouteList方法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// routeList 调用服务端RouteList方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">routeList</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">//调用服务端RouteList方法，获流</span><br> stream, err := streamClient.RouteList(context.Background())<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;Upload list err: %v&quot;</span>, err)<br> &#125;<br> <span class="hljs-keyword">for</span> n := <span class="hljs-number">0</span>; n &lt; <span class="hljs-number">5</span>; n++ &#123;<br>  <span class="hljs-comment">//向流中发送消息</span><br>  err := stream.Send(&amp;pb.StreamRequest&#123;StreamData: <span class="hljs-string">&quot;stream client rpc &quot;</span> + strconv.Itoa(n)&#125;)<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   log.Fatalf(<span class="hljs-string">&quot;stream request err: %v&quot;</span>, err)<br>  &#125;<br> &#125;<br> <span class="hljs-comment">//关闭流并获取返回的消息</span><br> res, err := stream.CloseAndRecv()<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;RouteList get response err: %v&quot;</span>, err)<br> &#125;<br> log.Println(res)<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC客户端</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Address 连接地址</span><br><span class="hljs-keyword">const</span> Address <span class="hljs-keyword">string</span> = <span class="hljs-string">&quot;:8000&quot;</span><br><br><span class="hljs-keyword">var</span> streamClient pb.StreamClientClient<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">// 连接服务器</span><br> conn, err := grpc.Dial(Address, grpc.WithInsecure())<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;net.Connect err: %v&quot;</span>, err)<br> &#125;<br> <span class="hljs-keyword">defer</span> conn.Close()<br><br> <span class="hljs-comment">// 建立gRPC连接</span><br> streamClient = pb.NewStreamClientClient(conn)<br> routeList()<br>&#125;<br></code></pre></td></tr></table></figure><p>运行客户端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">go run client.go<br></code></pre></td></tr></table></figure><p>服务端不断从客户端获取到数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">stream client rpc 0<br>stream client rpc 1<br>stream client rpc 2<br>stream client rpc 3<br>stream client rpc 4<br></code></pre></td></tr></table></figure><h3 id="2-4-双向流式RPC">2.4 <strong>双向流式RPC</strong></h3><p>上一节介绍了客户端流式RPC，客户端不断的向服务端发送数据流，在发送结束或流关闭后，由服务端返回一个响应。本节将介绍双向流式RPC。</p><p><strong>双向流式RPC</strong>：客户端和服务端双方使用读写流去发送一个消息序列，两个流独立操作，双方可以同时发送和同时接收。</p><p><strong>情景模拟</strong>：双方对话（可以一问一答、一问多答、多问一答，形式灵活）。</p><h4 id="2-4-1-新建proto文件">2.4.1 <strong>新建proto文件</strong></h4><p>新建both_stream.proto文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs text">// 定义流式请求信息<br>message StreamRequest&#123;<br>    //流请求参数<br>    string question = 1;<br>&#125;<br><br>// 定义流式响应信息<br>message StreamResponse&#123;<br>    //流响应数据<br>    string answer = 1;<br>&#125;<br><br><br>//双向流式rpc，只要在请求的参数前和响应参数前都添加stream即可<br>service Stream&#123;<br>    // 双向流式rpc，同时在请求参数前和响应参数前加上stream<br>    rpc Conversations(stream StreamRequest) returns(stream StreamResponse)&#123;&#125;;<br>&#125;<br></code></pre></td></tr></table></figure><p>编译参照demo部分编译即可。</p><h4 id="2-4-2-创建Server端">2.4.2 <strong>创建Server端</strong></h4><ol><li>定义我们的服务，并实现RouteList方法 这里简单实现对话中一问一答的形式</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// StreamService 定义我们的服务</span><br><span class="hljs-keyword">type</span> StreamService <span class="hljs-keyword">struct</span>&#123;&#125;<br><span class="hljs-comment">// Conversations 实现Conversations方法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *StreamService)</span> <span class="hljs-title">Conversations</span><span class="hljs-params">(srv pb.Stream_ConversationsServer)</span> <span class="hljs-title">error</span></span> &#123;<br> n := <span class="hljs-number">1</span><br> <span class="hljs-keyword">for</span> &#123;<br>  req, err := srv.Recv()<br>  <span class="hljs-keyword">if</span> err == io.EOF &#123;<br>   <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>  &#125;<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>  &#125;<br>  err = srv.Send(&amp;pb.StreamResponse&#123;<br>   Answer: <span class="hljs-string">&quot;from stream server answer: the &quot;</span> + strconv.Itoa(n) + <span class="hljs-string">&quot; question is &quot;</span> + req.Question,<br>  &#125;)<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>  &#125;<br>  n++<br>  log.Printf(<span class="hljs-string">&quot;from stream client question: %s&quot;</span>, req.Question)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC服务器</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">const</span> (<br> <span class="hljs-comment">// Address 监听地址</span><br> Address <span class="hljs-keyword">string</span> = <span class="hljs-string">&quot;:8000&quot;</span><br> <span class="hljs-comment">// Network 网络通信协议</span><br> Network <span class="hljs-keyword">string</span> = <span class="hljs-string">&quot;tcp&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">// 监听本地端口</span><br> listener, err := net.Listen(Network, Address)<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;net.Listen err: %v&quot;</span>, err)<br> &#125;<br> log.Println(Address + <span class="hljs-string">&quot; net.Listing...&quot;</span>)<br> <span class="hljs-comment">// 新建gRPC服务器实例</span><br> grpcServer := grpc.NewServer()<br> <span class="hljs-comment">// 在gRPC服务器注册我们的服务</span><br> pb.RegisterStreamServer(grpcServer, &amp;StreamService&#123;&#125;)<br><br> <span class="hljs-comment">//用服务器 Serve() 方法以及我们的端口信息区实现阻塞等待，直到进程被杀死或者 Stop() 被调用</span><br> err = grpcServer.Serve(listener)<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatalf(<span class="hljs-string">&quot;grpcServer.Serve err: %v&quot;</span>, err)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>运行服务端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">go run server.go<br>:8000 net.Listing...<br></code></pre></td></tr></table></figure><h4 id="2-4-3-创建Client端">2.4.3 <strong>创建Client端</strong></h4><p>创建调用服务端Conversations方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs text">// conversations 调用服务端的Conversations方法<br>func conversations() &#123;<br> //调用服务端的Conversations方法，获取流<br> stream, err := streamClient.Conversations(context.Background())<br> if err != nil &#123;<br>  log.Fatalf(&quot;get conversations stream err: %v&quot;, err)<br> &#125;<br> for n := 0; n &lt; 5; n++ &#123;<br>  err := stream.Send(&amp;pb.StreamRequest&#123;Question: &quot;stream client rpc &quot; + strconv.Itoa(n)&#125;)<br>  if err != nil &#123;<br>   log.Fatalf(&quot;stream request err: %v&quot;, err)<br>  &#125;<br>  res, err := stream.Recv()<br>  if err == io.EOF &#123;<br>   break<br>  &#125;<br>  if err != nil &#123;<br>   log.Fatalf(&quot;Conversations get stream err: %v&quot;, err)<br>  &#125;<br>  // 打印返回值<br>  log.Println(res.Answer)<br> &#125;<br> //最后关闭流<br> err = stream.CloseSend()<br> if err != nil &#123;<br>  log.Fatalf(&quot;Conversations close stream err: %v&quot;, err)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>启动gRPC客户端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs text">// Address 连接地址<br>const Address string = &quot;:8000&quot;<br><br>var streamClient pb.StreamClient<br><br>func main() &#123;<br> // 连接服务器<br> conn, err := grpc.Dial(Address, grpc.WithInsecure())<br> if err != nil &#123;<br>  log.Fatalf(&quot;net.Connect err: %v&quot;, err)<br> &#125;<br> defer conn.Close()<br><br> // 建立gRPC连接<br> streamClient = pb.NewStreamClient(conn)<br> conversations()<br>&#125;<br></code></pre></td></tr></table></figure><p>运行客户端，获取到服务端的应答</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">go run client.go<br>from stream server answer: the 1 question is stream client rpc 0<br>from stream server answer: the 2 question is stream client rpc 1<br>from stream server answer: the 3 question is stream client rpc 2<br>from stream server answer: the 4 question is stream client rpc 3<br>from stream server answer: the 5 question is stream client rpc 4<br></code></pre></td></tr></table></figure><p>服务端获取到来自客户端的提问</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">from stream client question: stream client rpc 0<br>from stream client question: stream client rpc 1<br>from stream client question: stream client rpc 2<br>from stream client question: stream client rpc 3<br>from stream client question: stream client rpc 4#<br></code></pre></td></tr></table></figure><h1>二、分析</h1><h2 id="1-server端启动流程">1. server端启动流程</h2><h3 id="1-1-构建本地监听端口">1.1 构建本地监听端口</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">lis, err := net.Listen(<span class="hljs-string">&quot;tcp&quot;</span>, <span class="hljs-string">&quot;127.0.0.1:8001&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>    log.Fatalf(<span class="hljs-string">&quot;failed to listen: %v&quot;</span>, err)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-2-创建server实例">1.2 创建server实例</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 实例化grpc服务端</span><br>s := grpc.NewServer()<br></code></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NewServer creates a gRPC server which has no service registered and has not</span><br><span class="hljs-comment">// started to accept requests yet.</span><br><span class="hljs-comment">// 创建一个新的server，该server还没有注册服务，并且没有接受请求</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(opt ...ServerOption)</span> *<span class="hljs-title">Server</span></span> &#123;<br>    <span class="hljs-comment">//把默认配置放到入参中</span><br>   opts := defaultServerOptions<br>   <span class="hljs-keyword">for</span> _, o := <span class="hljs-keyword">range</span> extraServerOptions &#123;<br>      o.apply(&amp;opts)<br>   &#125;<br>   <span class="hljs-keyword">for</span> _, o := <span class="hljs-keyword">range</span> opt &#123;<br>      o.apply(&amp;opts)<br>   &#125;<br>    <span class="hljs-comment">// 构造Server实例</span><br>   s := &amp;Server&#123;<br>      lis:      <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[net.Listener]<span class="hljs-keyword">bool</span>),<br>      opts:     opts,<br>      conns:    <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]<span class="hljs-keyword">map</span>[transport.ServerTransport]<span class="hljs-keyword">bool</span>),<br>      services: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*serviceInfo),<br>      quit:     grpcsync.NewEvent(),<br>      done:     grpcsync.NewEvent(),<br>      czData:   <span class="hljs-built_in">new</span>(channelzData),<br>   &#125;<br><span class="hljs-comment">//chains all unary server interceptors into one.</span><br>   chainUnaryServerInterceptors(s)<br>    <span class="hljs-comment">//chains all stream server interceptors into one.</span><br>   chainStreamServerInterceptors(s)<br>   s.cv = sync.NewCond(&amp;s.mu)<br>   <span class="hljs-comment">// 判断是否开启链路追踪</span><br>   <span class="hljs-keyword">if</span> EnableTracing &#123;<br>      _, file, line, _ := runtime.Caller(<span class="hljs-number">1</span>)<br>      s.events = trace.NewEventLog(<span class="hljs-string">&quot;grpc.Server&quot;</span>, fmt.Sprintf(<span class="hljs-string">&quot;%s:%d&quot;</span>, file, line))<br>   &#125;<br><br>   <span class="hljs-keyword">if</span> s.opts.numServerWorkers &gt; <span class="hljs-number">0</span> &#123;<br>      s.initServerWorkers()<br>   &#125;<br><br>   s.channelzID = channelz.RegisterServer(&amp;channelzServer&#123;s&#125;, <span class="hljs-string">&quot;&quot;</span>)<br>   channelz.Info(logger, s.channelzID, <span class="hljs-string">&quot;Server created&quot;</span>)<br>   <span class="hljs-keyword">return</span> s<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-3-注册服务">1.3 注册服务</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 注册Greeter服务</span><br>pb.RegisterGreeterServer(s, &amp;server&#123;&#125;)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">RegisterGreeterServer</span><span class="hljs-params">(s *grpc.Server, srv GreeterServer)</span></span> &#123;<br>s.RegisterService(&amp;_Greeter_serviceDesc, srv)<br>&#125;<br><br><span class="hljs-comment">// RegisterService registers a service and its implementation to the gRPC</span><br><span class="hljs-comment">// server. It is called from the IDL generated code. This must be called before</span><br><span class="hljs-comment">// invoking Serve. If ss is non-nil (for legacy code), its type is checked to</span><br><span class="hljs-comment">// ensure it implements sd.HandlerType.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Server)</span> <span class="hljs-title">RegisterService</span><span class="hljs-params">(sd *ServiceDesc, ss <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br><span class="hljs-keyword">if</span> ss != <span class="hljs-literal">nil</span> &#123;<br>ht := reflect.TypeOf(sd.HandlerType).Elem()<br>st := reflect.TypeOf(ss)<br><span class="hljs-keyword">if</span> !st.Implements(ht) &#123;<br>logger.Fatalf(<span class="hljs-string">&quot;grpc: Server.RegisterService found the handler of type %v that does not satisfy %v&quot;</span>, st, ht)<br>&#125;<br>&#125;<br>s.register(sd, ss)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Server)</span> <span class="hljs-title">register</span><span class="hljs-params">(sd *ServiceDesc, ss <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br>s.mu.Lock()<br><span class="hljs-keyword">defer</span> s.mu.Unlock()<br>s.printf(<span class="hljs-string">&quot;RegisterService(%q)&quot;</span>, sd.ServiceName)<br><span class="hljs-keyword">if</span> s.serve &#123;<br>logger.Fatalf(<span class="hljs-string">&quot;grpc: Server.RegisterService after Server.Serve for %q&quot;</span>, sd.ServiceName)<br>&#125;<br><span class="hljs-keyword">if</span> _, ok := s.services[sd.ServiceName]; ok &#123;<br>logger.Fatalf(<span class="hljs-string">&quot;grpc: Server.RegisterService found duplicate service registration for %q&quot;</span>, sd.ServiceName)<br>&#125;<br>info := &amp;serviceInfo&#123;<br>serviceImpl: ss,<br>methods:     <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*MethodDesc),<br>streams:     <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]*StreamDesc),<br>mdata:       sd.Metadata,<br>&#125;<br><span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> sd.Methods &#123;<br>d := &amp;sd.Methods[i]<br>info.methods[d.MethodName] = d<br>&#125;<br><span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> sd.Streams &#123;<br>d := &amp;sd.Streams[i]<br>info.streams[d.StreamName] = d<br>&#125;<br>s.services[sd.ServiceName] = info<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-4-注册反射服务">1.4 注册反射服务</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 往grpc服务端注册反射服务</span><br>reflection.Register(s)<br><br><span class="hljs-comment">// Register registers the server reflection service on the given gRPC server.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Register</span><span class="hljs-params">(s GRPCServer)</span></span> &#123;<br>svr := NewServer(ServerOptions&#123;Services: s&#125;)<br>v1alphagrpc.RegisterServerReflectionServer(s, svr)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-5-启动grpc服务">1.5 启动grpc服务</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 启动grpc服务</span><br><span class="hljs-keyword">if</span> err := s.Serve(lis); err != <span class="hljs-literal">nil</span> &#123;<br>   log.Fatalf(<span class="hljs-string">&quot;failed to serve: %v&quot;</span>, err)<br>&#125;<br><br><span class="hljs-comment">// Serve accepts incoming connections on the listener lis, creating a new</span><br><span class="hljs-comment">// ServerTransport and service goroutine for each. The service goroutines</span><br><span class="hljs-comment">// read gRPC requests and then call the registered handlers to reply to them.</span><br><span class="hljs-comment">// Serve returns when lis.Accept fails with fatal errors.  lis will be closed when</span><br><span class="hljs-comment">// this method returns.</span><br><span class="hljs-comment">// Serve will return a non-nil error unless Stop or GracefulStop is called.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Server)</span> <span class="hljs-title">Serve</span><span class="hljs-params">(lis net.Listener)</span> <span class="hljs-title">error</span></span> &#123;<br>s.mu.Lock()<br>s.printf(<span class="hljs-string">&quot;serving&quot;</span>)<br>s.serve = <span class="hljs-literal">true</span><br><span class="hljs-keyword">if</span> s.lis == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-comment">// Serve called after Stop or GracefulStop.</span><br>s.mu.Unlock()<br>lis.Close()<br><span class="hljs-keyword">return</span> ErrServerStopped<br>&#125;<br><br>s.serveWG.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>s.serveWG.Done()<br><span class="hljs-keyword">if</span> s.quit.HasFired() &#123;<br><span class="hljs-comment">// Stop or GracefulStop called; block until done and return nil.</span><br>&lt;-s.done.Done()<br>&#125;<br>&#125;()<br><br>ls := &amp;listenSocket&#123;Listener: lis&#125;<br>s.lis[ls] = <span class="hljs-literal">true</span><br><br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>s.mu.Lock()<br><span class="hljs-keyword">if</span> s.lis != <span class="hljs-literal">nil</span> &amp;&amp; s.lis[ls] &#123;<br>ls.Close()<br><span class="hljs-built_in">delete</span>(s.lis, ls)<br>&#125;<br>s.mu.Unlock()<br>&#125;()<br><br><span class="hljs-keyword">var</span> err error<br>ls.channelzID, err = channelz.RegisterListenSocket(ls, s.channelzID, lis.Addr().String())<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>s.mu.Unlock()<br><span class="hljs-keyword">return</span> err<br>&#125;<br>s.mu.Unlock()<br>channelz.Info(logger, ls.channelzID, <span class="hljs-string">&quot;ListenSocket created&quot;</span>)<br><br><span class="hljs-keyword">var</span> tempDelay time.Duration <span class="hljs-comment">// how long to sleep on accept failure</span><br><span class="hljs-keyword">for</span> &#123;<br>rawConn, err := lis.Accept()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">if</span> ne, ok := err.(<span class="hljs-keyword">interface</span> &#123;<br>Temporary() <span class="hljs-keyword">bool</span><br>&#125;); ok &amp;&amp; ne.Temporary() &#123;<br><span class="hljs-keyword">if</span> tempDelay == <span class="hljs-number">0</span> &#123;<br>tempDelay = <span class="hljs-number">5</span> * time.Millisecond<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>tempDelay *= <span class="hljs-number">2</span><br>&#125;<br><span class="hljs-keyword">if</span> max := <span class="hljs-number">1</span> * time.Second; tempDelay &gt; max &#123;<br>tempDelay = max<br>&#125;<br>s.mu.Lock()<br>s.printf(<span class="hljs-string">&quot;Accept error: %v; retrying in %v&quot;</span>, err, tempDelay)<br>s.mu.Unlock()<br>timer := time.NewTimer(tempDelay)<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-timer.C:<br><span class="hljs-keyword">case</span> &lt;-s.quit.Done():<br>timer.Stop()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">continue</span><br>&#125;<br>s.mu.Lock()<br>s.printf(<span class="hljs-string">&quot;done serving; Accept = %v&quot;</span>, err)<br>s.mu.Unlock()<br><br><span class="hljs-keyword">if</span> s.quit.HasFired() &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">return</span> err<br>&#125;<br>tempDelay = <span class="hljs-number">0</span><br><span class="hljs-comment">// Start a new goroutine to deal with rawConn so we don&#x27;t stall this Accept</span><br><span class="hljs-comment">// loop goroutine.</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// Make sure we account for the goroutine so GracefulStop doesn&#x27;t nil out</span><br><span class="hljs-comment">// s.conns before this conn can be added.</span><br>s.serveWG.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>s.handleRawConn(lis.Addr().String(), rawConn)<br>s.serveWG.Done()<br>&#125;()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-keepalive">2. keepalive</h2><h4 id="2-1-客户端keepalive">2.1 客户端keepalive</h4><p>在gRPC中，会在新建Http2Client的时候，会启动一个goroutine来处理keepalive。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// newHTTP2Client constructs a connected ClientTransport to addr based on HTTP2</span><br><span class="hljs-comment">// and starts to receive messages on it. Non-nil error returns if construction</span><br><span class="hljs-comment">// fails.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newHTTP2Client</span><span class="hljs-params">(connectCtx, ctx context.Context, addr resolver.Address, opts ConnectOptions, onPrefaceReceipt <span class="hljs-keyword">func</span>()</span>, <span class="hljs-title">onGoAway</span> <span class="hljs-title">func</span><span class="hljs-params">(GoAwayReason)</span>, <span class="hljs-title">onClose</span> <span class="hljs-title">func</span><span class="hljs-params">()</span>) <span class="hljs-params">(_ *http2Client, err error)</span></span> &#123;<br>    ...<br><span class="hljs-keyword">if</span> t.keepaliveEnabled &#123;<br>t.kpDormancyCond = sync.NewCond(&amp;t.mu)<br><span class="hljs-keyword">go</span> t.keepalive()<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来，看下 <a href="https://github.com/grpc/grpc-go/blob/master/internal/transport/http2_client.go#L1350"><code>keepalive</code> 方法</a> 的实现：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(t *http2Client)</span> <span class="hljs-title">keepalive</span><span class="hljs-params">()</span></span> &#123;<br>p := &amp;ping&#123;data: [<span class="hljs-number">8</span>]<span class="hljs-keyword">byte</span>&#123;&#125;&#125; <span class="hljs-comment">//ping 的内容</span><br>timer := time.NewTimer(t.kp.Time) <span class="hljs-comment">// 启动一个定时器, 触发时间为配置的 Time 值</span><br><span class="hljs-comment">//for loop</span><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-comment">// 定时器触发</span><br><span class="hljs-keyword">case</span> &lt;-timer.C:<br><span class="hljs-keyword">if</span> atomic.CompareAndSwapUint32(&amp;t.activity, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>) &#123;<br>timer.Reset(t.kp.Time)<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-comment">// Check if keepalive should go dormant.</span><br>t.mu.Lock()<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(t.activeStreams) &lt; <span class="hljs-number">1</span> &amp;&amp; !t.kp.PermitWithoutStream &#123;<br><span class="hljs-comment">// Make awakenKeepalive writable.</span><br>&lt;-t.awakenKeepalive<br>t.mu.Unlock()<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-t.awakenKeepalive:<br><span class="hljs-comment">// If the control gets here a ping has been sent</span><br><span class="hljs-comment">// need to reset the timer with keepalive.Timeout.</span><br><span class="hljs-keyword">case</span> &lt;-t.ctx.Done():<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>t.mu.Unlock()<br><span class="hljs-keyword">if</span> channelz.IsOn() &#123;<br>atomic.AddInt64(&amp;t.czData.kpCount, <span class="hljs-number">1</span>)<br>&#125;<br><span class="hljs-comment">// Send ping.</span><br>t.controlBuf.put(p)<br>&#125;<br><br><span class="hljs-comment">// By the time control gets here a ping has been sent one way or the other.</span><br>timer.Reset(t.kp.Timeout)<br><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-timer.C:<br><span class="hljs-keyword">if</span> atomic.CompareAndSwapUint32(&amp;t.activity, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>) &#123;<br>timer.Reset(t.kp.Time)<br><span class="hljs-keyword">continue</span><br>&#125;<br>t.Close()<br><span class="hljs-keyword">return</span><br><span class="hljs-keyword">case</span> &lt;-t.ctx.Done():<br><span class="hljs-keyword">if</span> !timer.Stop() &#123;<br>&lt;-timer.C<br>&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// 上层通知 context 结束</span><br><span class="hljs-keyword">case</span> &lt;-t.ctx.Done():<br><span class="hljs-keyword">if</span> !timer.Stop() &#123;<br><span class="hljs-comment">// 返回 false，表示 timer 未被销毁</span><br>&lt;-timer.C<br>&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从客户端的 <code>keepalive</code> 实现中梳理下执行逻辑：</p><ol><li>填充 <code>ping</code> 包内容, 为 <code>[8]byte&#123;&#125;</code>，创建定时器, 触发时间为用户配置中的 <code>Time</code></li><li>循环处理，select 的两大分支，一为定时器触发后执行的逻辑，另一分支为 <code>t.ctx.Done()</code>，即 <code>keepalive</code> 的上层应用调用了 <code>cancel</code> 结束 context 子树</li><li>核心逻辑在定时器触发的过程中</li></ol><h4 id="2-2-服务端keepalive">2.2 服务端keepalive</h4><p>gRPC 的服务端主要有两块逻辑：</p><ol><li>接收并相应客户端的 ping 包</li><li>单独启动 goroutine 探测客户端是否存活</li></ol><p>gRPC 服务端提供 keepalive 配置，分为两部分 <code>keepalive.EnforcementPolicy</code> 和 <code>keepalive.ServerParameters</code>，如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">var</span> kaep = keepalive.EnforcementPolicy&#123;<br>MinTime:             <span class="hljs-number">5</span> * time.Second, <span class="hljs-comment">// If a client pings more than once every 5 seconds, terminate the connection</span><br>PermitWithoutStream: <span class="hljs-literal">true</span>,            <span class="hljs-comment">// Allow pings even when there are no active streams</span><br>&#125;<br><br><span class="hljs-keyword">var</span> kasp = keepalive.ServerParameters&#123;<br>MaxConnectionIdle:     <span class="hljs-number">15</span> * time.Second, <span class="hljs-comment">// If a client is idle for 15 seconds, send a GOAWAY</span><br>MaxConnectionAge:      <span class="hljs-number">30</span> * time.Second, <span class="hljs-comment">// If any connection is alive for more than 30 seconds, send a GOAWAY</span><br>MaxConnectionAgeGrace: <span class="hljs-number">5</span> * time.Second,  <span class="hljs-comment">// Allow 5 seconds for pending RPCs to complete before forcibly closing connections</span><br>Time:                  <span class="hljs-number">5</span> * time.Second,  <span class="hljs-comment">// Ping the client if it is idle for 5 seconds to ensure the connection is still active</span><br>Timeout:               <span class="hljs-number">1</span> * time.Second,  <span class="hljs-comment">// Wait 1 second for the ping ack before assuming the connection is dead</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>...<br>s := grpc.NewServer(grpc.KeepaliveEnforcementPolicy(kaep), grpc.KeepaliveParams(kasp))<br>...<br>&#125;<br></code></pre></td></tr></table></figure><p><code>keepalive.EnforcementPolicy</code>：</p><ul><li><code>MinTime</code>：如果客户端两次 ping 的间隔小于 <code>5s</code>，则关闭连接</li><li><code>PermitWithoutStream</code>： 即使没有 active stream, 也允许 ping</li></ul><p><code>keepalive.ServerParameters</code>：</p><ul><li><code>MaxConnectionIdle</code>：如果一个 client 空闲超过 <code>15s</code>, 发送一个 GOAWAY, 为了防止同一时间发送大量 GOAWAY, 会在 <code>15s</code> 时间间隔上下浮动 <code>15*10%</code>, 即 <code>15+1.5</code> 或者 <code>15-1.5</code></li><li><code>MaxConnectionAge</code>：如果任意连接存活时间超过 <code>30s</code>, 发送一个 GOAWAY</li><li><code>MaxConnectionAgeGrace</code>：在强制关闭连接之间, 允许有 <code>5s</code> 的时间完成 pending 的 rpc 请求</li><li><code>Time</code>： 如果一个 client 空闲超过 <code>5s</code>, 则发送一个 ping 请求</li><li><code>Timeout</code>： 如果 ping 请求 <code>1s</code> 内未收到回复, 则认为该连接已断开</li></ul><p>服务端处理客户端的 <code>ping</code> 包的 response 的逻辑在 <a href="https://github.com/grpc/grpc-go/blob/master/internal/transport/http2_server.go#L693"><code>handlePing</code> 方法</a> 中。<br><code>handlePing</code> 方法会判断是否违反两条 policy, 如果违反则将 <code>pingStrikes++</code>, 当违反次数大于 <code>maxPingStrikes(2)</code> 时, 打印一条错误日志并且发送一个 goAway 包，断开这个连接，具体实现如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(t *http2Server)</span> <span class="hljs-title">handlePing</span><span class="hljs-params">(f *http2.PingFrame)</span></span> &#123;<br><span class="hljs-keyword">if</span> f.IsAck() &#123;<br><span class="hljs-keyword">if</span> f.Data == goAwayPing.data &amp;&amp; t.drainChan != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">close</span>(t.drainChan)<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// Maybe it&#x27;s a BDP ping.</span><br><span class="hljs-keyword">if</span> t.bdpEst != <span class="hljs-literal">nil</span> &#123;<br>t.bdpEst.calculate(f.Data)<br>&#125;<br><span class="hljs-keyword">return</span><br>&#125;<br>pingAck := &amp;ping&#123;ack: <span class="hljs-literal">true</span>&#125;<br><span class="hljs-built_in">copy</span>(pingAck.data[:], f.Data[:])<br>t.controlBuf.put(pingAck)<br><br>now := time.Now()<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>t.lastPingAt = now<br>&#125;()<br><span class="hljs-comment">// A reset ping strikes means that we don&#x27;t need to check for policy</span><br><span class="hljs-comment">// violation for this ping and the pingStrikes counter should be set</span><br><span class="hljs-comment">// to 0.</span><br><span class="hljs-keyword">if</span> atomic.CompareAndSwapUint32(&amp;t.resetPingStrikes, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>) &#123;<br>t.pingStrikes = <span class="hljs-number">0</span><br><span class="hljs-keyword">return</span><br>&#125;<br>t.mu.Lock()<br>ns := <span class="hljs-built_in">len</span>(t.activeStreams)<br>t.mu.Unlock()<br><span class="hljs-keyword">if</span> ns &lt; <span class="hljs-number">1</span> &amp;&amp; !t.kep.PermitWithoutStream &#123;<br><span class="hljs-comment">// Keepalive shouldn&#x27;t be active thus, this new ping should</span><br><span class="hljs-comment">// have come after at least defaultPingTimeout.</span><br><span class="hljs-keyword">if</span> t.lastPingAt.Add(defaultPingTimeout).After(now) &#123;<br>t.pingStrikes++<br>&#125;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// Check if keepalive policy is respected.</span><br><span class="hljs-keyword">if</span> t.lastPingAt.Add(t.kep.MinTime).After(now) &#123;<br>t.pingStrikes++<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">if</span> t.pingStrikes &gt; maxPingStrikes &#123;<br><span class="hljs-comment">// Send goaway and close the connection.</span><br><span class="hljs-keyword">if</span> logger.V(logLevel) &#123;<br>logger.Errorf(<span class="hljs-string">&quot;transport: Got too many pings from the client, closing the connection.&quot;</span>)<br>&#125;<br>t.controlBuf.put(&amp;goAway&#123;code: http2.ErrCodeEnhanceYourCalm, debugData: []<span class="hljs-keyword">byte</span>(<span class="hljs-string">&quot;too_many_pings&quot;</span>), closeConn: <span class="hljs-literal">true</span>&#125;)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意，对 <code>pingStrikes</code> 累加的逻辑：</p><ul><li><p><code>t.lastPingAt.Add(defaultPingTimeout).After(now)</code>：</p></li><li><p><code>t.lastPingAt.Add(t.kep.MinTime).After(now)</code>：</p></li></ul><p>gRPC 服务端新建一个 HTTP2 server 的时候会启动一个单独的 goroutine 处理 keepalive 逻辑，<a href="https://github.com/grpc/grpc-go/blob/master/internal/transport/http2_server.go#L129"><code>newHTTP2Server</code> 方法</a>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newHTTP2Server</span><span class="hljs-params">(conn net.Conn, config *ServerConfig)</span> <span class="hljs-params">(_ ServerTransport, err error)</span></span> &#123;<br>...<br><span class="hljs-keyword">go</span> t.keepalive()<br>...<br>&#125;<br></code></pre></td></tr></table></figure><p>简单分析下 <code>keepalive</code> 的实现，核心逻辑是启动 <code>3</code> 个定时器，分别为 <code>maxIdle</code>、<code>maxAge</code> 和 <code>keepAlive</code>，然后在 <code>for select</code> 中处理相关定时器触发事件：</p><ul><li><code>maxIdle</code> 逻辑： 判断 client 空闲时间是否超出配置的时间, 如果超时, 则调用 <code>t.drain</code>, 该方法会发送一个 GOAWAY 包</li><li><code>maxAge</code> 逻辑： 触发之后首先调用 <code>t.drain</code> 发送 GOAWAY 包, 接着重置定时器, 时间设置为 <code>MaxConnectionAgeGrace</code>, 再次触发后调用 <code>t.Close()</code> 直接关闭（有些 graceful 的意味）</li><li><code>keepalive</code> 逻辑： 首先判断 activity 是否为 <code>1</code>, 如果不是则置 <code>pingSent</code> 为 <code>true</code>, 并且发送 ping 包, 接着重置定时器时间为 <code>Timeout</code>, 再次触发后如果 activity 不为 1（即未收到 ping 的回复） 并且 <code>pingSent</code> 为 <code>true</code>, 则调用 <code>t.Close()</code> 关闭连接</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs stylus">func (t *http2Server) keepalive() &#123;<br><span class="hljs-selector-tag">p</span> := &amp;ping&#123;&#125;<br><span class="hljs-selector-tag">var</span> pingSent bool<br>maxIdle := <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.NewTimer</span>(t<span class="hljs-selector-class">.kp</span>.MaxConnectionIdle)<br>maxAge := <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.NewTimer</span>(t<span class="hljs-selector-class">.kp</span>.MaxConnectionAge)<br>keepalive := <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.NewTimer</span>(t<span class="hljs-selector-class">.kp</span>.Time)<br><span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> All exit paths of this function should reset their</span><br><span class="hljs-comment">// respective timers. A failure to do so will cause the</span><br><span class="hljs-comment">// following clean-up to deadlock and eventually leak.</span><br>defer func() &#123;<br><span class="hljs-comment">// 退出前，完成定时器的回收工作</span><br><span class="hljs-keyword">if</span> !maxIdle<span class="hljs-selector-class">.Stop</span>() &#123;<br>&lt;-maxIdle<span class="hljs-selector-class">.C</span><br>&#125;<br><span class="hljs-keyword">if</span> !maxAge<span class="hljs-selector-class">.Stop</span>() &#123;<br>&lt;-maxAge<span class="hljs-selector-class">.C</span><br>&#125;<br><span class="hljs-keyword">if</span> !keepalive<span class="hljs-selector-class">.Stop</span>() &#123;<br>&lt;-keepalive<span class="hljs-selector-class">.C</span><br>&#125;<br>&#125;()<br><span class="hljs-keyword">for</span> &#123;<br>select &#123;<br>case &lt;-maxIdle<span class="hljs-selector-class">.C</span>:<br>t<span class="hljs-selector-class">.mu</span><span class="hljs-selector-class">.Lock</span>()<br>idle := t<span class="hljs-selector-class">.idle</span><br><span class="hljs-keyword">if</span> idle<span class="hljs-selector-class">.IsZero</span>() &#123; <span class="hljs-comment">// The connection is non-idle.</span><br>t<span class="hljs-selector-class">.mu</span><span class="hljs-selector-class">.Unlock</span>()<br>maxIdle<span class="hljs-selector-class">.Reset</span>(t<span class="hljs-selector-class">.kp</span>.MaxConnectionIdle)<br>continue<br>&#125;<br>val := t<span class="hljs-selector-class">.kp</span><span class="hljs-selector-class">.MaxConnectionIdle</span> - <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.Since</span>(idle)<br>t<span class="hljs-selector-class">.mu</span><span class="hljs-selector-class">.Unlock</span>()<br><span class="hljs-keyword">if</span> val &lt;= <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// The connection has been idle for a duration of keepalive.MaxConnectionIdle or more.</span><br><span class="hljs-comment">// Gracefully close the connection.</span><br>t<span class="hljs-selector-class">.drain</span>(http2<span class="hljs-selector-class">.ErrCodeNo</span>, <span class="hljs-selector-attr">[]</span>byte&#123;&#125;)<br><span class="hljs-comment">// Resetting the timer so that the clean-up doesn&#x27;t deadlock.</span><br>maxIdle<span class="hljs-selector-class">.Reset</span>(infinity)<br>return<br>&#125;<br>maxIdle<span class="hljs-selector-class">.Reset</span>(val)<br>case &lt;-maxAge<span class="hljs-selector-class">.C</span>:<br>t<span class="hljs-selector-class">.drain</span>(http2<span class="hljs-selector-class">.ErrCodeNo</span>, <span class="hljs-selector-attr">[]</span>byte&#123;&#125;)<br>maxAge<span class="hljs-selector-class">.Reset</span>(t<span class="hljs-selector-class">.kp</span>.MaxConnectionAgeGrace)<br>select &#123;<br>case &lt;-maxAge<span class="hljs-selector-class">.C</span>:<br><span class="hljs-comment">// Close the connection after grace period.</span><br>t<span class="hljs-selector-class">.Close</span>()<br><span class="hljs-comment">// Resetting the timer so that the clean-up doesn&#x27;t deadlock.</span><br>maxAge<span class="hljs-selector-class">.Reset</span>(infinity)<br>case &lt;-t<span class="hljs-selector-class">.ctx</span><span class="hljs-selector-class">.Done</span>():<br>&#125;<br>return<br>case &lt;-keepalive<span class="hljs-selector-class">.C</span>:<br><span class="hljs-keyword">if</span> atomic<span class="hljs-selector-class">.CompareAndSwapUint32</span>(&amp;t<span class="hljs-selector-class">.activity</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>) &#123;<br>pingSent = false<br>keepalive<span class="hljs-selector-class">.Reset</span>(t<span class="hljs-selector-class">.kp</span>.Time)<br>continue<br>&#125;<br><span class="hljs-keyword">if</span> pingSent &#123;<br>t<span class="hljs-selector-class">.Close</span>()<br><span class="hljs-comment">// Resetting the timer so that the clean-up doesn&#x27;t deadlock.</span><br>keepalive<span class="hljs-selector-class">.Reset</span>(infinity)<br>return<br>&#125;<br>pingSent = true<br><span class="hljs-keyword">if</span> channelz<span class="hljs-selector-class">.IsOn</span>() &#123;<br>atomic<span class="hljs-selector-class">.AddInt64</span>(&amp;t<span class="hljs-selector-class">.czData</span><span class="hljs-selector-class">.kpCount</span>, <span class="hljs-number">1</span>)<br>&#125;<br>t<span class="hljs-selector-class">.controlBuf</span><span class="hljs-selector-class">.put</span>(p)<br>keepalive<span class="hljs-selector-class">.Reset</span>(t<span class="hljs-selector-class">.kp</span>.Timeout)<br>case &lt;-t<span class="hljs-selector-class">.ctx</span><span class="hljs-selector-class">.Done</span>():<br>return<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1>三、通信报文格式</h1><p>Protocol Buffers 是一种与语言、平台无关，可扩展的序列化结构化数据的方法，常用于通信协议，数据存储等等。相较于 JSON、XML，它更小、更快、更简单，因此也更受开发人员的青眯。</p><h1>四、拦截器</h1><p>在 gRPC 调用过程中，我们可以拦截 RPC 的执行，在 RPC 服务执行前或执行后运行一些自定义逻辑，这在某些场景下很有用，例如身份验证、日志等，我们可以在 RPC 服务执行前检查调用方的身份信息，若未通过验证，则拒绝执行，也可以在执行前后记录下详细的请求响应信息到日志。这种拦截机制与 Gin 中的中间件技术类似，在 gRPC 中被称为 <strong>拦截器</strong>，它是 gRPC 核心扩展机制之一</p><p>拦截器不止可以作用在服务端上，客户端同样可以拦截，在请求发出之前和收到响应之后执行一些自定义逻辑，根据拦截的 RPC 类型，可分为 <strong>一元拦截器</strong> 和 <strong>流拦截器</strong>。</p><h2 id="1-服务端拦截器">1. 服务端拦截器</h2><p>在 gRPC 服务端，可以插入一个或多个拦截器，收到的请求按注册顺序通过各个拦截器，返回响应时则倒序通过。</p><h3 id="1-1-一元拦截器">1.1 一元拦截器</h3><p>通过以下步骤实现一元拦截器：</p><ul><li>定义一元拦截器方法：</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 函数名无特殊要求，参数需一致</span><br><span class="hljs-comment">// req包含请求的所有信息，info包含一元RPC服务的所有信息</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">orderUnaryServerInterceptor</span><span class="hljs-params">(ctx context.Context, req <span class="hljs-keyword">interface</span>&#123;&#125;, info *grpc.UnaryServerInfo,</span></span><br><span class="hljs-params"><span class="hljs-function">handler grpc.UnaryHandler)</span> <span class="hljs-params">(<span class="hljs-keyword">interface</span>&#123;&#125;, error)</span></span> &#123;<br>        <span class="hljs-comment">// 前置处理逻辑</span><br>        log.Printf(<span class="hljs-string">&quot;[unary interceptor request] %s&quot;</span>, info.FullMethod)<br>        <span class="hljs-comment">// 完成RPC服务的正常执行</span><br>        m, err := handler(ctx, req)<br>        <span class="hljs-comment">// 后置处理逻辑</span><br>        log.Printf(<span class="hljs-string">&quot;[unary interceptor resonse] %s&quot;</span>, m)<br>        <span class="hljs-comment">// 返回响应</span><br>        <span class="hljs-keyword">return</span> m, err<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>注册定义的一元拦截器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ...<br><span class="hljs-comment">// 创建gRPC服务器实例的时候注册拦截器</span><br>    <span class="hljs-comment">// NewServer 可传入多个拦截器</span><br>s := grpc.NewServer(grpc.UnaryInterceptor(orderUnaryServerInterceptor))<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-2-流拦截器">1.2 流拦截器</h3><p>流拦截器包括前置处理阶段和流操作阶段，前置处理阶段可以在流 RPC 进入具体服务实现之前进行拦截，而在流操作阶段，可以对流中的每一条消息进行拦截，通过以下步骤实现流拦截器：</p><ul><li>自定义一个嵌入grpc.ServerStream的包装器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> wrappedStream <span class="hljs-keyword">struct</span> &#123;<br>grpc.ServerStream<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>实现包装器的 RecvMsg 和 SendMsg 方法</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 自定义RecvMsg和SendMsg方法实现对每一个流消息的拦截</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *wrappedStream)</span> <span class="hljs-title">RecvMsg</span><span class="hljs-params">(m <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br>log.Printf(<span class="hljs-string">&quot;[stream interceptor recv] type: %T&quot;</span>, m)<br><span class="hljs-keyword">return</span> w.ServerStream.RecvMsg(m)<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *wrappedStream)</span> <span class="hljs-title">SendMsg</span><span class="hljs-params">(m <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br>log.Printf(<span class="hljs-string">&quot;[stream interceptor send] %s&quot;</span>, m)<br><span class="hljs-keyword">return</span> w.ServerStream.SendMsg(m)<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>实现流拦截器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">orderServerStreamInterceptor</span><span class="hljs-params">(srv <span class="hljs-keyword">interface</span>&#123;&#125;, ss grpc.ServerStream,</span></span><br><span class="hljs-params"><span class="hljs-function">info *grpc.StreamServerInfo, handler grpc.StreamHandler)</span> <span class="hljs-title">error</span></span> &#123;<br>    <span class="hljs-comment">// 前置处理阶段</span><br>log.Printf(<span class="hljs-string">&quot;[stream interceptor request] %s&quot;</span>, info.FullMethod)<br><span class="hljs-comment">// 使用自定义包装器处理流</span><br>err := handler(srv, &amp;wrappedStream&#123;ss&#125;)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>log.Printf(<span class="hljs-string">&quot;[stream Intercept error] %v&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">return</span> err<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>注册流拦截器</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ...<br>s := grpc.NewServer(grpc.StreamInterceptor(orderServerStreamInterceptor))<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-客户端拦截器">2. 客户端拦截器</h2><p>在服务端可以拦截收到的 RPC 调用，客户端同样可以拦截发出去的 RPC 请求以及收到的响应，同样可以实现一元拦截器以及流拦截器。</p><h3 id="2-1-一元拦截器">2.1 一元拦截器</h3><p>和服务端一元拦截器一样的方法，只是方法参数略微有所差别，此外在建立连接的时候注册拦截器，同样可以注册多个拦截器：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// method请求方法字符串，req包含请求的所有信息参数等，reply在实际RPC调用后存储响应信息，通过invoker实际调用</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">orderUnaryClientInterceptor</span><span class="hljs-params">(ctx context.Context, method <span class="hljs-keyword">string</span>, req, reply <span class="hljs-keyword">interface</span>&#123;&#125;,</span></span><br><span class="hljs-params"><span class="hljs-function">cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption)</span> <span class="hljs-title">error</span></span> &#123;<br><span class="hljs-comment">// 前置处理阶段</span><br>log.Println(<span class="hljs-string">&quot;method: &quot;</span> + method)<br><span class="hljs-comment">// 实际的RPC调用</span><br>err := invoker(ctx, method, req, reply, cc, opts...)<br><span class="hljs-comment">// 后置处理</span><br>log.Println(reply)<br><span class="hljs-keyword">return</span> err<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ...<br>conn, err := grpc.Dial(address, grpc.WithInsecure(),           grpc.WithUnaryInterceptor(orderUnaryClientInterceptor))<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-2-流拦截器">2.2 流拦截器</h3><p>流拦截器也是和服务端一样的步骤：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> wrappedStream <span class="hljs-keyword">struct</span> &#123;<br>grpc.ClientStream<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *wrappedStream)</span> <span class="hljs-title">SendMsg</span><span class="hljs-params">(m <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br>log.Printf(<span class="hljs-string">&quot;[stream interceptor send] %s&quot;</span>, m)<br><span class="hljs-keyword">return</span> w.ClientStream.SendMsg(m)<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *wrappedStream)</span> <span class="hljs-title">RecvMsg</span><span class="hljs-params">(m <span class="hljs-keyword">interface</span>&#123;&#125;)</span> <span class="hljs-title">error</span></span> &#123;<br>log.Printf(<span class="hljs-string">&quot;[stream interceptor recv] type: %T&quot;</span>, m)<br><span class="hljs-keyword">return</span> w.ClientStream.RecvMsg(m)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">orderClientStreamInterceptor</span><span class="hljs-params">(ctx context.Context, desc *grpc.StreamDesc,</span></span><br><span class="hljs-params"><span class="hljs-function">cc *grpc.ClientConn, method <span class="hljs-keyword">string</span>, streamer grpc.Streamer, opts ...grpc.CallOption)</span> <span class="hljs-params">(grpc.ClientStream, error)</span></span> &#123;<br>    <span class="hljs-comment">// 前置处理阶段，RPC请求发出之前拦截</span><br>log.Printf(<span class="hljs-string">&quot;[client interceptor send] %s&quot;</span>, method)<br>    <span class="hljs-comment">// 发出RPC请求</span><br>s, err := streamer(ctx, desc, cc, method, opts...)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><span class="hljs-keyword">return</span> &amp;wrappedStream&#123;s&#125;, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ...<br>conn, err := grpc.Dial(address, grpc.WithInsecure(),<br>grpc.WithStreamInterceptor(orderClientStreamInterceptor))<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h1>五、gRPC特性</h1><p>多语言</p><p>轻量级、高性能：序列化支持PB和JSON</p><p>IDL：基于文件定义服务，通过proto3工具生成指定语言的数据结构、服务端接口以及客户端Stub。</p><p>移动端：基于标准的HTTP/2设计，支持双向流、消息头压缩、单TCP的多路复用、服务端推送等特性。</p><p>元数据交换</p><p>标准化状态码</p><h1>六、HealthCheck</h1><p>gRPC有一个标准的健康检测协议，在gRPC的所有语言实现中基本都提供了生成代码和用于设置运行状态的功能。</p><p>HealthCheck可以在服务提供者服务不稳定时，被消费者感知，临时从负载均衡中摘除，减少错误请求。当服务提供者重新稳定后，health check成功，重新加入到消费者的负载均衡，恢复请求。同样也会被用于外挂方式的容器健康监测，或者流量监测。</p><h2 id="平滑下线">平滑下线</h2><ol><li>K8S向discovery发起注销请求，发送一个kill信号。</li><li>K8S向APP发送SIGTER信号，进入优雅退出过程，把自己标志成跛脚鸭状态，就算没有收到节点的下线请求，也可以通过HC的机制下线，几种方式保障。</li><li>其他客户端在2个心跳周期内退出，如果有正在运行的连接请求，要等待结束后才退出。</li><li>K8S退出超时，强制退出SIGKILL。</li></ol><h1>七、服务发现</h1><h2 id="客户端发现">客户端发现</h2><p>一个服务实例被启动后，他的网络地址会被写到注册表上；当服务实例终止时，再从注册表删除；这种服务实例的注册表通过心跳机制动态刷新；客户端使用一个负载均衡算法，去选择一个可用的服务实例，来响应这个请求。</p><h2 id="服务端发现">服务端发现</h2><p>客户端通过负载均衡器向一个服务发送请求，这个负载均衡器会查询服务服务注册表，并将请求路由到可用的服务实例上。服务实例再服务注册表上被注册和注销。</p><p>客户端发现是直连，服务端发现是集中式部署。</p><p>通常可以使用zookeeper作为服务发现</p>]]></content>
    
    
    <categories>
      
      <category>gRPC</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gRPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JWT</title>
    <link href="/2022/12/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E9%89%B4%E6%9D%83%E6%9C%BA%E5%88%B6/01.jwt/"/>
    <url>/2022/12/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E9%89%B4%E6%9D%83%E6%9C%BA%E5%88%B6/01.jwt/</url>
    
    <content type="html"><![CDATA[<h2 id="1-摘要">1. 摘要</h2><p>JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案，本质就是一个字符串书写规范，作用是用来在用户和服务器之间传递安全可靠的信息。</p><h2 id="2-JWT是什么">2. JWT是什么</h2><p>根据维基百科的定义，JSON WEB Token（JWT，读作 [/dʒɒt/]），是一种基于JSON的、用于在网络上声明某种主张的令牌（token）。JWT通常由三部分组成: 头信息（header）, 消息体（payload）和签名（signature）。</p><p>在目前前后端分离的开发过程中，使用token鉴权机制用于身份验证是最常见的方案，流程如下</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7bc95b7fab854121900bfa9db432d1c3~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt="Image.png"></p><ol><li>假设用户要登录一个APP，用户就需要输入用户名和密码，然后发送给APP的服务器</li><li>服务器验证过用户发来的用户名和密码后，就会生成一个token，</li><li>服务端返回JWT信息给用户，JWT中</li><li>用户发送请求的时候一般会在HTTP头部加上这个Token</li><li>服务器收到Token后，对Token进行核实，Token验证通过，且没有过期</li><li>用户直接登录，不需要再次输入用户名密码，服务器只需识别头部的Token就可以确认用户身份</li></ol><p>这里生成的Token就用的JWT这种数据结构</p><p>✒️Token的携带 token可以放在Cookie，Authorization，或者Body里面</p><h2 id="3-JWT-的数据结构">3. JWT 的数据结构</h2><p>Token，分成了三部分，头部（Header）、载荷（Payload）、签名（Signature），并以.进行拼接。其中头部和载荷都是以JSON格式存放数据，只是进行了base64 编码(secret 部分是否进行 base64 编码是可选的，header 和 payload 则是必须进行 base64 编码)，由于编码过程是可逆的，如果得知编码方式后，那么整个 jwt 串便是明文了，所以pyaload中一定不能放密码等重要信息。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5a979f6cbd9e48eda11c79268ad975f4~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt="Image [2].png"></p><h4 id="header">header</h4><p>Token，分成了三部分，头部（Header）、载荷（Payload）、签名（Signature），并以.进行拼接。其中头部和载荷都是以JSON格式存放数据，只是进行了base64 编码(secret 部分是否进行 base64 编码是可选的，header 和 payload 则是必须进行 base64 编码)，由于编码过程是可逆的，如果得知编码方式后，那么整个 jwt 串便是明文了，所以pyaload中一定不能放密码等重要信息。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5a979f6cbd9e48eda11c79268ad975f4~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?" alt="Image [2].png"></p><h4 id="header-2">header</h4><p>头部主要是用来指明签名的算法，避免消息被篡改，JWT 中常用的签名算法是 HS256，常见的还有md5,sha 等，签名算法是不可逆的。声明算法的字段名为alg，同时还有一个typ的字段，默认JWT即可。以下示例中算法为HS256。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&#123;<span class="hljs-string">&quot;alg&quot;</span>: HS256, <span class="hljs-string">&quot;typ&quot;</span>: <span class="hljs-string">&quot;JWT&quot;</span>&#125;<br></code></pre></td></tr></table></figure><h4 id="payload">payload</h4><p>负载主要是用来存放数据，一般可以存放相应用户数据来生成不同的JWT</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-string">&quot;payload&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;data&quot;</span>: [<br>          &#123;<br>            <span class="hljs-string">&quot;tooltt&quot;</span>: <span class="hljs-string">&quot;https://tooltt.com&quot;</span><br>          &#125;<br>        ],<br>        <span class="hljs-string">&quot;iat&quot;</span>: <span class="hljs-number">1650451633</span>,<br>        <span class="hljs-string">&quot;exp&quot;</span>: <span class="hljs-number">1650556799</span><br>  &#125;<br></code></pre></td></tr></table></figure><p>JWT规定了7个官方字段，供选用</p><ul><li>iss (issuer)：签发人</li><li>exp (expiration time)：过期时间</li><li>sub (subject)：主题</li><li>aud (audience)：受众</li><li>nbf (Not Before)：生效时间</li><li>iat (Issued At)：签发时间</li><li>jti (JWT ID)：编号</li></ul><p>除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs javascript">&#123;<br>      <span class="hljs-string">&quot;sub&quot;</span>: <span class="hljs-string">&quot;1234567890&quot;</span>,<br>      <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;John Doe&quot;</span>,<br>      <span class="hljs-string">&quot;admin&quot;</span>: <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>由于编码的可逆性，不要把秘密信息放在这个部分。</p><h4 id="Signature">Signature</h4><p>签名是对头部和负载两个部分进行签名，防止数据篡改。 签名里面有个核心就是要定义一个密钥，这个密钥只有服务器能知道，然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。 公式如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">token, err = tokenClaims.SignedString([]<span class="hljs-keyword">byte</span>(JwtKey))<br></code></pre></td></tr></table></figure><p>一旦前面两部分数据被篡改，只要服务器加密用的密钥没有泄露，得到的签名肯定和之前的签名不一致</p><h3 id="验证流程：">验证流程：</h3><ul><li>在头部信息中声明加密算法和常量，然后把header使用json转化为字符串</li><li>在载荷中声明用户信息，同时还有一些其他的内容，再次使用json把在和部分进行转化，转化为字符串</li><li>使用在header中声明的加密算法来进行加密，把第一部分字符串和第二部分的字符串结合和每个项目随机生成的secret字符串进行加密，生成新的字符串，此字符串是独一无二的</li><li>解密的时候，只要客户端带着jwt来发起请求，服务端就直接使用secret进行解密，解签证解出第一部分和第二部分，然后比对第二部分的信息和客户端穿过来的信息是否一致。如果一致验证成功，否则验证失败。</li></ul><h3 id="两种登录状态">两种登录状态</h3><h4 id="有状态登录">有状态登录</h4><p>为了保证客户端cookie的安全性，服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，典型的设计如tomcat中的session。</p><p>例如登录：用户登录后，我们把登录者的信息保存在服务端session中，并且给用户一个cookie值，记录对应的session。然后下次请求，用户携带cookie值来，我们就能识别到对应session，从而找到用户的信息。</p><p>缺点是什么？</p><ul><li>服务端保存大量数据，增加服务端压力</li><li>服务端保存用户状态，无法进行水平扩展</li><li>客户端请求依赖服务端，多次请求必须访问同一台服务器</li><li>即使使用redis保存用户的信息，也会损耗服务器资源。</li></ul><h4 id="无状态登录">无状态登录</h4><p>微服务集群中的每个服务，对外提供的都是Rest风格的接口。而Rest风格的一个最重要的规范就是：服务的无状态性，即：</p><p>服务端不保存任何客户端请求者信息<br>客户端的每次请求必须具备自描述信息，通过这些信息识别客户端身份</p><p>带来的好处是什么呢？</p><ul><li>客户端请求不依赖服务端的信息，任何多次请求不需要必须访问到同一台服务</li><li>服务端的集群和状态对客户端透明</li><li>服务端可以任意的迁移和伸缩</li><li>减小服务端存储压力</li></ul><p>无状态登录的流程：</p><ul><li>当客户端第一次请求服务时，服务端对用户进行信息认证（登录）</li><li>认证通过，将用户信息进行加密形成token，返回给客户端，作为登录凭证</li><li>以后每次请求，客户端都携带认证的token</li><li>服务的对token进行解密，判断是否有效。</li></ul><h3 id="单点登录">单点登录</h3><h5 id="Jwt-认证中心redis-多系统redis">Jwt + 认证中心redis + 多系统redis</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-number">1</span>.用户去认证中心登录，认证中心生成jwt，保存到redis并返回给客户端。<br>  <span class="hljs-number">2</span>.客户端携带jwt去多个系统认证  <br>    <span class="hljs-number">3</span>.多系统(比如系统<span class="hljs-selector-tag">A</span>)收到jwt，<span class="hljs-selector-tag">A</span>解析并取出用户信息，先判断自己的<span class="hljs-selector-tag">A</span>的redis中有没有jwt。<br>    <span class="hljs-number">3.1</span> 如果有，就合法，<span class="hljs-selector-tag">a</span>系统可以继续执行业务逻辑。<br>        <span class="hljs-number">3.2</span> 如果没有就拿着jwt去认证中心验证。<br>        <span class="hljs-number">3.2</span>.<span class="hljs-number">1</span> 如果通过，<span class="hljs-selector-tag">a</span>系统就把这个jwt保存到自己的redis，并设置对应的失效时间。<br>              下次这个jwt再来到<span class="hljs-selector-tag">a</span>的时候，就不需要去认证中心校验了。<br>          <span class="hljs-number">3.2</span>.<span class="hljs-number">2</span> 如果验证不通过此次请求就不合法，告诉客户端需要跳转登录页面，<br>             去认证中心登录，返回步骤<span class="hljs-number">1</span>。<br>       <br><br>优点：安全性高，平均认证过程较快。<br><br>缺点：服务端流程复杂，需要考虑jwt的同步问题。比如注销或重新登录后，认证中心删除旧jwt需要同步给其他系统，其他系统删除自己保存的jwt。<br></code></pre></td></tr></table></figure><h3 id="JWT的优缺点">JWT的优缺点</h3><h4 id="优点">优点</h4><ul><li>JWT具有通用性，所以可以跨语言组成简单，</li><li>字节占用小，便于传输服务端无需保存会话信息，</li><li>很容易进行水平扩展一处生成，多处使用，</li><li>可以在分布式系统中，</li><li>解决单点登录问题可防护CSRF攻击</li></ul><h4 id="缺点">缺点</h4><ul><li>payload部分仅仅是进行简单编码，所以只能用于存储逻辑必需的非敏感信息</li><li>需要保护好加密密钥，一旦泄露后果不堪设想</li><li>为避免token被劫持，最好使用https协议</li></ul><h3 id="解决单点登录问题可防护CSRF攻击">解决单点登录问题可防护CSRF攻击</h3><p><strong>CSRF攻击-其他页面窃取cookie</strong></p><p>用户访问A网站(<a href="https://link.zhihu.com/?target=http%3A//www.aaa.com">http://www.aaa.com</a>)，输入用户名密码</p><p>服务器验证通过，生成sessionid并返回给客户端存入cookie</p><p>用户在没有退出或者没有关闭A网站，cookie还未过期的情况下访问恶意网站B</p><p>B网站返回含有如下代码的html：</p><p>//假设A网站注销用户的url为：<a href="https://link.zhihu.com/?target=https%3A//www.aaa.com/delete_user">https://www.aaa.com/delete_user</a></p><p>token验证过程</p><p>用户访问网站，输入账号密码登入</p><p>服务器校验通过，生成JWT，不保存JWT，直接返回给客户端</p><p>客户端将JWT存入cookie或者localStorage</p><p>此后用户发起的请求，都将使用js从cookie或者localStorage读取JWT放在http请求的header中，发给服务端</p><p><strong>服务端获取header中的JWT，用base64URL算法解码各部分内容，并在服务端用同样的秘钥和算法生成signature，与传过来的signature对比，验证JWT是否合法</strong></p><p>使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。同时用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。</p><p>不过，无论是cookie-session还是JWT，都存在被XSS攻击盗取的风险：</p><h3 id="白名单机制">白名单机制</h3><p>在中间件中执行，借鉴gin的路由前缀树思想，将所有的API路由构建成前缀树，通过请求的URL进行匹配，如果在白名单数组中接口可以直接跳过登录鉴权。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kratos</title>
    <link href="/2022/11/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/02.%E6%A1%86%E6%9E%B6/03.kratos/"/>
    <url>/2022/11/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/02.%E6%A1%86%E6%9E%B6/03.kratos/</url>
    
    <content type="html"><![CDATA[<ol><li>kratos在启动的时候，不同的server由内置的errgroup进行管理，如果app的ctx被cancel，errgroup的ctx也会被销毁</li><li>kratos在new的时候，需要传入对应的grpc和http服务，在run时，就是遍历app的servers来实现的，不管是grpc还是http，都是属于kratos的transport模块下，他们都是实现了server的start和stop方法</li><li>在server初始化时，他们都一开始就添加了拦截器，并且在拦截器中会有一个merge的方法，kratos-grpc-server的context和每个grpc请求的context合并为一个请求，</li><li>定义中间件类型，</li></ol><p>把请求的ctx和kratos的ctx合并起来(前面文章有说)</p><p>把app信息和请求的metadata等信息放到transport中,然后把transport放到前面合并的ctx中继续往下传递(前面文章有说)</p><p>最后初始化在kratos-grpc-server的多个Middleware中选出匹配的和最终要执行的handler串联起来成一个handler.</p><p>最后才是执行这个被串联出来的handler</p>]]></content>
    
    
    <categories>
      
      <category>Kratos</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kratos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GMP调度模型</title>
    <link href="/2022/11/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/08.GMP%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/11/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/08.GMP%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1>一、Goroutine</h1><h2 id="1-定义">1. 定义</h2><p><code>goroutine</code> 是 Go语言中的轻量级线程实现，由 Go 运行时（runtime）管理。Go 程序会智能地将 <code>goroutine</code>中的任务合理地分配给每个 CPU。</p><p>goroutine是一个与其他goroutines并行运行在同一地址空间的go函数或者方法。一个运行的程序由一个或者更多个goroutine组成。它与线程、协程、进程等不同。它是一个goroutine。</p><h2 id="2-goroutine-和-thread的区别">2.goroutine 和 thread的区别</h2><ol><li>内存占用。goroutine的内存开销小，一个goroutine内存开销在2k左右，而thread的开销在1-8M，并且为了防止栈溢出导致污染其他线程，线程间还有guard page的存在，内存开销大。</li><li>创建和销毁。thread是内核级的，内核调用消耗的性能代价比较高，开销较大。而goroutine是一种用户态线程，由go runtime管理，创建和销毁的销毁代价小。</li><li>调度切换。抛开陷入内核，线程切换大概是1000-1500纳秒，而goroutine切换为200ns（用户态，三个寄存器），一个纳秒平均可以执行12-18个指令，所以可以少执行12000-18000条指令，所以更快。</li><li>复杂性。线程创建和退出复杂，多个thread间通讯间复杂，不能大量创建多线程。</li></ol><h2 id="3-启动">3.启动</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span>&#123;<br><br>&#125;<br></code></pre></td></tr></table></figure><h1>二、M:N模型</h1><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5Cimage-20230321175048601.png" alt="image-20230321175048601"></p><p>go创建了M个线程，之后创建的N个goroutine都会依附在这M个线程上执行，即M:N模型。在运行时goroutine数量是远大于线程数量的，同一时刻，一个线程执行一个goroutine，而当goroutine阻塞时，go runtime会把这个goroutine调度走，让其他goroutine继续执行，而不是让线程休眠阻塞，尽可能的让CPU忙起来。</p><p><strong>Tips</strong>:线程是CPU执行调度的单元，内核的结构是task_struct，他和进程用同一个结构体，区别是有一个字段决定了地址空间是否共享。</p><h1>三、GMP模型</h1><p>G: goroutine，使用struct runtime.g，包含了当前goroutine的堆栈、状态、上下文。</p><p>M: Machine，也称为工作线程，使用struct runtime.m，所有M是有线程栈的。如果不对该线程栈提供内存提供内存，系统会给该线程栈提供内存。当指定了内存，则M.stack-&gt;G.stack，M的PC寄存器指向G提供的函数，然后去执行。</p><h2 id="1-GM调度器">1. GM调度器</h2><p>go 1.2之前的调度器，限制了go并发的伸缩性，尤其是有高吞吐或并行运算需求的服务程序。</p><p>当goroutine调用了一个阻塞的系统调用，运行这个goroutine的线程就会被阻塞，这时候就应该创建或者唤醒一个线程来运行别的没有阻塞的goroutine。线程在这里可以创建不止一个，可以按需不断创建，而活跃的线程最大个数存储在变量GOMAXPROCS中。</p><p><strong>问题</strong>：单一全局互斥锁和集中的状态存储；goroutine传递问题；Per-M持有一个内存缓存；严重的线程阻塞。</p><h2 id="2-GMP概念">2. GMP概念</h2><p>P:<code>Processor</code> G和M的调度对象，用来调度G和M之间的关系，数量可以通过GOMAXPROCS()来设置。</p><p>它代表了M所需的上下文环境，也是处理用户级代码逻辑的处理器，mcache/stackalloc从M移到了P，而G队列也被分为两类，保留全局G队列，同时每个P都会有一个本地的G队列。由于引入了本地队列，runtime不需要去进行一个集中式的调度，每一个M都会在P的本地队列，全局队列，或者其他P的队列中找G执行，减少全局锁对性能的影响。</p><p><strong>注意</strong>：P的本地队列还是可能面临一个并发访问的场景，为了避免加锁，这里P的本地队列是使用了一个叫LockFree的队列，窃取G时使用CAS原子操作来完成。</p><h2 id="3-work-stealing">3. work stealing</h2><p>当一个P执行完本地所有的G，并且全局队列为空，会尝试挑选一个P，从它的队列中窃取一半的G，否则会从全局队列获取（当前个数/GOMAXPROCS）个G。为了保证公平性，遍历的顺序也随机化了。</p><p>光窃取失败时获取是不够的，还是有可能就导致全局队列饥饿。P的调度算法中，会每N轮调度后就去全局队列中获取一个G。</p><p>谁放入的全局队列呢？新建G时，本地队列的G放不下已满并达到256时，会放半数的G到全局队列中，阻塞的系统调用如果没有空闲的P也会把G放到全局队列。</p><h2 id="4-Syscall">4. Syscall</h2><p>调用syscall后会解绑P，然后M和G进入阻塞，而P此时状态就是syscall，表明这个P的G正在syscall中，这时的P是不能被调度给别的M的。如果短时间内阻塞的M就唤醒了，那么M会优先来重新获取这个P，就能继续获取并绑定回去，这样有利于数据的局部性。</p><p>系统监视器（system monitor），称为sysmon会定时扫描。在执行syscall时，如果一个P的G执行时间超过一个syscall tick（10ms），就会把他设为idle，重新调度给需要的M，强制解绑。</p><p>而syscall结束后，M按照一下规则知道满足其中一个条件：</p><ol><li>尝试获取同一个P，恢复执行G。</li><li>尝试获取idle list中其他空闲的P，恢复执行G。</li><li>找不到空闲的P，把G放回global queue，M放回到idle list。</li></ol><h2 id="5-Spining-thread">5. Spining thread</h2><p>线程自旋是相对于线程阻塞而言的，表象就是循环执行一个指定的逻辑（调度逻辑，目的是为了不停地寻找G）。</p><p>有两个地方引入了自旋：</p><ol><li>类型1：M不带P的寻找P挂载，一有P就释放</li><li>类型2：M带P的寻找G运行，一有runable的G就会执行</li></ol><p>自旋的M最多只允许GOMAXPROCS(busy P)个。</p><p>在新G被创建、M进入系统调用，M从空闲被激活这三种状态变化前，调度器至少确保至少有一个自旋M存在（唤醒或者创建一个M），除非没有空闲的P。</p><p>当新G被创建，如果有可用的P，就意味着新G可以被立即执行，即便不在同一个P也无妨，所以我们保留一个自旋的M就可以很快被运行。</p><p>当M进入系统调用时，这个M不知道何时可以被唤醒，所以需要一个自旋M来确保执行剩下的G。</p><p>当M从空闲被激活时，意味着一个M从空闲状态开始工作了，这时要检查并确保还有一个自旋M存在，以防还有G或者P空着。</p><h2 id="6-GMP问题总结">6. GMP问题总结</h2><h3 id="6-1-单一全局互斥锁和集中状态存储">6.1 单一全局互斥锁和集中状态存储</h3><p>G被分成了全局队列和P的本地队列，全局队列依然是全局锁，但是使用场景变少，P本地队列是无锁队列，使用原子操作来面对可能得并发场景。</p><h3 id="6-2-goroutine传递问题">6.2 goroutine传递问题</h3><p>G创建时就在本地队列，避免在G之间的传递，而且G对P的数据局部性好；当G开始运行了，系统调用返回后M会尝试获取可用P，获取到了的话可以避免在M之间的传递，而且优先获取调用阻塞签的P，所以G对M和P的数据。</p><h3 id="6-3-Per-M-持有内存缓存">6.3 Per-M 持有内存缓存</h3><p>内存mcache只存在P结构中，P最多只有GOMAXPROCS个，远小于M的个数，所以内存没有过多的消耗。</p><h3 id="6-4-严重的线程阻塞-解锁">6.4 严重的线程阻塞/解锁</h3><p>通过引入自旋，保证任何时候都有处于等待状态的自旋M，避免在等待可用的P和G时频繁地阻塞和唤醒。</p><h1>三、Sysmon</h1><p>监控线程，它无需P也可以运行，他是一个死循环，每20us-10ms执行一次，循环一次之后sleep一会，为什么是动态周期呢，主要是避免空转，如果每次循环没有要做的事，就是加大sleep时间。</p><ul><li>释放闲置超过5分钟的span内存。</li><li>如果超过2分钟没有垃圾回收，强制执行</li><li>将长时间未处理的netpoll添加到全局队列</li><li>向长时间执行的G任务发出抢占调度</li><li>收回因syscall长时间阻塞的P</li></ul><p>当P在M上执行时间超过10ms，sysmon 调用 preemptone 将 G 标记为 stackPreempt 。因此需要在某个地方触发检测逻辑，Go 当前是在检查栈是否溢出的地方判定(morestack())，M 会保存当前 G 的上下文，重新进入调度逻辑。</p><p>异步抢占，注册 sigurg 信号，通过 sysmon 检测，对M对应的线程发送信号，触发注册的handler，它往当前G的PC中插入一条指令(调用某个方法)，在处理完handler，G恢复后，自己把自己推到了global queue中。</p><h1>四、协程泄漏</h1><p>排查方式：</p><ol><li>使用火焰图确定是哪一段代码内存消耗高</li><li>使用pprof top 监控是不是有地方发生了协程泄漏</li><li>使用list命令确定协程是在哪一行代码阻塞</li></ol><h1>五、Network epoller</h1><p>Go 所有的 I/O 都是阻塞的。然后通过 goroutine + channel 来处理并发。因此所有的 IO 逻辑都是直来直去的，你不再需要回调，不再需要 future，要的仅仅是 step by step。这对于代码的可读性是很有帮助的。<br>G 发起网络 I/O 操作也不会导致 M 被阻塞(仅阻塞G)，从而不会导致大量 M 被创建出来。将异步 I/O 转换为阻塞 I/O 的部分称为 netpoller。打开或接受连接都被设置为非阻塞模式。如果你试图对其进行 I/O 操作，并且文件描述符数据还没有准备好，G 会进入 gopark 函数，将当前正在执行的 G 状态保存起来，然后切换到新的堆栈上执行新的 G。</p><p><strong>那什么时候 G 被调度回来呢？</strong></p><ul><li><p>sysmon</p></li><li><p>schedule()：M 找 G 的调度函数</p></li><li><p>GC：start the world</p></li></ul><p>调用 netpoll() 在某一次调度 G 的过程中，处于就绪状态的 fd 对应的 G 就会被调度回来。</p><p>G 的 gopark 状态：G 置为 waiting 状态，等待显示 goready 唤醒，在 poller 中用得较多，还有锁、chan 等。</p><h1>六、goroutine生命周期</h1><h2 id="main方法的执行">main方法的执行</h2><p>整段程序始于一个runtime.rt0_go中，会执行很多初始工作。</p><p><img src="C:%5CUsers%5C75713%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20230322143825932.png" alt="image-20230322143825932"></p><ol><li>启动并绑定一个m0和g0，m0就是程序的主线程，g0负责调度，即shedule()函数。</li><li>创建 P，绑定 m0 和 p0，首先会创建 GOMAXPROCS 个 P ，存储在 sched 的 空闲链表(pidle)。</li><li>新建任务 g 到 p0 本地队列，m0 的 g0 会创建一个 指向 runtime.main() 的 g ，并放到 p0 的本地队列。</li><li>runtime.main(): 启动 sysmon 线程；启动 GC 协程；执行 init，即代码中的各种 init 函数；执行 main.main 函数。</li></ol><p><strong>注意</strong>：一开始是runtime的main函数，然后才是用户的main函数。</p><h2 id="wakeup机制">wakeup机制</h2><p>准备运行的新 goroutine 将唤醒 P 以更好地分发工作。这个 P 将创建一个与之关联的 M 绑定到一个 OS thread。<br>go func() 中 触发 Wakeup 唤醒机制：<br>有空闲的 P 而没有在 spinning 状态的 M 时候, 需要去唤醒一个空闲(睡眠)的 M 或者新建一个。当线程首次创建时，会执行一个特殊的 G，即 g0，它负责管理和调度 G。</p><p>Go 基于两种断点将 G 调度到线程上：</p><ul><li>当 G 阻塞时：系统调用、互斥锁或 chan。阻塞的 G 进入睡眠模式/进入队列，并允许 Go 安排和运行等待其他的 G。</li><li>在函数调用期间，如果 G 必须扩展其堆栈。这个断点允许 Go 调度另一个 G 并避免运行 G 占用 CPU。</li><li>在这两种情况下，运行调度程序的 g0 将当前 G 替换为另一个 G，即 ready to run。然后，选择的 G 替换 g0 并在线程上运行。与常规 G 相反，g0 有一个固定和更大的栈。</li><li>Defer 函数的分配</li><li>GC 收集，比如 STW、扫描 G 的堆栈和标记、清除操作</li><li>栈扩容，当需要的时候，由 g0 进行扩栈操作</li></ul><h2 id="Goroutine-Recycle"><strong>Goroutine Recycle</strong></h2><p>G 很容易创建，栈很小以及快速的上下文切换。基于这些原因，开发人员非常喜欢并使用它们。然而，一个产生许多 shortlive 的 G 的程序将花费相当长的时间来创建和销毁它们。<br>每个 P 维护一个 freelist G，保持这个列表是本地的，这样做的好处是不使用任何锁来 push/get 一个空闲的 G。当 G 退出当前工作时，它将被 push 到这个空闲列表中。</p><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5Cimage-20230322145008140.png" alt="image-20230322145008140">为了更好地分发空闲的 G ，调度器也有自己的列表。它实际上有两个列表：一个包含已分配栈的 G，另一个包含释放过堆栈的 G（无栈）。<br>锁保护 central list，因为任何 M 都可以访问它。当本地列表长度超过64时，调度程序持有的列表从 P 获取 G。然后一半的 G 将移动到中心列表。需求回收 G 是一种节省分配成本的好方法。但是，由于堆栈是动态增长的，现有的G 最终可能会有一个大栈。因此，当堆栈增长（即超过2K)时，Go 不会保留这些栈。</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GC机制</title>
    <link href="/2022/10/27/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/13.GC%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/10/27/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/13.GC%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1>垃圾回收机制</h1><h2 id="1-Mark-Sweep">1. Mark &amp; Sweep</h2><p>两个主要概念:</p><ul><li><p>STW: stop the world, GC 的一些阶段需要停止所有的 mutator 以确定当前的引用关系。这便是很多人对 GC 担心的来源，这也是 GC 算法优化的重点。</p></li><li><p>Root: 根对象是 mutator 不需要通过其他对象就可以直接访问到的对象。比如全局对象，栈对象中的数据等。通过Root 对象，可以追踪到其他存活的对象。</p></li></ul><p>在Go1.1版本，Mark-Sweep算法就是严格按照追踪式算法的思路来实现的：</p><ol><li>Stop the World</li><li>Mark：通过 Root 和 Root 直接间接访问到的对象， 来寻找所有可达的对象，并进行标记。</li><li>Sweep：对堆对象迭代，已标记的对象置位标记。所有未标记的对象加入freelist， 可用于再分配。</li><li>Start the Wrold，这个算法最大的问题是 GC 执行期间需要把整个程序完全暂停，朴素的 Mark Sweep 是整体 STW，并且分配速度慢，内存碎片率高，GC时间为秒级。</li></ol><p>在Go1.3的版本中，标记过程需要 STW，因为对象引用关系如果在标记阶段做了修改，会影响标记结果的正确性。<br>并发 GC 分为两层含义：</p><ul><li>每个 mark 或 sweep 本身是多个线程(协程)执行的(concurrent)</li><li>mutator 和 collector 同时运行(background)<br>concurrent 这一层是比较好实现的, GC 时整体进行STW，那么对象引用关系不会再改变，对 mark 或者sweep 任务进行分块，就能多个线程(协程) conncurrent 执行任务 mark 或 sweep。而对于 backgroud 这一层, 也就是说 mutator 和 mark，sweep 同时运行，则相对复杂。</li><li>1.3以前的版本使用标记-清扫的方式，整个过程都需要 STW。</li><li>1.3版本分离了标记和清扫的操作，标记过程STW，清扫过程并发执行。<br>backgroup sweep 是比较容易实现的，因为 mark 后，哪些对象是存活，哪些是要被 sweep 是已知的，sweep 的是不再引用的对象。sweep 结束前，这些对象不会再被分配到，所以 sweep 和 mutator 运行共存。无论全局还是栈不可能能访问的到这些对象，可以安全清理。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sync包</title>
    <link href="/2022/10/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/11.sync/"/>
    <url>/2022/10/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/11.sync/</url>
    
    <content type="html"><![CDATA[<h1>data race</h1><p>需要注意代码中得data race行为，这时候需要锁来控制，同时产生了读写，通常我们可以使用<code>go test -race</code>来查询竞争行为。</p><h2 id="detecting-race-conditions-with-go">detecting race conditions with go</h2><h1><strong>sync.Pool</strong></h1><h2 id="1-概要">1. 概要</h2><p>Go 并发相关库 sync 里面有一个有趣的 package Pool，<code>sync.Pool</code> 是个有趣的库，用很少的代码实现了很巧的功能。第一眼看到 <code>Pool</code> 这个名字，就让人想到池子，<strong>元素池化是常用的性能优化的手段</strong>（性能优化的几把斧头：并发，预处理，缓存）。比如，创建一个 100 个元素的池，然后就可以在池子里面直接获取到元素，免去了申请和初始化的流程，大大提高了性能。释放元素也是直接丢回池子而免去了真正释放元素带来的开销。</p><p>但是再仔细一看 <code>sync.Pool</code> 的实现，发现比我预期的还更有趣。<code>sync.Pool</code> 除了最常见的池化提升性能的思路，最重要的是减少 GC 。常用于一些对象实例创建昂贵的场景。注意，<strong>Pool 是 Goroutine 并发安全的。</strong></p><h2 id="2-使用姿势">2. 使用姿势</h2><h4 id="2-1-初始化-Pool-实例-New">2.1 <strong>初始化 Pool 实例 New</strong></h4><p>第一个步骤就是创建一个 Pool 实例，关键一点是配置 New 方法，声明 Pool 元素创建的方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go">bufferpool := &amp;sync.Pool &#123;<br>    New: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span> <span class="hljs-title">interface</span></span> &#123;&#125; &#123;<br>        <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;Create new instance&quot;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2-2-申请对象-Get">2.2 <strong>申请对象 Get</strong></h4><p><code>buffer := bufferPool.Get()</code></p><p><code>Get</code> 方法会返回 Pool 已经存在的对象，如果没有，那么就走慢路径，也就是调用初始化的时候定义的 New 方法（也就是最开始定义的初始化行为）来初始化一个对象。</p><h4 id="2-3-释放对象-Put">2.3 <strong>释放对象 Put</strong></h4><p><strong><code>bufferPool.Put(buffer)</code></strong></p><p>使用对象之后，调用 Put 方法声明把对象放回池子。注意了，这个调用之后仅仅是把这个对象放回池子，池子里面的<strong>对象啥时候真正释放外界是不清楚的，是不受外部控制的</strong>。</p><p>你看，Pool 的用户使用界面就这三个接口，非常简单，而且是通用型的 Pool 池模式，针对所有的对象类型都可以用。</p><h2 id="3-思考">3. <strong>思考</strong></h2><h4 id="3-1-为什么用-Pool，而不是在运行的时候直接实例化对象呢？">3.1 <strong>为什么用 Pool，而不是在运行的时候直接实例化对象呢？</strong></h4><p><strong>本质原因</strong>：Go 的内存释放是由 runtime 来自动处理的，有 GC 过程。</p><p><strong>举个栗子</strong>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs GO"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;sync&quot;</span><br>    <span class="hljs-string">&quot;sync/atomic&quot;</span><br>)<br><br><span class="hljs-comment">// 用来统计实例真正创建的次数</span><br><span class="hljs-keyword">var</span> numCalcsCreated <span class="hljs-keyword">int32</span><br><br><span class="hljs-comment">// 创建实例的函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">createBuffer</span><span class="hljs-params">()</span> <span class="hljs-title">interface</span></span>&#123;&#125; &#123;<br>    <span class="hljs-comment">// 这里要注意下，非常重要的一点。这里必须使用原子加，不然有并发问题；</span><br>    atomic.AddInt32(&amp;numCalcsCreated, <span class="hljs-number">1</span>)<br>    buffer := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">byte</span>, <span class="hljs-number">1024</span>)<br>    <span class="hljs-keyword">return</span> &amp;buffer<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// 创建实例</span><br>    bufferPool := &amp;sync.Pool&#123;<br>        New: createBuffer,<br>    &#125;<br><br>    <span class="hljs-comment">// 多 goroutine 并发测试</span><br>    numWorkers := <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span><br>    <span class="hljs-keyword">var</span> wg sync.WaitGroup<br>    wg.Add(numWorkers)<br><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; numWorkers; i++ &#123;<br>        <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>            <span class="hljs-keyword">defer</span> wg.Done()<br>            <span class="hljs-comment">// 申请一个 buffer 实例</span><br>            buffer := bufferPool.Get()<br>            _ = buffer.(*[]<span class="hljs-keyword">byte</span>)<br>            <span class="hljs-comment">// 释放一个 buffer 实例</span><br>            <span class="hljs-keyword">defer</span> bufferPool.Put(buffer)<br>        &#125;()<br>    &#125;<br>    wg.Wait()<br>    fmt.Printf(<span class="hljs-string">&quot;%d buffer objects were created.\n&quot;</span>, numCalcsCreated)<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的例子可以直接复制运行起来看下，控制台输出：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">➜  pool# <span class="hljs-keyword">go</span> run test_pool.<span class="hljs-keyword">go</span>        <br><span class="hljs-number">3</span> buffer objects were created.<br>➜  pool# <span class="hljs-keyword">go</span> run test_pool.<span class="hljs-keyword">go</span><br><span class="hljs-number">4</span> buffer objects were created.<br></code></pre></td></tr></table></figure><p>程序 <code>go run</code> 运行了两次，一次结果是 3 ，一次是 4 。这个是什么原因呢？</p><p>首先，这个是正常的情况，不知道你有没有注意到，创建 Pool 实例的时候，只要求填充了 <code>New</code> 函数，而根本没有声明或者限制这个 Pool 的大小。所以，<strong>记住一点，程序员作为使用方不能对 Pool 里面的元素个数做假定</strong>。</p><p>再来，如果我不用 Pool 来申请实例，而是直接申请，也就是上面的代码只改一行：</p><p>将以下代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 申请一个 buffer 实例</span><br>buffer := bufferPool.Get()<br></code></pre></td></tr></table></figure><p>修改成：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 申请一个 buffer 实例</span><br>buffer := createBuffer()<br></code></pre></td></tr></table></figure><p>这个时候，我们再执行程序 <code>go run test_pool.go</code>，会发现什么？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">➜  pool <span class="hljs-keyword">go</span> run test_pool_1.<span class="hljs-keyword">go</span><br><span class="hljs-number">1048576</span> buffer objects were created.<br>➜  pool <span class="hljs-keyword">go</span> run test_pool_1.<span class="hljs-keyword">go</span><br><span class="hljs-number">1048576</span> buffer objects were created.<br></code></pre></td></tr></table></figure><p><strong>注意到，和之前有两个不同点</strong>：</p><ol><li>同样也是运行两次，两次结果相同。</li><li>对象创建的数量和并发 Worker 数量相同，数量等于 1048576 （这个就是 1024*1024）；</li></ol><p>原因很简单，因为每次都是直接调用 <code>createBuffer</code> 函数申请 buffer，有 1048576 个并发 Worker 调用，所以跑多少次结果都会是 1048576。</p><p>实际上还有一个不同点，就是程序跑的过程中，该进程分配消耗的内存很大。因为 Go 申请内存是程序员触发的，回收却是 Go 内部 runtime GC 回收器来执行的，这是一个异步的操作。这种业务不负责任的内存使用会对 GC 带来非常大的负担，进而影响整体程序的性能。</p><h4 id="3-2-sync-Pool-是并发安全的吗？">3.2 <strong>sync.Pool 是并发安全的吗？</strong></h4><p>sync.Pool 当然是并发安全的。官方文档里明确说了：</p><blockquote><p>A Pool is safe for use by multiple goroutines simultaneously.</p></blockquote><p>但是，为什么我这里会单独提出来呢？</p><p>因为 <code>sync.Pool</code> 只是本身的 <code>Pool</code> 数据结构是并发安全的，并不是说 <code>Pool.New</code> 函数一定是线程安全的。<code>**Pool.New**</code> <strong>函数可能会被并发调用</strong> ，如果 New 函数里面的实现是非并发安全的，那就会有问题。</p><p>细心的小伙伴会注意到我在上面的代码例子里，关于 <code>createBuffer</code> 函数的实现里，对于 <code>numCalcsCreated</code> 的计数加是用原子操作的：<code>atomic.AddInt32(&amp;numCalcsCreated, 1)</code> 。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">createBuffer</span><span class="hljs-params">()</span> <span class="hljs-title">interface</span></span>&#123;&#125; &#123;<br>    <span class="hljs-comment">// 这里要注意下，非常重要的一点。这里必须使用原子加，不然有并发问题；</span><br>    atomic.AddInt32(&amp;numCalcsCreated, <span class="hljs-number">1</span>)<br>    buffer := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">byte</span>, <span class="hljs-number">1024</span>)<br>    <span class="hljs-keyword">return</span> &amp;buffer<br>&#125;<br></code></pre></td></tr></table></figure><p>因为 <code>numCalcsCreated</code> 是个全局变量，<code>Pool.New</code>（ 也就是 <code>createBuffer</code> ） 并发调用的时候，会导致 data race ，所以只有用原子操作才能保证数据的正确性。</p><p>小伙伴们可以尝试下，把 <code>atomic.AddInt32(&amp;numCalcsCreated, 1)</code> 这样代码改成 <code>numCalcsCreated++</code> ，然后用 <code>go run -race test_pool.go</code> 命令检查一下，肯定会报告告警的，类似如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go">WARNING: DATA RACE<br>Read at <span class="hljs-number">0x000001287538</span> by goroutine <span class="hljs-number">10</span>:<br><br>Previous write at <span class="hljs-number">0x000001287538</span> by goroutine <span class="hljs-number">7</span>:<br><br>==================<br>==================<br>WARNING: DATA RACE<br>Read at <span class="hljs-number">0x000001287538</span> by goroutine <span class="hljs-number">9</span>:<br>  main.createBuffer()<br><br></code></pre></td></tr></table></figure><p><strong>本质原因：<code>Pool.New</code> 函数可能会被并发调用。</strong></p><h4 id="3-3-为什么-sync-Pool-不适合用于像-socket-长连接或数据库连接池">3.3 <strong>为什么 sync.Pool 不适合用于像 socket 长连接或数据库连接池?</strong></h4><p>因为，我们不能对 sync.Pool 中保存的元素做任何假设，以下事情是都可以发生的：</p><ol><li>Pool 池里的元素随时可能释放掉，释放策略完全由 runtime 内部管理；</li><li>Get 获取到的元素对象可能是刚创建的，也可能是之前创建好 cache 住的。使用者无法区分；</li><li>Pool 池里面的元素个数你无法知道；</li></ol><p>所以，只有的你的场景满足以上的假定，才能正确的使用 Pool 。sync.Pool 本质用途是增加<strong>临时对象</strong>的重用率，减少 GC 负担。<strong>划重点：临时对象</strong>。所以说，像 socket 这种带状态的，长期有效的资源是不适合 Pool 的。</p><h2 id="4-总结">4. <strong>总结</strong></h2><ol><li>sync.Pool 本质用途是增加<strong>临时对象</strong>的重用率，减少 GC 负担；</li><li>不能对 Pool.Get 出来的对象做预判，有可能是新的（新分配的），有可能是旧的（之前人用过，然后 Put 进去的）；</li><li>不能对 Pool 池里的元素个数做假定，你不能够；</li><li>sync.Pool 本身的 Get, Put 调用是并发安全的，<code>sync.New</code> 指向的初始化函数会并发调用，里面安不安全只有自己知道；</li><li>当用完一个从 Pool 取出的实例时候，一定要记得调用 Put，否则 Pool 无法复用这个实例，通常这个用 defer 完成；</li></ol>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>简历</title>
    <link href="/2022/09/26/04.%E9%9D%A2%E8%AF%95/%E7%AE%80%E5%8E%86/"/>
    <url>/2022/09/26/04.%E9%9D%A2%E8%AF%95/%E7%AE%80%E5%8E%86/</url>
    
    <content type="html"><![CDATA[<h2 id="个人总结">个人总结</h2><p><strong>工作经历</strong>：拥有4年软件开发经验，Golang 开发经验 4年，拥有多个完整项目从需求到落地的开发经验，完成微服务的划分、开发，独立完成代码的编辑和重构，熟悉常用开发组件，拥有良好编码规范，熟悉分布式高并发场景下的开发工作，熟悉CI/DI开发流程。</p><p><strong>综合能力</strong>：拥有全局思维和良好的计划、组织、协调、沟通协调能力，擅长发现和直击问题本质并解决问题，富有团队精神，具备较强的逻辑分析能力和学习能力，以结果为导向开展工作，有强烈成功的意愿，可从多角度分析并解决问题。<br><strong>职业规划</strong>：本人坚定技术开发岗位，不断跟踪研究技术相关知识和技能，专注技术，未来个人发展倾向于架构师方向，用技术为公司赋能。</p><h2 id="教育经历">教育经历</h2><p><strong>湖南农业大学</strong></p><p><strong>统招本科</strong></p><p>电子信息工程</p><p>2015 年 09 月 - 2019 年06 月</p><h2 id="工作经历">工作经历</h2><h3 id="中软国际科技服务（湖南）有限公司"><strong>中软国际科技服务（湖南）有限公司</strong></h3><p><strong>岗位</strong>：Golang 开发工程师<strong>工作时间</strong>：2022年10月-至今<strong>工作地点</strong>：长沙</p><p><strong>岗位职责</strong>：</p><ul><li><p>负责腾讯公益机构服务平台的服务端研发工作，包括机构平台、运营平台、接口服务等。</p></li><li><p>参与服务架构设计，独立完成业务需求分析、技术设计以及代码实现，撰写详细设计文档，参与编码规范手册的定制。</p></li></ul><h3 id="湖南多行云计算机科技有限公司">湖南多行云计算机科技有限公司</h3><p><strong>岗位</strong>：后端开发工程师（Java，Go）<strong>工作时间</strong>：2022 年04 月 – 2022年09月<strong>工作地点</strong>：长沙</p><p><strong>公司简介</strong>：于 2018 年成立，公司主要业务为摩智云手机业务，为个人用户和企业用户提供一个或者多个云端高性能安卓设备。</p><p><strong>岗位职责</strong>：</p><ul><li><p>主导摩智云手机项目运营管理模块的设计开发，负责基于gin框架的代码重构工作，研究新技术，研究数据采集功能，并对采集的数据进行视图化处理。</p></li><li><p>参与部分生产系统开发及维护工作，解决生产系统问题及进行系统调优。</p></li></ul><h3 id="深圳四方精创资讯股份有限公司">深圳四方精创资讯股份有限公司</h3><p><strong>岗位</strong>：后端开发工程师（Java，Go）<strong>工作时间</strong>：2019 年 07 月 - 2022 年04 月<strong>工作地点</strong>：深圳</p><p><strong>公司简介</strong>：于 2003 年成立，公司经营范围包括从事计算机软、硬件的技术开发，销售自行开发软件等，公司规模 2000+人。</p><p><strong>岗位职责</strong>：</p><ul><li><p>负责企业级SAAS平台的研究产品模块设计开发，分析项目功能及需求，分析影响性能因素，优化网络模型，满足高并发需求。</p></li><li><p>维护数据库数据，对代码进行重构和升级，优化应用性能，保证代码的长期稳定性。</p></li><li><p>负责编写单元测试和接口测试，完成负载测试等相关工作。</p></li><li><p>协作完成项目业务系统、数据系统等，编写和完善项目说明以及接口说明等文档。</p></li></ul><h3 id="亚信科技（中国）有限公司">亚信科技（中国）有限公司</h3><p><strong>岗位</strong>：Java大学实习生<strong>工作时间</strong>：2018年09月 - 2019年04月<strong>工作地点</strong>：长沙</p><ul><li><p>为现场开发提供远程技术支持</p></li><li><p>针对业务场景并提出设计方案，并且通过评审</p></li><li><p>使用Java实现业务功能</p></li></ul><h2 id="项目经历">项目经历</h2><h3 id="腾讯公益机构服务平台"><strong>腾讯公益机构服务平台</strong></h3><p>2022年10月 – 至今</p><p>Golang 开发工程师  长沙</p><p><strong>应用技术</strong>：微服务架构，Golang，Kratos，MySQL，gRPC，JWT，Redis。</p><p><strong>项目描述</strong>：以服务和赋能公益机构为目标，帮助公益机构提升公益项目的规范化、透明化、智能化的管理。</p><p><strong>负责内容</strong>：</p><ol><li><p>封装微信扫码登录接口，使用JWT完成接口认证机制，用于登录和接口验证，实现单点登录、白名单等功能，通过腾讯侧安全评估</p></li><li><p>负责平台的核心模块项目中心、审核管理和配置管理模块的落地实现，使用gRPC完成服务间通信。</p></li><li><p>负责敏感词过滤问题，使用DFA算法和字典树完成敏感词匹配功能，十万敏感词，在一万字的文本的情况下，匹配速度为20ms。</p></li><li><p>优化应用中慢查询，通过数据库表结构设计和代码层的优化，使慢查询告警清零。</p></li></ol><h3 id="摩智云手机"><strong>摩智云手机</strong></h3><p>2022年04月 – 2022年9月</p><p>后端开发工程师 长沙</p><p><strong>应用技术</strong>：微服务架构，Golang，gin，MySQL，K8S，docker。</p><p><strong>项目描述</strong>：摩智云手机使用自主研发ARM+Android 云计算技术，为个人和企业用户提供一个和多个云端高性能安卓设备，用于办公、娱乐等场景。</p><p><strong>负责内容：</strong></p><ol><li><p>负责微服务的划分，通过领域驱动设计的思想，对业务模型进行领域划分。</p></li><li><p>负责日志分析系统，使用Elasticsearch，Logstash，Kibana完成日志收集搜索功能。</p></li><li><p>负责使用nginx进行反向代理，保护真实web服务器，并解决跨域问题。</p></li><li><p>负责部署MySQL集群，实现主从同步，防止数据丢失。</p></li><li><p>负责封装Golang与Linux工具包，并对常用操作进行模块化封装，减少重复造轮子过程。</p></li><li><p>实现运营模块核心逻辑转移存储，通过实现Golang和服务器terminal的交互，用Linux命令的方式将云手机数据迁移到不同集群的不同服务器上，并辅助协程并发技术实现多份数据同时转移。</p></li><li><p>收集用户行为数据，分析生成报表发送邮件给指定人员，频率最高的行为，月数据量大概在100w左右，针对此种情况，制定了可行性高的横向分表设计，有效提高了数据的安全性、稳定性和处理效率。</p></li></ol><h3 id="SPW线上购物系统"><strong>SPW线上购物系统</strong></h3><p>2020年05月 – 2022年04月</p><p>后端开发工程师 长沙</p><p><strong>应用技术</strong>：微服务架构，Golang， beego，MySQL，Redis，Elasticsearch，K8S，docker，MiniIO。</p><p><strong>项目描述</strong>：泰国 SiamPiwat 集团无现金交易电商系统，包括集团旗下 Loft、Ecotopia 等多商户的后台管理，以及 Kiosk、App、 Web、Handhold POS 等多终端多渠道的购物系统，项目包括产品、购物车、订单、支付、折扣等模块，采用分布式系统，满足高并发需求。</p><p><strong>负责内容</strong>：</p><ol><li><p>负责文件存储模块，在golang中实现基于MiniIO的文件存储服务器，解决了大量商品视频图片存储问题，并对需要保存到应用本地的图片信息进行SHA256加密。</p></li><li><p>设计图片批量上传/下载方案，解决接口超时问题，通过使用协程并发，同时上传/下载多个图片，使用channel向主线程汇总每个图片下载结果，通过sync.Pool设计临时变量池，减少GC，使原来30秒的接口优化至1秒以内响应。</p></li><li><p>负责定时任务执行模块，使用Azkaban工作流调度系统，统一管理所有定时任务，同时利用分布式锁控制定时任务执行的唯一性，解决K8S集群中，多个实例的情况下，定时任务重复执行问题。</p></li><li><p>负责商品模块和支付模块API的幂等性处理，解决用户在重发请求后，数据处理结果的统一性，防止支付时重复扣款，重复扣库存等严重问题。</p></li><li><p>负责商品库存模块开发设计及落地，主导数据库设计，通过分库分表操作，处理冗余数据，完成数据层面的性能优化， 并针对慢查询进行SQL优化，单机处理扫码识别商品的QPS在1500左右。</p></li><li><p>通过csv文件+SFTP的方式，实现与外部系统的商品与库存百万级数据同步更新，使用分段处理的方式，对于失败的更新实现断点更新功能。</p></li><li><p>负责Redis热点数据缓存，使用redis实现购物车及订单支付，并对redis缓存活动商品数据行，同时防止缓存雪崩、击穿。</p></li><li><p>负责开发环境docker容器的部署工作，编写DockerFile并且完成部署。</p></li><li><p>负责编写开发规范文档，统一 Go 编码风格，以保障公司项目代码的易维护性和编码安全性。</p></li></ol><h3 id="ThungNgern">ThungNgern</h3><p>2019-11 - 2020-05<br>主要目标用户为泰国微小型商户，用户可以通过扫码或者手动输录入产品信息并生成订单，可以通过泰国银行卡或者其他线上支付的方式进行支付。<br>负责内容：<br>● 主责模块：负责产品模块接口的设计开发及维护，实现当日增量产品至Center互通功能。完成支付详情查询、订单详情查询、订单历史转存、公共参数查询、扫码功能、公共产品分类管理、商户产品分类管理等功能服务开发及优化。<br>● 压力测试：完成压力测试，优化服务及SQL，解决索引无效问题，拆解SQL中关联表，通过explain优化SQL让服务通过不同量级压力测试，达到不同阶段业务并发量要求，同时并维护项目数据库的数据字典及ER图。<br>● 主要技术：Golang、K8s、Docker、Mysql、Beego、Nginx、Harbor、Solace等。</p><h3 id="LEGO项目">LEGO项目</h3><p>2019-07 - 2019-11<br>为开拓东南亚市场，与泰国泰京银行合作试点项目，基于beego以微服务的形式构建项目，包括公共、钱包、转账等模块，此项目为DEMO项目，其目标为致力于为企业提供Iaas、Paas等服务。<br>负责内容：<br>● 功能开发：基于Beego框架，负责钱包模块部分功能的开发及维护，加解密方案设计及开发，数据库数据维护，并协助完成压力测试。<br>● 主要技术：Golang、K8s、Docker、Mysql、Beego、Nginx、Harbor、Solace等。</p><h2 id="技能">技能</h2><p>精通 Golang 语言，熟练掌握常用包，熟悉内存分析方法。<br>熟悉Java，Python等语言；<br>熟悉 Docker、K8S 等容器技术，熟悉容器编排和容器管理，了解容器监控技术；<br>熟悉常用Linux 系统操作；<br>熟悉 MySQL，Redis，ES等数据库，掌握SQL优化等操作；熟悉计算机网络，熟悉TCP/IP、Http 等协议；熟悉Nginx 等组件；<br>熟悉 git 等常用工具；<br>熟悉常用数据结构和算法。</p>]]></content>
    
    
    <categories>
      
      <category>简历</category>
      
    </categories>
    
    
    <tags>
      
      <tag>简历</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>kafka</title>
    <link href="/2022/09/25/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/kafka/kafka/"/>
    <url>/2022/09/25/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/kafka/kafka/</url>
    
    <content type="html"><![CDATA[<h1>一、前言</h1><p>Kafka已被多家不同类型的公司作为多种类型的数据管道和消息系统使用。行为流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。</p><span id="more"></span><h1>二、基础概念</h1><p>kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：</p><p>以时间复杂度未O(1)的方式提供消息持久化能力，即使对TB级以上的数据也能保证常数时间复杂度的访问性能；</p><p>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输；</p><p>支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消费顺序传输；</p><p>同时支持离线数据处理和实时数据处理；</p><p>scale out：支持在线水平扩展</p><h2 id="2-1-Topic主题">2.1 Topic主题</h2><p>Topic在逻辑上可以被认为一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。我们把一类消息按照主题来分类，有点类似于数据库中的表。</p><h2 id="2-2-Broker">2.2 Broker</h2><p>Kafka集群包含一个或者多个服务器，每个服务器节点称为一个Broker。</p><p>Broker存储Topic的数据。如果某个Topic有N个Partition，集群有N个Broker，那么每个Broker存储该Topic的一个Partition。</p><p>从scale out 的性能角度思考，通过Broker Kafka server 的更多节点，带更多的存储，建立更多的Partition 把IO负载到更多的物理节点，提高总吞吐IOPS。</p><p>从scale up的角度思考，一个Node拥有越多的Physical Disk，也可以负载更多的Partition，提升总吞吐</p><p>Topic只是一个逻辑概念，真正在Broker间分布的时Partition。</p><h1>三、存储原理</h1><p>Kafka为什么性能好？</p><p>Kafka的消息是存在于文件系统之上的。Kafka高度依赖文件系统来存储和缓存消息，一般的人认为”磁盘是缓慢的“。</p><p>操作系统还会将主内存剩余的所有空闲内存都用作磁盘缓存，所有的磁盘读写操作都会经过同意的磁盘缓存（除了直接IO会绕过磁盘缓存）。</p><p>Kafka利用了顺序IO，在文件尾部追加到数据文件尾部。</p><p>利用了linux的page cache的能力。</p>]]></content>
    
    
    <categories>
      
      <category>kafka</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mutex</title>
    <link href="/2022/07/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/06.mutex/"/>
    <url>/2022/07/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/06.mutex/</url>
    
    <content type="html"><![CDATA[<h2 id="同步锁">同步锁</h2><p>当一个 Goroutine（协程）获得了 Mutex 后，其他 Goroutine（协程）就只能乖乖的等待，除非该 Goroutine 释放了该 Mutex。RWMutex 在读锁占用的情况下，会阻止写，但不阻止读。RWMutex在写锁占用情况下，会阻止任何其他Goroutine（无论读和写）进来，整个锁相当于由该 Goroutine 独占同步锁的作用是保证资源在使用时的独有性，不会因为并发而导致数据错乱，保证系统的稳定性。</p><span id="more"></span><h2 id="Mutex">Mutex</h2><h3 id="四种状态">四种状态</h3><ul><li>Locked - 互斥锁锁定状态</li><li>Woken - 是否有协程已被唤醒</li><li>Starving - 是否处于饥饿状态</li><li>Waiter - 表示等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量</li></ul><h3 id="两种模式">两种模式</h3><ul><li>normal:正常模式，所有等待锁的goroutine按照FIFO顺序等待，唤醒的goroutine不会直接拥有锁，而是和新请求的goroutine竞争锁，新请求的goroutine更容易竞争到锁，因为它正在CPU上执行，所以刚刚唤醒的goroutine很大可能会竞争失败，这种情况下，会把刚刚唤醒的goroutine放到队列前面，而且加锁不成功会判断是否满足自旋条件，如果满足则会自动自旋，尝试抢锁。</li><li>饥饿模式 在饥饿模式下，会直接把锁交给队列第一位的goroutine，新进来的G也不会进入自旋状态而是放到队尾，当一个goroutine等待锁时间超过1ms时，或者当前队列只剩下一个goroutine时，Mutex切换到饥饿模式。</li></ul><h3 id="自旋条件">自旋条件</h3><ul><li>锁已经被占用了，并且锁不处于饥饿模式</li><li>积累的自选次数小于4次</li><li>CPU核数大于1</li><li>有空闲的P</li><li>当前goroutine所挂载的P下，本地队列为空</li></ul><h1>实现原理</h1><h2 id="Barging">Barging</h2><p>这种模式是为了提高吞吐量，当锁被释放时，它会唤醒第一个等待者，然后把锁给第一个等待者或者第一个请求锁的人</p><h2 id="Handsoff">Handsoff</h2><p>当锁被释放时候，锁会一直持有知道第一个等待者准备好获取锁。它降低了吞吐量，因为锁被持有，即使另一个goroutine准备获取它。平衡了锁分配，因为它会迫使第一个goroutine等待所。</p><h2 id="Spinning">Spinning</h2><p>自旋在等待队列为空或者应用程序重度使用锁时效果不错，parking和unpariking goroutine有不低的性能成本开销，相比自旋来说慢得多。</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java面试题</title>
    <link href="/2022/07/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/java/Java%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2022/07/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/java/Java%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="Java基础">Java基础</h2><h3 id="1-JDK和JRE有什么区别？">1.JDK和JRE有什么区别？</h3><p>JDK 是java开发工具包，提供了java的开发环境<br>JRE 是java运行环境，为java的运行提供了所需环境</p><h3 id="2-和-equals-的区别">2.== 和 equals 的区别</h3><p>== 对于基本类型来说是值比较，对于引用类型来说比较的是引用<br>equals 本质也是==，默认情况下是引用比较，只是在很多类中重写了equals方法，比如String，Integer等把它变成了值比较，所以一般情况下是是值比较</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keepalived</title>
    <link href="/2022/06/23/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E9%AB%98%E5%B9%B6%E5%8F%91/02.Keepalived/"/>
    <url>/2022/06/23/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E9%AB%98%E5%B9%B6%E5%8F%91/02.Keepalived/</url>
    
    <content type="html"><![CDATA[<h1>一、简介</h1><p>Keepalived一个基于VRRP协议来实现的 LVS 服务高可用方案，可以利用其来解决单点故障。一个LVS服务会有2台服务器运行Keepalived，一台为主服务器（MASTER），一台为备份服务器（BACKUP），但是对外表现为一个<code>虚拟IP</code>，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候， 备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。</p><span id="more"></span><h1>二、Keepalived 的作用</h1><p>如上述所说，<strong>Keepalived</strong> 提供了很好的<code>高可用性保障服务</code>，它可以检查服务器的状态，如果有服务器出现问题，Keepalived 会将其从系统中移除，并且同时使用备份服务器代替该服务器的工作，当这台服务器可以正常工作后，Keepalived 再将其放入服务器群中，这个过程是 Keepalived 自动完成的，不需要人工干涉，我们只需要修复出现问题的服务器即可。</p><h1>三、Keepalived 原理</h1><h2 id="3-1-基于VRRP协议的理解">3.1 基于VRRP协议的理解</h2><p>Keepalived 是以 <code>VRRP</code> 协议为实现基础的，VRRP全称<code>Virtual Router Redundancy Protocol</code>，即<code>虚拟路由冗余协议</code>。</p><p>虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master 和多个 backup，master 上面有一个对外提供服务的 <code>VIP(Virtual IP Address)</code>（该路由器所在局域网内其他机器的默认路由为该 vip），master 会发组播，当 backup 收不到 vrrp 包时就认为 master 宕掉了，这时就需要根据 VRRP 的优先级来<code>选举</code>一个 backup 当 master。这样的话就可以保证路由器的高可用了。</p><p>keepalived 主要有三个模块，分别是core、check 和 vrrp。core 模块为keepalived的<strong>核心</strong>，负责主进程的启动、维护以及全局配置文件的加载和解析。check 负责健康检查，包括常见的各种检查方式。vrrp 模块是来实现 VRRP 协议的。</p><h3 id="3-2-基于TCP-IP协议的理解">3.2 基于TCP/IP协议的理解</h3><p>以检测 web 服务器为例，Keepalived 从3个层次来检测服务器的状态</p><p>Layer3 、Layer4 以及 Layer7 工作在IP/TCP协议栈的IP层，TCP层，及应用层,原理分别如下：</p><h4 id="3-2-1-Layer3">3.2.1 <strong>Layer3</strong></h4><p>Keepalived使用Layer3的方式工作时，Keepalived会定期向服务器群中的服务器发送一个ICMP的数据包（既我们平时用的Ping程序）,如果发现某台服务的IP地址没有激活，Keepalived 便报告这台服务器失效，并将它从服务器群中剔除，这种情况的典型例子是某台服务器被非法关机。Layer3 的方式是以服务器的<code>IP地址</code>是否有效作为服务器工作正常与否的标准。</p><h4 id="3-2-2-Layer4">3.2.2 <strong>Layer4</strong></h4><p>如果您理解了Layer3的方式，Layer4就容易了。Layer4主要以<code>TCP 端口的状态</code>来决定服务器工作正常与否。如 web server 的服务端口一般是80，如果 Keepalived 检测到80端口没有启动，则 Keepalived 将把这台服务器从服务器群中剔除。</p><h4 id="3-2-3-Layer7：">3.2.3 <strong>Layer7：</strong></h4><p>Layer7 就是工作在具体的应用层了，比Layer3,Layer4要复杂一点，在网络上占用的带宽也要大一些。Keepalived 将根据用户的设定检查服务器程序的运行是否正常，如果与用户的设定不相符，则 Keepalived 将把服务器从服务器群中剔除。</p><p><img src="https://pic1.zhimg.com/v2-2784a5063dfcd3043c3a45b27c1e9ac4_b.jpg" alt="img"></p><h1>四、Keepalived 选举策略</h1><h2 id="4-1-选举策略">4.1 选举策略</h2><p>首先，每个节点有一个初始优先级，由配置文件中的<code>priority</code>配置项指定，MASTER 节点的 priority 应比 BAKCUP 高。运行过程中 keepalived 根据 vrrp_script 的 <code>weight</code> 设定，增加或减小节点优先级。规则如下：</p><ol><li>weight值为正时,脚本检测成功时”weight”值会加到”priority”上,检测失败时不加<ul><li>主失败: 主priority &lt;  备priority+weight之和时会切换</li><li>主成功: 主priority+weight之和 &gt; 备priority+weight之和时,主依然为主,即不发生切换</li></ul></li><li>weight为负数时,脚本检测成功时”weight”不影响”priority”,检测失败时,Master节点的权值将是“priority“值与“weight”值之差<ul><li>主失败: 主priotity-abs(weight) &lt; 备priority时会发生切换</li><li>主成功: 主priority &gt; 备priority 不切换</li></ul></li><li>当两个节点的优先级相同时，以节点发送<code>VRRP通告</code>的 IP 作为比较对象，IP较大者为MASTER。</li></ol><h2 id="4-2-priority-和-weight-的设定">4.2 priority 和 weight 的设定</h2><ol><li>主从的优先级初始值priority和变化量weight设置非常关键，配错的话会导致无法进行主从切换。比如，当MASTER初始值定得太高，即使script脚本执行失败，也比BACKUP的priority + weight大，就没法进行VIP漂移了。</li><li>所以priority和weight值的设定应遵循: abs(MASTER priority - BAKCUP priority) &lt; abs(weight)。一般情况下，初始值MASTER的priority值应该比较BACKUP大，但不能超过weight的绝对值。 另外，当网络中不支持多播(例如某些云环境)，或者出现网络分区的情况，keepalived BACKUP节点收不到MASTER的VRRP通告，就会出现脑裂(split brain)现象，此时集群中会存在多个MASTER节点。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Keepalived</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Keepalived</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL语句优化</title>
    <link href="/2022/05/31/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/02.MySQL/mysql%E4%BC%98%E5%8C%96/"/>
    <url>/2022/05/31/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/02.MySQL/mysql%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在项目业务中，SQL优化是性能瓶颈最为关键的一环，本文主要记录了工作中常用的MySQL的语句优化点。</p><span id="more"></span><h3 id="1-explain关键字">1. explain关键字</h3><p>MySQL数据库中，通过使用explain关键字可以解析出SQL语句的执行计划，分析查询语句或是结构的性能瓶颈，其中主要包括以下几个参数</p><h4 id="1-id">1. id</h4><p>SELECT识别符，每个表的加载和读取顺序，原则是：id值越大越先被执行。id值相同的按从上到下的顺序执行。id为NULL的最后执行。</p><h4 id="2-select-type">2. select_type</h4><p>SELECT类型：simple，primary，union。</p><h4 id="3-table">3. table</h4><p>输出的行所用的表。</p><h4 id="4-type-访问类型">4. type 访问类型</h4><p>表示MySQL是如何访问数据的，是全表扫描还是通过索引，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL。</p><ul><li>system：表里只有一行记录，这个属于const类型的特例，一行数据平时很少出现，可以忽略不计。</li><li>const：表示通过索引一次就找到了，const用于比较primary key 或者 unique索引。</li><li>rq_ref:唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描。</li><li>ref:不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。</li><li>range：只检索给定范围的行，使用一个索引来选择行。</li><li>index：Full Index Scan，index与ALL区别为index类型只遍历索引树。</li><li>all：全表扫描，意味MySQL需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了。</li></ul><h4 id="5-possible-keys">5.possible_keys</h4><p>这一列显示查询可能使用哪些索引来查找。</p><h4 id="6-key">6.key</h4><p>这一列显示MySQL实际采用哪个索引来优化对该表的访问。</p><h4 id="7-key-len">7.key_len</h4><p>表示索引中使用的字节数，查询中使用的索引的长度（最大可能长度），并非实际使用长度，理论上长度越短越好。</p><h4 id="8-ref">8.ref</h4><p>这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：const（常量），字段名。</p><h4 id="9-rows">9.rows</h4><p>根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数</p><h4 id="10-Extra">10.Extra</h4><ul><li>Using filesort：MySQL对数据使用一个外部的索引排序，而不是按照表内的索引进行排序读取。</li><li>Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。</li><li>Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了访问表的数据行，效率高 如果同时出现Using where，表明索引被用来执行索引键值的查找 如果没用同时出现Using where，表明索引用来读取数据而非执行查找动作。</li></ul><h3 id="2-什么情况下不会走索引">2.什么情况下不会走索引</h3><ol><li>使用了!=或者&lt;&gt;时</li><li>数据类型不一致导致索引失效</li><li>函数导致索引失效</li><li>运算符导致索引失效</li><li>OR 导致索引失效</li><li>模糊搜索导致索引失效</li><li>not in，not exists导致索引失效</li><li>联合索引，没有使用第一列索引</li></ol><h3 id="3-表设计">3.表设计</h3><p>要根据查询速度来设计，尽量做到建立索引后，查询匹配的结构集数据量少。</p><h4 id="三大范式">三大范式</h4><p>第一范式：每一列都不可以再拆分，保持原子性。<br>第二范式：在第一范式的基础上，非主键列完全依赖于主键列，而不只依赖于主键的一部分。<br>第三范式：在第二范式的基础上，非主键列只依赖于主键列，而不依赖于其他非主键列。</p><h3 id="4-分库分表">4.分库分表</h3><h4 id="数据库瓶颈">数据库瓶颈</h4><ol><li>IO瓶颈<br>第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -&gt; 分库和垂直分表。<br>第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -&gt; 分库。</li><li>CPU瓶颈<br>第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -&gt; SQL优化，建立合适的索引，在业务Service层进行业务计算。<br>第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -&gt; 水平分表。</li></ol><h4 id="分表分库方式">分表分库方式</h4><h4 id="水平分库">水平分库</h4><p>概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。<br>结果：每个库的结构都一样；每个库的数据都不一样，没有交集；所有库的并集是全量数据。<br>场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。<br>分析：库多了，io和cpu的压力自然可以成倍缓解。</p><h4 id="水平分表">水平分表</h4><p>概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。<br>结果：每个表的结构都一样；每个表的数据都不一样，没有交集；所有表的并集是全量数据。<br>场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。推荐：一次SQL查询优化原理分析。<br>分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。</p><h4 id="垂直分库">垂直分库</h4><p>概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。<br>结果：每个库的结构都不一样；每个库的数据也不一样，没有交集；所有库的并集是全量数据。<br>场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。<br>分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。</p><h4 id="垂直分表">垂直分表</h4><p>概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。<br>结果：每个表的结构都不一样；每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；所有表的并集是全量数据。<br>场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。<br>分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。</p><h4 id="分库分表步骤">分库分表步骤</h4><p>根据容量（当前容量和增长量）评估分库或分表个数 -&gt; 选key（均匀）-&gt; 分表规则（hash或range等）-&gt; 执行（一般双写）-&gt; 扩容问题（尽量减少数据的移动）。</p><h3 id="5-分库分表问题">5.分库分表问题</h3><p>1、非partition key的查询问题<br>端上除了partition key只有一个非partition key作为条件查询<br>映射法<br>基因法</p><p>端上除了partition key只有一个非partition key作为条件查询<br>映射法<br>冗余法</p><p>2、非partition key跨库跨表分页查询问题<br>问题原因：跨越多个水平切分数据库，且分库依据与排序依据为不同属性，并需要进行分页</p><p>解决方案：</p><p>全局视野法：</p><p>（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y<br>（2）服务层将改写后的SQL语句发往各个分库：即例子中的各取3页数据<br>（3）假设共分为N个库，服务层将得到N*(X+Y)条数据：即例子中的6页数据<br>（4）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录，就是全局视野所需的一页数据</p><p>业务折衷法：</p><p>业务折衷一：禁止跳页查询</p><p>业务折衷二：允许数据精度损失</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>链表</title>
    <link href="/2022/04/11/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/"/>
    <url>/2022/04/11/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%93%BE%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="定义">定义</h2><p>链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。</p><span id="more"></span><h2 id="特性">特性</h2><p>新增删除：<br>在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。<br>查询：</p><h2 id="常见列表结构">常见列表结构</h2><h3 id="单链表">单链表</h3><p>头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。</p><h3 id="循环列表">循环列表</h3><p>循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。</p><h3 id="双向链表">双向链表</h3><p>单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。</p><h2 id="通过链表实现LRU-least-recently-used-算法">通过链表实现LRU(least recently used)算法</h2><p>维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。</p><ol><li>如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。</li><li>如果此数据没有在缓存链表中，又可以分为两种情况：</li></ol><ul><li>如果此时缓存未满，则将此结点直接插入到链表的头部；</li><li>如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。</li></ul><h2 id="如何优雅的写出链表代码">如何优雅的写出链表代码</h2><h3 id="一、理解指针或引用的含义">一、理解指针或引用的含义</h3><p>1.含义：将某个变量（对象）赋值给指针（引用），实际上就是就是将这个变量（对象）的地址赋值给指针（引用）。<br>2.示例：<br>p—&gt;next = q; 表示p节点的后继指针存储了q节点的内存地址。<br>p—&gt;next = p—&gt;next—&gt;next; 表示p节点的后继指针存储了p节点的下下个节点的内存地址。</p><h3 id="二、警惕指针丢失和内存泄漏（单链表）">二、警惕指针丢失和内存泄漏（单链表）</h3><p>1.插入节点<br>在节点a和节点b之间插入节点x，b是a的下一节点，，p指针指向节点a，则造成指针丢失和内存泄漏的代码：p—&gt;next = x;x—&gt;next = p—&gt;next; 显然这会导致x节点的后继指针指向自身。<br>正确的写法是2句代码交换顺序，即：x—&gt;next = p—&gt;next; p—&gt;next = x;<br>2.删除节点<br>在节点a和节点b之间删除节点b，b是a的下一节点，p指针指向节点a：p—&gt;next = p—&gt;next—&gt;next;</p><h3 id="三、利用“哨兵”简化实现难度">三、利用“哨兵”简化实现难度</h3><p>1.什么是“哨兵”？<br>链表中的“哨兵”节点是解决边界问题的，不参与业务逻辑。如果我们引入“哨兵”节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。我们把这种有“哨兵”节点的链表称为带头链表，相反，没有“哨兵”节点的链表就称为不带头链表。<br>2.未引入“哨兵”的情况<br>如果在p节点后插入一个节点，只需2行代码即可搞定：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs C">new_node—&gt;next = p—&gt;next;<br>p—&gt;next = new_node;<br></code></pre></td></tr></table></figure><p>但，若向空链表中插入一个节点，则代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">if</span>(head == null)&#123;<br>  head = new_node;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果要删除节点p的后继节点，只需1行代码即可搞定：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C">p—&gt;next = p—&gt;next—&gt;next;<br></code></pre></td></tr></table></figure><p>但，若是删除链表的最有一个节点（链表中只剩下这个节点），则代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">if</span>(head—&gt;next == null)&#123;<br>  head = null;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上面的情况可以看出，针对链表的插入、删除操作，需要对插入第一个节点和删除最后一个节点的情况进行特殊处理。这样代码就会显得很繁琐，所以引入“哨兵”节点来解决这个问题。<br>3.引入“哨兵”的情况<br>“哨兵”节点不存储数据，无论链表是否为空，head指针都会指向它，作为链表的头结点始终存在。这样，插入第一个节点和插入其他节点，删除最后一个节点和删除其他节点都可以统一为相同的代码实现逻辑了。<br>4.“哨兵”还有哪些应用场景？<br>这个知识有限，暂时想不出来呀！但总结起来，哨兵最大的作用就是简化边界条件的处理。</p><h3 id="四、重点留意边界条件处理">四、重点留意边界条件处理</h3><p>经常用来检查链表是否正确的边界4个边界条件：<br>1.如果链表为空时，代码是否能正常工作？<br>2.如果链表只包含一个节点时，代码是否能正常工作？<br>3.如果链表只包含两个节点时，代码是否能正常工作？<br>4.代码逻辑在处理头尾节点时是否能正常工作？</p><h3 id="五、举例画图，辅助思考">五、举例画图，辅助思考</h3><p>核心思想：释放脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。</p><h3 id="六、多写多练，没有捷径">六、多写多练，没有捷径</h3><p>5个常见的链表操作：<br>1.单链表反转</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> ListNode <span class="hljs-keyword">struct</span> &#123;<br>Val  <span class="hljs-keyword">int</span><br>Next *ListNode<br>&#125;<br><span class="hljs-comment">//反转链表 迭代解法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">reverseList1</span><span class="hljs-params">(head *ListNode)</span> *<span class="hljs-title">ListNode</span></span> &#123;<br><span class="hljs-keyword">var</span> prev *ListNode<br>curr := head<br><span class="hljs-keyword">for</span> curr != <span class="hljs-literal">nil</span> &#123;<br>next := curr.Next<br>curr.Next = prev<br>prev = curr<br>curr = next<br>&#125;<br><span class="hljs-keyword">return</span> prev<br>&#125;<br><br><span class="hljs-comment">//反转链表 递归解法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">reverseList</span><span class="hljs-params">(head *ListNode)</span> *<span class="hljs-title">ListNode</span></span> &#123;<br><span class="hljs-keyword">if</span> head == <span class="hljs-literal">nil</span> || head.Next == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> head<br>&#125;<br>ret := reverseList(head.Next)<br>head.Next.Next = head<br>head.Next = <span class="hljs-literal">nil</span><br><span class="hljs-keyword">return</span> ret<br>&#125;<br></code></pre></td></tr></table></figure><p>2.链表中环的检测</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">hasCycle</span><span class="hljs-params">(head *ListNode)</span> <span class="hljs-title">bool</span></span> &#123;<br><span class="hljs-keyword">if</span> head == <span class="hljs-literal">nil</span> || head.Next == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>slow, fast := head, head.Next<br><span class="hljs-keyword">for</span> slow != fast &#123;<br><span class="hljs-keyword">if</span> fast == <span class="hljs-literal">nil</span> || fast.Next == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>slow = slow.Next<br>fast = fast.Next.Next<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><p>3.两个有序链表合并</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//合并两个有序链表</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mergeTwoLists</span><span class="hljs-params">(list1 *ListNode, list2 *ListNode)</span> *<span class="hljs-title">ListNode</span></span> &#123;<br><span class="hljs-keyword">if</span> list1 == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> list2<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> list2 == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> list1<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> list1.Val &lt; list2.Val &#123;<br>list1.Next = mergeTwoLists(list1.Next, list2)<br><span class="hljs-keyword">return</span> list1<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>list2.Next = mergeTwoLists(list1, list2.Next)<br><span class="hljs-keyword">return</span> list2<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>4.删除链表倒数第n个节点</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//合并两个有序链表</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mergeTwoLists</span><span class="hljs-params">(list1 *ListNode, list2 *ListNode)</span> *<span class="hljs-title">ListNode</span></span> &#123;<br><span class="hljs-keyword">if</span> list1 == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> list2<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> list2 == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> list1<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> list1.Val &lt; list2.Val &#123;<br>list1.Next = mergeTwoLists(list1.Next, list2)<br><span class="hljs-keyword">return</span> list1<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>list2.Next = mergeTwoLists(list1, list2.Next)<br><span class="hljs-keyword">return</span> list2<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>5.求链表的中间节点</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">middleNode</span><span class="hljs-params">(head *ListNode)</span> *<span class="hljs-title">ListNode</span></span> &#123;<br>slow, fast := head, head<br><span class="hljs-keyword">for</span> fast != <span class="hljs-literal">nil</span> &amp;&amp; fast.Next != <span class="hljs-literal">nil</span> &#123;<br>slow = slow.Next<br>fast = fast.Next.Next<br>&#125;<br><span class="hljs-keyword">return</span> slow<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>链表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常用emoji</title>
    <link href="/2021/10/14/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/emoji/"/>
    <url>/2021/10/14/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/emoji/</url>
    
    <content type="html"><![CDATA[<p>😄 寻找一些 <code>emoji</code>表情</p><span id="more"></span><h1>People</h1><table><thead><tr><th>😄 <code>:smile:</code></th><th>😆 <code>:laughing:</code></th><th></th></tr></thead><tbody><tr><td>😊 <code>:blush:</code></td><td>😃 <code>:smiley:</code></td><td>☺️ <code>:relaxed:</code></td></tr><tr><td>😏 <code>:smirk:</code></td><td>😍 <code>:heart_eyes:</code></td><td>😘 <code>:kissing_heart:</code></td></tr><tr><td>😚 <code>:kissing_closed_eyes:</code></td><td>😳 <code>:flushed:</code></td><td>😌 <code>:relieved:</code></td></tr><tr><td>😆 <code>:satisfied:</code></td><td>😁 <code>:grin:</code></td><td>😉 <code>:wink:</code></td></tr><tr><td>😜 <code>:stuck_out_tongue_winking_eye:</code></td><td>😝 <code>:stuck_out_tongue_closed_eyes:</code></td><td>😀 <code>:grinning:</code></td></tr><tr><td>😗 <code>:kissing:</code></td><td>😙 <code>:kissing_smiling_eyes:</code></td><td>😛 <code>:stuck_out_tongue:</code></td></tr><tr><td>😴 <code>:sleeping:</code></td><td>😟 <code>:worried:</code></td><td>😦 <code>:frowning:</code></td></tr><tr><td>😧 <code>:anguished:</code></td><td>😮 <code>:open_mouth:</code></td><td>😬 <code>:grimacing:</code></td></tr><tr><td>😕 <code>:confused:</code></td><td>😯 <code>:hushed:</code></td><td>😑 <code>:expressionless:</code></td></tr><tr><td>😒 <code>:unamused:</code></td><td>😅 <code>:sweat_smile:</code></td><td>😓 <code>:sweat:</code></td></tr><tr><td>😥 <code>:disappointed_relieved:</code></td><td>😩 <code>:weary:</code></td><td>😔 <code>:pensive:</code></td></tr><tr><td>😞 <code>:disappointed:</code></td><td>😖 <code>:confounded:</code></td><td>😨 <code>:fearful:</code></td></tr><tr><td>😰 <code>:cold_sweat:</code></td><td>😣 <code>:persevere:</code></td><td>😢 <code>:cry:</code></td></tr><tr><td>😭 <code>:sob:</code></td><td>😂 <code>:joy:</code></td><td>😲 <code>:astonished:</code></td></tr><tr><td>😱 <code>:scream:</code></td><td></td><td>😫 <code>:tired_face:</code></td></tr><tr><td>😠 <code>:angry:</code></td><td>😡 <code>:rage:</code></td><td>😤 <code>:triumph:</code></td></tr><tr><td>😪 <code>:sleepy:</code></td><td>😋 <code>:yum:</code></td><td>😷 <code>:mask:</code></td></tr><tr><td>😎 <code>:sunglasses:</code></td><td>😵 <code>:dizzy_face:</code></td><td>👿 <code>:imp:</code></td></tr></tbody></table><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>😈 <code>:smiling_imp:</code></td><td>😐 <code>:neutral_face:</code></td><td>😶 <code>:no_mouth:</code></td></tr><tr><td>😇 <code>:innocent:</code></td><td>👽 <code>:alien:</code></td><td>💛 <code>:yellow_heart:</code></td></tr><tr><td>💙 <code>:blue_heart:</code></td><td>💜 <code>:purple_heart:</code></td><td>❤️ <code>:heart:</code></td></tr><tr><td>💚 <code>:green_heart:</code></td><td>💔 <code>:broken_heart:</code></td><td>💓 <code>:heartbeat:</code></td></tr><tr><td>💗 <code>:heartpulse:</code></td><td>💕 <code>:two_hearts:</code></td><td>💞 <code>:revolving_hearts:</code></td></tr><tr><td>💘 <code>:cupid:</code></td><td>💖 <code>:sparkling_heart:</code></td><td>✨ <code>:sparkles:</code></td></tr><tr><td>⭐️ <code>:star:</code></td><td>🌟 <code>:star2:</code></td><td>💫 <code>:dizzy:</code></td></tr><tr><td>💥 <code>:boom:</code></td><td>💥 <code>:collision:</code></td><td>💢 <code>:anger:</code></td></tr><tr><td>❗️ <code>:exclamation:</code></td><td>❓ <code>:question:</code></td><td>❕ <code>:grey_exclamation:</code></td></tr><tr><td>❔ <code>:grey_question:</code></td><td>💤 <code>:zzz:</code></td><td>💨 <code>:dash:</code></td></tr><tr><td>💦 <code>:sweat_drops:</code></td><td>🎶 <code>:notes:</code></td><td>🎵 <code>:musical_note:</code></td></tr><tr><td>🔥 <code>:fire:</code></td><td>💩 <code>:hankey:</code></td><td>💩 <code>:poop:</code></td></tr><tr><td>💩 <code>:shit:</code></td><td>👍 <code>:+1:</code></td><td>👍 <code>:thumbsup:</code></td></tr><tr><td>👎 <code>:-1:</code></td><td>👎 <code>:thumbsdown:</code></td><td>👌 <code>:ok_hand:</code></td></tr><tr><td>👊 <code>:punch:</code></td><td>👊 <code>:facepunch:</code></td><td>✊ <code>:fist:</code></td></tr><tr><td>✌️ <code>:v:</code></td><td>👋 <code>:wave:</code></td><td>✋ <code>:hand:</code></td></tr><tr><td>✋ <code>:raised_hand:</code></td><td>👐 <code>:open_hands:</code></td><td>☝️ <code>:point_up:</code></td></tr><tr><td>👇 <code>:point_down:</code></td><td>👈 <code>:point_left:</code></td><td>👉 <code>:point_right:</code></td></tr><tr><td>🙌 <code>:raised_hands:</code></td><td>🙏 <code>:pray:</code></td><td>👆 <code>:point_up_2:</code></td></tr><tr><td>👏 <code>:clap:</code></td><td>💪 <code>:muscle:</code></td><td>🤘 <code>:metal:</code></td></tr><tr><td>🖕 <code>:fu:</code></td><td>🚶 <code>:walking:</code></td><td>🏃 <code>:runner:</code></td></tr><tr><td>🏃 <code>:running:</code></td><td>👫 <code>:couple:</code></td><td>👪 <code>:family:</code></td></tr><tr><td>👬 <code>:two_men_holding_hands:</code></td><td>👭 <code>:two_women_holding_hands:</code></td><td>💃 <code>:dancer:</code></td></tr><tr><td>👯 <code>:dancers:</code></td><td>🙆 <code>:ok_woman:</code></td><td>🙅 <code>:no_good:</code></td></tr><tr><td>💁 <code>:information_desk_person:</code></td><td>🙋 <code>:raising_hand:</code></td><td>👰 <code>:bride_with_veil:</code></td></tr><tr><td>🙎 <code>:person_with_pouting_face:</code></td><td>🙍 <code>:person_frowning:</code></td><td>🙇 <code>:bow:</code></td></tr><tr><td>💏 <code>:couplekiss:</code></td><td>💑 <code>:couple_with_heart:</code></td><td>💆 <code>:massage:</code></td></tr><tr><td>💇 <code>:haircut:</code></td><td>💅 <code>:nail_care:</code></td><td>👦 <code>:boy:</code></td></tr><tr><td>👧 <code>:girl:</code></td><td>👩 <code>:woman:</code></td><td>👨 <code>:man:</code></td></tr><tr><td>👶 <code>:baby:</code></td><td>👵 <code>:older_woman:</code></td><td>👴 <code>:older_man:</code></td></tr><tr><td>👱 <code>:person_with_blond_hair:</code></td><td>👲 <code>:man_with_gua_pi_mao:</code></td><td>👳 <code>:man_with_turban:</code></td></tr><tr><td>👷 <code>:construction_worker:</code></td><td>👮 <code>:cop:</code></td><td>👼 <code>:angel:</code></td></tr><tr><td>👸 <code>:princess:</code></td><td>😺 <code>:smiley_cat:</code></td><td>😸 <code>:smile_cat:</code></td></tr><tr><td>😻 <code>:heart_eyes_cat:</code></td><td>😽 <code>:kissing_cat:</code></td><td>😼 <code>:smirk_cat:</code></td></tr><tr><td>🙀 <code>:scream_cat:</code></td><td>😿 <code>:crying_cat_face:</code></td><td>😹 <code>:joy_cat:</code></td></tr><tr><td>😾 <code>:pouting_cat:</code></td><td>👹 <code>:japanese_ogre:</code></td><td>👺 <code>:japanese_goblin:</code></td></tr><tr><td>🙈 <code>:see_no_evil:</code></td><td>🙉 <code>:hear_no_evil:</code></td><td>🙊 <code>:speak_no_evil:</code></td></tr><tr><td>💂 <code>:guardsman:</code></td><td>💀 <code>:skull:</code></td><td>🐾 <code>:feet:</code></td></tr><tr><td>👄 <code>:lips:</code></td><td>💋 <code>:kiss:</code></td><td>💧 <code>:droplet:</code></td></tr><tr><td>👂 <code>:ear:</code></td><td>👀 <code>:eyes:</code></td><td>👃 <code>:nose:</code></td></tr><tr><td>👅 <code>:tongue:</code></td><td>💌 <code>:love_letter:</code></td><td>👤 <code>:bust_in_silhouette:</code></td></tr><tr><td>👥 <code>:busts_in_silhouette:</code></td><td>💬 <code>:speech_balloon:</code></td><td>💭 <code>:thought_balloon:</code></td></tr></tbody></table><h1>Nature</h1><table><thead><tr><th>☀️ <code>:sunny:</code></th><th>☔️ <code>:umbrella:</code></th><th>☁️ <code>:cloud:</code></th></tr></thead><tbody><tr><td>❄️ <code>:snowflake:</code></td><td>⛄️ <code>:snowman:</code></td><td>⚡️ <code>:zap:</code></td></tr><tr><td>🌀 <code>:cyclone:</code></td><td>🌁 <code>:foggy:</code></td><td>🌊 <code>:ocean:</code></td></tr><tr><td>🐱 <code>:cat:</code></td><td>🐶 <code>:dog:</code></td><td>🐭 <code>:mouse:</code></td></tr><tr><td>🐹 <code>:hamster:</code></td><td>🐰 <code>:rabbit:</code></td><td>🐺 <code>:wolf:</code></td></tr><tr><td>🐸 <code>:frog:</code></td><td>🐯 <code>:tiger:</code></td><td>🐨 <code>:koala:</code></td></tr><tr><td>🐻 <code>:bear:</code></td><td>🐷 <code>:pig:</code></td><td>🐽 <code>:pig_nose:</code></td></tr><tr><td>🐮 <code>:cow:</code></td><td>🐗 <code>:boar:</code></td><td>🐵 <code>:monkey_face:</code></td></tr><tr><td>🐒 <code>:monkey:</code></td><td>🐴 <code>:horse:</code></td><td>🐎 <code>:racehorse:</code></td></tr><tr><td>🐫 <code>:camel:</code></td><td>🐑 <code>:sheep:</code></td><td>🐘 <code>:elephant:</code></td></tr><tr><td>🐼 <code>:panda_face:</code></td><td>🐍 <code>:snake:</code></td><td>🐦 <code>:bird:</code></td></tr><tr><td>🐤 <code>:baby_chick:</code></td><td>🐥 <code>:hatched_chick:</code></td><td>🐣 <code>:hatching_chick:</code></td></tr><tr><td>🐔 <code>:chicken:</code></td><td>🐧 <code>:penguin:</code></td><td>🐢 <code>:turtle:</code></td></tr><tr><td>🐛 <code>:bug:</code></td><td>🐝 <code>:honeybee:</code></td><td>🐜 <code>:ant:</code></td></tr><tr><td>🐞 <code>:beetle:</code></td><td>🐌 <code>:snail:</code></td><td>🐙 <code>:octopus:</code></td></tr><tr><td>🐠 <code>:tropical_fish:</code></td><td>🐟 <code>:fish:</code></td><td>🐳 <code>:whale:</code></td></tr><tr><td>🐋 <code>:whale2:</code></td><td>🐬 <code>:dolphin:</code></td><td>🐄 <code>:cow2:</code></td></tr><tr><td>🐏 <code>:ram:</code></td><td>🐀 <code>:rat:</code></td><td>🐃 <code>:water_buffalo:</code></td></tr><tr><td>🐅 <code>:tiger2:</code></td><td>🐇 <code>:rabbit2:</code></td><td>🐉 <code>:dragon:</code></td></tr><tr><td>🐐 <code>:goat:</code></td><td>🐓 <code>:rooster:</code></td><td>🐕 <code>:dog2:</code></td></tr><tr><td>🐖 <code>:pig2:</code></td><td>🐁 <code>:mouse2:</code></td><td>🐂 <code>:ox:</code></td></tr><tr><td>🐲 <code>:dragon_face:</code></td><td>🐡 <code>:blowfish:</code></td><td>🐊 <code>:crocodile:</code></td></tr><tr><td>🐪 <code>:dromedary_camel:</code></td><td>🐆 <code>:leopard:</code></td><td>🐈 <code>:cat2:</code></td></tr><tr><td>🐩 <code>:poodle:</code></td><td>🐾 <code>:paw_prints:</code></td><td>💐 <code>:bouquet:</code></td></tr><tr><td>🌸 <code>:cherry_blossom:</code></td><td>🌷 <code>:tulip:</code></td><td>🍀 <code>:four_leaf_clover:</code></td></tr><tr><td>🌹 <code>:rose:</code></td><td>🌻 <code>:sunflower:</code></td><td>🌺 <code>:hibiscus:</code></td></tr><tr><td>🍁 <code>:maple_leaf:</code></td><td>🍃 <code>:leaves:</code></td><td>🍂 <code>:fallen_leaf:</code></td></tr><tr><td>🌿 <code>:herb:</code></td><td>🍄 <code>:mushroom:</code></td><td>🌵 <code>:cactus:</code></td></tr><tr><td>🌴 <code>:palm_tree:</code></td><td>🌲 <code>:evergreen_tree:</code></td><td>🌳 <code>:deciduous_tree:</code></td></tr><tr><td>🌰 <code>:chestnut:</code></td><td>🌱 <code>:seedling:</code></td><td>🌼 <code>:blossom:</code></td></tr><tr><td>🌾 <code>:ear_of_rice:</code></td><td>🐚 <code>:shell:</code></td><td>🌐 <code>:globe_with_meridians:</code></td></tr><tr><td>🌞 <code>:sun_with_face:</code></td><td>🌝 <code>:full_moon_with_face:</code></td><td>🌚 <code>:new_moon_with_face:</code></td></tr><tr><td>🌑 <code>:new_moon:</code></td><td>🌒 <code>:waxing_crescent_moon:</code></td><td>🌓 <code>:first_quarter_moon:</code></td></tr><tr><td>🌔 <code>:waxing_gibbous_moon:</code></td><td>🌕 <code>:full_moon:</code></td><td>🌖 <code>:waning_gibbous_moon:</code></td></tr><tr><td>🌗 <code>:last_quarter_moon:</code></td><td>🌘 <code>:waning_crescent_moon:</code></td><td>🌜 <code>:last_quarter_moon_with_face:</code></td></tr><tr><td>🌛 <code>:first_quarter_moon_with_face:</code></td><td>🌔 <code>:moon:</code></td><td>🌍 <code>:earth_africa:</code></td></tr><tr><td>🌎 <code>:earth_americas:</code></td><td>🌏 <code>:earth_asia:</code></td><td>🌋 <code>:volcano:</code></td></tr><tr><td>🌌 <code>:milky_way:</code></td><td>⛅️ <code>:partly_sunny:</code></td><td></td></tr></tbody></table><h1>Objects</h1><table><thead><tr><th>🎍 <code>:bamboo:</code></th><th>💝 <code>:gift_heart:</code></th><th>🎎 <code>:dolls:</code></th></tr></thead><tbody><tr><td>🎒 <code>:school_satchel:</code></td><td>🎓 <code>:mortar_board:</code></td><td>🎏 <code>:flags:</code></td></tr><tr><td>🎆 <code>:fireworks:</code></td><td>🎇 <code>:sparkler:</code></td><td>🎐 <code>:wind_chime:</code></td></tr><tr><td>🎑 <code>:rice_scene:</code></td><td>🎃 <code>:jack_o_lantern:</code></td><td>👻 <code>:ghost:</code></td></tr><tr><td>🎅 <code>:santa:</code></td><td>🎄 <code>:christmas_tree:</code></td><td>🎁 <code>:gift:</code></td></tr><tr><td>🔔 <code>:bell:</code></td><td>🔕 <code>:no_bell:</code></td><td>🎋 <code>:tanabata_tree:</code></td></tr><tr><td>🎉 <code>:tada:</code></td><td>🎊 <code>:confetti_ball:</code></td><td>🎈 <code>:balloon:</code></td></tr><tr><td>🔮 <code>:crystal_ball:</code></td><td>💿 <code>:cd:</code></td><td>📀 <code>:dvd:</code></td></tr><tr><td>💾 <code>:floppy_disk:</code></td><td>📷 <code>:camera:</code></td><td>📹 <code>:video_camera:</code></td></tr><tr><td>🎥 <code>:movie_camera:</code></td><td>💻 <code>:computer:</code></td><td>📺 <code>:tv:</code></td></tr><tr><td>📱 <code>:iphone:</code></td><td>☎️ <code>:phone:</code></td><td>☎️ <code>:telephone:</code></td></tr><tr><td>📞 <code>:telephone_receiver:</code></td><td>📟 <code>:pager:</code></td><td>📠 <code>:fax:</code></td></tr><tr><td>💽 <code>:minidisc:</code></td><td>📼 <code>:vhs:</code></td><td>🔉 <code>:sound:</code></td></tr><tr><td>🔈 <code>:speaker:</code></td><td>🔇 <code>:mute:</code></td><td>📢 <code>:loudspeaker:</code></td></tr><tr><td>📣 <code>:mega:</code></td><td>⌛️ <code>:hourglass:</code></td><td>⏳ <code>:hourglass_flowing_sand:</code></td></tr><tr><td>⏰ <code>:alarm_clock:</code></td><td>⌚️ <code>:watch:</code></td><td>📻 <code>:radio:</code></td></tr><tr><td>📡 <code>:satellite:</code></td><td>➿ <code>:loop:</code></td><td>🔍 <code>:mag:</code></td></tr><tr><td>🔎 <code>:mag_right:</code></td><td>🔓 <code>:unlock:</code></td><td>🔒 <code>:lock:</code></td></tr><tr><td>🔏 <code>:lock_with_ink_pen:</code></td><td>🔐 <code>:closed_lock_with_key:</code></td><td>🔑 <code>:key:</code></td></tr><tr><td>💡 <code>:bulb:</code></td><td>🔦 <code>:flashlight:</code></td><td>🔆 <code>:high_brightness:</code></td></tr><tr><td>🔅 <code>:low_brightness:</code></td><td>🔌 <code>:electric_plug:</code></td><td>🔋 <code>:battery:</code></td></tr><tr><td>📲 <code>:calling:</code></td><td>✉️ <code>:email:</code></td><td>📫 <code>:mailbox:</code></td></tr><tr><td>📮 <code>:postbox:</code></td><td>🛀 <code>:bath:</code></td><td>🛁 <code>:bathtub:</code></td></tr><tr><td>🚿 <code>:shower:</code></td><td>🚽 <code>:toilet:</code></td><td>🔧 <code>:wrench:</code></td></tr><tr><td>🔩 <code>:nut_and_bolt:</code></td><td>🔨 <code>:hammer:</code></td><td>💺 <code>:seat:</code></td></tr><tr><td>💰 <code>:moneybag:</code></td><td>💴 <code>:yen:</code></td><td>💵 <code>:dollar:</code></td></tr><tr><td>💷 <code>:pound:</code></td><td>💶 <code>:euro:</code></td><td>💳 <code>:credit_card:</code></td></tr><tr><td>💸 <code>:money_with_wings:</code></td><td>📧 <code>:e-mail:</code></td><td>📥 <code>:inbox_tray:</code></td></tr><tr><td>📤 <code>:outbox_tray:</code></td><td>✉️ <code>:envelope:</code></td><td>📨 <code>:incoming_envelope:</code></td></tr><tr><td>📯 <code>:postal_horn:</code></td><td>📪 <code>:mailbox_closed:</code></td><td>📬 <code>:mailbox_with_mail:</code></td></tr><tr><td>📭 <code>:mailbox_with_no_mail:</code></td><td>🚪 <code>:door:</code></td><td>🚬 <code>:smoking:</code></td></tr><tr><td>💣 <code>:bomb:</code></td><td>🔫 <code>:gun:</code></td><td>🔪 <code>:hocho:</code></td></tr><tr><td>💊 <code>:pill:</code></td><td>💉 <code>:syringe:</code></td><td>📄 <code>:page_facing_up:</code></td></tr><tr><td>📃 <code>:page_with_curl:</code></td><td>📑 <code>:bookmark_tabs:</code></td><td>📊 <code>:bar_chart:</code></td></tr><tr><td>📈 <code>:chart_with_upwards_trend:</code></td><td>📉 <code>:chart_with_downwards_trend:</code></td><td>📜 <code>:scroll:</code></td></tr><tr><td>📋 <code>:clipboard:</code></td><td>📆 <code>:calendar:</code></td><td>📅 <code>:date:</code></td></tr><tr><td>📇 <code>:card_index:</code></td><td>📁 <code>:file_folder:</code></td><td>📂 <code>:open_file_folder:</code></td></tr><tr><td>✂️ <code>:scissors:</code></td><td>📌 <code>:pushpin:</code></td><td>📎 <code>:paperclip:</code></td></tr><tr><td>✒️ <code>:black_nib:</code></td><td>✏️ <code>:pencil2:</code></td><td>📏 <code>:straight_ruler:</code></td></tr><tr><td>📐 <code>:triangular_ruler:</code></td><td>📕 <code>:closed_book:</code></td><td>📗 <code>:green_book:</code></td></tr><tr><td>📘 <code>:blue_book:</code></td><td>📙 <code>:orange_book:</code></td><td>📓 <code>:notebook:</code></td></tr><tr><td>📔 <code>:notebook_with_decorative_cover:</code></td><td>📒 <code>:ledger:</code></td><td>📚 <code>:books:</code></td></tr><tr><td>🔖 <code>:bookmark:</code></td><td>📛 <code>:name_badge:</code></td><td>🔬 <code>:microscope:</code></td></tr><tr><td>🔭 <code>:telescope:</code></td><td>📰 <code>:newspaper:</code></td><td>🏈 <code>:football:</code></td></tr><tr><td>🏀 <code>:basketball:</code></td><td>⚽️ <code>:soccer:</code></td><td>⚾️ <code>:baseball:</code></td></tr><tr><td>🎾 <code>:tennis:</code></td><td>🎱 <code>:8ball:</code></td><td>🏉 <code>:rugby_football:</code></td></tr><tr><td>🎳 <code>:bowling:</code></td><td>⛳️ <code>:golf:</code></td><td>🚵 <code>:mountain_bicyclist:</code></td></tr><tr><td>🚴 <code>:bicyclist:</code></td><td>🏇 <code>:horse_racing:</code></td><td>🏂 <code>:snowboarder:</code></td></tr><tr><td>🏊 <code>:swimmer:</code></td><td>🏄 <code>:surfer:</code></td><td>🎿 <code>:ski:</code></td></tr><tr><td>♠️ <code>:spades:</code></td><td>♥️ <code>:hearts:</code></td><td>♣️ <code>:clubs:</code></td></tr><tr><td>♦️ <code>:diamonds:</code></td><td>💎 <code>:gem:</code></td><td>💍 <code>:ring:</code></td></tr><tr><td>🏆 <code>:trophy:</code></td><td>🎼 <code>:musical_score:</code></td><td>🎹 <code>:musical_keyboard:</code></td></tr><tr><td>🎻 <code>:violin:</code></td><td>👾 <code>:space_invader:</code></td><td>🎮 <code>:video_game:</code></td></tr><tr><td>🃏 <code>:black_joker:</code></td><td>🎴 <code>:flower_playing_cards:</code></td><td>🎲 <code>:game_die:</code></td></tr><tr><td>🎯 <code>:dart:</code></td><td>🀄️ <code>:mahjong:</code></td><td>🎬 <code>:clapper:</code></td></tr><tr><td>📝 <code>:memo:</code></td><td>📝 <code>:pencil:</code></td><td>📖 <code>:book:</code></td></tr><tr><td>🎨 <code>:art:</code></td><td>🎤 <code>:microphone:</code></td><td>🎧 <code>:headphones:</code></td></tr><tr><td>🎺 <code>:trumpet:</code></td><td>🎷 <code>:saxophone:</code></td><td>🎸 <code>:guitar:</code></td></tr><tr><td>👞 <code>:shoe:</code></td><td>👡 <code>:sandal:</code></td><td>👠 <code>:high_heel:</code></td></tr><tr><td>💄 <code>:lipstick:</code></td><td>👢 <code>:boot:</code></td><td>👕 <code>:shirt:</code></td></tr><tr><td>👕 <code>:tshirt:</code></td><td>👔 <code>:necktie:</code></td><td>👚 <code>:womans_clothes:</code></td></tr><tr><td>👗 <code>:dress:</code></td><td>🎽 <code>:running_shirt_with_sash:</code></td><td>👖 <code>:jeans:</code></td></tr><tr><td>👘 <code>:kimono:</code></td><td>👙 <code>:bikini:</code></td><td>🎀 <code>:ribbon:</code></td></tr><tr><td>🎩 <code>:tophat:</code></td><td>👑 <code>:crown:</code></td><td>👒 <code>:womans_hat:</code></td></tr><tr><td>👞 <code>:mans_shoe:</code></td><td>🌂 <code>:closed_umbrella:</code></td><td>💼 <code>:briefcase:</code></td></tr><tr><td>👜 <code>:handbag:</code></td><td>👝 <code>:pouch:</code></td><td>👛 <code>:purse:</code></td></tr><tr><td>👓 <code>:eyeglasses:</code></td><td>🎣 <code>:fishing_pole_and_fish:</code></td><td>☕️ <code>:coffee:</code></td></tr><tr><td>🍵 <code>:tea:</code></td><td>🍶 <code>:sake:</code></td><td>🍼 <code>:baby_bottle:</code></td></tr><tr><td>🍺 <code>:beer:</code></td><td>🍻 <code>:beers:</code></td><td>🍸 <code>:cocktail:</code></td></tr><tr><td>🍹 <code>:tropical_drink:</code></td><td>🍷 <code>:wine_glass:</code></td><td>🍴 <code>:fork_and_knife:</code></td></tr><tr><td>🍕 <code>:pizza:</code></td><td>🍔 <code>:hamburger:</code></td><td>🍟 <code>:fries:</code></td></tr><tr><td>🍗 <code>:poultry_leg:</code></td><td>🍖 <code>:meat_on_bone:</code></td><td>🍝 <code>:spaghetti:</code></td></tr><tr><td>🍛 <code>:curry:</code></td><td>🍤 <code>:fried_shrimp:</code></td><td>🍱 <code>:bento:</code></td></tr><tr><td>🍣 <code>:sushi:</code></td><td>🍥 <code>:fish_cake:</code></td><td>🍙 <code>:rice_ball:</code></td></tr><tr><td>🍘 <code>:rice_cracker:</code></td><td>🍚 <code>:rice:</code></td><td>🍜 <code>:ramen:</code></td></tr><tr><td>🍲 <code>:stew:</code></td><td>🍢 <code>:oden:</code></td><td>🍡 <code>:dango:</code></td></tr><tr><td>🥚 <code>:egg:</code></td><td>🍞 <code>:bread:</code></td><td>🍩 <code>:doughnut:</code></td></tr><tr><td>🍮 <code>:custard:</code></td><td>🍦 <code>:icecream:</code></td><td>🍨 <code>:ice_cream:</code></td></tr><tr><td>🍧 <code>:shaved_ice:</code></td><td>🎂 <code>:birthday:</code></td><td>🍰 <code>:cake:</code></td></tr><tr><td>🍪 <code>:cookie:</code></td><td>🍫 <code>:chocolate_bar:</code></td><td>🍬 <code>:candy:</code></td></tr><tr><td>🍭 <code>:lollipop:</code></td><td>🍯 <code>:honey_pot:</code></td><td>🍎 <code>:apple:</code></td></tr><tr><td>🍏 <code>:green_apple:</code></td><td>🍊 <code>:tangerine:</code></td><td>🍋 <code>:lemon:</code></td></tr><tr><td>🍒 <code>:cherries:</code></td><td>🍇 <code>:grapes:</code></td><td>🍉 <code>:watermelon:</code></td></tr><tr><td>🍓 <code>:strawberry:</code></td><td>🍑 <code>:peach:</code></td><td>🍈 <code>:melon:</code></td></tr><tr><td>🍌 <code>:banana:</code></td><td>🍐 <code>:pear:</code></td><td>🍍 <code>:pineapple:</code></td></tr><tr><td>🍠 <code>:sweet_potato:</code></td><td>🍆 <code>:eggplant:</code></td><td>🍅 <code>:tomato:</code></td></tr><tr><td>🌽 <code>:corn:</code></td><td></td><td></td></tr></tbody></table><h1>Places</h1><table><thead><tr><th>🏠 <code>:house:</code></th><th>🏡 <code>:house_with_garden:</code></th><th>🏫 <code>:school:</code></th></tr></thead><tbody><tr><td>🏢 <code>:office:</code></td><td>🏣 <code>:post_office:</code></td><td>🏥 <code>:hospital:</code></td></tr><tr><td>🏦 <code>:bank:</code></td><td>🏪 <code>:convenience_store:</code></td><td>🏩 <code>:love_hotel:</code></td></tr><tr><td>🏨 <code>:hotel:</code></td><td>💒 <code>:wedding:</code></td><td>⛪️ <code>:church:</code></td></tr><tr><td>🏬 <code>:department_store:</code></td><td>🏤 <code>:european_post_office:</code></td><td>🌇 <code>:city_sunrise:</code></td></tr><tr><td>🌆 <code>:city_sunset:</code></td><td>🏯 <code>:japanese_castle:</code></td><td>🏰 <code>:european_castle:</code></td></tr><tr><td>⛺️ <code>:tent:</code></td><td>🏭 <code>:factory:</code></td><td>🗼 <code>:tokyo_tower:</code></td></tr><tr><td>🗾 <code>:japan:</code></td><td>🗻 <code>:mount_fuji:</code></td><td>🌄 <code>:sunrise_over_mountains:</code></td></tr><tr><td>🌅 <code>:sunrise:</code></td><td>🌠 <code>:stars:</code></td><td>🗽 <code>:statue_of_liberty:</code></td></tr><tr><td>🌉 <code>:bridge_at_night:</code></td><td>🎠 <code>:carousel_horse:</code></td><td>🌈 <code>:rainbow:</code></td></tr><tr><td>🎡 <code>:ferris_wheel:</code></td><td>⛲️ <code>:fountain:</code></td><td>🎢 <code>:roller_coaster:</code></td></tr><tr><td>🚢 <code>:ship:</code></td><td>🚤 <code>:speedboat:</code></td><td>⛵️ <code>:boat:</code></td></tr><tr><td>⛵️ <code>:sailboat:</code></td><td>🚣 <code>:rowboat:</code></td><td>⚓️ <code>:anchor:</code></td></tr><tr><td>🚀 <code>:rocket:</code></td><td>✈️ <code>:airplane:</code></td><td>🚁 <code>:helicopter:</code></td></tr><tr><td>🚂 <code>:steam_locomotive:</code></td><td>🚊 <code>:tram:</code></td><td>🚞 <code>:mountain_railway:</code></td></tr><tr><td>🚲 <code>:bike:</code></td><td>🚡 <code>:aerial_tramway:</code></td><td>🚟 <code>:suspension_railway:</code></td></tr><tr><td>🚠 <code>:mountain_cableway:</code></td><td>🚜 <code>:tractor:</code></td><td>🚙 <code>:blue_car:</code></td></tr><tr><td>🚘 <code>:oncoming_automobile:</code></td><td>🚗 <code>:car:</code></td><td>🚗 <code>:red_car:</code></td></tr><tr><td>🚕 <code>:taxi:</code></td><td>🚖 <code>:oncoming_taxi:</code></td><td>🚛 <code>:articulated_lorry:</code></td></tr><tr><td>🚌 <code>:bus:</code></td><td>🚍 <code>:oncoming_bus:</code></td><td>🚨 <code>:rotating_light:</code></td></tr><tr><td>🚓 <code>:police_car:</code></td><td>🚔 <code>:oncoming_police_car:</code></td><td>🚒 <code>:fire_engine:</code></td></tr><tr><td>🚑 <code>:ambulance:</code></td><td>🚐 <code>:minibus:</code></td><td>🚚 <code>:truck:</code></td></tr><tr><td>🚋 <code>:train:</code></td><td>🚉 <code>:station:</code></td><td>🚆 <code>:train2:</code></td></tr><tr><td>🚅 <code>:bullettrain_front:</code></td><td>🚄 <code>:bullettrain_side:</code></td><td>🚈 <code>:light_rail:</code></td></tr><tr><td>🚝 <code>:monorail:</code></td><td>🚃 <code>:railway_car:</code></td><td>🚎 <code>:trolleybus:</code></td></tr><tr><td>🎫 <code>:ticket:</code></td><td>⛽️ <code>:fuelpump:</code></td><td>🚦 <code>:vertical_traffic_light:</code></td></tr><tr><td>🚥 <code>:traffic_light:</code></td><td>⚠️ <code>:warning:</code></td><td>🚧 <code>:construction:</code></td></tr><tr><td>🔰 <code>:beginner:</code></td><td>🏧 <code>:atm:</code></td><td>🎰 <code>:slot_machine:</code></td></tr><tr><td>🚏 <code>:busstop:</code></td><td>💈 <code>:barber:</code></td><td>♨️ <code>:hotsprings:</code></td></tr><tr><td>🏁 <code>:checkered_flag:</code></td><td>🎌 <code>:crossed_flags:</code></td><td>🏮 <code>:izakaya_lantern:</code></td></tr><tr><td>🗿 <code>:moyai:</code></td><td>🎪 <code>:circus_tent:</code></td><td>🎭 <code>:performing_arts:</code></td></tr><tr><td>📍 <code>:round_pushpin:</code></td><td>🚩 <code>:triangular_flag_on_post:</code></td><td>🇯🇵 <code>:jp:</code></td></tr><tr><td>🇰🇷 <code>:kr:</code></td><td>🇨🇳 <code>:cn:</code></td><td>🇺🇸 <code>:us:</code></td></tr><tr><td>🇫🇷 <code>:fr:</code></td><td>🇪🇸 <code>:es:</code></td><td>🇮🇹 <code>:it:</code></td></tr><tr><td>🇷🇺 <code>:ru:</code></td><td>🇬🇧 <code>:gb:</code></td><td>🇬🇧 <code>:uk:</code></td></tr><tr><td>🇩🇪 <code>:de:</code></td><td></td><td></td></tr></tbody></table><h1>Symbols</h1><table><thead><tr><th>1️⃣ <code>:one:</code></th><th>2️⃣ <code>:two:</code></th><th>3️⃣ <code>:three:</code></th></tr></thead><tbody><tr><td>4️⃣ <code>:four:</code></td><td>5️⃣ <code>:five:</code></td><td>6️⃣ <code>:six:</code></td></tr><tr><td>7️⃣ <code>:seven:</code></td><td>8️⃣ <code>:eight:</code></td><td>9️⃣ <code>:nine:</code></td></tr><tr><td>🔟 <code>:keycap_ten:</code></td><td>🔢 <code>:1234:</code></td><td>0️⃣ <code>:zero:</code></td></tr><tr><td>#️⃣ <code>:hash:</code></td><td>🔣 <code>:symbols:</code></td><td>◀️ <code>:arrow_backward:</code></td></tr><tr><td>⬇️ <code>:arrow_down:</code></td><td>▶️ <code>:arrow_forward:</code></td><td>⬅️ <code>:arrow_left:</code></td></tr><tr><td>🔠 <code>:capital_abcd:</code></td><td>🔡 <code>:abcd:</code></td><td>🔤 <code>:abc:</code></td></tr><tr><td>↙️ <code>:arrow_lower_left:</code></td><td>↘️ <code>:arrow_lower_right:</code></td><td>➡️ <code>:arrow_right:</code></td></tr><tr><td>⬆️ <code>:arrow_up:</code></td><td>↖️ <code>:arrow_upper_left:</code></td><td>↗️ <code>:arrow_upper_right:</code></td></tr><tr><td>⏬ <code>:arrow_double_down:</code></td><td>⏫ <code>:arrow_double_up:</code></td><td>🔽 <code>:arrow_down_small:</code></td></tr><tr><td>⤵️ <code>:arrow_heading_down:</code></td><td>⤴️ <code>:arrow_heading_up:</code></td><td>↩️<code>:leftwards_arrow_with_hook:</code></td></tr><tr><td>↪️ <code>:arrow_right_hook:</code></td><td>↔️ <code>:left_right_arrow:</code></td><td>↕️ <code>:arrow_up_down:</code></td></tr><tr><td>🔼 <code>:arrow_up_small:</code></td><td>🔃 <code>:arrows_clockwise:</code></td><td>🔄 <code>:arrows_counterclockwise:</code></td></tr><tr><td>⏪ <code>:rewind:</code></td><td>⏩ <code>:fast_forward:</code></td><td>ℹ️ <code>:information_source:</code></td></tr><tr><td>🆗 <code>:ok:</code></td><td>🔀 <code>:twisted_rightwards_arrows:</code></td><td>🔁 <code>:repeat:</code></td></tr><tr><td>🔂 <code>:repeat_one:</code></td><td>🆕 <code>:new:</code></td><td>🔝 <code>:top:</code></td></tr><tr><td>🆙 <code>:up:</code></td><td>🆒 <code>:cool:</code></td><td>🆓 <code>:free:</code></td></tr><tr><td>🆖 <code>:ng:</code></td><td>🎦 <code>:cinema:</code></td><td>🈁 <code>:koko:</code></td></tr><tr><td>📶 <code>:signal_strength:</code></td><td>🈹 <code>:u5272:</code></td><td>🈴 <code>:u5408:</code></td></tr><tr><td>🈺 <code>:u55b6:</code></td><td>🈯️ <code>:u6307:</code></td><td>🈷️ <code>:u6708:</code></td></tr><tr><td>🈶 <code>:u6709:</code></td><td>🈵 <code>:u6e80:</code></td><td>🈚️ <code>:u7121:</code></td></tr><tr><td>🈸 <code>:u7533:</code></td><td>🈳 <code>:u7a7a:</code></td><td>🈲 <code>:u7981:</code></td></tr><tr><td>🈂️ <code>:sa:</code></td><td>🚻 <code>:restroom:</code></td><td>🚹 <code>:mens:</code></td></tr><tr><td>🚺 <code>:womens:</code></td><td>🚼 <code>:baby_symbol:</code></td><td>🚭 <code>:no_smoking:</code></td></tr><tr><td>🅿️ <code>:parking:</code></td><td>♿️ <code>:wheelchair:</code></td><td>🚇 <code>:metro:</code></td></tr><tr><td>🛄 <code>:baggage_claim:</code></td><td>🉑 <code>:accept:</code></td><td>🚾 <code>:wc:</code></td></tr><tr><td>🚰 <code>:potable_water:</code></td><td>🚮 <code>:put_litter_in_its_place:</code></td><td>㊙️ <code>:secret:</code></td></tr><tr><td>㊗️ <code>:congratulations:</code></td><td>Ⓜ️ <code>:m:</code></td><td>🛂 <code>:passport_control:</code></td></tr><tr><td>🛅 <code>:left_luggage:</code></td><td>🛃 <code>:customs:</code></td><td>🉐 <code>:ideograph_advantage:</code></td></tr><tr><td>🆑 <code>:cl:</code></td><td>🆘 <code>:sos:</code></td><td>🆔 <code>:id:</code></td></tr><tr><td>🚫 <code>:no_entry_sign:</code></td><td>🔞 <code>:underage:</code></td><td>📵 <code>:no_mobile_phones:</code></td></tr><tr><td>🚯 <code>:do_not_litter:</code></td><td>🚱 <code>:non-potable_water:</code></td><td>🚳 <code>:no_bicycles:</code></td></tr><tr><td>🚷 <code>:no_pedestrians:</code></td><td>🚸 <code>:children_crossing:</code></td><td>⛔️ <code>:no_entry:</code></td></tr><tr><td>✳️ <code>:eight_spoked_asterisk:</code></td><td>✴️ <code>:eight_pointed_black_star:</code></td><td>💟 <code>:heart_decoration:</code></td></tr><tr><td>🆚 <code>:vs:</code></td><td>📳 <code>:vibration_mode:</code></td><td>📴 <code>:mobile_phone_off:</code></td></tr><tr><td>💹 <code>:chart:</code></td><td>💱 <code>:currency_exchange:</code></td><td>♈️ <code>:aries:</code></td></tr><tr><td>♉️ <code>:taurus:</code></td><td>♊️ <code>:gemini:</code></td><td>♋️ <code>:cancer:</code></td></tr><tr><td>♌️ <code>:leo:</code></td><td>♍️ <code>:virgo:</code></td><td>♎️ <code>:libra:</code></td></tr><tr><td>♏️ <code>:scorpius:</code></td><td>♐️ <code>:sagittarius:</code></td><td>♑️ <code>:capricorn:</code></td></tr><tr><td>♒️ <code>:aquarius:</code></td><td>♓️ <code>:pisces:</code></td><td>⛎ <code>:ophiuchus:</code></td></tr><tr><td>🔯 <code>:six_pointed_star:</code></td><td>❎<code>:negative_squared_cross_mark:</code></td><td>🅰️ <code>:a:</code></td></tr><tr><td>🅱️ <code>:b:</code></td><td>🆎 <code>:ab:</code></td><td>🅾️ <code>:o2:</code></td></tr><tr><td>💠<code>:diamond_shape_with_a_dot_inside:</code></td><td>♻️ <code>:recycle:</code></td><td>🔚 <code>:end:</code></td></tr><tr><td>🔛 <code>:on:</code></td><td>🔜 <code>:soon:</code></td><td>🕐 <code>:clock1:</code></td></tr><tr><td>🕜 <code>:clock130:</code></td><td>🕙 <code>:clock10:</code></td><td>🕥 <code>:clock1030:</code></td></tr><tr><td>🕚 <code>:clock11:</code></td><td>🕦 <code>:clock1130:</code></td><td>🕛 <code>:clock12:</code></td></tr><tr><td>🕧 <code>:clock1230:</code></td><td>🕑 <code>:clock2:</code></td><td>🕝 <code>:clock230:</code></td></tr><tr><td>🕒 <code>:clock3:</code></td><td>🕞 <code>:clock330:</code></td><td>🕓 <code>:clock4:</code></td></tr><tr><td>🕟 <code>:clock430:</code></td><td>🕔 <code>:clock5:</code></td><td>🕠 <code>:clock530:</code></td></tr><tr><td>🕕 <code>:clock6:</code></td><td>🕡 <code>:clock630:</code></td><td>🕖 <code>:clock7:</code></td></tr><tr><td>🕢 <code>:clock730:</code></td><td>🕗 <code>:clock8:</code></td><td>🕣 <code>:clock830:</code></td></tr><tr><td>🕘 <code>:clock9:</code></td><td>🕤 <code>:clock930:</code></td><td>💲 <code>:heavy_dollar_sign:</code></td></tr><tr><td>©️ <code>:copyright:</code></td><td>®️ <code>:registered:</code></td><td>™️ <code>:tm:</code></td></tr><tr><td>❌ <code>:x:</code></td><td>❗️ <code>:heavy_exclamation_mark:</code></td><td>‼️ <code>:bangbang:</code></td></tr><tr><td>⁉️ <code>:interrobang:</code></td><td>⭕️ <code>:o:</code></td><td>✖️ <code>:heavy_multiplication_x:</code></td></tr><tr><td>➕ <code>:heavy_plus_sign:</code></td><td>➖ <code>:heavy_minus_sign:</code></td><td>➗ <code>:heavy_division_sign:</code></td></tr><tr><td>💮 <code>:white_flower:</code></td><td>💯 <code>:100:</code></td><td>✔️ <code>:heavy_check_mark:</code></td></tr><tr><td>☑️ <code>:ballot_box_with_check:</code></td><td>🔘 <code>:radio_button:</code></td><td>🔗 <code>:link:</code></td></tr><tr><td>➰ <code>:curly_loop:</code></td><td>〰️ <code>:wavy_dash:</code></td><td>〽️ <code>:part_alternation_mark:</code></td></tr><tr><td>🔱 <code>:trident:</code></td><td>:black_square: <code>:black_square:</code></td><td>:white_square: <code>:white_square:</code></td></tr><tr><td>✅ <code>:white_check_mark:</code></td><td>🔲 <code>:black_square_button:</code></td><td>🔳 <code>:white_square_button:</code></td></tr><tr><td>⚫️ <code>:black_circle:</code></td><td>⚪️ <code>:white_circle:</code></td><td>🔴 <code>:red_circle:</code></td></tr><tr><td>🔵 <code>:large_blue_circle:</code></td><td>🔷 <code>:large_blue_diamond:</code></td><td>🔶 <code>:large_orange_diamond:</code></td></tr><tr><td>🔹 <code>:small_blue_diamond:</code></td><td>🔸 <code>:small_orange_diamond:</code></td><td>🔺 <code>:small_red_triangle:</code></td></tr><tr><td>🔻 <code>:small_red_triangle_down:</code></td><td></td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Markdown</category>
      
    </categories>
    
    
    <tags>
      
      <tag>emoji</tag>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vue基础知识</title>
    <link href="/2021/06/05/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/vue/vue/"/>
    <url>/2021/06/05/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/vue/vue/</url>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>概述：Vue是一套构建用户界面的 渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。另一方面，Vue 完全有能力驱动采用单文件组件和 Vue 生态系统支持的库开发的复杂单页应用。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。框架是一套现成的解决方案，只能遵守框架的规范，去编写自己的业务功能。</p><span id="more"></span><h2 id="特性">特性</h2><ol><li><p>数据驱动视图</p></li><li><p>双向数据绑定</p></li></ol><h2 id="使用步骤">使用步骤</h2><ol><li>导入vue.js脚本文件</li><li>声明被vue控制的区域</li><li>创建vm实例化对象</li></ol><h2 id="一、-vue实例">一、 vue实例</h2><p>el：挂载点<br>作用范围：vue会管理el选项中命中的元素及其内部的后代元素<br>data：数据源<br>渲染到页面的数据，复杂数据遵守JS语法即可<br>methods:事件处理函数</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">var</span> app = <span class="hljs-keyword">new</span> Vue(&#123;<br>  <span class="hljs-attr">el</span>: <span class="hljs-string">&#x27;#app&#x27;</span>,<br>  <span class="hljs-attr">data</span>: &#123;<br>    <span class="hljs-attr">message</span>: <span class="hljs-string">&#x27;Hello Vue!&#x27;</span><br>  &#125;,<br>  <span class="hljs-attr">methods</span>:&#123;<br>    <span class="hljs-function"><span class="hljs-title">doSomething</span>(<span class="hljs-params"></span>)</span>&#123;<br><br>    &#125;<br>  &#125;<br>&#125;)<br></code></pre></td></tr></table></figure><h2 id="二、指令">二、指令</h2><p>指令 (Directives) 是带有 v- 前缀的特殊 attribute。指令 attribute 的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM，辅助开发者渲染页面。</p><h3 id="1-内容渲染指令">1. 内容渲染指令</h3><p>辅助开发者渲染DOM元素的文本内容</p><h4 id="1-1-v-text">1.1 v-text</h4><p>缺点：会覆盖原来的内容</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">v-text</span> = <span class="hljs-string">&quot;username&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><br>```  <br><br>#### 1.2 &#123;&#123;&#125;&#125;<br><br>数据绑定最常见的形式就是使&quot;Mustache&quot;语法 (双大括号) 的文本插值<br><br>```HTML  <br><span class="hljs-comment">&lt;!-- 插值表达式 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">span</span>&gt;</span>Message: &#123;&#123; msg &#125;&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span> <br>```  <br><br>#### 1.3 v-html<br><br>可以把带有标签的字符串渲染成真正的HTML<br>双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用 v-html 指令：<br><br>```HTML<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>Using mustaches: &#123;&#123; rawHtml &#125;&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>Using v-html directive: <span class="hljs-tag">&lt;<span class="hljs-name">span</span> <span class="hljs-attr">v-html</span>=<span class="hljs-string">&quot;rawHtml&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="2-属性绑定指令">2. 属性绑定指令</h3><p>注意：插值表达式只能用在内容节点中，不能用在属性节点中</p><h4 id="2-1-v-bind">2.1 v-bind</h4><p>为元素的属性动态绑定值</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs HTMl"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">v-bind:href</span>=<span class="hljs-string">&quot;url&quot;</span>&gt;</span>...<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br><br><span class="hljs-comment">&lt;!-- v-bind 可以简写成: --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">:href</span>=<span class="hljs-string">&quot;url&quot;</span>&gt;</span>...<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br><br><span class="hljs-comment">&lt;!-- 动态参数 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">v-bind:</span>[<span class="hljs-attr">attributeName</span>]=<span class="hljs-string">&quot;url&quot;</span>&gt;</span> ... <span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></td></tr></table></figure><p>使用 JavaScript 表达式<br>迄今为止，在我们的模板中，我们一直都只绑定简单的 property 键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持<br>如果绑定内容需要进行动态拼接，则字符串外面需要包裹一层单引号</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs HTML">&#123;&#123; number + 1 &#125;&#125;<br><br>&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;<br><br>&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;<br><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">v-bind:id</span>=<span class="hljs-string">&quot;&#x27;list-&#x27; + id&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="3-事件绑定指令">3. 事件绑定指令</h3><h4 id="3-1-v-on">3.1 v-on</h4><p>为DOM元素绑定事件监听</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-comment">&lt;!-- 完整语法 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">v-on:click</span>=<span class="hljs-string">&quot;doSomething&quot;</span>&gt;</span>...<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br><br><span class="hljs-comment">&lt;!-- 缩写 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> @<span class="hljs-attr">click</span>=<span class="hljs-string">&quot;doSomething&quot;</span>&gt;</span>...<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br><br><span class="hljs-comment">&lt;!-- 动态参数的缩写 (2.6.0+) --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> @[<span class="hljs-attr">event</span>]=<span class="hljs-string">&quot;doSomething&quot;</span>&gt;</span> ... <span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></td></tr></table></figure><h4 id="3-2-事件修饰符">3.2 事件修饰符</h4><ul><li>使用this能够访问数据源的数据</li><li>事件绑定可以在方式中传一个入参e，调用方不传参数，或者传入$event</li><li>事件修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定<br>例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()：</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">&lt;<span class="hljs-keyword">form</span> v-<span class="hljs-keyword">on</span>:submit.prevent=<span class="hljs-string">&quot;onSubmit&quot;</span>&gt;...&lt;/<span class="hljs-keyword">form</span>&gt;<br></code></pre></td></tr></table></figure><h4 id="3-3-按键修饰符">3.3 按键修饰符</h4><p>在监听键盘事件时，我们经常需要判断详细的按键，此时，可以为键盘相关事件添加按键修饰符</p>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
      <category>Vue</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>Vue</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>WebPack自动化构建</title>
    <link href="/2021/06/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/vue/webPack/"/>
    <url>/2021/06/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/vue/webPack/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><p>概述：webpack实现前端项目的模块化，旨在更高效地管理和维护项目中的每一个资源</p><span id="more"></span><h2 id="1、项目工程化">1、项目工程化</h2><ol><li>模块化 （js、css的模块化）</li><li>组件化 复用现有的UI结构，样式，行为</li><li>规范化 目录结构、编码规范、接口、git</li><li>自动化 自动化构建、部署、测试</li></ol><h2 id="2、webpack">2、webpack</h2><p>前端工程化的具体解决方案，提供了友好的前端模块化开发，以及代码压缩混淆、处理浏览器JavaScript的兼容行、性能优化等功能</p><h3 id="2-1-安装">2.1 安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install webpack@5.42.1 webpack-cli@4.7.2 -D<br></code></pre></td></tr></table></figure><p>在package.json中<br>dependencies - 生产需要的包，命令中添加-S<br>devDependencies - dev环境需要的生产不需要的包，命令中添加-D</p><h3 id="2-2-配置">2.2 配置</h3><ol><li>在根目录中中创建webpack.config.js，并初始化如下配置：</li></ol><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>.exports = &#123;<br>    <span class="hljs-attr">mode</span>: <span class="hljs-string">&quot;development&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><ol start="2"><li>在package.json的scripts节点下，新增dev和build<br>scripts：可运行脚本</li></ol><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-string">&quot;scripts&quot;</span>: &#123;<br>  <span class="hljs-string">&quot;dev&quot;</span>: <span class="hljs-string">&quot;webpack server&quot;</span>,<br>  <span class="hljs-string">&quot;build&quot;</span>: <span class="hljs-string">&quot;webpack --mode production&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><ol><li>在终端数据npm run dev完成打包构建</li></ol><h3 id="2-3-指定entry和output">2.3 指定entry和output</h3><p>默认情况下，打包入口文件为：src -&gt; index.js<br>默认情况下，打包输出文件为：dist -&gt; main.js</p><p>在 webpack.config.js 文件中，通过entry节点指定打包的入口，通过output节点指定打包的出口。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>.exports = &#123;<br>    <span class="hljs-attr">mode</span>: <span class="hljs-string">&quot;development&quot;</span>,<br><br>    <span class="hljs-comment">//指定处理哪个文件</span><br>    <span class="hljs-attr">entry</span>: path.join(__dirname, <span class="hljs-string">&quot;./src/index.js&quot;</span>),<br>    <span class="hljs-comment">//指定生成文件存放目录</span><br>    <span class="hljs-attr">output</span>: &#123;<br>        <span class="hljs-attr">path</span>: path.join(__dirname, <span class="hljs-string">&quot;dist&quot;</span>),<br>        <span class="hljs-attr">filename</span>: <span class="hljs-string">&quot;bundle.js&quot;</span><br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-4-devServer常用选项">2.4  devServer常用选项</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>.exports = &#123;<br>    <span class="hljs-attr">mode</span>: <span class="hljs-string">&quot;development&quot;</span>,<br>    <span class="hljs-attr">plugins</span>: [htmlPlugin],<br>    <span class="hljs-attr">devServer</span>: &#123;<br>        <span class="hljs-attr">open</span>: <span class="hljs-literal">true</span>, <span class="hljs-comment">// 自动打开浏览器</span><br>        <span class="hljs-attr">port</span>: <span class="hljs-number">8081</span>, <span class="hljs-comment">// 修改端口</span><br>        <span class="hljs-attr">host</span>: <span class="hljs-string">&#x27;127.0.0.1&#x27;</span> <span class="hljs-comment">// 指定地址</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-webpack-dev-server插件">3. webpack-dev-server插件</h2><p>热更新，自动生成输出文件，安装命令如下</p><h3 id="3-1-安装">3.1 安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install webpack-dev-server@3.11.2 -D<br></code></pre></td></tr></table></figure><h3 id="3-2-配置">3.2 配置</h3><ol><li>修改package.json中的配置如下，在webpack后加上server</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-string">&quot;scripts&quot;</span>: &#123;<br>  <span class="hljs-attr">&quot;dev&quot;</span>: <span class="hljs-string">&quot;webpack server&quot;</span><br>&#125;,<br></code></pre></td></tr></table></figure><ol start="2"><li><p>再次运行npm run dev命令</p></li><li><p>如果启动失败，遇到以下问题：<br><img src="../../../image/webPack_1.png" alt="启动失败"><br>则需要额外安装</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm i --save-dev webpack-cli  -D<br></code></pre></td></tr></table></figure><h3 id="3-3-工作原理">3.3 工作原理</h3><p>webpack会把输出文件放在内存中，所以可以在保存文件后进行打包编译，实现热更新</p><h2 id="4-html-webpack-plugin插件">4. html-webpack-plugin插件</h2><h3 id="4-1-安装">4.1 安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install html-webpack-plugin@5.3.2 -D<br></code></pre></td></tr></table></figure><h3 id="4-2-配置">4.2 配置</h3><p>修改package.json中的配置如下，在webpack后加上server</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//导入插件</span><br><span class="hljs-keyword">const</span> HtmlPlugin = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;html-webpack-plugin&quot;</span>);<br><span class="hljs-comment">//创建实例</span><br><span class="hljs-keyword">const</span> htmlPlugin = <span class="hljs-keyword">new</span> HtmlPlugin(&#123;<br>    <span class="hljs-comment">//源文件</span><br>    <span class="hljs-attr">template</span>: <span class="hljs-string">&#x27;./src/index.html&#x27;</span>,<br>    <span class="hljs-comment">//被复制的文件</span><br>    <span class="hljs-attr">filename</span>: <span class="hljs-string">&#x27;./index.html&#x27;</span><br>&#125;)<br><span class="hljs-comment">//使用插件</span><br><span class="hljs-built_in">module</span>.exports = &#123;<br>    <span class="hljs-attr">mode</span>: <span class="hljs-string">&quot;development&quot;</span>,<br>    <span class="hljs-attr">plugins</span>: [htmlPlugin]<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-3-特性">4.3 特性</h3><ol><li>将指定的html文件复制到指定目录下</li><li>注入生成的js文件</li></ol><h2 id="5-loader">5. loader</h2><p>webpack只能打包js结尾的文件，其他非js结尾的文件由loader打包特定文件，比如：css-loader<br>当webpack发现某个文件不能处理时，回去找相应的loader处理</p><h3 id="5-1-style-loader、css-loader">5.1 style-loader、css-loader</h3><h4 id="5-1-1-安装">5.1.1 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install style-loader@3.0.0 css-loader@5.2.6 -D<br></code></pre></td></tr></table></figure><h4 id="5-1-2-配置">5.1.2 配置</h4><p>在webpack.config.js的module -&gt; rules中配置loader规则</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>: &#123;<br>    <span class="hljs-attr">rules</span>: [&#123;<br>        <span class="hljs-attr">test</span>: <span class="hljs-regexp">/\.css$/</span>,<br>        use: [<span class="hljs-string">&#x27;style-loader&#x27;</span>, <span class="hljs-string">&#x27;css-loader&#x27;</span>] <span class="hljs-comment">// 从后往前调用，依次处理</span><br>    &#125;]<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="5-2-url-loader">5.2 url-loader</h3><h4 id="5-2-1-安装">5.2.1 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install url-loader@4.1.1 file-loader@6.2.0 -D<br></code></pre></td></tr></table></figure><h4 id="5-2-2-配置">5.2.2 配置</h4><p>在webpack.config.js的module -&gt; rules中配置loader规则</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>: &#123;<br>    <span class="hljs-attr">rules</span>: [&#123;<br>        <span class="hljs-attr">test</span>: <span class="hljs-regexp">/\.jpg|png|gif$/</span>,<br>        use: [<span class="hljs-string">&#x27;url-loader?limit=22229&#x27;</span>] <span class="hljs-comment">// ?之后是loader的参数项，只有小于limit的图片，才会转换为base64</span><br>    &#125;]<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="5-3-label-loader">5.3 label-loader</h3><p>转换处理js中webpack不能处理得一些高级语法</p><h4 id="5-3-1-安装">5.3.1 安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install babel-loader@8.2.2 @babel/core@7.14.6 @babel/plugin-proposal-decorators@7.14.5 -D<br></code></pre></td></tr></table></figure><h4 id="5-3-2-配置">5.3.2 配置</h4><p>在webpack.config.js的module -&gt; rules中配置loader规则</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>: &#123;<br>    <span class="hljs-attr">rules</span>: [&#123;<br>        <span class="hljs-attr">test</span>: <span class="hljs-regexp">/\.js$/</span>,<br>        use: [<span class="hljs-string">&#x27;babel-loader&#x27;</span>], <span class="hljs-comment">// ?之后是loader的参数项，只有小于limit的图片，才会转换为base64</span><br>        <span class="hljs-attr">exlude</span>: <span class="hljs-regexp">/node_modules/</span> <span class="hljs-comment">// 排除不需要处理得代码</span><br>    &#125;]<br>&#125;<br></code></pre></td></tr></table></figure><p>在根目录下创建babel.config.js，并在此文件中添加可用插件</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-built_in">module</span>.exports = &#123;<br>    <span class="hljs-comment">// 生命babel可用得插件</span><br>    <span class="hljs-attr">plugins</span>: [[<span class="hljs-string">&#x27;@babel/plugin-proposal-decorators&#x27;</span>, &#123;<span class="hljs-attr">legacy</span>: <span class="hljs-literal">true</span>&#125;]]<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
      <category>Vue</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>Vue</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？</title>
    <link href="/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/11.%E5%9C%A8%20TIME_WAIT%20%E7%8A%B6%E6%80%81%E7%9A%84%20TCP%20%E8%BF%9E%E6%8E%A5%EF%BC%8C%E6%94%B6%E5%88%B0%20SYN%20%E5%90%8E%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <url>/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/11.%E5%9C%A8%20TIME_WAIT%20%E7%8A%B6%E6%80%81%E7%9A%84%20TCP%20%E8%BF%9E%E6%8E%A5%EF%BC%8C%E6%94%B6%E5%88%B0%20SYN%20%E5%90%8E%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？</h1><p>大家好，我是小林。</p><p>周末跟朋友讨论了一些 TCP 的问题，在查阅《Linux 服务器高性能编程》这本书的时候，发现书上写了这么一句话：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/65739ee668999bda02aa9236aad6437f.png" alt="图片"></p><p>书上说，处于 TIME_WAIT 状态的连接，在收到相同四元组的 SYN 后，会回 RST 报文，对方收到后就会断开连接。</p><p>书中作者只是提了这么一句话，没有给予源码或者抓包图的证据。</p><p>起初，我看到也觉得这个逻辑也挺符合常理的，但是当我自己去啃了 TCP 源码后，发现并不是这样的。</p><p>所以，今天就来讨论下这个问题，「<strong>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</strong>」</p><p>问题现象如下图，左边是服务端，右边是客户端：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/74b53919396dcda634cfd5b5795cbf16.png" alt="图片"></p><h2 id="先说结论">先说结论</h2><p>在跟大家分析 TCP 源码前，我先跟大家直接说下结论。</p><p>针对这个问题，<strong>关键是要看 SYN 的「序列号和时间戳」是否合法</strong>，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会判断 SYN 的「序列号和时间戳」是否合法，然后根据判断结果的不同做不同的处理。</p><p>先跟大家说明下， 什么是「合法」的 SYN？</p><ul><li><strong>合法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。</li><li><strong>非法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong> SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。</li></ul><p>上面 SYN 合法判断是基于双方都开启了 TCP 时间戳机制的场景，如果双方都没有开启 TCP 时间戳机制，则 SYN 合法判断如下：</p><ul><li><strong>合法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>。</li><li><strong>非法 SYN</strong>：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>。</li></ul><h3 id="收到合法-SYN">收到合法 SYN</h3><p>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，<strong>就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程</strong>。</p><p>用下图作为例子，双方都启用了 TCP 时间戳机制，TSval 是发送报文时的时间戳：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/39d0d04adf72fe3d37623acff9ae2507.png" alt="图片"></p><p>上图中，在收到第三次挥手的 FIN 报文时，会记录该报文的 TSval （21），用 ts_recent 变量保存。然后会计算下一次期望收到的序列号，本次例子下一次期望收到的序列号就是 301，用 rcv_nxt 变量保存。</p><p>处于 TIME_WAIT 状态的连接收到 SYN 后，<strong>因为 SYN 的 seq（400） 大于 rcv_nxt（301），并且 SYN 的 TSval（30） 大于 ts_recent（21），所以是一个「合法的 SYN」，于是就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</strong></p><h3 id="收到非法的-SYN">收到非法的 SYN</h3><p>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端</strong>。</p><p>用下图作为例子，双方都启用了 TCP 时间戳机制，TSval 是发送报文时的时间戳：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/tw%E6%94%B6%E5%88%B0%E4%B8%8D%E5%90%88%E6%B3%95.png" alt="img"></p><p>上图中，在收到第三次挥手的 FIN 报文时，会记录该报文的 TSval （21），用 ts_recent 变量保存。然后会计算下一次期望收到的序列号，本次例子下一次期望收到的序列号就是 301，用 rcv_nxt 变量保存。</p><p>处于 TIME_WAIT 状态的连接收到 SYN 后，<strong>因为 SYN 的 seq（200） 小于 rcv_nxt（301），所以是一个「非法的 SYN」，就会再回复一个与第四次挥手一样的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。</p><blockquote><p>PS：这里先埋一个疑问，处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？</p></blockquote><h2 id="源码分析">源码分析</h2><p>下面源码分析是基于 Linux 4.2 版本的内核代码。</p><p>Linux 内核在收到 TCP 报文后，会执行 <code>tcp_v4_rcv</code> 函数，在该函数和 TIME_WAIT 状态相关的主要代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">tcp_v4_rcv</span><span class="hljs-params">(struct sk_buff *skb)</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sock</span> *<span class="hljs-title">sk</span>;</span><br> ...<br>  <span class="hljs-comment">//收到报文后，会调用此函数，查找对应的 sock</span><br> sk = __inet_lookup_skb(&amp;tcp_hashinfo, skb, __tcp_hdrlen(th), th-&gt;source,<br>          th-&gt;dest, sdif, &amp;refcounted);<br> <span class="hljs-keyword">if</span> (!sk)<br>  <span class="hljs-keyword">goto</span> no_tcp_socket;<br><br>process:<br>  <span class="hljs-comment">//如果连接的状态为 time_wait，会跳转到 do_time_wait</span><br> <span class="hljs-keyword">if</span> (sk-&gt;sk_state == TCP_TIME_WAIT)<br>  <span class="hljs-keyword">goto</span> do_time_wait;<br><br>...<br><br>do_time_wait:<br>  ...<br>  <span class="hljs-comment">//由tcp_timewait_state_process函数处理在 time_wait 状态收到的报文</span><br> <span class="hljs-keyword">switch</span> (tcp_timewait_state_process(inet_twsk(sk), skb, th)) &#123;<br>    <span class="hljs-comment">// 如果是TCP_TW_SYN，那么允许此 SYN 重建连接</span><br>    <span class="hljs-comment">// 即允许TIM_WAIT状态跃迁到SYN_RECV</span><br>    <span class="hljs-keyword">case</span> TCP_TW_SYN: &#123;<br>      <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sock</span> *<span class="hljs-title">sk2</span> =</span> inet_lookup_listener(....);<br>      <span class="hljs-keyword">if</span> (sk2) &#123;<br>          ....<br>          <span class="hljs-keyword">goto</span> process;<br>      &#125;<br>    &#125;<br>    <span class="hljs-comment">// 如果是TCP_TW_ACK，那么，返回记忆中的ACK</span><br>    <span class="hljs-keyword">case</span> TCP_TW_ACK:<br>      tcp_v4_timewait_ack(sk, skb);<br>      <span class="hljs-keyword">break</span>;<br>    <span class="hljs-comment">// 如果是TCP_TW_RST直接发送RESET包</span><br>    <span class="hljs-keyword">case</span> TCP_TW_RST:<br>      tcp_v4_send_reset(sk, skb);<br>      inet_twsk_deschedule_put(inet_twsk(sk));<br>      <span class="hljs-keyword">goto</span> discard_it;<br>     <span class="hljs-comment">// 如果是TCP_TW_SUCCESS则直接丢弃此包，不做任何响应</span><br>    <span class="hljs-keyword">case</span> TCP_TW_SUCCESS:;<br> &#125;<br> <span class="hljs-keyword">goto</span> discard_it;<br>&#125;<br></code></pre></td></tr></table></figure><p>该代码的过程：</p><ol><li>接收到报文后，会调用 <code>__inet_lookup_skb()</code> 函数查找对应的 sock 结构；</li><li>如果连接的状态是 <code>TIME_WAIT</code>，会跳转到 do_time_wait 处理；</li><li>由 <code>tcp_timewait_state_process()</code> 函数来处理收到的报文，处理后根据返回值来做相应的处理。</li></ol><p>先跟大家说下，如果收到的 SYN 是合法的，<code>tcp_timewait_state_process()</code> 函数就会返回 <code>TCP_TW_SYN</code>，然后重用此连接。如果收到的 SYN 是非法的，<code>tcp_timewait_state_process()</code> 函数就会返回 <code>TCP_TW_ACK</code>，然后会回上次发过的 ACK。</p><p>接下来，看 <code>tcp_timewait_state_process()</code> 函数是如何判断 SYN 包的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">enum</span> tcp_tw_status</span><br><span class="hljs-function"><span class="hljs-title">tcp_timewait_state_process</span><span class="hljs-params">(struct inet_timewait_sock *tw, struct sk_buff *skb,</span></span><br><span class="hljs-params"><span class="hljs-function">      <span class="hljs-keyword">const</span> struct tcphdr *th)</span></span><br><span class="hljs-function"></span>&#123;<br> ...<br>  <span class="hljs-comment">//paws_reject 为 false，表示没有发生时间戳回绕</span><br>  <span class="hljs-comment">//paws_reject 为 true，表示发生了时间戳回绕</span><br> <span class="hljs-keyword">bool</span> paws_reject = <span class="hljs-literal">false</span>;<br><br> tmp_opt.saw_tstamp = <span class="hljs-number">0</span>;<br>  <span class="hljs-comment">//TCP头中有选项且旧连接开启了时间戳选项</span><br> <span class="hljs-keyword">if</span> (th-&gt;doff &gt; (<span class="hljs-keyword">sizeof</span>(*th) &gt;&gt; <span class="hljs-number">2</span>) &amp;&amp; tcptw-&gt;tw_ts_recent_stamp) &#123; <br>  <span class="hljs-comment">//解析选项</span><br>    tcp_parse_options(twsk_net(tw), skb, &amp;tmp_opt, <span class="hljs-number">0</span>, <span class="hljs-literal">NULL</span>);<br><br>  <span class="hljs-keyword">if</span> (tmp_opt.saw_tstamp) &#123;<br>   ...<br>      <span class="hljs-comment">//检查收到的报文的时间戳是否发生了时间戳回绕</span><br>   paws_reject = tcp_paws_reject(&amp;tmp_opt, th-&gt;rst);<br>  &#125;<br> &#125;<br><br>....<br><br>  <span class="hljs-comment">//是SYN包、没有RST、没有ACK、时间戳没有回绕，并且序列号也没有回绕，</span><br> <span class="hljs-keyword">if</span> (th-&gt;syn &amp;&amp; !th-&gt;rst &amp;&amp; !th-&gt;ack &amp;&amp; !paws_reject &amp;&amp;<br>     (after(TCP_SKB_CB(skb)-&gt;seq, tcptw-&gt;tw_rcv_nxt) ||<br>      (tmp_opt.saw_tstamp &amp;&amp; <span class="hljs-comment">//新连接开启了时间戳</span><br>       (s32)(tcptw-&gt;tw_ts_recent - tmp_opt.rcv_tsval) &lt; <span class="hljs-number">0</span>))) &#123; <span class="hljs-comment">//时间戳没有回绕</span><br>    <span class="hljs-comment">// 初始化序列号</span><br>    u32 isn = tcptw-&gt;tw_snd_nxt + <span class="hljs-number">65535</span> + <span class="hljs-number">2</span>; <br>    <span class="hljs-keyword">if</span> (isn == <span class="hljs-number">0</span>)<br>      isn++;<br>    TCP_SKB_CB(skb)-&gt;tcp_tw_isn = isn;<br>    <span class="hljs-keyword">return</span> TCP_TW_SYN; <span class="hljs-comment">//允许重用TIME_WAIT四元组重新建立连接</span><br> &#125;<br><br><br> <span class="hljs-keyword">if</span> (!th-&gt;rst) &#123;<br>    <span class="hljs-comment">// 如果时间戳回绕，或者报文里包含ack，则将 TIMEWAIT 状态的持续时间重新延长</span><br>  <span class="hljs-keyword">if</span> (paws_reject || th-&gt;ack)<br>    inet_twsk_schedule(tw, &amp;tcp_death_row, TCP_TIMEWAIT_LEN,<br>        TCP_TIMEWAIT_LEN);<br><br>     <span class="hljs-comment">// 返回TCP_TW_ACK, 发送上一次的 ACK</span><br>    <span class="hljs-keyword">return</span> TCP_TW_ACK;<br> &#125;<br> inet_twsk_put(tw);<br> <span class="hljs-keyword">return</span> TCP_TW_SUCCESS;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果双方启用了 TCP 时间戳机制，就会通过 <code>tcp_paws_reject()</code> 函数来判断时间戳是否发生了回绕，也就是「当前收到的报文的时间戳」是否大于「上一次收到的报文的时间戳」：</p><ul><li>如果大于，就说明没有发生时间戳绕回，函数返回 false。</li><li>如果小于，就说明发生了时间戳回绕，函数返回 true。</li></ul><p>从源码可以看到，当收到 SYN 包后，如果该 SYN 包的时间戳没有发生回绕，也就是时间戳是递增的，并且 SYN 包的序列号也没有发生回绕，也就是 SYN 的序列号「大于」下一次期望收到的序列号。就会初始化一个序列号，然后返回 TCP_TW_SYN，接着就重用该连接，也就跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</p><p>如果双方都没有启用 TCP 时间戳机制，就只需要判断 SYN 包的序列号有没有发生回绕，如果 SYN 的序列号大于下一次期望收到的序列号，就可以跳过 2MSL，重用该连接。</p><p>如果 SYN 包是非法的，就会返回 TCP_TW_ACK，接着就会发送与上一次一样的 ACK 给对方。</p><h2 id="在-TIME-WAIT-状态，收到-RST-会断开连接吗？">在 TIME_WAIT 状态，收到 RST 会断开连接吗？</h2><p>在前面我留了一个疑问，处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？</p><p>会不会断开，关键看 <code>net.ipv4.tcp_rfc1337</code> 这个内核参数（默认情况是为 0）：</p><ul><li>如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。</li><li>如果这个参数设置为 1， 就会丢掉 RST 报文。</li></ul><p>源码处理如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">enum</span> tcp_tw_status</span><br><span class="hljs-function"><span class="hljs-title">tcp_timewait_state_process</span><span class="hljs-params">(struct inet_timewait_sock *tw, struct sk_buff *skb,</span></span><br><span class="hljs-params"><span class="hljs-function">      <span class="hljs-keyword">const</span> struct tcphdr *th)</span></span><br><span class="hljs-function"></span>&#123;<br>....<br>  <span class="hljs-comment">//rst报文的时间戳没有发生回绕</span><br> <span class="hljs-keyword">if</span> (!paws_reject &amp;&amp;<br>     (TCP_SKB_CB(skb)-&gt;seq == tcptw-&gt;tw_rcv_nxt &amp;&amp;<br>      (TCP_SKB_CB(skb)-&gt;seq == TCP_SKB_CB(skb)-&gt;end_seq || th-&gt;rst))) &#123;<br><br>      <span class="hljs-comment">//处理rst报文</span><br>      <span class="hljs-keyword">if</span> (th-&gt;rst) &#123;<br>        <span class="hljs-comment">//不开启这个选项，当收到 RST 时会立即回收tw，但这样做是有风险的</span><br>        <span class="hljs-keyword">if</span> (twsk_net(tw)-&gt;ipv4.sysctl_tcp_rfc1337 == <span class="hljs-number">0</span>) &#123;<br>          kill:<br>          <span class="hljs-comment">//删除tw定时器，并释放tw</span><br>          inet_twsk_deschedule_put(tw);<br>          <span class="hljs-keyword">return</span> TCP_TW_SUCCESS;<br>        &#125;<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">//将 TIMEWAIT 状态的持续时间重新延长</span><br>        inet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);<br>      &#125;<br><br>      ...<br>      <span class="hljs-keyword">return</span> TCP_TW_SUCCESS;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>TIME_WAIT 状态收到 RST 报文而释放连接，这样等于跳过 2MSL 时间，这么做还是有风险。</p><p>sysctl_tcp_rfc1337 这个参数是在 rfc 1337 文档提出来的，目的是避免因为 TIME_WAIT 状态收到 RST 报文而跳过 2MSL 的时间，文档里也给出跳过 2MSL 时间会有什么潜在问题。</p><p>TIME_WAIT 状态之所以要持续 2MSL 时间，主要有两个目的：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p>详细的为什么要设计 TIME_WAIT 状态，我在这篇有详细说明：<a href="https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&amp;mid=2247502380&amp;idx=1&amp;sn=7b82818a5fb6f1127d17f0ded550c4bd&amp;scene=21#wechat_redirect">如果 TIME_WAIT 状态持续时间过短或者没有，会有什么问题？(opens new window)</a></p><p>虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。</p><p>《UNIX网络编程》一书中却说道：<strong>TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它</strong>。</p><p>所以，我个人觉得将 <code>net.ipv4.tcp_rfc1337</code> 设置为 1 会比较安全。</p><h2 id="总结">总结</h2><p>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</p><p>如果双方开启了时间戳机制：</p><ul><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>大</strong>，<strong>并且</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>大</strong>。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</li><li>如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要<strong>小</strong>，<strong>或者</strong>SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要<strong>小</strong>。那么就会<strong>再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。</li></ul><p>在 TIME_WAIT 状态，收到 RST 会断开连接吗？</p><ul><li>如果 <code>net.ipv4.tcp_rfc1337</code> 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。</li><li>如果 <code>net.ipv4.tcp_rfc1337</code> 参数为 1，则会丢掉该 RST 报文。</li></ul><p>完！</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 连接，一端断电和进程崩溃有什么区别</title>
    <link href="/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/12.TCP%20%E8%BF%9E%E6%8E%A5%EF%BC%8C%E4%B8%80%E7%AB%AF%E6%96%AD%E7%94%B5%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%B4%A9%E6%BA%83%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/"/>
    <url>/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/12.TCP%20%E8%BF%9E%E6%8E%A5%EF%BC%8C%E4%B8%80%E7%AB%AF%E6%96%AD%E7%94%B5%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%B4%A9%E6%BA%83%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1>TCP 连接，一端断电和进程崩溃有什么区别？</h1><p>有位读者找我说，他在面试腾讯的时候，遇到了这么个问题：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p><p>这个属于 <strong>TCP 异常断开连接</strong>的场景，这部分内容在我的「图解网络」还没有详细介绍过，这次就乘着这次机会补一补。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225821993.png" alt="在这里插入图片描述"></p><p>这个问题有几个关键词：</p><ul><li>没有开启 keepalive；</li><li>一直没有数据交互；</li><li>进程崩溃；</li><li>主机崩溃；</li></ul><p>我们先来认识认识什么是 TCP keepalive 呢？</p><p>这东西其实就是 <strong>TCP 的保活机制</strong>，它的工作原理我之前的文章写过，这里就直接贴下以前的内容。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225825871.png" alt="在这里插入图片描述"></p><p>如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。</p><ul><li>如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225831506.png" alt="在这里插入图片描述"></p><p>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><h2 id="主机崩溃">主机崩溃</h2><p>知道了 TCP keepalive 作用，我们再回过头看题目中的「主机崩溃」这种情况。</p><blockquote><p>在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。</p></blockquote><p>客户端主机崩溃了，服务端是<strong>无法感知到的</strong>，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，<strong>服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态</strong>，直到服务端重启进程。</p><p>所以，我们可以得知一个点，在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。</p><h2 id="进程崩溃">进程崩溃</h2><blockquote><p>那题目中的「进程崩溃」的情况呢？</p></blockquote><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程。</p><p>我自己做了实验，使用 kill -9 来模拟进程崩溃的情况，发现<strong>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</strong>。</p><p>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225835745.png" alt="在这里插入图片描述"></p><hr><h2 id="有数据传输的场景">有数据传输的场景</h2><p>以上就是对这个面试题的回答，接下来我们看看在「<strong>有数据传输</strong>」的场景下的一些异常情况：</p><ul><li>第一种，客户端主机宕机，又迅速重启，会发生什么？</li><li>第二种，客户端主机宕机，一直没有重启，会发生什么？</li></ul><h3 id="客户端主机宕机，又迅速重启">客户端主机宕机，又迅速重启</h3><p>在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的报文。</p><p>服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：</p><ul><li>如果客户端主机上<strong>没有</strong>进程绑定该 TCP 报文的目标端口号，那么客户端内核就会<strong>回复 RST 报文，重置该 TCP 连接</strong>；</li><li>如果客户端主机上<strong>有</strong>进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会<strong>回复 RST 报文，重置该 TCP 连接</strong>。</li></ul><p>所以，<strong>只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接</strong>。</p><h3 id="客户端主机宕机，一直没有重启">客户端主机宕机，一直没有重启</h3><p>这种情况，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225840360.png" alt="img"></p><blockquote><p>那 TCP 的数据报文具体重传几次呢？</p></blockquote><p>在 Linux 系统中，提供一个叫 tcp_retries2 配置项，默认值是 15，如下图：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/20210615134059647.png" alt="在这里插入图片描述"></p><p>这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。</p><p>不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，<strong>内核会根据 tcp_retries2 设置的值，计算出一个 timeout</strong>（<em>如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms</em>），<strong>如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接</strong>。</p><p>在发生超时重传的过程中，每一轮的超时时间（RTO）都是<strong>倍数增长</strong>的，比如如果第一轮 RTO 是 200 毫秒，那么第二轮 RTO 是 400 毫秒，第三轮 RTO 是 800 毫秒，以此类推。</p><p>而 RTO 是基于 RTT（一个包的往返时间） 来计算的，如果 RTT 较大，那么计算出来的 RTO 就越大，那么经过几轮重传后，很快就达到了上面的 timeout 值了。</p><p>举个例子，如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms，如果重传总间隔时长达到了 timeout 就会停止重传，然后就会断开 TCP 连接：</p><ul><li>如果 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，也就是第一轮的超时时间是 200 毫秒，由于 timeout 总时长是 924600 ms，表现出来的现象刚好就是重传了 15 次，超过了 timeout 值，从而断开 TCP 连接</li><li>如果 RTT 比较大，假设 RTO 初始值计算得到的是 1000 ms，也就是第一轮的超时时间是 1 秒，那么根本不需要重传 15 次，重传总间隔就会超过 924600 ms。</li></ul><p>最小 RTO 和最大 RTO 是在 Linux 内核中定义好了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> TCP_RTO_MAX ((unsigned)(120*HZ))</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> TCP_RTO_MIN ((unsigned)(HZ/5))</span><br></code></pre></td></tr></table></figure><p>Linux 2.6+ 使用 1000 毫秒的 HZ，因此<code>TCP_RTO_MIN</code>约为 200 毫秒，<code>TCP_RTO_MAX</code>约为 120 秒。</p><p>如果<code>tcp_retries</code>设置为<code>15</code>，且 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，这意味着<strong>它需要 924.6 秒</strong>才能将断开的 TCP 连接通知给上层（即应用程序），每一轮的 RTO 增长关系如下表格：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0ODI3Njc0,size_16,color_FFFFFF,t_70-20230309225847765.png" alt="在这里插入图片描述"></p><hr><h2 id="总结">总结</h2><p>如果「<strong>客户端进程崩溃</strong>」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。</p><p>但是，「<strong>客户端主机宕机</strong>」，那么是不会发生四次挥手的，具体后续会发生什么？还要看服务端会不会发送数据？</p><ul><li>如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；</li><li>如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？<ul><li>如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；</li><li>如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。</li></ul></li></ul><p>最后说句，TCP 牛逼，啥异常都考虑到了。</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>拔掉网线后，原本的 TCP 连接还存在吗？</title>
    <link href="/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/13.%E6%8B%94%E6%8E%89%E7%BD%91%E7%BA%BF%E5%90%8E%EF%BC%8C%E5%8E%9F%E6%9C%AC%E7%9A%84%20TCP%20%E8%BF%9E%E6%8E%A5%E8%BF%98%E5%AD%98%E5%9C%A8%E5%90%97%EF%BC%9F/"/>
    <url>/2021/05/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/13.%E6%8B%94%E6%8E%89%E7%BD%91%E7%BA%BF%E5%90%8E%EF%BC%8C%E5%8E%9F%E6%9C%AC%E7%9A%84%20TCP%20%E8%BF%9E%E6%8E%A5%E8%BF%98%E5%AD%98%E5%9C%A8%E5%90%97%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>拔掉网线后，原本的 TCP 连接还存在吗？</h1><p>今天，聊一个有趣的问题：<strong>拔掉网线几秒，再插回去，原本的 TCP 连接还存在吗？</strong></p><p>可能有的同学会说，网线都被拔掉了，那说明物理层被断开了，那在上层的传输层理应也会断开，所以原本的 TCP 连接就不会存在的了。就好像， 我们拨打有线电话的时候，如果某一方的电话线被拔了，那么本次通话就彻底断了。</p><p>真的是这样吗？</p><p>上面这个逻辑就有问题。问题在于，错误的认为拔掉网线这个动作会影响传输层，事实上并不会影响。</p><p>实际上，TCP 连接在 Linux 内核中是一个名为 <code>struct socket</code> 的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。</p><p>我在我的电脑上做了个小实验，我用 ssh 终端连接了我的云服务器，然后我通过断开 wifi 的方式来模拟拔掉网线的场景，此时查看 TCP 连接的状态没有发生变化，还是处于 ESTABLISHED 状态。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/fff358407ee92aeea1e17386191a5d18.png" alt="图片"></p><p>通过上面这个实验结果，我们知道了，拔掉网线这个动作并不会影响 TCP 连接的状态。</p><p>接下来，要看拔掉网线后，双方做了什么动作。</p><p>所以， 针对这个问题，要分场景来讨论：</p><ul><li>拔掉网线后，有数据传输；</li><li>拔掉网线后，没有数据传输；</li></ul><h2 id="拔掉网线后，有数据传输">拔掉网线后，有数据传输</h2><p>在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发<strong>超时重传</strong>机制，重传未得到响应的数据报文。</p><p><strong>如果在服务端重传报文的过程中，客户端刚好把网线插回去了</strong>，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于 ESTABLISHED 状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。</p><p>此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。</p><p>但是，<strong>如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去</strong>，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</p><p>而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。</p><p>此时，客户端和服务端的 TCP 连接都已经断开了。</p><blockquote><p>那 TCP 的数据报文具体重传几次呢？</p></blockquote><p>在 Linux 系统中，提供了一个叫 tcp_retries2 配置项，默认值是 15，如下图：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f92c00c7e9cd01e89326e943232e5f04.png" alt="图片"></p><p>这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。</p><p>不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，<strong>内核会根据 tcp_retries2 设置的值，计算出一个 timeout</strong>（<em>如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms</em>），<strong>如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接</strong>。</p><p>在发生超时重传的过程中，每一轮的超时时间（RTO）都是<strong>倍数增长</strong>的，比如如果第一轮 RTO 是 200 毫秒，那么第二轮 RTO 是 400 毫秒，第三轮 RTO 是 800 毫秒，以此类推。</p><p>而 RTO 是基于 RTT（一个包的往返时间） 来计算的，如果 RTT 较大，那么计算出来的 RTO 就越大，那么经过几轮重传后，很快就达到了上面的 timeout 值了。</p><p>举个例子，如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms，如果重传总间隔时长达到了 timeout 就会停止重传，然后就会断开 TCP 连接：</p><ul><li>如果 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，也就是第一轮的超时时间是 200 毫秒，由于 timeout 总时长是 924600 ms，表现出来的现象刚好就是重传了 15 次，超过了 timeout 值，从而断开 TCP 连接</li><li>如果 RTT 比较大，假设 RTO 初始值计算得到的是 1000 ms，也就是第一轮的超时时间是 1 秒，那么根本不需要重传 15 次，重传总间隔就会超过 924600 ms。</li></ul><p>最小 RTO 和最大 RTO 是在 Linux 内核中定义好了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> TCP_RTO_MAX ((unsigned)(120*HZ))</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> TCP_RTO_MIN ((unsigned)(HZ/5))</span><br></code></pre></td></tr></table></figure><p>Linux 2.6+ 使用 1000 毫秒的 HZ，因此<code>TCP_RTO_MIN</code>约为 200 毫秒，<code>TCP_RTO_MAX</code>约为 120 秒。</p><p>如果<code>tcp_retries</code>设置为<code>15</code>，且 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，这意味着<strong>它需要 924.6 秒</strong>才能将断开的 TCP 连接通知给上层（即应用程序），每一轮的 RTO 增长关系如下表格：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/10fa6882db83aee68f246c04fcb7d760.png" alt="img"></p><h2 id="拔掉网线后，没有数据传输">拔掉网线后，没有数据传输</h2><p>针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制 （TCP 保活机制）。</p><p>如果<strong>没有开启</strong> TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。</p><p>而如果<strong>开启</strong>了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文：</p><ul><li>如果<strong>对端是正常工作</strong>的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>如果<strong>对端主机宕机</strong>（<em>注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机</em>），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p><blockquote><p>TCP keepalive 机制具体是怎么样的？</p></blockquote><p>这个机制的原理是这样的：</p><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">net.ipv4.tcp_keepalive_time=7200<br>net.ipv4.tcp_keepalive_intvl=75  <br>net.ipv4.tcp_keepalive_probes=9<br></code></pre></td></tr></table></figure><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/46906e588260607680db43a68fe00278.png" alt="img"></p><p>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><blockquote><p>TCP keepalive 机制探测的时间也太长了吧？</p></blockquote><p>对的，是有点长。</p><p>TCP keepalive 是 <strong>TCP 层（内核态）</strong> 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。</p><p>实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。</p><p>比如，web 服务软件一般都会提供 <code>keepalive_timeout</code> 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/c881f163091a4c6427d68b7144c3a980.png" alt="图片"></p><h2 id="总结">总结</h2><p>客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。</p><p>有数据传输的情况：</p><ul><li>在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。</li><li>在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。</li></ul><p>没有数据传输的情况：</p><ul><li>如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。</li><li>如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。</li></ul><p>除了客户端拔掉网线的场景，还有客户端「<a href="https://xiaolincoding.com/network/3_tcp/tcp_down_and_crash.html">主机宕机和进程崩溃 (opens new window)</a>」的两种场景。</p><p>第一个场景，客户端宕机这件事跟拔掉网线是一样无法被服务端的感知的，所以如果在没有数据传输，并且没有开启 TCP keepalive 机制时，，<strong>服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态</strong>，直到服务端重启进程。</p><p>所以，我们可以得知一个点。在没有使用 TCP 保活机制，且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态时，并不代表另一方的 TCP 连接还一定是正常的。</p><p>第二个场景，客户端的进程崩溃后，客户端的内核就会向服务端发送 FIN 报文，<strong>与服务端进行四次挥手</strong>。</p><p>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p><p>完！</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SYN 报文什么时候情况下会被丢弃？</title>
    <link href="/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/08.SYN%20%E6%8A%A5%E6%96%87%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%83%85%E5%86%B5%E4%B8%8B%E4%BC%9A%E8%A2%AB%E4%B8%A2%E5%BC%83%EF%BC%9F/"/>
    <url>/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/08.SYN%20%E6%8A%A5%E6%96%87%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%83%85%E5%86%B5%E4%B8%8B%E4%BC%9A%E8%A2%AB%E4%B8%A2%E5%BC%83%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>SYN 报文什么时候情况下会被丢弃？</h1><p>这个问题跟工作上也是有关系的，因为我就在工作中碰到这么奇怪的时候，客户端向服务端发起了连接，但是连接并没有建立起来，通过抓包分析发现，服务端是收到 SYN 报文了，但是并没有回复 SYN+ACK（TCP 第二次握手），说明 SYN 报文被服务端忽略了，然后客户端就一直在超时重传 SYN 报文，直到达到最大的重传次数。</p><p>接下来，我就给出我遇到过 SYN 报文被丢弃的两种场景：</p><ul><li>开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃</li><li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</li></ul><h2 id="坑爹的-tcp-tw-recycle">坑爹的 tcp_tw_recycle</h2><p>TCP 四次挥手过程中，主动断开连接方会有一个 TIME_WAIT 的状态，这个状态会持续 2 MSL 后才会转变为 CLOSED 状态。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/bee0c8e8d84047e7434803fb340f9e5d.png" alt="img"></p><p>在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768~61000 ，也可以通过如下参数设置指定范围：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">net.ipv4.ip_local_port_range<br></code></pre></td></tr></table></figure><p><strong>如果客户端（发起连接方）的 TIME_WAIT 状态过多</strong>，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的。具体可以看我这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/port.html#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%AB%AF%E5%8F%A3%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%A4%8D%E4%BD%BF%E7%94%A8%E5%90%97">客户端的端口可以重复使用吗？(opens new window)</a></p><p>因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务器建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务器建立连接了。</p><p>不过，即使是在这种场景下，只要连接的是不同的服务器，端口是可以重复使用的，所以客户端还是可以向其他服务器发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。</p><p>但是 TIME_WAIT 状态也不是摆设作用，它的作用有两个：</p><ul><li>防止具有相同四元组的旧数据包被收到，也就是防止历史连接中的数据，被后面的连接接受，否则就会导致后面的连接收到一个无效的数据，</li><li>保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭;</li></ul><p>不过，Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接，这两个参数都是默认关闭的：</p><ul><li>net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。**所以该选项只适用于连接发起方。</li><li>net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；</li></ul><p>要使得这两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps=1（默认即为 1)）。</p><p><strong>tcp_tw_recycle 在使用了 NAT 的网络下是不安全的！</strong></p><p>对于服务器来说，如果同时开启了recycle 和 timestamps 选项，则会开启一种称之为「 per-host 的 PAWS 机制」。</p><blockquote><p>首先给大家说说什么是 PAWS 机制？</p></blockquote><p>tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。</p><p>正常来说每个 TCP 包都会有自己唯一的 SEQ，出现 TCP 数据包重传的时候会复用 SEQ 号，这样接收方能通过 SEQ 号来判断数据包的唯一性，也能在重复收到某个数据包的时候判断数据是不是重传的。<strong>但是 TCP 这个 SEQ 号是有限的，一共 32 bit，SEQ 开始是递增，溢出之后从 0 开始再次依次递增</strong>。</p><p>所以当 SEQ 号出现溢出后单纯通过 SEQ 号无法标识数据包的唯一性，某个数据包延迟或因重发而延迟时可能导致连接传递的数据被破坏，比如：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f5fbe947240026cc2f076267cb698496.png" alt="img"></p><p>上图 A 数据包出现了重传，并在 SEQ 号耗尽再次从 A 递增时，第一次发的 A 数据包延迟到达了 Server，这种情况下如果没有别的机制来保证，Server 会认为延迟到达的 A 数据包是正确的而接收，反而是将正常的第三次发的 SEQ 为 A 的数据包丢弃，造成数据传输错误。</p><p>PAWS 就是为了避免这个问题而产生的，在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时的时间戳，PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p><p>对于上面图中的例子有了 PAWS 机制就能做到在收到 Delay 到达的 A 号数据包时，识别出它是个过期的数据包而将其丢掉。</p><blockquote><p>那什么是 per-host 的 PAWS 机制呢？</p></blockquote><p>前面我提到，开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS 机制。<strong>per-host 是对「对端 IP 做 PAWS 检查」</strong>，而非对「IP + 端口」四元组做 PAWS 检查。</p><p>但是如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</p><p>Per-host PAWS 机制利用TCP option里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值。</p><p>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，<strong>客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包</strong>。</p><p>因此，tcp_tw_recycle 在使用了 NAT 的网络下是存在问题的，如果它是对 TCP 四元组做 PAWS 检查，而不是对「相同的 IP 做 PAWS 检查」，那么就不会存在这个问题了。</p><p>网上很多博客都说开启 tcp_tw_recycle 参数来优化 TCP，我信你个鬼，糟老头坏的很！</p><p>tcp_tw_recycle 在 Linux 4.12 版本后，直接取消了这一参数。</p><h2 id="accpet-队列满了">accpet 队列满了</h2><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accepet 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/c9959166180b0e239bb48234ff7c2f5b.png" alt="img"></p><h3 id="半连接队列满了">半连接队列满了</h3><p>当服务器造成syn攻击，就有可能导致 <strong>TCP 半连接队列满了，这时后面来的 syn 包都会被丢弃</strong>。</p><p>但是，<strong>如果开启了syncookies 功能，即使半连接队列满了，也不会丢弃syn 包</strong>。</p><p>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/58e01036d1febd0103dd0ec4d5acff05.png" alt="img"></p><p>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/e795b4ff5be76c85814ee190b4921f25.png" alt="img"></p><p>这里给出几种防御 SYN 攻击的方法：</p><ul><li>增大半连接队列；</li><li>开启 tcp_syncookies 功能</li><li>减少 SYN+ACK 重传次数</li></ul><p><em>方式一：增大半连接队列</em></p><p><strong>要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列</strong>。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/29f1fd2894162e15cbac938a2373b543.png" alt="img"></p><p>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/a6b11fbd1fcb742cdcc87447fc23b73f.png" alt="img"></p><p>最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。</p><p><em>方式二：开启 tcp_syncookies 功能</em></p><p>开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/54b7411607978cb9ff36d88cf47eb5c4.png" alt="img"></p><p><em>方式三：减少 SYN+ACK 重传次数</em></p><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_RECV 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_RECV 状态的 TCP 连接断开。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/19443a03430368b72c201113150471c5.png" alt="img"></p><h3 id="全连接队列满了">全连接队列满了</h3><p><strong>在服务端并发处理大量请求时，如果 TCP accpet 队列过小，或者应用程序调用 accept() 不及时，就会造成 accpet 队列满了 ，这时后续的连接就会被丢弃，这样就会出现服务端请求数量上不去的现象。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d1538f8d3b50da26039bc6b171a13ad1.png" alt="img"></p><p>我们可以通过 ss 命令来看 accpet 队列大小，在「LISTEN 状态」时，<code>Recv-Q/Send-Q</code> 表示的含义如下：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d7e8fcbb4afa583687b76064b7f1afac.png" alt="img"></p><ul><li>Recv-Q：当前 accpet 队列的大小，也就是当前已完成三次握手并等待服务端 <code>accept()</code> 的 TCP 连接个数；</li><li>Send-Q：当前 accpet 最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务进程，accpet 队列的最大长度为 128；</li></ul><p>如果 Recv-Q 的大小超过 Send-Q，就说明发生了 accpet 队列满的情况。</p><p>要解决这个问题，我们可以：</p><ul><li>调大 accpet 队列的最大长度，调大的方式是通过<strong>调大 backlog 以及 somaxconn 参数。</strong></li><li>检查系统或者代码为什么调用 accept() 不及时；</li></ul>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>已建立连接的TCP，收到SYN会发生什么？</title>
    <link href="/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/09.%E5%B7%B2%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E7%9A%84TCP%EF%BC%8C%E6%94%B6%E5%88%B0SYN%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <url>/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/09.%E5%B7%B2%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E7%9A%84TCP%EF%BC%8C%E6%94%B6%E5%88%B0SYN%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>已建立连接的TCP，收到SYN会发生什么？</h1><p>一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？</p><p>看过我的图解网络的读者都知道，TCP 连接是由「四元组」唯一确认的。</p><p>然后这个场景中，客户端的 IP、服务端 IP、目的端口并没有变化，所以这个问题关键要看客户端发送的 SYN 报文中的源端口是否和上一次连接的源端口相同。</p><p><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong></p><p>如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。</p><p>那旧连接里处于 Established 状态的服务端最后会怎么样呢？</p><p>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。</p><p>如果服务端一直没有发送数据包给客户端，在超过一段时间后，TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</p><p><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p><p>如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，也就是处于 Established 状态的服务端收到了这个 SYN 报文。</p><p>大家觉得服务端此时会做什么处理呢？</p><ul><li>丢掉 SYN 报文？</li><li>回复 RST 报文？</li><li>回复 ACK 报文？</li></ul><p>刚开始我看到这个问题的时候，也是没有思路的，因为之前没关注过，然后这个问题不能靠猜，所以我就看了 RFC 规范和看了 Linux 内核源码，最终知道了答案。</p><p>我不卖关子，先直接说答案。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/est_syn.png" alt="img"></p><p><strong>处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。</strong></p><p><strong>接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</strong></p><h2 id="RFC-文档解释">RFC 文档解释</h2><p>RFC 793 文档里的第 34 页里，有说到这个例子。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/873ad18443c040708c415bab6592ae41.png" alt="img"></p><p>原文的解释我也贴出来给大家看看。</p><ul><li>When the SYN arrives at line 3, TCP B, being in a synchronized state, and the incoming segment outside the window, responds with an acknowledgment indicating what sequence it next expects to hear (ACK 100).</li><li>TCP A sees that this segment does not acknowledge anything it sent and, being unsynchronized, sends a reset (RST) because it has detected a half-open connection.</li><li>TCP B aborts at line 5.</li><li>TCP A willcontinue to try to Established the connection;</li></ul><p>我就不瞎翻译了，意思和我在前面用中文说的解释差不多。</p><h2 id="源码分析">源码分析</h2><p>处于 Established 状态的服务端如果收到了客户端的 SYN 报文时，内核会调用这些函数：</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs csharp">tcp_v4_rcv<br>  -&gt; tcp_v4_do_rcv<br>    -&gt; tcp_rcv_Establisheded<br>      -&gt; tcp_validate_incoming<br>        -&gt; tcp_send_ack<br></code></pre></td></tr></table></figure><p>我们只关注 tcp_validate_incoming 函数是怎么处理 SYN 报文的，精简后的代码如下：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/780bc02c8fa940c0a320a5916b216c21.png" alt="img"></p><p>从上面的代码实现可以看到，处于 Established 状态的服务端，在收到报文后，首先会判断序列号是否在窗口内，如果不在，则看看 RST 标记有没有被设置，如果有就会丢掉。然后如果没有 RST 标志，就会判断是否有 SYN 标记，如果有 SYN 标记就会跳转到 syn_challenge 标签，然后执行 tcp_send_challenge_ack 函数。</p><p>tcp_send_challenge_ack 函数里就会调用 tcp_send_ack 函数来回复一个携带了正确序列号和确认号的 ACK 报文。</p><h2 id="如何关闭一个-TCP-连接？">如何关闭一个 TCP 连接？</h2><p>这里问题大家这么一个问题，如何关闭一个 TCP 连接？</p><p>可能大家第一反应是「杀掉进程」不就行了吗？</p><p>是的，这个是最粗暴的方式，杀掉客户端进程和服务端进程影响的范围会有所不同：</p><ul><li>在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接，这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。</li><li>而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。</li></ul><p>所以，关闭进程的方式并不可取，最好的方式要精细到关闭某一条 TCP 连接。</p><p>有的小伙伴可能会说，伪造一个四元组相同的 RST 报文不就行了？</p><p>这个思路很好，但是不要忘了还有个序列号的问题，你伪造的 RST 报文的序列号一定能被对方接受吗？</p><p>如果 RST 报文的序列号不是对方期望收到的序列号，这个 RST 报文会被对方丢弃的，就达不到关闭的连接的效果。</p><p>举个例子，下面这个场景，客户端发送了一个长度为 100 的 TCP 数据报文，服务端收到后响应了 ACK 报文，表示收到了这个 TCP 数据报文。<strong>服务端响应的这个 ACK 报文中的确认号（ack = x + 100）就是表明服务端下一次期望收到的序列号是 x + 100</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/rst%E5%90%88%E6%B3%95.png" alt="img"></p><p>所以，<strong>要伪造一个能关闭 TCP 连接的 RST 报文，必须同时满足「四元组相同」和「序列号是对方期望的」这两个条件。</strong></p><p>直接伪造符合预期的序列号是比较困难，因为如果一个正在传输数据的 TCP 连接，序列号都是时刻都在变化，因此很难刚好伪造一个正确序列号的 RST 报文。</p><h3 id="killcx-的工具">killcx 的工具</h3><p>办法还是有的，<strong>我们可以伪造一个四元组相同的 SYN 报文，来拿到“合法”的序列号！</strong></p><p>正如我们最开始学到的，如果处于 Established 状态的服务端，收到四元组相同的 SYN 报文后，<strong>会回复一个 Challenge ACK，这个 ACK 报文里的「确认号」，正好是服务端下一次想要接收的序列号，说白了，就是可以通过这一步拿到服务端下一次预期接收的序列号。</strong></p><p><strong>然后用这个确认号作为 RST 报文的序列号，发送给服务端，此时服务端会认为这个 RST 报文里的序列号是合法的，于是就会释放连接！</strong></p><p>在 Linux 上有个叫 killcx 的工具，就是基于上面这样的方式实现的，它会主动发送 SYN 包获取 SEQ/ACK 号，然后利用 SEQ/ACK 号伪造两个 RST 报文分别发给客户端和服务端，这样双方的 TCP 连接都会被释放，这种方式活跃和非活跃的 TCP 连接都可以杀掉。</p><p>killcx 的工具使用方式也很简单，如果在服务端执行 killcx 工具，只需指明客户端的 IP 和端口号，如果在客户端执行 killcx 工具，则就指明服务端的 IP 和端口号。</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csharp">./killcx &lt;IP地址&gt;:&lt;端口号&gt;<br></code></pre></td></tr></table></figure><p>killcx 工具的工作原理，如下图，下图是在客户端执行 killcx 工具。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/95592346a9a747819cd27741a660213c.png" alt="img"></p><p>它伪造客户端发送 SYN 报文，服务端收到后就会回复一个携带了正确「序列号和确认号」的 ACK 报文（Challenge ACK），然后就可以利用这个 ACK 报文里面的信息，伪造两个 RST 报文：</p><ul><li>用 Challenge ACK 里的确认号伪造 RST 报文发送给服务端，服务端收到 RST 报文后就会释放连接。</li><li>用 Challenge ACK 里的序列号伪造 RST 报文发送给客户端，客户端收到 RST 也会释放连接。</li></ul><p>正是通过这样的方式，成功将一个 TCP 连接关闭了！</p><p>这里给大家贴一个使用 killcx 工具关闭连接的抓包图，大家多看看序列号和确认号的变化。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/71cbefee5ab741018386b6a37f492614.png" alt="img"></p><p>所以，以后抓包中，如果莫名奇妙出现一个 SYN 包，有可能对方接下来想要对你发起的 RST 攻击，直接将你的 TCP 连接断开！</p><p>怎么样，很巧妙吧！</p><h3 id="tcpkill-的工具">tcpkill 的工具</h3><p>除了 killcx 工具能关闭 TCP 连接，还有 tcpkill 工具也可以做到。</p><p>这两个工具都是通过伪造 RST 报文来关闭指定的 TCP 连接，但是它们拿到正确的序列号的实现方式是不同的。</p><ul><li>tcpkill 工具是在双方进行 TCP 通信时，拿到对方下一次期望收到的序列号，然后将序列号填充到伪造的 RST 报文，并将其发送给对方，达到关闭 TCP 连接的效果。</li><li>killcx 工具是主动发送一个 SYN 报文，对方收到后会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK，这时就可以拿到对方下一次期望收到的序列号，然后将序列号填充到伪造的 RST 报文，并将其发送给对方，达到关闭 TCP 连接的效果。</li></ul><p>可以看到， 这两个工具在获取对方下一次期望收到的序列号的方式是不同的。</p><p>tcpkill 工具属于被动获取，就是在双方进行 TCP 通信的时候，才能获取到正确的序列号，很显然<strong>这种方式无法关闭非活跃的 TCP 连接</strong>，只能用于关闭活跃的 TCP 连接。因为如果这条 TCP 连接一直没有任何数据传输，则就永远获取不到正确的序列号。</p><p>killcx 工具则是属于主动获取，它是主动发送一个 SYN 报文，通过对方回复的 Challenge ACK 来获取正确的序列号，所以这种方式<strong>无论 TCP 连接是否活跃，都可以关闭</strong>。</p><p>接下来，我就用这 tcpkill 工具来做个实验。</p><p>在这里， 我用 nc 工具来模拟一个 TCP 服务端，监听 8888 端口。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill1.png" alt="img"></p><p>接着，在客户端机子上，用 nc 工具模拟一个 TCP 客户端，连接我们刚才启动的服务端，并且指定了客户端的端口为 11111。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill2.png" alt="img"></p><p>这时候， 服务端就可以看到这条 TCP 连接了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill3.png" alt="图片"></p><p>注意，我这台服务端的公网 IP 地址是 121.43.173.240，私网 IP 地址是 172.19.11.21，在服务端通过 netstat 命令查看 TCP 连接的时候，则会将服务端的地址显示成私网 IP 地址 。至此，我们前期工作就做好了。</p><p>接下来，我们在服务端执行 tcpkill 工具，来关闭这条 TCP 连接，看看会发生什么？</p><p>在这里，我指定了要关闭的客户端 IP 为 114.132.166.90 和端口为 11111 的 TCP 连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill4.png" alt="图片"></p><p>可以看到，tcpkill 工具阻塞中，没有任何输出，而且此时的 TCP 连接还是存在的，并没有被干掉。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill5.png" alt="图片"></p><p>为什么 TCP 连接没用被干掉？</p><p>因为在执行 tcpkill 工具后，这条 TCP 连接并没有传输任何数据，而 tcpkill 工具是需要拦截双方的 TCP 通信，才能获取到正确的序列号，从而才能伪装出正确的序列号的 RST 报文。</p><p>所以，从这里也说明了，<strong>tcpkill 工具不适合关闭非活跃的 TCP 连接</strong>。</p><p>接下来，我们尝试在客户端发送一个数据。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill8.png" alt="图片"></p><p>可以看到，在发送了「hi」数据后，客户端就断开了，并且错误提示连接被对方关闭了。</p><p>此时，服务端已经查看不到刚才那条 TCP 连接了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill7.png" alt="图片"></p><p>然后，我们在服务端看看 tcpkill 工具输出的信息。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill8.png" alt="图片"></p><p>可以看到， <strong>tcpkill 工具给服务端和客户端都发送了伪造的 RST 报文，从而达到关闭一条 TCP 连接的效果</strong>。</p><p>到这里我们知道了， 运行 tcpkill 工具后，只有目标连接有新 TCP 包发送/接收的时候，才能关闭一条 TCP 连接。因此，<strong>tcpkill 只适合关闭活跃的 TCP 连接，不适合用来关闭非活跃的 TCP 连接</strong>。</p><p>上面的实验过程，我也抓了数据包，流程如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/tcpkill/tcpkill9.png" alt="图片"></p><p>最后一个 RST 报文就是 tcpkill 工具伪造的 RST 报文。</p><h2 id="总结">总结</h2><p>要伪造一个能关闭 TCP 连接的 RST 报文，必须同时满足「四元组相同」和「序列号是对方期望的」这两个条件。</p><p>今天给大家介绍了两种关闭 TCP 连接的工具：tcpkill 和 killcx 工具。</p><p>这两种工具都是通过伪造 RST 报文来关闭 TCP 连接的，但是它们获取「对方下一次期望收到的序列号的方式是不同的，也正因此，造就了这两个工具的应用场景有区别。</p><ul><li>tcpkill 工具只能用来关闭活跃的 TCP 连接，无法关闭非活跃的 TCP 连接，因为 tcpkill 工具是等双方进行 TCP 通信后，才去获取正确的序列号，如果这条 TCP 连接一直没有任何数据传输，则就永远获取不到正确的序列号。</li><li>killcx 工具可以用来关闭活跃和非活跃的 TCP 连接，因为 killcx 工具是主动发送 SYN 报文，这时对方就会回复 Challenge ACK ，然后 killcx 工具就能从这个 ACK 获取到正确的序列号。</li></ul><p>完！</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>四次挥手中收到乱序的 FIN 包会如何处理？</title>
    <link href="/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/10.%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%AD%E6%94%B6%E5%88%B0%E4%B9%B1%E5%BA%8F%E7%9A%84%20FIN%20%E5%8C%85%E4%BC%9A%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F/"/>
    <url>/2021/05/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/10.%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%AD%E6%94%B6%E5%88%B0%E4%B9%B1%E5%BA%8F%E7%9A%84%20FIN%20%E5%8C%85%E4%BC%9A%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>四次挥手中收到乱序的 FIN 包会如何处理？</h1><p>收到个读者的问题，他在面试鹅厂的时候，被搞懵了，因为面试官问了他这么一个网络问题：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_17,color_FFFFFF,t_70,g_se,x_16.jpeg" alt="img"></p><p>不得不说，鹅厂真的很喜欢问网络问题，而且爱问异常情况下的网络问题。</p><p>不过这道鹅厂的网络题可能是提问的读者表述有问题，<strong>因为如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个乱序的报文，此时客户端的 TCP 连接并不会从 FIN_WAIT_2 状态转换到 TIME_WAIT 状态</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p><p>因此，我们要关注到点是看「<strong>在 FIN_WAIT_2 状态下，是如何处理收到的乱序到 FIN 报文，然后 TCP 连接又是什么时候才进入到 TIME_WAIT 状态?</strong>」。</p><p>我这里先直接说结论：</p><p><strong>在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。</strong></p><p><strong>等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。</strong></p><p>我也画了一张图，大家可以结合着图来理解。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16-20230309230147654.png" alt="img"></p><h2 id="TCP-源码分析">TCP 源码分析</h2><p>接下来，我带大家看看源码，听到要源码分析，可能有的同学就怂了。</p><p>其实要分析我们今天这个问题，只要懂 if else 就行了，我也会用中文来表述代码的逻辑，所以单纯看我的文字也是可以的。c</p><p>这次我们重点分析的是，在 FIN_WAIT_2 状态下，收到 FIN 报文是如何处理的。</p><p>在 Linux 内核里，当 IP 层处理完消息后，会通过回调 tcp_v4_rcv 函数将消息转给 TCP 层，所以这个函数就是 TCP 层收到消息的入口。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16.jpeg" alt="img"> 处于 FIN_WAIT_2 状态下的客户端，在收到服务端的报文后，最终会调用 tcp_v4_do_rcv 函数。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/c5ca5b3fea0e4ad6baa2ab370358f03e.jpg" alt="img"></p><p>接下来，tcp_v4_do_rcv 方法会调用 tcp_rcv_state_process，在这里会根据 TCP 状态做对应的处理，这里我们只关注 FIN_WAIT_2 状态。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f76b7e2167544fec859700f55138e95f.jpg" alt="img"></p><p>在上面这个代码里，可以看到如果 shutdown 关闭了读方向，那么在收到对方发来的数据包，则会回复 RST 报文。</p><p>而我们这次的题目里， shutdown 只关闭了写方向，所以会继续往下调用 tcp_data_queue 函数（因为 case TCP_FIN_WAIT2 代码块里并没有 break 语句，所以会走到该函数）。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/4ff161a34408447fa38b120b014b29f4.jpg" alt="img"> 在上面的 tcp_data_queue 函数里，如果收到的报文的序列号是我们预期的，也就是有序的话：</p><ul><li>会判断该报文有没有 FIN 标志，如果有的话就会调用 tcp_fin 函数，这个函数负责将 FIN_WAIT_2 状态转换为 TIME_WAIT。</li><li>接着还会看乱序队列有没有数据，如果有的话会调用 tcp_ofo_queue 函数，这个函数负责检查乱序队列中是否有数据包可用，即能不能在乱序队列找到与当前数据包保持序列号连续的数据包。</li></ul><p>而当收到的报文的序列号不是我们预期的，也就是乱序的话，则调用 tcp_data_queue_ofo 函数，将报文加入到乱序队列，这个队列的数据结构是红黑树。</p><p>我们的题目里，客户端收到的 FIN 报文实际上是一个乱序的报文，因此此时并不会调用 tcp_fin 函数进行状态转换，而是将报文通过 tcp_data_queue_ofo 函数加入到乱序队列。</p><p>然后当客户端收到被网络延迟的数据包后，此时因为该数据包的序列号是期望的，然后又因为上一次收到的乱序 FIN 报文被加入到了乱序队列，表明乱序队列是有数据的，于是就会调用 tcp_ofo_queue 函数。</p><p>我们来看看 tcp_ofo_queue 函数。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/dd51b407245d45549eeae64d24634133.jpg" alt="img"></p><p>在上面的 tcp_ofo_queue 函数里，在乱序队列中找到能与当前报文的序列号保持的顺序的报文后，会看该报文是否有 FIN 标志，如果有的话，就会调用 tcp_fin() 函数。</p><p>最后，我们来看看 tcp_fin 函数的处理。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/67b33007fcd04d2fa98e79d19823fc95.jpg" alt="img"></p><p>可以看到，如果当前的 TCP 状态为 TCP_FIN_WAIT2，就会发送第四次挥手 ack，然后调用 tcp_time_wait 函数，这个函数里会将 TCP 状态变更为 TIME_WAIT，并启动 TIME_WAIT 的定时器。</p><h2 id="怎么看-TCP-源码？">怎么看 TCP 源码？</h2><p>之前有不少同学问我，我是怎么看 TCP 源码的？</p><p>其实我看 TCP 源码，并不是直接打开 Linux 源码直接看，因为 Linux 源码实在太庞大了，如果我不知道 TCP 入口函数在哪，那简直就是大海捞针。</p><p>所以，在看 TCP 源码，我们可以去网上搜索下别人的源码分析，网上已经有很多前辈帮我们分析了 TCP 源码了，而且各个函数的调用链路，他们都有写出来了。</p><p>比如，你想了解 TCP 三次握手/四次挥手的源码实现，你就可以以「TCP 三次握手/四次挥手的源码分析」这样关键字来搜索，大部分文章的注释写的还是很清晰，我最开始就按这种方式来学习 TCP 源码的。</p><p>网上的文章一般只会将重点的部分，很多代码细节没有贴出来，如果你想完整的看到函数的所有代码，那就得看内核代码了。</p><p>这里推荐个看 Linux 内核代码的在线网站：</p><p><a href="https://elixir.bootlin.com/linux/latest/source">https://elixir.bootlin.com/linux/latest/source</a></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16-20230309230247590.png" alt="img"></p><p>我觉得还是挺好用的，左侧各个版本的代码都有，右上角也可以搜索函数。</p><p>所以，我看 TCP 源码的经验就是，先在网上找找前辈写的 TCP 源码分析，然后知道整个函数的调用链路后，如果想具体了解某个函数的具体实现，可以在我说的那个看 Linux 内核代码的在线网站上搜索该函数，就可以看到完整的函数的实现。如果中途遇到看不懂的代码，也可以将这个代码复制到百度或者谷歌搜索，一般也能找到别人分析的过程。</p><p>学会了看 TCP 源码其实有助于我们分析一些异常问题，就比如今天这道网络题目，在网上其实是搜索不出答案的，而且我们也很难用实验的方式来模拟。</p><p>所以要想知道答案，只能去看源码。</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</title>
    <link href="/2021/05/16/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/07.%E4%B8%BA%E4%BB%80%E4%B9%88%20TCP%20%E6%AF%8F%E6%AC%A1%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%97%B6%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BA%8F%E5%88%97%E5%8F%B7%E9%83%BD%E8%A6%81%E4%B8%8D%E4%B8%80%E6%A0%B7%E5%91%A2%EF%BC%9F/"/>
    <url>/2021/05/16/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/07.%E4%B8%BA%E4%BB%80%E4%B9%88%20TCP%20%E6%AF%8F%E6%AC%A1%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%97%B6%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BA%8F%E5%88%97%E5%8F%B7%E9%83%BD%E8%A6%81%E4%B8%8D%E4%B8%80%E6%A0%B7%E5%91%A2%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</h1><p><strong>为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</strong></p><p>接下来，我一步一步给大家讲明白，我觉得应该有不少人会有类似的问题，所以今天在肝一篇！</p><blockquote><p>为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</p></blockquote><p>主要原因是为了防止历史报文被下一个相同四元组的连接接收。</p><blockquote><p>TCP 四次挥手中的 TIME_WAIT 状态不是会持续 2 MSL 时长，历史报文不是早就在网络中消失了吗？</p></blockquote><p>是的，如果能正常四次挥手，由于 TIME_WAIT 状态会持续 2 MSL 时长，历史报文会在下一个连接之前就会自然消失。</p><p>但是来了，我们并不能保证每次连接都能通过四次挥手来正常关闭连接。</p><p>假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E7%9B%B8%E5%90%8C.png" alt="img"></p><p>过程如下：</p><ul><li>客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。</li><li>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；</li><li>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</li></ul><p>可以看到，如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。</p><blockquote><p>客户端和服务端的初始化序列号不一样不是也会发生这样的事情吗？</p></blockquote><p>是的，即使客户端和服务端的初始化序列号不一样，也会存在收到历史报文的可能。</p><p>但是我们要清楚一点，历史报文能否被对方接收，还要看该历史报文的序列号是否正好在对方接收窗口内，如果不在就会丢弃，如果在才会接收。</p><p>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文，比如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E4%B8%8D%E7%9B%B8%E5%90%8C.png" alt="img"></p><p>相反，如果每次建立连接客户端和服务端的初始化序列号都「一样」，就有大概率遇到历史报文的序列号刚「好在」对方的接收窗口内，从而导致历史报文被新连接成功接收。</p><p>所以，每次初始化序列号不一样能够很大程度上避免历史报文被下一个相同四元组的连接接收，注意是很大程度上，并不是完全避免了。</p><blockquote><p>那客户端和服务端的初始化序列号都是随机的，那还是有可能随机成一样的呀？</p></blockquote><p>RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。</p><ul><li>M是一个计时器，这个计时器每隔 4 微秒加1。</li><li>F 是一个 Hash 算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值，要保证 hash 算法不能被外部轻易推算得出。</li></ul><p>可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。</p><blockquote><p>懂了，客户端和服务端初始化序列号都是随机生成的话，就能避免连接接收历史报文了。</p></blockquote><p>是的，但是也不是完全避免了。</p><p>为了能更好的理解这个原因，我们先来了解序列号（SEQ）和初始序列号（ISN）。</p><ul><li><strong>序列号</strong>，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。<strong>序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0</strong>。</li><li><strong>初始序列号</strong>，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。<strong>初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时</strong>。</li></ul><p>给大家抓了一个包，下图中的 Seq 就是序列号，其中红色框住的分别是客户端和服务端各自生成的初始序列号。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/ed84bb4aa742a33f50d8035da2867ca2.png" alt="img"></p><p>通过前面我们知道，<strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong>。</p><p>不要以为序列号的上限值是 4GB，就以为很大，很难发生回绕。在一个速度足够快的网络中传输大量数据时，序列号的回绕时间就会变短。如果序列号回绕的时间极短，我们就会再次面临之前延迟的报文抵达后序列号依然有效的问题。</p><p>为了解决这个问题，就需要有 TCP 时间戳。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，<strong>一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）</strong>。</p><p>试看下面的示例，假设 TCP 的发送窗口是 1 GB，并且使用了时间戳选项，发送方会为每个 TCP 报文分配时间戳数值，我们假设每个报文时间加 1，然后使用这个连接传输一个 6GB 大小的数据流。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/1d497c38621ebc44ee3d8763fd03da67.png" alt="图片"></p><p>32 位的序列号在时刻 D 和 E 之间回绕。假设在时刻B有一个报文丢失并被重传，又假设这个报文段在网络上绕了远路并在时刻 F 重新出现。如果 TCP 无法识别这个绕回的报文，那么数据完整性就会遭到破坏。</p><p>使用时间戳选项能够有效的防止上述问题，如果丢失的报文会在时刻 F 重新出现，由于它的时间戳为 2，小于最近的有效时间戳（5 或 6），因此防回绕序列号算法（PAWS）会将其丢弃。</p><p>防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p><blockquote><p>懂了，客户端和服务端的初始化序列号都是随机生成，能很大程度上避免历史报文被下一个相同四元组的连接接收，然后又引入时间戳的机制，从而完全避免了历史报文被接收的问题。</p></blockquote><p>嗯嗯，没错。</p><blockquote><p>如果时间戳也回绕了怎么办？</p></blockquote><p>时间戳的大小是 32 bit，所以理论上也是有回绕的可能性的。</p><p>时间戳回绕的速度只与对端主机时钟频率有关。</p><p>Linux 以本地时钟计数（jiffies）作为时间戳的值，不同的增长时间会有不同的问题：</p><ul><li>如果时钟计数加 1 需要1ms，则需要约 24.8 天才能回绕一半，只要报文的生存时间小于这个值的话判断新旧数据就不会出错。</li><li>如果时钟计数提高到 1us 加1，则回绕需要约71.58分钟才能回绕，这时问题也不大，因为网络中旧报文几乎不可能生存超过70分钟，只是如果70分钟没有报文收发则会有一个包越过PAWS（这种情况会比较多见，相比之下 24 天没有数据传输的TCP连接少之又少），但除非这个包碰巧是序列号回绕的旧数据包而被放入接收队列（太巧了吧），否则也不会有问题；</li><li>如果时钟计数提高到 0.1 us 加 1 回绕需要 7 分钟多一点，这时就可能会有问题了，连接如果 7 分钟没有数据收发就会有一个报文越过 PAWS，对于TCP连接而言这么短的时间内没有数据交互太常见了吧！这样的话会频繁有包越过 PAWS 检查，从而使得旧包混入数据中的概率大大增加；</li></ul><p>Linux 在 PAWS 检查做了一个特殊处理，如果一个 TCP 连接连续 24 天不收发数据则在接收第一个包时基于时间戳的 PAWS 会失效，也就是可以 PAWS 函数会放过这个特殊的情况，认为是合法的，可以接收该数据包。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// tcp_paws_check 函数如果返回 true 则 PAWS 通过：</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">bool</span> <span class="hljs-title">tcp_paws_check</span><span class="hljs-params">(<span class="hljs-keyword">const</span> struct tcp_options_received *rx_opt, <span class="hljs-keyword">int</span> paws_win)</span></span><br><span class="hljs-function"></span>&#123;<br>......<br>    <br>   <span class="hljs-comment">//从上次收到包到现在经历的时间多于24天，返回true</span><br> <span class="hljs-keyword">if</span> (unlikely(get_seconds() &gt;= rx_opt-&gt;ts_recent_stamp + TCP_PAWS_24DAYS))<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br><br>.....<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>要解决时间戳回绕的问题，可以考虑以下解决方案：</p><p>1）增加时间戳的大小，由32 bit扩大到64bit</p><p>这样虽然可以在能够预见的未来解决时间戳回绕的问题，但会导致新旧协议兼容性问题，像现在的IPv4与IPv6一样</p><p>2）将一个与时钟频率无关的值作为时间戳，时钟频率可以增加但时间戳的增速不变</p><p>随着时钟频率的提高，TCP在相同时间内能够收发的包也会越来越多。如果时间戳的增速不变，则会有越来越多的报文使用相同的时间戳。这种趋势到达一定程度则时间戳就会失去意义，除非在可预见的未来这种情况不会发生。</p><p>3）暂时没想到</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何理解是 TCP 面向字节流协议？</title>
    <link href="/2021/05/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/06.%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%98%AF%20TCP%20%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E5%8D%8F%E8%AE%AE%EF%BC%9F/"/>
    <url>/2021/05/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/06.%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%98%AF%20TCP%20%E9%9D%A2%E5%90%91%E5%AD%97%E8%8A%82%E6%B5%81%E5%8D%8F%E8%AE%AE%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>如何理解是 TCP 面向字节流协议？</h1><p>有个读者问我，这么个问题：</p><blockquote><p>TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的「面向字节流」和「面向报文」该如何理解。</p></blockquote><hr><h2 id="如何理解字节流？">如何理解字节流？</h2><p>之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的<strong>发送方的机制不同</strong>，也就是问题原因在发送方。</p><blockquote><p>先来说说为什么 UDP 是面向报文的协议？</p></blockquote><p>当用户消息通过 UDP 协议传输时，<strong>操作系统不会对消息进行拆分</strong>，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是<strong>每个 UDP 报文就是一个用户消息的边界</strong>，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。</p><p>你可能会问，如果收到了两个 UDP 报文，操作系统是怎么区分开的？</p><p>操作系统在收到 UDP 报文后，会将其插入到队列里，<strong>队列里的每一个元素就是一个 UDP 报文</strong>，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/a9116c5b375d356048df033dcb53582e.png" alt="图片"></p><blockquote><p>再来说说为什么 TCP 是面向字节流的协议？</p></blockquote><p>当用户消息通过 TCP 协议传输时，<strong>消息可能会被操作系统分组成多个的 TCP 报文</strong>，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。</p><p>这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。</p><p>举个实际的例子来说明。</p><p>发送方准备发送 「Hi.」和「I am Xiaolin」这两个消息。</p><p>在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。</p><p>至于什么时候真正被发送，<strong>取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件</strong>。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去。</p><p>如果我们考虑实际网络传输过程中的各种影响，假设发送端陆续调用 send 函数先后发送 「Hi.」和「I am Xiaolin」 报文，那么实际的发送很有可能是这几种情况。</p><p>第一种情况，这两个消息被分到同一个 TCP 报文，像这样：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/02dce678f870c8c70482b6e37dbb5574.png" alt="图片"></p><p>第二种情况，「I am Xiaolin」的部分随 「Hi」 在一个 TCP 报文中发送出去，像这样：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f58b70cde860188b8f95a433e2f5293b.png" alt="图片"></p><p>第三种情况，「Hi.」 的一部分随 TCP 报文被发送出去，另一部分和 「I am Xiaolin」 一起随另一个 TCP 报文发送出去，像这样。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/68080e783d7acc842fa254e4f9ec5630.png" alt="图片"></p><p>类似的情况还能举例很多种，这里主要是想说明，我们不知道 「Hi.」和 「I am Xiaolin」 这两个用户消息是如何进行 TCP 分组传输的。</p><p>因此，<strong>我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议</strong>。</p><p>当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。</p><p>要解决这个问题，要交给<strong>应用程序</strong>。</p><h2 id="如何解决粘包？">如何解决粘包？</h2><p>粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。</p><p>一般有三种方式分包的方式：</p><ul><li>固定长度的消息；</li><li>特殊字符作为边界；</li><li>自定义消息结构。</li></ul><h4 id="固定长度的消息">固定长度的消息</h4><p>这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。</p><p>但是这种方式灵活性不高，实际中很少用。</p><h3 id="特殊字符作为边界">特殊字符作为边界</h3><p>我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。</p><p>HTTP 是一个非常好的例子。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/a49a6bb8cd38ae1738d9c00aec68b444.png" alt="图片"></p><p>HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。</p><p>有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。</p><h3 id="自定义消息结构">自定义消息结构</h3><p>我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。</p><p>比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span> <br>    <span class="hljs-keyword">u_int32_t</span> message_length; <br>    <span class="hljs-keyword">char</span> message_data[]; <br>&#125; message;<br></code></pre></td></tr></table></figure><p>当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何优化 TCP?</title>
    <link href="/2021/05/14/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/05.%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%20TCP/"/>
    <url>/2021/05/14/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/05.%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%20TCP/</url>
    
    <content type="html"><![CDATA[<h1>如何优化 TCP?</h1><p>TCP 性能的提升不仅考察 TCP 的理论知识，还考察了对于操作系统提供的内核参数的理解与应用。</p><p>TCP 协议是由操作系统实现，所以操作系统提供了不少调节 TCP 的参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/2.jpg" alt="Linux TCP 参数"></p><p>如何正确有效的使用这些参数，来提高 TCP 性能是一个不那么简单事情。我们需要针对 TCP 每个阶段的问题来对症下药，而不是病急乱投医。</p><p>接下来，将以三个角度来阐述提升 TCP 的策略，分别是：</p><ul><li>TCP 三次握手的性能提升；</li><li>TCP 四次挥手的性能提升；</li><li>TCP 数据传输的性能提升；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/3.jpg" alt="本节提纲"></p><hr><h2 id="TCP-三次握手的性能提升">TCP 三次握手的性能提升</h2><p>TCP 是面向连接的、可靠的、双向传输的传输层通信协议，所以在传输数据之前需要经过三次握手才能建立连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/4.jpg" alt="三次握手与数据传输"></p><p>那么，三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。</p><p>如何正确有效的使用这些参数，来提高 TCP 三次握手的性能，这就需要理解「三次握手的状态变迁」，这样当出现问题时，先用 <code>netstat</code> 命令查看是哪个握手阶段出现了问题，再来对症下药，而不是病急乱投医。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/5.jpg" alt="TCP 三次握手的状态变迁"></p><p>客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。</p><p>所以，客户端（主动发起连接方）和服务端（被动连接方）优化的方式是不同的，接下来分别针对客户端和服务端优化。</p><h3 id="客户端优化">客户端优化</h3><p>三次握手建立连接的首要目的是「同步序列号」。</p><p>只有同步了序列号才有可靠传输，TCP 许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握手中的报文称为 SYN 的原因，SYN 的全称就叫 <em>Synchronize Sequence Numbers</em>（同步序列号）。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/6.jpg" alt="TCP 头部"></p><blockquote><p>SYN_SENT 状态的优化</p></blockquote><p>客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 <code>SYN_SENT</code> 状态。</p><p>客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包，<strong>重发的次数由 tcp_syn_retries 参数控制</strong>，默认是 5 次：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/7.jpg" alt="img"></p><p>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，<strong>每次超时的时间是上一次的 2 倍</strong>。</p><p>当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就会终止三次握手。</p><p>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/8.jpg" alt="SYN 超时重传"></p><p>你可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。</p><h3 id="服务端优化">服务端优化</h3><p>当服务端收到 SYN 包后，服务端会立马回复 SYN+ACK 包，表明确认收到了客户端的序列号，同时也把自己的序列号发给对方。</p><p>此时，服务端出现了新连接，状态是 <code>SYN_RCV</code>。在这个状态下，Linux 内核就会建立一个「半连接队列」来维护「未完成」的握手信息，当半连接队列溢出后，服务端就无法再建立新的连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/9.jpg" alt="半连接队列与全连接队列"></p><p>SYN 攻击，攻击的是就是这个半连接队列。</p><blockquote><p>如何查看由于 SYN 半连接队列已满，而被丢弃连接的情况？</p></blockquote><p>我们可以通过该 <code>netstat -s</code> 命令给出的统计结果中， 可以得到由于半连接队列已满，引发的失败次数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/10.jpg" alt="img"></p><p>上面输出的数值是<strong>累计值</strong>，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。<strong>隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象</strong>。</p><blockquote><p>如何调整 SYN 半连接队列大小？</p></blockquote><p>要想增大半连接队列，<strong>不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</strong></p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/11.jpg" alt="img"></p><p>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/12.jpg" alt="img"></p><p>最后，改变了如上这些参数后，要重启 Nginx 服务，因为 SYN 半连接队列和 accept 队列都是在 <code>listen()</code> 初始化的。</p><blockquote><p>如果 SYN 半连接队列已满，只能丢弃连接吗？</p></blockquote><p>并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>。</p><p>syncookies 的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/13.jpg" alt="开启 syncookies 功能"></p><p>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/14.jpg" alt="img"></p><blockquote><p>SYN_RCV 状态的优化</p></blockquote><p>当客户端接收到服务器发来的 SYN+ACK 报文后，就会回复 ACK 给服务器，同时客户端连接状态从 SYN_SENT 转换为 ESTABLISHED，表示连接建立成功。</p><p>服务器端连接成功建立的时间还要再往后，等到服务端收到客户端的 ACK 后，服务端的连接状态才变为 ESTABLISHED。</p><p>如果服务器没有收到 ACK，就会重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态。</p><p>当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。<strong>修改重发次数的方法是，调整 tcp_synack_retries 参数</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/15.jpg" alt="img"></p><p>tcp_synack_retries 的默认重试次数是 5 次，与客户端重传 SYN 类似，它的重传会经历 1、2、4、8、16 秒，最后一次重传后会继续等待 32 秒，如果服务端仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒。</p><p>服务器收到 ACK 后连接建立成功，此时，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</p><p>如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/16.jpg" alt=" accept 队列溢出"></p><blockquote><p>accept 队列已满，只能丢弃连接吗？</p></blockquote><p>丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。打开这一功能需要将 tcp_abort_on_overflow 参数设置为 1。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/17.jpg" alt="img"></p><p>tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</p><ul><li>0 ：如果 accept 队列满了，那么 server 扔掉 client 发过来的 ack ；</li><li>1 ：如果 accept 队列满了，server 发送一个 <code>RST</code> 包给 client，表示废掉这个握手过程和这个连接；</li></ul><p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 <code>connection reset by peer</code> 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p><p>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。</p><p>举个例子，当 accept 队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，客户端进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，客户端的请求就会被多次「重发」。<strong>如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 accept 队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/18.jpg" alt="tcp_abort_on_overflow 为 0 可以应对突发流量"></p><p>所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。</p><blockquote><p>如何调整 accept 队列的长度呢？</p></blockquote><p>accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：</p><ul><li>somaxconn 是 Linux 内核的参数，默认值是 128，可以通过 <code>net.core.somaxconn</code> 来设置其值；</li><li>backlog 是 <code>listen(int sockfd, int backlog)</code> 函数中的 backlog 大小；</li></ul><p>Tomcat、Nginx、Apache 常见的 Web 服务的 backlog 默认值都是 511。</p><blockquote><p>如何查看服务端进程 accept 队列的长度？</p></blockquote><p>可以通过 <code>ss -ltn</code> 命令查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/19.jpg" alt="img"></p><ul><li>Recv-Q：当前 accept 队列的大小，也就是当前已完成三次握手并等待服务端 <code>accept()</code> 的 TCP 连接；</li><li>Send-Q：accept 队列最大长度，上面的输出结果说明监听 8088 端口的 TCP 服务，accept 队列的最大长度为 128；</li></ul><blockquote><p>如何查看由于 accept 连接队列已满，而被丢弃的连接？</p></blockquote><p>当超过了 accept 连接队列，服务端则会丢掉后续进来的 TCP 连接，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/20.jpg" alt="img"></p><p>上面看到的 41150 times ，表示 accept 队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话，说明 accept 连接队列偶尔满了。</p><p>如果持续不断地有连接因为 accept 队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</p><h3 id="如何绕过三次握手？">如何绕过三次握手？</h3><p>以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。</p><p>三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/21.jpg" alt="常规 HTTP 请求"></p><p>在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。</p><blockquote><p>接下来说说，TCP Fast Open 功能的工作方式。</p></blockquote><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/22.jpg" alt="开启 TCP Fast Open 功能"></p><p>在客户端首次建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；</li><li>支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；</li><li>客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。</li></ol><p>所以，第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程。</p><p>之后，如果客户端再次向服务器建立连接时的过程：</p><ol><li>客户端发送 SYN 报文，该报文包含「数据」（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 Cookie；</li><li>支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；</li><li>如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，<strong>这就减少了握手带来的 1 个 RTT 的时间消耗</strong>；</li><li>客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；</li><li>此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。</li></ol><p>所以，之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗。</p><p>开启了 TFO 功能，cookie 的值是存放到 TCP option 字段里的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/TCP%20option%E5%AD%97%E6%AE%B5%20-%20TFO.png" alt="TCP option 字段 - TFO"></p><p>注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）。</p><blockquote><p>Linux 下怎么打开 TCP Fast Open 功能呢？</p></blockquote><p>在 Linux 系统中，可以通过<strong>设置 tcp_fastopn 内核参数，来打开 Fast Open 功能</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/23.jpg" alt="img"></p><p>tcp_fastopn 各个值的意义:</p><ul><li>0 关闭</li><li>1 作为客户端使用 Fast Open 功能</li><li>2 作为服务端使用 Fast Open 功能</li><li>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</li></ul><p><strong>TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。</strong></p><h3 id="小结">小结</h3><p>本小结主要介绍了关于优化 TCP 三次握手的几个 TCP 参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/24.jpg" alt="三次握手优化策略"></p><blockquote><p>客户端的优化</p></blockquote><p>当客户端发起 SYN 包时，可以通过 <code>tcp_syn_retries</code> 控制其重传的次数。</p><blockquote><p>服务端的优化</p></blockquote><p>当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 <code>netstat -s</code> 观察半连接队列溢出的情况，如果 SYN 半连接队列溢出情况比较严重，可以通过 <code>tcp_max_syn_backlog、somaxconn、backlog</code> 参数来调整 SYN 半连接队列的大小。</p><p>服务端回复 SYN+ACK 的重传次数由 <code>tcp_synack_retries</code> 参数控制。如果遭受 SYN 攻击，应把 <code>tcp_syncookies</code> 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。</p><p>服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。</p><p>可以通过 <code>ss -lnt</code> 查看服务端进程的 accept 队列长度，如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 <code>tcp_abort_on_overflow</code> 设置为 1 ，表示用 RST 通知客户端连接建立失败。</p><p>如果 accpet 队列溢出严重，可以通过 listen 函数的 <code>backlog</code> 参数和 <code>somaxconn</code> 系统参数提高队列大小，accept 队列长度取决于 min(backlog, somaxconn)。</p><blockquote><p>绕过三次握手</p></blockquote><p>TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 <code>tcp_fastopen</code> 开启该功能，同时必须保证服务端和客户端同时支持。</p><hr><h2 id="TCP-四次挥手的性能提升">TCP 四次挥手的性能提升</h2><p>接下来，我们一起看看针对 TCP 四次挥手关闭连接时，如何优化性能。</p><p>在开始之前，我们得先了解四次挥手状态变迁的过程。</p><p>客户端和服务端双方都可以主动断开连接，<strong>通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/25.jpg" alt="客户端主动关闭"></p><p>可以看到，<strong>四次挥手过程只涉及了两种报文，分别是 FIN 和 ACK</strong>：</p><ul><li>FIN 就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；</li><li>ACK 就是确认的意思，用来通知对方：你方的发送通道已经关闭；</li></ul><p>四次挥手的过程:</p><ul><li>当主动方关闭连接时，会发送 FIN 报文，此时发送方的 TCP 连接将从 ESTABLISHED 变成 FIN_WAIT1。</li><li>当被动方收到 FIN 报文后，内核会自动回复 ACK 报文，连接状态将从 ESTABLISHED 变成 CLOSE_WAIT，表示被动方在等待进程调用 close 函数关闭连接。</li><li>当主动方收到这个 ACK 后，连接状态由 FIN_WAIT1 变为 FIN_WAIT2，也就是表示<strong>主动方的发送通道就关闭了</strong>。</li><li>当被动方进入 CLOSE_WAIT 时，被动方还会继续处理数据，等到进程的 read 函数返回 0 后，应用程序就会调用 close 函数，进而触发内核发送 FIN 报文，此时被动方的连接状态变为 LAST_ACK。</li><li>当主动方收到这个 FIN 报文后，内核会回复 ACK 报文给被动方，同时主动方的连接状态由 FIN_WAIT2 变为 TIME_WAIT，<strong>在 Linux 系统下大约等待 1 分钟后，TIME_WAIT 状态的连接才会彻底关闭</strong>。</li><li>当被动方收到最后的 ACK 报文后，<strong>被动方的连接就会关闭</strong>。</li></ul><p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><p>主动关闭方和被动关闭方优化的思路也不同，接下来分别说说如何优化他们。</p><h3 id="主动方的优化">主动方的优化</h3><p>关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。</p><p>如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。</p><p>安全关闭连接的方式必须通过四次挥手，它由进程调用 <code>close</code> 和 <code>shutdown</code> 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。</p><blockquote><p>调用 close 函数和 shutdown 函数有什么区别？</p></blockquote><p>调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong></p><p>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 <code>shutdown</code> 函数，<strong>它可以控制只关闭一个方向的连接</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/26.jpg" alt="img"></p><p>第二个参数决定断开连接的方式，主要有以下三种方式：</p><ul><li>SHUT_RD(0)：<strong>关闭连接的「读」这个方向</strong>，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。</li><li>SHUT_WR(1)：<strong>关闭连接的「写」这个方向</strong>，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端。</li><li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，<strong>关闭套接字的读和写两个方向</strong>。</li></ul><p>close 和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数也不相同。</p><blockquote><p>FIN_WAIT1 状态的优化</p></blockquote><p>主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变为 FIN_WAIT2 状态。</p><p>但是当迟迟收不到对方返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，<strong>内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制</strong>（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/27.jpg" alt="img"></p><p>你可能会好奇，这 0 表示几次？<strong>实际上当为 0 时，特指 8 次</strong>，从下面的内核源码可知：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/28.jpg" alt="img"></p><p>如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。</p><p>对于普遍正常情况时，调低 tcp_orphan_retries 就已经可以了。如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：</p><ul><li>首先，TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文也不能提前发送。</li><li>其次，TCP 有流量控制功能，当接收方接收窗口为 0 时，发送方就不能再发送数据。所以，当攻击者下载大文件时，就可以通过接收窗口设为 0 ，这就会使得 FIN 报文都无法发送出去，那么连接会一直处于 FIN_WAIT1 状态。</li></ul><p>解决这种问题的方法，是<strong>调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/29.jpg" alt="img"></p><p>当进程调用了 <code>close</code> 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法再发送和接收数据。Linux 系统为了防止孤儿连接过多，导致系统资源长时间被占用，就提供了 <code>tcp_max_orphans</code> 参数。如果孤儿连接数量大于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。</p><blockquote><p>FIN_WAIT2 状态的优化</p></blockquote><p>当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。</p><p>这时，<strong>如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长</strong>，默认值是 60 秒：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/30.jpg" alt="img"></p><p>它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。</p><p>这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的，后面我们再来说说为什么是 60 秒。</p><blockquote><p>TIME_WAIT 状态的优化</p></blockquote><p>TIME_WAIT 是主动方四次挥手的最后一个状态，也是最常遇见的状态。</p><p>当收到被动方发来的 FIN 报文后，主动方会立刻回复 ACK，表示确认对方的发送通道已经关闭，接着就处于 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。</p><p>TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p><p>TIME-WAIT 的状态尤其重要，主要是两个原因：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p><em>原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收</em></p><p>TIME-WAIT 的一个作用是<strong>防止收到历史数据，从而导致数据错乱的问题。</strong></p><p>假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/6385cc99500b01ba2ef288c27523c1e7.png" alt="TIME-WAIT 时间过短，收到旧连接的数据报文"></p><ul><li>如上图：<ul><li>服务端在关闭连接之前发送的 <code>SEQ = 301</code> 报文，被网络延迟了。</li><li>接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 <code>SEQ = 301</code> 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li></ul></li></ul><p>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></p><p><em>原因二：保证「被动关闭连接」的一方，能被正确的关闭</em></p><p>在 RFC 793 指出 TIME-WAIT 另一个重要的作用是：</p><p><em>TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.</em></p><p>也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p><p>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。</p><p>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSED 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/3a81c23ce57c27cf63fc2b77e34de0ab.png" alt="TIME-WAIT 时间过短，没有确保连接正常关闭"></p><p>服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</p><p>为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TIME-WAIT%E8%BF%9E%E6%8E%A5%E6%AD%A3%E5%B8%B8%E5%85%B3%E9%97%AD.drawio.png" alt="TIME-WAIT 时间正常，确保了连接正常关闭"></p><p>客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。</p><p>我们再回过头来看看，为什么 TIME_WAIT 状态要保持 60 秒呢？</p><p>这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的原理是一样的，<strong>因为这两个状态都需要保持 2MSL 时长。MSL 全称是 Maximum Segment Lifetime，它定义了一个报文在网络中的最长生存时间</strong>（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。</p><p>为什么是 2 MSL 的时长呢？这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。</p><p>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p><p><strong>因此，TIME_WAIT 和 FIN_WAIT2 状态的最大时长都是 2 MSL，由于在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。</strong></p><blockquote><p>TIME_WAIT 状态优化方式一</p></blockquote><p><strong>Linux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭：</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/33.jpg" alt="img"></p><p>当服务器的并发连接增多时，相应地，同时处于 TIME_WAIT 状态的连接数量也会变多，此时就应当调大 <code>tcp_max_tw_buckets</code> 参数，减少不同连接间数据错乱的概率。tcp_max_tw_buckets 也不是越大越好，毕竟系统资源是有限的。</p><blockquote><p>TIME_WAIT 状态优化方式二</p></blockquote><p><strong>有一种方式可以在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。但是需要注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的，而对于服务端（被动连接方）是没有用的。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/34.jpg" alt="img"></p><p>网上很多博客都说在服务端开启 tcp_tw_reuse 参数来优化 TCP，我信你个鬼，糟老头坏的很！<strong>tcp_tw_reuse 只作用在 connect 函数，也就是客户端，跟服务端一毛关系的没有</strong>。</p><p>tcp_tw_reuse 从协议角度理解是安全可控的，可以复用处于 TIME_WAIT 的端口为新的连接所用。</p><p>什么是协议角度理解的安全可控呢？主要有两点：</p><ul><li>只适用于连接发起方，也就是 C/S 模型中的客户端；</li><li>对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。</li></ul><p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持（对方也要打开 ）：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/35.jpg" alt="img"></p><p>由于引入了时间戳，它能带来了些好处：</p><ul><li>我们在前面提到的 2MSL（TIME_WAIT状态的持续时间） 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；</li><li>同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；</li></ul><p>时间戳是在 TCP 的选项字段里定义的，开启了时间戳功能，在 TCP 报文传输的时候会带上发送报文的时间戳。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/TCP%20option%E5%AD%97%E6%AE%B5-%E6%97%B6%E9%97%B4%E6%88%B3.png" alt="TCP option 字段 - 时间戳"></p><p>另外，老版本的 Linux 还提供了 <code>tcp_tw_recycle</code> 参数，但是当开启了它，允许处于 TIME_WAIT 状态的连接被快速回收，但是有个<strong>大坑</strong>。</p><p>开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS（判断TCP 报文中时间戳是否是历史报文） 机制，<strong>per-host 是对「对端 IP 做 PAWS 检查」</strong>，而非对「IP + 端口」四元组做 PAWS 检查。</p><p>如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</p><p>Per-host PAWS 机制利用 TCP option 里的 timestamp 字段的增长来判断串扰数据，而 timestamp 是根据客户端各自的 CPU tick 得出的值。</p><p>当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，<strong>客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包</strong>。</p><p>因此，tcp_tw_recycle 在使用了 NAT 的网络下是存在问题的，如果它是对 TCP 四元组做 PAWS 检查，而不是对「相同的 IP 做 PAWS 检查」，那么就不会存在这个问题了。</p><p>网上很多博客都说开启 tcp_tw_recycle 参数来优化 TCP，我信你个鬼，糟老头坏的很！</p><p>所以，不建议设置为 1 ，在 Linux 4.12 版本后，Linux 内核直接取消了这一参数，建议关闭它：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/36.jpg" alt="img"></p><blockquote><p>TIME_WAIT 状态优化方式三</p></blockquote><p>我们可以在程序中设置 socket 选项，来设置调用 close 关闭连接行为。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/37.jpg" alt="img"></p><p>如果 <code>l_onoff</code> 为非 0， 且 <code>l_linger</code> 值为 0，<strong>那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。</strong></p><p>这种方式只推荐在客户端使用，服务端千万不要使用。因为服务端一调用 close，就发送 RST 报文的话，客户端就总是看到 TCP 连接错误 “connnection reset by peer”。</p><h3 id="被动方的优化">被动方的优化</h3><p>当被动方收到 FIN 报文时，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p><p>内核没有权利替代进程去关闭连接，因为如果主动方是通过 shutdown 关闭连接，那么它就是想在半关闭连接上接收数据或发送数据。因此，Linux 并没有限制 CLOSE_WAIT 状态的持续时间。</p><p>当然，大多数应用程序并不使用 shutdown 函数关闭连接。所以，<strong>当你用 netstat 命令发现大量 CLOSE_WAIT 状态。就需要排查你的应用程序，因为可能因为应用程序出现了 Bug，read 函数返回 0 时，没有调用 close 函数。</strong></p><p>处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。</p><p>如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。</p><p>还有一点我们需要注意的，<strong>如果被动方迅速调用 close 函数，那么被动方的 ACK 和 FIN 有可能在一个报文中发送，这样看起来，四次挥手会变成三次挥手，这只是一种特殊情况，不用在意。</strong></p><blockquote><p>如果连接双方同时关闭连接，会怎么样？</p></blockquote><p>由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。</p><p>此时，上面介绍的优化策略仍然适用。两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/38.jpg" alt="同时关闭"></p><p>接下来，<strong>双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态</strong>。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。</p><h3 id="小结-2">小结</h3><p>针对 TCP 四次挥手的优化，我们需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/39.jpg" alt="四次挥手的优化策略"></p><blockquote><p>主动方的优化</p></blockquote><p>主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 <code>tcp_orphan_retries</code> 参数决定。</p><p>当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：</p><ul><li>如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 <code>tcp_fin_timeout</code> 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，<code>tcp_max_orphans</code> 定义了最大孤儿连接的数量，超过时连接就会直接释放。</li><li>反之是 shutdown 函数关闭的连接，则不受此参数限制；</li></ul><p>当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，<code>tcp_max_tw_buckets</code> 定义了最大数量，超过时连接也会直接释放。</p><p>当 TIME_WAIT 状态过多时，还可以通过设置 <code>tcp_tw_reuse</code> 和 <code>tcp_timestamps</code> 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。</p><blockquote><p>被动方的优化</p></blockquote><p>被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。</p><p>当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 <code>tcp_orphan_retries</code> 参数的控制下重发 FIN 报文。</p><hr><h2 id="TCP-传输数据的性能提升">TCP 传输数据的性能提升</h2><p>在前面介绍的是三次握手和四次挥手的优化策略，接下来主要介绍的是 TCP 传输数据时的优化策略。</p><p>TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：</p><ul><li>如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；</li><li>如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；</li></ul><p>因此，我们必须理解 Linux 下 TCP 内存的用途，才能正确地配置内存大小。</p><h3 id="滑动窗口是如何影响传输速度的？">滑动窗口是如何影响传输速度的？</h3><p>TCP 会保证每一个报文都能够抵达对方，它的机制是这样：报文发出去后，必须接收到对方返回的确认报文 ACK，如果迟迟未收到，就会超时重发该报文，直到收到对方的 ACK 为止。</p><p><strong>所以，TCP 报文发出去后，并不会立马从内存中删除，因为重传时还需要用到它。</strong></p><p>由于 TCP 是内核维护的，所以报文存放在内核缓冲区。如果连接非常多，我们可以通过 free 命令观察到 <code>buff/cache</code> 内存是会增大。</p><p>如果 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句，但这种方式的缺点是效率比较低的。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/40.jpg" alt="按数据包进行确认应答"></p><p>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。</p><p><strong>要解决这一问题不难，并行批量发送报文，再批量确认报文即可。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/41.jpg" alt="并行处理"></p><p>然而，这引出了另一个问题，发送方可以随心所欲的发送报文吗？<strong>当然这不现实，我们还得考虑接收方的处理能力。</strong></p><p>当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。</p><p><strong>为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来。</strong></p><p>接收方根据它的缓冲区，可以计算出后续能够接收多少字节的报文，这个数字叫做接收窗口。当内核接收到报文时，必须用缓冲区存放它们，这样剩余缓冲区空间变小，接收窗口也就变小了；当进程调用 read 函数后，数据被读入了用户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报文，接收窗口就会变大。</p><p>因此，接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的<strong>窗口字段</strong>，这样就可以起到窗口大小通知的作用。</p><p>发送方的窗口等价于接收方的窗口吗？如果不考虑拥塞控制，发送方的窗口大小「约等于」接收方的窗口大小，因为窗口通知报文在网络传输是存在时延的，所以是约等于的关系。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/42.jpg" alt="TCP 头部"></p><p>从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。</p><p>这个窗口大小最大值，在当今高速网络下，很明显是不够用的。所以后续有了扩充窗口的方法：<strong>在 TCP 选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/TCP%20option%E5%AD%97%E6%AE%B5-%E7%AA%97%E5%8F%A3.png" alt="TCP option 选项 - 窗口扩展"></p><p>Linux 中打开这一功能，需要把 tcp_window_scaling 配置设为 1（默认打开）：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/43.jpg" alt="img"></p><p>要使用窗口扩大选项，通讯双方必须在各自的 SYN 报文中发送这个选项：</p><ul><li>主动建立连接的一方在 SYN 报文中发送这个选项；</li><li>而被动建立连接的一方只有在收到带窗口扩大选项的 SYN 报文之后才能发送这个选项。</li></ul><p>这样看来，只要进程能及时地调用 read 函数读取数据，并且接收缓冲区配置得足够大，那么接收窗口就可以无限地放大，发送方也就无限地提升发送速度。</p><p><strong>这是不可能的，因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。</strong></p><h3 id="如何确定最大传输速度？">如何确定最大传输速度？</h3><p>在前面我们知道了 TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力。其中，窗口大小由内核缓冲区大小决定。如果缓冲区与网络传输能力匹配，那么缓冲区的利用率就达到了最大化。</p><p>问题来了，如何计算网络的传输能力呢？</p><p>相信大家都知道网络是有「带宽」限制的，带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:</p><ul><li>带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；</li><li>缓冲区单位是字节，当网络速度乘以时间才能得到字节数；</li></ul><p>这里需要说一个概念，就是带宽时延积，它决定网络中飞行报文的大小，它的计算方式：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/44.jpg" alt="img"></p><p>比如最大带宽是 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节。</p><p>这个 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为 BDP，Bandwidth Delay Product）。同时，这 1MB 也表示「飞行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1 MB，就会导致网络过载，容易丢包。</p><p><strong>由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。</strong></p><p>发送缓冲区与带宽时延积的关系：</p><ul><li>如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；</li><li>如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。</li></ul><p>所以，发送缓冲区的大小最好是往带宽时延积靠近。</p><h3 id="怎样调整缓冲区大小？">怎样调整缓冲区大小？</h3><p>在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行<strong>动态调节</strong>。</p><blockquote><p>调节发送缓冲区范围</p></blockquote><p>先来看看发送缓冲区，它的范围通过 tcp_wmem 参数配置；</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/45.jpg" alt="img"></p><p>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，4096 byte = 4K；</li><li>第二个数值是初始默认值，16384 byte ≈ 16K；</li><li>第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；</li></ul><p><strong>发送缓冲区是自行调节的</strong>，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。</p><blockquote><p>调节接收缓冲区范围</p></blockquote><p>而接收缓冲区的调整就比较复杂一些，先来看看设置接收缓冲区范围的 tcp_rmem 参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/46.jpg" alt="img"></p><p>上面三个数字单位都是字节，它们分别表示：</p><ul><li>第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4096 byte = 4K；</li><li>第二个数值是初始默认值，87380 byte ≈ 86K；</li><li>第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；</li></ul><p><strong>接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：</strong></p><ul><li>如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；</li><li>反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；</li></ul><p>发送缓冲区的调节功能是自动开启的，<strong>而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能</strong>：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/47.jpg" alt="img"></p><blockquote><p>调节 TCP 内存范围</p></blockquote><p>接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/48.jpg" alt="img"></p><p>上面三个数字单位不是字节，而是「页面大小」，1 页表示 4KB，它们分别表示：</p><ul><li>当 TCP 内存小于第 1 个值时，不需要进行自动调节；</li><li>在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；</li><li>大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；</li></ul><p>一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 tcp_mem 最大内存页面数是 177120，当内存为 (177120 * 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP 连接分配内存，即 TCP 连接将被拒绝。</p><blockquote><p>根据实际场景调节的策略</p></blockquote><p>在高并发服务器中，为了兼顾网速与大量的并发连接，<strong>我们应当保证缓冲区的动态调整的最大值达到带宽时延积，而最小值保持默认的 4K 不变即可。而对于内存紧张的服务而言，调低默认值是提高并发的有效手段。</strong></p><p>同时，如果这是网络 IO 型服务器，那么，<strong>调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存，这有利于提升并发能力</strong>。需要注意的是，tcp_wmem 和 tcp_rmem 的单位是字节，而 tcp_mem 的单位是页面大小。而且，<strong>千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF，这样会关闭缓冲区的动态调整功能。</strong></p><h3 id="小结-3">小结</h3><p>本节针对 TCP 优化数据传输的方式，做了一些介绍。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/49.jpg" alt="数据传输的优化策略"></p><p>TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。</p><p>可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 <code>tcp_window_scaling</code> 为 1 做到的，此时最大值可高达 1GB。</p><p>滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。</p><p>内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。</p><p>Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。</p><p>但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。</p><p>有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 半连接队列和全连接队列</title>
    <link href="/2021/05/13/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/04.TCP%20%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/"/>
    <url>/2021/05/13/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/04.TCP%20%E5%8D%8A%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E9%98%9F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h1>TCP 半连接队列和全连接队列</h1><p>网上许多博客针对增大 TCP 半连接队列和全连接队列的方式如下：</p><ul><li>增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog；</li><li>增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog；</li></ul><p>这里先跟大家说下，<strong>上面的方式都是不准确的。</strong></p><blockquote><p>“你怎么知道不准确？”</p></blockquote><p>很简单呀，因为我做了实验和看了 TCP 协议栈的内核源码，发现要增大这两个队列长度，不是简简单单增大某一个参数就可以的。</p><p>接下来，就会以<strong>实战 + 源码分析，带大家解密 TCP 半连接队列和全连接队列。</strong></p><blockquote><p>“源码分析，那不是劝退吗？我们搞 Java 的看不懂呀”</p></blockquote><p>放心，本文的源码分析不会涉及很深的知识，因为都被我删减了，你只需要会条件判断语句 if、左移右移操作符、加减法等基本语法，就可以看懂。</p><p>另外，不仅有源码分析，还会介绍 Linux 排查半连接队列和全连接队列的命令。</p><blockquote><p>“哦？似乎很有看头，那我姑且看一下吧！”</p></blockquote><p>行，没有被劝退的小伙伴，值得鼓励，下面这图是本文的提纲：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/2.jpg" alt="本文提纲"></p><hr><h2 id="什么是-TCP-半连接队列和全连接队列？">什么是 TCP 半连接队列和全连接队列？</h2><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accept 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，<strong>内核会把该连接存储到半连接队列</strong>，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，<strong>内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" alt="半连接队列与全连接队列"></p><p>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。</p><hr><h2 id="实战-TCP-全连接队列溢出">实战 - TCP 全连接队列溢出</h2><blockquote><p>如何知道应用程序的 TCP 全连接队列大小？</p></blockquote><p>在服务端可以使用 <code>ss</code> 命令，来查看 TCP 全连接队列的情况：</p><p>但需要注意的是 <code>ss</code> 命令获取的 <code>Recv-Q/Send-Q</code> 在「LISTEN 状态」和「非 LISTEN 状态」所表达的含义是不同的。从下面的内核代码可以看出区别：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/4.jpg" alt="img"></p><p>在「LISTEN 状态」时，<code>Recv-Q/Send-Q</code> 表示的含义如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/5.jpg" alt="img"></p><ul><li>Recv-Q：当前全连接队列的大小，也就是当前已完成三次握手并等待服务端 <code>accept()</code> 的 TCP 连接；</li><li>Send-Q：当前全连接最大队列长度，上面的输出结果说明监听 8088 端口的 TCP 服务，最大全连接长度为 128；</li></ul><p>在「非 LISTEN 状态」时，<code>Recv-Q/Send-Q</code> 表示的含义如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/6.jpg" alt="img"></p><ul><li>Recv-Q：已收到但未被应用进程读取的字节数；</li><li>Send-Q：已发送但未收到确认的字节数；</li></ul><blockquote><p>如何模拟 TCP 全连接队列溢出的场景？</p></blockquote><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/7.jpg" alt="测试环境"></p><p>实验环境：</p><ul><li>客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32</li><li>服务端 IP 192.168.3.200，客户端 IP 192.168.3.100</li><li>服务端是 Nginx 服务，端口为 8088</li></ul><p>这里先介绍下 <code>wrk</code> 工具，它是一款简单的 HTTP 压测工具，它能够在单机多核 CPU 的条件下，使用系统自带的高性能 I/O 机制，通过多线程和事件模式，对目标机器产生大量的负载。</p><p>本次模拟实验就使用 <code>wrk</code> 工具来压力测试服务端，发起大量的请求，一起看看服务端 TCP 全连接队列满了会发生什么？有什么观察指标？</p><p>客户端执行 <code>wrk</code> 命令对服务端发起压力测试，并发 3 万个连接：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/8.jpg" alt="img"></p><p>在服务端可以使用 <code>ss</code> 命令，来查看当前 TCP 全连接队列的情况：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/9.jpg" alt="img"></p><p>其间共执行了两次 ss 命令，从上面的输出结果，可以发现当前 TCP 全连接队列上升到了 129 大小，超过了最大 TCP 全连接队列。</p><p><strong>当超过了 TCP 最大全连接队列，服务端则会丢掉后续进来的 TCP 连接</strong>，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/10.jpg" alt="img"></p><p>上面看到的 41150 times ，表示全连接队列溢出的次数，注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话肯定全连接队列偶尔满了。</p><p>从上面的模拟结果，可以得知，<strong>当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/11.jpg" alt="全连接队列溢出"></p><blockquote><p>Linux 有个参数可以指定当 TCP 全连接队列满了会使用什么策略来回应客户端。</p></blockquote><p>实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/12.jpg" alt="img"></p><p>tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</p><ul><li>0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；</li><li>1 ：如果全连接队列满了，server 发送一个 <code>reset</code> 包给 client，表示废掉这个握手过程和这个连接；</li></ul><p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 <code>connection reset by peer</code> 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p><p>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。</p><p>举个例子，当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次<strong>重发</strong>。如果服务器上的进程只是<strong>短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong></p><p>所以，tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以尽快通知客户端。</p><blockquote><p>如何增大 TCP 全连接队列呢？</p></blockquote><p>是的，当发现 TCP 全连接队列发生溢出的时候，我们就需要增大该队列的大小，以便可以应对客户端大量的请求。</p><p><strong>TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)</strong>。从下面的 Linux 内核代码可以得知：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/13.jpg" alt="img"></p><ul><li><code>somaxconn</code> 是 Linux 内核的参数，默认值是 128，可以通过 <code>/proc/sys/net/core/somaxconn</code> 来设置其值；</li><li><code>backlog</code> 是 <code>listen(int sockfd, int backlog)</code> 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；</li></ul><p>前面模拟测试中，我的测试环境：</p><ul><li>somaxconn 是默认值 128；</li><li>Nginx 的 backlog 是默认值 511</li></ul><p>所以测试环境的 TCP 全连接队列最大值为 min(128, 511)，也就是 <code>128</code>，可以执行 <code>ss</code> 命令查看：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/14.jpg" alt="img"></p><p>现在我们重新压测，把 TCP 全连接队列<strong>搞大</strong>，把 <code>somaxconn</code> 设置成 5000：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/15.jpg" alt="img"></p><p>接着把 Nginx 的 backlog 也同样设置成 5000：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/16.jpg" alt="img"></p><p>最后要重启 Nginx 服务，因为只有重新调用 <code>listen()</code> 函数 TCP 全连接队列才会重新初始化。</p><p>重启完后 Nginx 服务后，服务端执行 ss 命令，查看 TCP 全连接队列大小：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/17.jpg" alt="img"></p><p>从执行结果，可以发现 TCP 全连接最大值为 5000。</p><blockquote><p>增大 TCP 全连接队列后，继续压测</p></blockquote><p>客户端同样以 3 万个连接并发发送请求给服务端：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/18.jpg" alt="img"></p><p>服务端执行 <code>ss</code> 命令，查看 TCP 全连接队列使用情况：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/19.jpg" alt="img"></p><p>从上面的执行结果，可以发现全连接队列使用增长的很快，但是一直都没有超过最大值，所以就不会溢出，那么 <code>netstat -s</code> 就不会有 TCP 全连接队列溢出个数的显示：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/20.jpg" alt="img"></p><p>说明 TCP 全连接队列最大值从 128 增大到 5000 后，服务端抗住了 3 万连接并发请求，也没有发生全连接队列溢出的现象了。</p><p><strong>如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</strong></p><hr><h2 id="实战-TCP-半连接队列溢出">实战 - TCP 半连接队列溢出</h2><blockquote><p>如何查看 TCP 半连接队列长度？</p></blockquote><p>很遗憾，TCP 半连接队列长度的长度，没有像全连接队列那样可以用 ss 命令查看。</p><p>但是我们可以抓住 TCP 半连接的特点，就是服务端处于 <code>SYN_RECV</code> 状态的 TCP 连接，就是 TCP 半连接队列。</p><p>于是，我们可以使用如下命令计算当前 TCP 半连接队列长度：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/21.jpg" alt="img"></p><blockquote><p>如何模拟 TCP 半连接队列溢出场景？</p></blockquote><p>模拟 TCP 半连接溢出场景不难，实际上就是对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得服务端有大量的处于 <code>SYN_RECV</code> 状态的 TCP 连接。</p><p>这其实也就是所谓的 SYN 洪泛、SYN 攻击、DDos 攻击。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/22.jpg" alt="测试环境"></p><p>实验环境：</p><ul><li>客户端和服务端都是 CentOs 6.5 ，Linux 内核版本 2.6.32</li><li>服务端 IP 192.168.3.200，客户端 IP 192.168.3.100</li><li>服务端是 Nginx 服务，端口为 8088</li></ul><p>注意：本次模拟实验是没有开启 tcp_syncookies，关于 tcp_syncookies 的作用，后续会说明。</p><p>本次实验使用 <code>hping3</code> 工具模拟 SYN 攻击：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/23.jpg" alt="img"></p><p>当服务端受到 SYN 攻击后，连接服务端 ssh 就会断开了，无法再连上。只能在服务端主机上执行查看当前 TCP 半连接队列大小：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/24.jpg" alt="img"></p><p>同时，还可以通过 netstat -s 观察半连接队列溢出的情况：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/25.jpg" alt="img"></p><p>上面输出的数值是<strong>累计值</strong>，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。<strong>隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象</strong>。</p><blockquote><p>大部分人都说 tcp_max_syn_backlog 是指定半连接队列的大小，是真的吗？</p></blockquote><p>很遗憾，半连接队列的大小并不单单只跟 <code>tcp_max_syn_backlog</code> 有关系。</p><p>上面模拟 SYN 攻击场景时，服务端的 tcp_max_syn_backlog 的默认值如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/26.jpg" alt="img"></p><p>但是在测试的时候发现，服务端最多只有 256 个半连接队列，而不是 512，所以<strong>半连接队列的最大长度不一定由 tcp_max_syn_backlog 值决定的</strong>。</p><blockquote><p>接下来，走进 Linux 内核的源码，来分析 TCP 半连接队列的最大值是如何决定的。</p></blockquote><p>TCP 第一次握手（收到 SYN 包）的 Linux 内核代码如下，其中缩减了大量的代码，只需要重点关注 TCP 半连接队列溢出的处理逻辑：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/27.jpg" alt="img"></p><p>从源码中，我可以得出共有三个条件因队列长度的关系而被丢弃的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/28.jpg" alt="img"></p><ol><li><strong>如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；</strong></li><li><strong>若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；</strong></li><li><strong>如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &gt;&gt; 2)，则会丢弃；</strong></li></ol><p>关于 tcp_syncookies 的设置，后面在详细说明，可以先给大家说一下，开启 tcp_syncookies 是缓解 SYN 攻击其中一个手段。</p><p>接下来，我们继续跟一下检测半连接队列是否满的函数 inet_csk_reqsk_queue_is_full 和 检测全连接队列是否满的函数 sk_acceptq_is_full ：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/29.jpg" alt="img"></p><p>从上面源码，可以得知：</p><ul><li><strong>全</strong>连接队列的最大值是 <code>sk_max_ack_backlog</code> 变量，sk_max_ack_backlog 实际上是在 listen() 源码里指定的，也就是 <strong>min(somaxconn, backlog)</strong>；</li><li><strong>半</strong>连接队列的最大值是 <code>max_qlen_log</code> 变量，max_qlen_log 是在哪指定的呢？现在暂时还不知道，我们继续跟进；</li></ul><p>我们继续跟进代码，看一下是哪里初始化了半连接队列的最大值 max_qlen_log：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/30.jpg" alt="img"></p><p>从上面的代码中，我们可以算出 max_qlen_log 是 8，于是代入到 检测半连接队列是否满的函数 reqsk_queue_is_full ：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/31.jpg" alt="img"></p><p>也就是 <code>qlen &gt;&gt; 8</code> 什么时候为 1 就代表半连接队列满了。这计算这不难，很明显是当 qlen 为 256 时，<code>256 &gt;&gt; 8 = 1</code>。</p><p>至此，总算知道为什么上面模拟测试 SYN 攻击的时候，服务端处于 <code>SYN_RECV</code> 连接最大只有 256 个。</p><p>可见，<strong>半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。</strong></p><p>在 Linux 2.6.32 内核版本，它们之间的关系，总体可以概况为：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/32.jpg" alt="img"></p><ul><li>当 max_syn_backlog &gt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;</li><li>当 max_syn_backlog &lt; min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;</li></ul><blockquote><p>半连接队列最大值 max_qlen_log 就表示服务端处于 SYN_RECV 状态的最大个数吗？</p></blockquote><p>依然很遗憾，并不是。</p><p>max_qlen_log 是<strong>理论</strong>半连接队列最大值，并不一定代表服务端处于 SYN_RECV 状态的最大个数。</p><p>在前面我们在分析 TCP 第一次握手（收到 SYN 包）时会被丢弃的三种条件：</p><ol><li>如果半连接队列满了，并且没有开启 tcp_syncookies，则会丢弃；</li><li>若全连接队列满了，且没有重传 SYN+ACK 包的连接请求多于 1 个，则会丢弃；</li><li><strong>如果没有开启 tcp_syncookies，并且 max_syn_backlog 减去 当前半连接队列长度小于 (max_syn_backlog &gt;&gt; 2)，则会丢弃；</strong></li></ol><p>假设条件 1 当前半连接队列的长度 「没有超过」理论的半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_RECV 状态的最大个数不会是理论值 max_qlen_log。</p><p>似乎很难理解，我们继续接着做实验，实验见真知。</p><p>服务端环境如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/33.jpg" alt="img"></p><p>配置完后，服务端要重启 Nginx，因为全连接队列最大值和半连接队列最大值是在 listen() 函数初始化。</p><p>根据前面的源码分析，我们可以计算出半连接队列 max_qlen_log 的最大值为 256：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/34.jpg" alt="img"></p><p>客户端执行 hping3 发起 SYN 攻击：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/35.jpg" alt="img"></p><p>服务端执行如下命令，查看处于 SYN_RECV 状态的最大个数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/36.jpg" alt="img"></p><p>可以发现，服务端处于 SYN_RECV 状态的最大个数并不是 max_qlen_log 变量的值。</p><p>这就是前面所说的原因：<strong>如果当前半连接队列的长度 「没有超过」理论半连接队列最大值 max_qlen_log，那么如果条件 3 成立，则依然会丢弃 SYN 包，也就会使得服务端处于 SYN_RECV 状态的最大个数不会是理论值 max_qlen_log。</strong></p><p>我们来分析一波条件 3 :</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/37.jpg" alt="img"></p><p>从上面的分析，可以得知如果触发「当前半连接队列长度 &gt; 192」条件，TCP 第一次握手的 SYN 包是会被丢弃的。</p><p>在前面我们测试的结果，服务端处于 SYN_RECV 状态的最大个数是 193，正好是触发了条件 3，所以处于 SYN_RECV 状态的个数还没到「理论半连接队列最大值 256」，就已经把 SYN 包丢弃了。</p><p>所以，服务端处于 SYN_RECV 状态的最大个数分为如下两种情况：</p><ul><li>如果「当前半连接队列」<strong>没超过</strong>「理论半连接队列最大值」，但是<strong>超过</strong> max_syn_backlog - (max_syn_backlog &gt;&gt; 2)，那么处于 SYN_RECV 状态的最大个数就是 max_syn_backlog - (max_syn_backlog &gt;&gt; 2)；</li><li>如果「当前半连接队列」<strong>超过</strong>「理论半连接队列最大值」，那么处于 SYN_RECV 状态的最大个数就是「理论半连接队列最大值」；</li></ul><blockquote><p>每个 Linux 内核版本「理论」半连接最大值计算方式会不同。</p></blockquote><p>在上面我们是针对 Linux 2.6.32 版本分析的「理论」半连接最大值的算法，可能每个版本有些不同。</p><p>比如在 Linux 5.0.0 的时候，「理论」半连接最大值就是全连接队列最大值，但依然还是有队列溢出的三个条件：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/38.jpg" alt="img"></p><blockquote><p>如果 SYN 半连接队列已满，只能丢弃连接吗？</p></blockquote><p>并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接</strong>，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接。</p><p>syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/39.jpg" alt="开启 syncookies 功能"></p><p>syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/40.jpg" alt="img"></p><blockquote><p>如何防御 SYN 攻击？</p></blockquote><p>这里给出几种防御 SYN 攻击的方法：</p><ul><li>增大半连接队列；</li><li>开启 tcp_syncookies 功能</li><li>减少 SYN+ACK 重传次数</li></ul><p><em>方式一：增大半连接队列</em></p><p>在前面源码和实验中，得知<strong>要想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列</strong>。否则，只单纯增大 tcp_max_syn_backlog 是无效的。</p><p>增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/41.jpg" alt="img"></p><p>增大 backlog 的方式，每个 Web 服务都不同，比如 Nginx 增大 backlog 的方法如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/42.jpg" alt="img"></p><p>最后，改变了如上这些参数后，要重启 Nginx 服务，因为半连接队列和全连接队列都是在 listen() 初始化的。</p><p><em>方式二：开启 tcp_syncookies 功能</em></p><p>开启 tcp_syncookies 功能的方式也很简单，修改 Linux 内核参数：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/43.jpg" alt="img"></p><p><em>方式三：减少 SYN+ACK 重传次数</em></p><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_RECV 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_RECV 状态的 TCP 连接断开。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/44.jpg" alt="img"></p><hr><p>参考资料：</p><p>[1] 系统性能调优必知必会.陶辉.极客时间.</p><p>[2] <a href="https://www.cnblogs.com/zengkefu/p/5606696.html">https://www.cnblogs.com/zengkefu/p/5606696.html</a></p><p>[3] <a href="https://blog.cloudflare.com/syn-packet-handling-in-the-wild/">https://blog.cloudflare.com/syn-packet-handling-in-the-wild/</a></p><hr><h2 id="读者问答">读者问答</h2><blockquote><p>读者问：“咦 我比较好奇博主都是从哪里学到这些知识的呀？书籍？视频？还是多种参考资料”</p></blockquote><p>你可以看我的参考文献呀，知识点我主要是在极客专栏学的，实战模拟实验和源码解析是自己瞎折腾出来的。</p><blockquote><p>读者问：“syncookies 启用后就不需要半链接了？那请求的数据会存在哪里？”</p></blockquote><p>syncookies = 1 时，半连接队列满后，后续的请求就不会存放到半连接队列了，而是在第二次握手的时候，服务端会计算一个 cookie 值，放入到 SYN +ACK 包中的序列号发给客户端，客户端收到后并回 ack ，服务端就会校验连接是否合法，合法就直接把连接放入到全连接队列。</p>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 实战抓包分析</title>
    <link href="/2021/05/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/03.TCP%20%E5%AE%9E%E6%88%98%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90/"/>
    <url>/2021/05/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/03.TCP%20%E5%AE%9E%E6%88%98%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1>TCP 实战抓包分析</h1><p>为了让大家更容易「看得见」 TCP，我搭建不少测试环境，并且数据包抓很多次，花费了不少时间，才抓到比较容易分析的数据包。</p><p>接下来丢包、乱序、超时重传、快速重传、选择性确认、流量控制等等 TCP 的特性，都能「一览无余」。</p><p>没错，我把 TCP 的&quot;衣服扒光&quot;了，就为了给大家看的清楚，嘻嘻。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/2.jpg" alt="提纲"></p><hr><h2 id="显形“不可见”的网络包">显形“不可见”的网络包</h2><p>网络世界中的数据包交互我们肉眼是看不见的，它们就好像隐形了一样，我们对着课本学习计算机网络的时候就会觉得非常的抽象，加大了学习的难度。</p><p>还别说，我自己在大学的时候，也是如此。</p><p>直到工作后，认识了两大分析网络的利器：<strong>tcpdump 和 Wireshark</strong>，这两大利器把我们“看不见”的数据包，呈现在我们眼前，一目了然。</p><p>唉，当初大学学习计网的时候，要是能知道这两个工具，就不会学的一脸懵逼。</p><blockquote><p>tcpdump 和 Wireshark 有什么区别？</p></blockquote><p>tcpdump 和 Wireshark 就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。</p><ul><li>tcpdump 仅支持命令行格式使用，常用在 Linux 服务器中抓取和分析网络包。</li><li>Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面。</li></ul><p>所以，这两者实际上是搭配使用的，先用 tcpdump 命令在 Linux 服务器上抓包，接着把抓包的文件拖出到 Windows 电脑后，用 Wireshark 可视化分析。</p><p>当然，如果你是在 Windows 上抓包，只需要用 Wireshark 工具就可以。</p><blockquote><p>tcpdump 在 Linux 下如何抓包？</p></blockquote><p>tcpdump 提供了大量的选项以及各式各样的过滤表达式，来帮助你抓取指定的数据包，不过不要担心，只需要掌握一些常用选项和过滤表达式，就可以满足大部分场景的需要了。</p><p>假设我们要抓取下面的 ping 的数据包：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/3.jpg" alt="img"></p><p>要抓取上面的 ping 命令数据包，首先我们要知道 ping 的数据包是 <code>icmp</code> 协议，接着在使用 tcpdump 抓包的时候，就可以指定只抓 icmp 协议的数据包：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/4.jpg" alt="img"></p><p>那么当 tcpdump 抓取到 icmp 数据包后， 输出格式如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/5.jpg" alt="img"></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/6.jpg" alt="img"></p><p>从 tcpdump 抓取的 icmp 数据包，我们很清楚的看到 <code>icmp echo</code> 的交互过程了，首先发送方发起了 <code>ICMP echo request</code> 请求报文，接收方收到后回了一个 <code>ICMP echo reply</code> 响应报文，之后 <code>seq</code> 是递增的。</p><p>我在这里也帮你整理了一些最常见的用法，并且绘制成了表格，你可以参考使用。</p><p>首先，先来看看常用的选项类，在上面的 ping 例子中，我们用过 <code>-i</code> 选项指定网口，用过 <code>-nn</code> 选项不对 IP 地址和端口名称解析。其他常用的选项，如下表格：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/7.jpg" alt="tcpdump 常用选项类"></p><p>接下来，我们再来看看常用的过滤表用法，在上面的 ping 例子中，我们用过的是 <code>icmp and host 183.232.231.174</code>，表示抓取 icmp 协议的数据包，以及源地址或目标地址为 183.232.231.174 的包。其他常用的过滤选项，我也整理成了下面这个表格。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/8.jpg" alt="tcpdump 常用过滤表达式类"></p><p>说了这么多，你应该也发现了，tcpdump 虽然功能强大，但是输出的格式并不直观。</p><p>所以，在工作中 tcpdump 只是用来抓取数据包，不用来分析数据包，而是把 tcpdump 抓取的数据包保存成 pcap 后缀的文件，接着用 Wireshark 工具进行数据包分析。</p><blockquote><p>Wireshark 工具如何分析数据包？</p></blockquote><p>Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面，同时，还内置了一系列的汇总分析工具。</p><p>比如，拿上面的 ping 例子来说，我们可以使用下面的命令，把抓取的数据包保存到 ping.pcap 文件</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/9.jpg" alt="img"></p><p>接着把 ping.pcap 文件拖到电脑，再用 Wireshark 打开它。打开后，你就可以看到下面这个界面：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/10.jpg" alt="img"></p><p>是吧？在 Wireshark 的页面里，可以更加直观的分析数据包，不仅展示各个网络包的头部信息，还会用不同的颜色来区分不同的协议，由于这次抓包只有 ICMP 协议，所以只有紫色的条目。</p><p>接着，在网络包列表中选择某一个网络包后，在其下面的网络包详情中，<strong>可以更清楚的看到，这个网络包在协议栈各层的详细信息</strong>。比如，以编号 1 的网络包为例子：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/11.jpg" alt="ping 网络包"></p><ul><li>可以在数据链路层，看到 MAC 包头信息，如源 MAC 地址和目标 MAC 地址等字段；</li><li>可以在 IP 层，看到 IP 包头信息，如源 IP 地址和目标 IP 地址、TTL、IP 包长度、协议等 IP 协议各个字段的数值和含义；</li><li>可以在 ICMP 层，看到 ICMP 包头信息，比如 Type、Code 等 ICMP 协议各个字段的数值和含义；</li></ul><p>Wireshark 用了分层的方式，展示了各个层的包头信息，把“不可见”的数据包，清清楚楚的展示了给我们，还有理由学不好计算机网络吗？是不是<strong>相见恨晚</strong>？</p><p>从 ping 的例子中，我们可以看到网络分层就像有序的分工，每一层都有自己的责任范围和信息，上层协议完成工作后就交给下一层，最终形成一个完整的网络包。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/12.jpg" alt="img"></p><hr><h2 id="解密-TCP-三次握手和四次挥手">解密 TCP 三次握手和四次挥手</h2><p>既然学会了 tcpdump 和 Wireshark 两大网络分析利器，那我们快马加鞭，接下来用它俩抓取和分析 HTTP 协议网络包，并理解 TCP 三次握手和四次挥手的工作原理。</p><p>本次例子，我们将要访问的 <a href="http://192.168.3.200">http://192.168.3.200</a> 服务端。在终端一用 tcpdump 命令抓取数据包：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/13.jpg" alt="img"></p><p>接着，在终端二执行下面的 curl 命令：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/14.jpg" alt="img"></p><p>最后，回到终端一，按下 Ctrl+C 停止 tcpdump，并把得到的 http.pcap 取出到电脑。</p><p>使用 Wireshark 打开 http.pcap 后，你就可以在 Wireshark 中，看到如下的界面：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/15.jpg" alt="HTTP 网络包"></p><p>我们都知道 HTTP 是基于 TCP 协议进行传输的，那么：</p><ul><li>最开始的 3 个包就是 TCP 三次握手建立连接的包</li><li>中间是 HTTP 请求和响应的包</li><li>而最后的 3 个包则是 TCP 断开连接的挥手包</li></ul><p>Wireshark 可以用时序图的方式显示数据包交互的过程，从菜单栏中，点击 统计 (Statistics) -&gt; 流量图 (Flow Graph)，然后，在弹出的界面中的「流量类型」选择 「TCP Flows」，你可以更清晰的看到，整个过程中 TCP 流的执行过程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/16.jpg" alt="TCP 流量图"></p><blockquote><p>你可能会好奇，为什么三次握手连接过程的 Seq 是 0 ？</p></blockquote><p>实际上是因为 Wireshark 工具帮我们做了优化，它默认显示的是序列号 seq 是相对值，而不是真实值。</p><p>如果你想看到实际的序列号的值，可以右键菜单， 然后找到「协议首选项」，接着找到「Relative Seq」后，把它给取消，操作如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/17.jpg" alt="取消序列号相对值显示"></p><p>取消后，Seq 显示的就是真实值了：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/18.jpg" alt="TCP 流量图"></p><p>可见，客户端和服务端的序列号实际上是不同的，序列号是一个随机值。</p><p>这其实跟我们书上看到的 TCP 三次握手和四次挥手很类似，作为对比，你通常看到的 TCP 三次握手和四次挥手的流程，基本是这样的：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/19.jpg" alt="TCP 三次握手和四次挥手的流程"></p><blockquote><p>为什么抓到的 TCP 挥手是三次，而不是书上说的四次？</p></blockquote><p>当被动关闭方（上图的服务端）在 TCP 挥手过程中，「<strong>没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</strong></p><p>而通常情况下，服务器端收到客户端的 <code>FIN</code> 后，很可能还没发送完数据，所以就会先回复客户端一个 <code>ACK</code> 包，稍等一会儿，完成所有数据包的发送后，才会发送 <code>FIN</code> 包，这也就是四次挥手了。</p><hr><h2 id="TCP-三次握手异常情况实战分析">TCP 三次握手异常情况实战分析</h2><p>TCP 三次握手的过程相信大家都背的滚瓜烂熟，那么你有没有想过这三个异常情况：</p><ul><li><strong>TCP 第一次握手的 SYN 丢包了，会发生了什么？</strong></li><li><strong>TCP 第二次握手的 SYN、ACK 丢包了，会发生什么？</strong></li><li><strong>TCP 第三次握手的 ACK 包丢了，会发生什么？</strong></li></ul><p>有的小伙伴可能说：“很简单呀，包丢了就会重传嘛。”</p><p>那我在继续问你：</p><ul><li>那会重传几次？</li><li>超时重传的时间 RTO 会如何变化？</li><li>在 Linux 下如何设置重传次数？</li><li>…</li></ul><p>是不是哑口无言，无法回答？</p><p>不知道没关系，接下里我用三个实验案例，带大家一起探究探究这三种异常。</p><h3 id="实验场景">实验场景</h3><p>本次实验用了两台虚拟机，一台作为服务端，一台作为客户端，它们的关系如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/21.jpg" alt="实验环境"></p><ul><li>客户端和服务端都是 CentOs 6.5 Linux，Linux 内核版本 2.6.32</li><li>服务端 192.168.12.36，apache web 服务</li><li>客户端 192.168.12.37</li></ul><h3 id="实验一：TCP-第一次握手-SYN-丢包">实验一：TCP 第一次握手 SYN 丢包</h3><p>为了模拟 TCP 第一次握手 SYN 丢包的情况，我是在拔掉服务器的网线后，立刻在客户端执行 curl 命令：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/22.jpg" alt="img"></p><p>其间 tcpdump 抓包的命令如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/23.jpg" alt="img"></p><p>过了一会， curl 返回了超时连接的错误：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/24.jpg" alt="img"></p><p>从 <code>date</code> 返回的时间，可以发现在超时接近 1 分钟的时间后，curl 返回了错误。</p><p>接着，把 tcp_sys_timeout.pcap 文件用 Wireshark 打开分析，显示如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/25.jpg" alt="SYN 超时重传五次"></p><p>从上图可以发现， 客户端发起了 SYN 包后，一直没有收到服务端的 ACK ，所以一直超时重传了 5 次，并且每次 RTO 超时时间是不同的：</p><ul><li>第一次是在 1 秒超时重传</li><li>第二次是在 3 秒超时重传</li><li>第三次是在 7 秒超时重传</li><li>第四次是在 15 秒超时重传</li><li>第五次是在 31 秒超时重传</li></ul><p>可以发现，每次超时时间 RTO 是<strong>指数（翻倍）上涨的</strong>，当超过最大重传次数后，客户端不再发送 SYN 包。</p><p>在 Linux 中，第一次握手的 <code>SYN</code> 超时重传次数，是如下内核参数指定的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat /proc/sys/net/ipv4/tcp_syn_retries<br>5<br></code></pre></td></tr></table></figure><p><code>tcp_syn_retries</code> 默认值为 5，也就是 SYN 最大重传次数是 5 次。</p><p>接下来，我们继续做实验，把 <code>tcp_syn_retries</code> 设置为 2 次：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">echo</span> 2 &gt; /proc/sys/net/ipv4/tcp_syn_retries<br></code></pre></td></tr></table></figure><p>重传抓包后，用 Wireshark 打开分析，显示如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/26.jpg" alt="SYN 超时重传两次"></p><blockquote><p>实验一的实验小结</p></blockquote><p>通过实验一的实验结果，我们可以得知，当客户端发起的 TCP 第一次握手 SYN 包，在超时时间内没收到服务端的 ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达 <code>tcp_syn_retries</code> 值后，客户端不再发送 SYN 包。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/27.jpg" alt="SYN 超时重传"></p><h3 id="实验二：TCP-第二次握手-SYN、ACK-丢包">实验二：TCP 第二次握手 SYN、ACK 丢包</h3><p>为了模拟客户端收不到服务端第二次握手 SYN、ACK 包，我的做法是在客户端加上防火墙限制，直接粗暴的把来自服务端的数据都丢弃，防火墙的配置如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/28.jpg" alt="img"></p><p>接着，在客户端执行 curl 命令：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/29.jpg" alt="img"></p><p>从 <code>date</code> 返回的时间前后，可以算出大概 1 分钟后，curl 报错退出了。</p><p>客户端在这其间抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/30.jpg" alt="img"></p><p>从图中可以发现：</p><ul><li>客户端发起 SYN 后，由于防火墙屏蔽了服务端的所有数据包，所以 curl 是无法收到服务端的 SYN、ACK 包，当发生超时后，就会重传 SYN 包</li><li>服务端收到客户的 SYN 包后，就会回 SYN、ACK 包，但是客户端一直没有回 ACK，服务端在超时后，重传了 SYN、ACK 包，<strong>接着一会，客户端超时重传的 SYN 包又抵达了服务端，服务端收到后，然后回了 SYN、ACK 包，但是SYN、ACK包的重传定时器并没有重置，还持续在重传，因为第二次握手在没收到第三次握手的 ACK 确认报文时，会继续重传，直到达到重传到最大次数。</strong></li><li>最后，客户端 SYN 超时重传次数达到了 5 次（tcp_syn_retries 默认值 5 次），就不再继续发送 SYN 包了。</li></ul><p>所以，我们可以发现，<strong>当第二次握手的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传 SYN、ACK 包。</strong></p><blockquote><p>咦？客户端设置了防火墙，屏蔽了服务端的网络包，为什么 tcpdump 还能抓到服务端的网络包？</p></blockquote><p>添加 iptables 限制后， tcpdump 是否能抓到包 ，这要看添加的 iptables 限制条件：</p><ul><li>如果添加的是 <code>INPUT</code> 规则，则可以抓得到包</li><li>如果添加的是 <code>OUTPUT</code> 规则，则抓不到包</li></ul><p>网络包进入主机后的顺序如下：</p><ul><li>进来的顺序 Wire -&gt; NIC -&gt; <strong>tcpdump -&gt; netfilter/iptables</strong></li><li>出去的顺序 <strong>iptables -&gt; tcpdump</strong> -&gt; NIC -&gt; Wire</li></ul><blockquote><p>tcp_syn_retries 是限制 SYN 重传次数，那第二次握手 SYN、ACK 限制最大重传次数是多少？</p></blockquote><p>TCP 第二次握手 SYN、ACK 包的最大重传次数是通过 <code>tcp_synack_retries</code> 内核参数限制的，其默认值如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ cat /proc/sys/net/ipv4/tcp_synack_retries<br>5<br></code></pre></td></tr></table></figure><p>是的，TCP 第二次握手 SYN、ACK 包的最大重传次数默认值是 <code>5</code> 次。</p><p>为了验证 SYN、ACK 包最大重传次数是 5 次，我们继续做下实验，我们先把客户端的 <code>tcp_syn_retries</code> 设置为 1，表示客户端 SYN 最大超时次数是 1 次，目的是为了防止多次重传 SYN，把服务端 SYN、ACK 超时定时器重置。</p><p>接着，还是如上面的步骤：</p><ol><li>客户端配置防火墙屏蔽服务端的数据包</li><li>客户端 tcpdump 抓取 curl 执行时的数据包</li></ol><p>把抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/31.jpg" alt="img"></p><p>从上图，我们可以分析出：</p><ul><li>客户端的 SYN 只超时重传了 1 次，因为 <code>tcp_syn_retries</code> 值为 1</li><li>服务端应答了客户端超时重传的 SYN 包后，由于一直收不到客户端的 ACK 包，所以服务端一直在超时重传 SYN、ACK 包，每次的 RTO 也是指数上涨的，一共超时重传了 5 次，因为 <code>tcp_synack_retries</code> 值为 5</li></ul><p>接着，我把 <strong>tcp_synack_retries 设置为 2</strong>，<code>tcp_syn_retries</code> 依然设置为 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">echo</span> 2 &gt; /proc/sys/net/ipv4/tcp_synack_retries<br>$ <span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/tcp_syn_retries<br></code></pre></td></tr></table></figure><p>依然保持一样的实验步骤进行操作，接着把抓取的数据包，用 Wireshark 打开分析，显示的时序图如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/32.jpg" alt="img"></p><p>可见：</p><ul><li>客户端的 SYN 包只超时重传了 1 次，符合 tcp_syn_retries 设置的值；</li><li>服务端的 SYN、ACK 超时重传了 2 次，符合 tcp_synack_retries 设置的值</li></ul><blockquote><p>实验二的实验小结</p></blockquote><p>通过实验二的实验结果，我们可以得知，当 TCP 第二次握手 SYN、ACK 包丢了后，客户端 SYN 包会发生超时重传，服务端 SYN、ACK 也会发生超时重传。</p><p>客户端 SYN 包超时重传的最大次数，是由 tcp_syn_retries 决定的，默认值是 5 次；服务端 SYN、ACK 包时重传的最大次数，是由 tcp_synack_retries 决定的，默认值是 5 次。</p><h3 id="实验三：TCP-第三次握手-ACK-丢包">实验三：TCP 第三次握手 ACK 丢包</h3><p>为了模拟 TCP 第三次握手 ACK 包丢，我的实验方法是<strong>在服务端配置防火墙，屏蔽客户端 TCP 报文中标志位是 ACK 的包</strong>，也就是当服务端收到客户端的 TCP ACK 的报文时就会丢弃。</p><p>iptables 配置命令如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/33.jpg" alt="img"></p><p>接着，在客户端执行如下 tcpdump 命令：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/34.jpg" alt="img"></p><p>然后，客户端向服务端发起 telnet，因为 telnet 命令是会发起 TCP 连接，所以用此命令做测试：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/35.jpg" alt="img"></p><p>此时，由于服务端收不到第三次握手的 ACK 包，所以一直处于 <code>SYN_RECV</code> 状态：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/36.jpg" alt="img"></p><p>而客户端是已完成 TCP 连接建立，处于 <code>ESTABLISHED</code> 状态：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/37.jpg" alt="img"></p><p>过了 1 分钟后，观察发现服务端的 TCP 连接不见了：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/38.jpg" alt="img"></p><p>过了 30 分钟，客户端依然还是处于 <code>ESTABLISHED</code> 状态：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/39.jpg" alt="img"></p><p>接着，在刚才客户端建立的 telnet 会话，输入 123456 字符，进行发送：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/40.jpg" alt="img"></p><p>持续「好长」一段时间，客户端的 telnet 才断开连接：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/41.jpg" alt="img"></p><p>以上就是本次的实现三的现象，这里存在两个疑点：</p><ul><li>为什么服务端原本处于 <code>SYN_RECV</code> 状态的连接，过 1 分钟后就消失了？</li><li>为什么客户端 telnet 输入 123456 字符后，过了好长一段时间，telnet 才断开连接？</li></ul><p>不着急，我们把刚抓的数据包，用 Wireshark 打开分析，显示的时序图如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/42.jpg" alt="img"></p><p>上图的流程：</p><ul><li>客户端发送 SYN 包给服务端，服务端收到后，回了个 SYN、ACK 包给客户端，此时服务端的 TCP 连接处于 <code>SYN_RECV</code> 状态；</li><li>客户端收到服务端的 SYN、ACK 包后，给服务端回了个 ACK 包，此时客户端的 TCP 连接处于 <code>ESTABLISHED</code> 状态；</li><li>由于服务端配置了防火墙，屏蔽了客户端的 ACK 包，所以服务端一直处于 <code>SYN_RECV</code> 状态，没有进入 <code>ESTABLISHED</code> 状态，tcpdump 之所以能抓到客户端的 ACK 包，是因为数据包进入系统的顺序是先进入 tcpudmp，后经过 iptables；</li><li>接着，服务端超时重传了 SYN、ACK 包，重传了 5 次后，也就是<strong>超过 tcp_synack_retries 的值（默认值是 5），然后就没有继续重传了，此时服务端的 TCP 连接主动中止了，所以刚才处于 SYN_RECV 状态的 TCP 连接断开了</strong>，而客户端依然处于<code>ESTABLISHED</code> 状态；</li><li>虽然服务端 TCP 断开了，但过了一段时间，发现客户端依然处于<code>ESTABLISHED</code> 状态，于是就在客户端的 telnet 会话输入了 123456 字符；</li><li>由于服务端的防火墙配置了屏蔽所有携带 ACK 标志位的 TCP 报文，客户端发送的数据报文，服务端并不会接收，而是丢弃（如果服务端没有设置防火墙，由于服务端已经断开连接，此时收到客户的发来的数据报文后，会回 RST 报文）。客户端由于一直收不到数据报文的确认报文，所以触发超时重传，在超时重传过程中，每一次重传，RTO 的值是指数增长的，所以持续了好长一段时间，客户端的 telnet 才报错退出了，此时共重传了 15 次，然后客户端的也断开了连接。</li></ul><p>通过这一波分析，刚才的两个疑点已经解除了：</p><ul><li>服务端在重传 SYN、ACK 包时，超过了最大重传次数 <code>tcp_synack_retries</code>，于是服务端的 TCP 连接主动断开了。</li><li>客户端向服务端发送数据报文时，如果迟迟没有收到数据包的确认报文，也会触发超时重传，一共重传了 15 次数据报文， 最后 telnet 就断开了连接。</li></ul><blockquote><p>TCP 第一次握手的 SYN 包超时重传最大次数是由 tcp_syn_retries 指定，TCP 第二次握手的 SYN、ACK 包超时重传最大次数是由 tcp_synack_retries 指定，那 TCP 建立连接后的数据包最大超时重传次数是由什么参数指定呢？</p></blockquote><p>TCP 建立连接后的数据包传输，最大超时重传次数是由 <code>tcp_retries2</code> 指定，默认值是 15 次，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">$ cat /proc/sys/net/ipv4/tcp_retries2<br>15<br></code></pre></td></tr></table></figure><p>如果 15 次重传都做完了，TCP 就会告诉应用层说：“搞不定了，包怎么都传不过去！”</p><blockquote><p>那如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？</p></blockquote><p>这里就需要提到 TCP 的 <strong>保活机制</strong>。这个机制的原理是这样的：</p><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个「探测报文」，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">net.ipv4.tcp_keepalive_time=7200<br>net.ipv4.tcp_keepalive_intvl=75  <br>net.ipv4.tcp_keepalive_probes=9<br></code></pre></td></tr></table></figure><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/43.jpg" alt="img"></p><p>这个时间是有点长的，所以如果我抓包足够久，或许能抓到探测报文。</p><blockquote><p>实验三的实验小结</p></blockquote><p>在建立 TCP 连接时，如果第三次握手的 ACK，服务端无法收到，则服务端就会短暂处于 <code>SYN_RECV</code> 状态，而客户端会处于 <code>ESTABLISHED</code> 状态。</p><p>由于服务端一直收不到 TCP 第三次握手的 ACK，则会一直重传 SYN、ACK 包，直到重传次数超过 <code>tcp_synack_retries</code> 值（默认值 5 次）后，服务端就会断开 TCP 连接。</p><p>而客户端则会有两种情况：</p><ul><li>如果客户端没发送数据包，一直处于 <code>ESTABLISHED</code> 状态，然后经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接，于是客户端连接就会断开连接。</li><li>如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 <code>tcp_retries2</code> 值（默认值 15 次）后，客户端就会断开 TCP 连接。</li></ul><hr><h2 id="TCP-快速建立连接">TCP 快速建立连接</h2><p>客户端在向服务端发起 HTTP GET 请求时，一个完整的交互过程，需要 2.5 个 RTT 的时延。</p><p>由于第三次握手是可以携带数据的，这时如果在第三次握手发起 HTTP GET 请求，需要 2 个 RTT 的时延。</p><p>但是在下一次（不是同个 TCP 连接的下一次）发起 HTTP GET 请求时，经历的 RTT 也是一样，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/44.jpg" alt="常规 HTTP 请求"></p><p>在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/45.jpg" alt="常规 HTTP 请求 与 Fast  Open HTTP 请求"></p><ul><li>在第一次建立连接的时候，服务端在第二次握手产生一个 <code>Cookie</code> （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 <code>Cookie</code>，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；</li><li>在下次请求的时候，客户端在 SYN 包带上 <code>Cookie</code> 发给服务端，就提前可以跳过三次握手的过程，因为 <code>Cookie</code> 中维护了一些信息，服务端可以从 <code>Cookie</code> 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；</li></ul><p>注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）</p><blockquote><p>在 Linux 上如何打开 Fast Open 功能？</p></blockquote><p>可以通过设置 <code>net.ipv4.tcp_fastopen</code> 内核参数，来打开 Fast Open 功能。</p><p>net.ipv4.tcp_fastopen 各个值的意义:</p><ul><li>0 关闭</li><li>1 作为客户端使用 Fast Open 功能</li><li>2 作为服务端使用 Fast Open 功能</li><li>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</li></ul><blockquote><p>TCP Fast Open 抓包分析</p></blockquote><p>在下图，数据包 7 号，客户端发起了第二次 TCP 连接时，SYN 包会携带 Cooike，并且长度为 5 的数据。</p><p>服务端收到后，校验 Cooike 合法，于是就回了 SYN、ACK 包，并且确认应答收到了客户端的数据包，ACK = 5 + 1 = 6</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/46.jpg" alt="TCP Fast Open 抓包分析"></p><hr><h2 id="TCP-重复确认和快速重传">TCP 重复确认和快速重传</h2><p>当接收方收到乱序数据包时，会发送重复的 ACK，以便告知发送方要重发该数据包，<strong>当发送方收到 3 个重复 ACK 时，就会触发快速重传，立刻重发丢失数据包。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/47.jpg" alt="快速重传机制"></p><p>TCP 重复确认和快速重传的一个案例，用 Wireshark 分析，显示如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/48.jpg" alt="img"></p><ul><li>数据包 1 期望的下一个数据包 Seq 是 1，但是数据包 2 发送的 Seq 却是 10945，说明收到的是乱序数据包，于是回了数据包 3 ，还是同样的 Seq = 1，Ack = 1，这表明是重复的 ACK；</li><li>数据包 4 和 6 依然是乱序的数据包，于是依然回了重复的 ACK；</li><li>当对方收到三次重复的 ACK 后，于是就快速重传了 Seq = 1 、Len = 1368 的数据包 8；</li><li>当收到重传的数据包后，发现 Seq = 1 是期望的数据包，于是就发送了个确认收到快速重传的 ACK</li></ul><p>注意：快速重传和重复 ACK 标记信息是 Wireshark 的功能，非数据包本身的信息。</p><p>以上案例在 TCP 三次握手时协商开启了<strong>选择性确认 SACK</strong>，因此一旦数据包丢失并收到重复 ACK ，即使在丢失数据包之后还成功接收了其他数据包，也只需要重传丢失的数据包。如果不启用 SACK，就必须重传丢失包之后的每个数据包。</p><p>如果要支持 <code>SACK</code>，必须双方都要支持。在 Linux 下，可以通过 <code>net.ipv4.tcp_sack</code> 参数打开这个功能（Linux 2.4 后默认打开）。</p><hr><h2 id="TCP-流量控制">TCP 流量控制</h2><p>TCP 为了防止发送方无脑的发送数据，导致接收方缓冲区被填满，所以就有了滑动窗口的机制，它可利用接收方的接收窗口来控制发送方要发送的数据量，也就是流量控制。</p><p>接收窗口是由接收方指定的值，存储在 TCP 头部中，它可以告诉发送方自己的 TCP 缓冲空间区大小，这个缓冲区是给应用程序读取数据的空间：</p><ul><li>如果应用程序读取了缓冲区的数据，那么缓冲空间区就会把被读取的数据移除</li><li>如果应用程序没有读取数据，则数据会一直滞留在缓冲区。</li></ul><p>接收窗口的大小，是在 TCP 三次握手中协商好的，后续数据传输时，接收方发送确认应答 ACK 报文时，会携带当前的接收窗口的大小，以此来告知发送方。</p><p>假设接收方接收到数据后，应用层能很快的从缓冲区里读取数据，那么窗口大小会一直保持不变，过程如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/49.jpg" alt="理想状态下的窗口变化"></p><p>但是现实中服务器会出现繁忙的情况，当应用程序读取速度慢，那么缓存空间会慢慢被占满，于是为了保证发送方发送的数据不会超过缓冲区大小，服务器则会调整窗口大小的值，接着通过 ACK 报文通知给对方，告知现在的接收窗口大小，从而控制发送方发送的数据大小。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/50.jpg" alt="服务端繁忙状态下的窗口变化"></p><h3 id="零窗口通知与窗口探测">零窗口通知与窗口探测</h3><p>假设接收方处理数据的速度跟不上接收数据的速度，缓存就会被占满，从而导致接收窗口为 0，当发送方接收到零窗口通知时，就会停止发送数据。</p><p>如下图，可以看到接收方的窗口大小在不断的收缩至 0：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/51.jpg" alt="窗口大小在收缩"></p><p>接着，发送方会<strong>定时发送窗口大小探测报文</strong>，以便及时知道接收方窗口大小的变化。</p><p>以下图 Wireshark 分析图作为例子说明：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/52.jpg" alt="零窗口 与 窗口探测"></p><ul><li>发送方发送了数据包 1 给接收方，接收方收到后，由于缓冲区被占满，回了个零窗口通知；</li><li>发送方收到零窗口通知后，就不再发送数据了，直到过了 <code>3.4</code> 秒后，发送了一个 TCP Keep-Alive 报文，也就是窗口大小探测报文；</li><li>当接收方收到窗口探测报文后，就立马回一个窗口通知，但是窗口大小还是 0；</li><li>发送方发现窗口还是 0，于是继续等待了 <code>6.8</code>（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回了窗口为 0 的通知；</li><li>发送方发现窗口还是 0，于是继续等待了 <code>13.5</code>（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回了窗口为 0 的通知；</li></ul><p>可以发现，这些窗口探测报文以 3.4s、6.5s、13.5s 的间隔出现，说明超时时间会<strong>翻倍</strong>递增。</p><p>这连接暂停了 25s，想象一下你在打王者的时候，25s 的延迟你还能上王者吗？</p><h3 id="发送窗口的分析">发送窗口的分析</h3><blockquote><p>在 Wireshark 看到的 Windows size 也就是 &quot; win = &quot;，这个值表示发送窗口吗？</p></blockquote><p>这不是发送窗口，而是在向对方声明自己的接收窗口。</p><p>你可能会好奇，抓包文件里有「Window size scaling factor」，它其实是算出实际窗口大小的乘法因子，「Window size value」实际上并不是真实的窗口大小，真实窗口大小的计算公式如下：</p><p>「Window size value」 * 「Window size scaling factor」 = 「Caculated window size 」</p><p>对应的下图案例，也就是 32 * 2048 = 65536。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/53.jpg" alt="img"></p><p>实际上是 Caculated window size 的值是 Wireshark 工具帮我们算好的，Window size scaling factor 和 Windos size value 的值是在 TCP 头部中，其中 Window size scaling factor 是在三次握手过程中确定的，如果你抓包的数据没有 TCP 三次握手，那可能就无法算出真实的窗口大小的值，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/54.jpg" alt="img"></p><blockquote><p>如何在包里看出发送窗口的大小？</p></blockquote><p>很遗憾，没有简单的办法，发送窗口虽然是由接收窗口决定，但是它又可以被网络因素影响，也就是拥塞窗口，实际上发送窗口是值是 min(拥塞窗口，接收窗口)。</p><blockquote><p>发送窗口和 MSS 有什么关系？</p></blockquote><p>发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少包才能发完。</p><p>举个例子，如果发送窗口为 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000 = 16 个包。</p><blockquote><p>发送方在一个窗口发出 n 个包，是不是需要 n 个 ACK 确认报文？</p></blockquote><p>不一定，因为 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后一个数据包的 ACK 报文就可以了。</p><hr><h2 id="TCP-延迟确认与-Nagle-算法">TCP 延迟确认与 Nagle 算法</h2><p>当我们 TCP 报文的承载的数据非常小的时候，例如几个字节，那么整个网络的效率是很低的，因为每个 TCP 报文中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，而数据只有几个字节，所以在整个报文中有效数据占有的比重就会非常低。</p><p>这就好像快递员开着大货车送一个小包裹一样浪费。</p><p>那么就出现了常见的两种策略，来减少小报文的传输，分别是：</p><ul><li>Nagle 算法</li><li>延迟确认</li></ul><blockquote><p>Nagle 算法是如何避免大量 TCP 小数据报文的传输？</p></blockquote><p>Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率。</p><p>Nagle 伪代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span> 有数据要发送 &#123;<br>    <span class="hljs-keyword">if</span> 可用窗口大小 &gt;= MSS <span class="hljs-keyword">and</span> 可发送的数据 &gt;= MSS &#123;<br>    立刻发送MSS大小的数据<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">if</span> 有未确认的数据 &#123;<br>            将数据放入缓存等待接收ACK<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            立刻发送数据<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才能可以发送数据：</p><ul><li>条件一：要等到窗口大小 &gt;= <code>MSS</code> 并且 数据大小 &gt;= <code>MSS</code>；</li><li>条件二：收到之前发送数据的 <code>ack</code> 回包；</li></ul><p>只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/55.jpg" alt="禁用 Nagle 算法 与 启用 Nagle 算法"></p><p>上图右侧启用了 Nagle 算法，它的发送数据的过程：</p><ul><li>一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；</li><li>接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方；</li><li>待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去</li></ul><p>可以看出，<strong>Nagle 算法一定会有一个小报文，也就是在最开始的时候。</strong></p><p>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。</p><p>可以在 Socket 设置 <code>TCP_NODELAY</code> 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/56.jpg" alt="关闭 Nagle 算法"></p><blockquote><p>那延迟确认又是什么？</p></blockquote><p>事实上当没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。</p><p>为了解决 ACK 传输效率低问题，所以就衍生出了 <strong>TCP 延迟确认</strong>。</p><p>TCP 延迟确认的策略：</p><ul><li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li><li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li><li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/57.jpg" alt="TCP 延迟确认"></p><p>延迟等待的时间是在 Linux 内核中定义的，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/58.jpg" alt="img"></p><p>关键就需要 <code>HZ</code> 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ 大小是 <code>1000</code>，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/59.jpg" alt="img"></p><p>知道了 HZ 的大小，那么就可以算出：</p><ul><li>最大延迟确认时间是 <code>200</code> ms （1000/5）</li><li>最短延迟确认时间是 <code>40</code> ms （1000/25）</li></ul><p>TCP 延迟确认可以在 Socket 设置 <code>TCP_QUICKACK</code> 选项来关闭这个算法。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/60.jpg" alt="关闭 TCP 延迟确认"></p><blockquote><p>延迟确认 和 Nagle 算法混合使用时，会产生新的问题</p></blockquote><p>当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/61.jpg" alt="TCP 延迟确认 和 Nagle 算法混合使用"></p><p>发送方使用了 Nagle 算法，接收方使用了 TCP 延迟确认会发生如下的过程：</p><ul><li>发送方先发出一个小报文，接收方收到后，由于延迟确认机制，自己又没有要发送的数据，只能干等着发送方的下一个报文到达；</li><li>而发送方由于 Nagle 算法机制，在未收到第一个报文的确认前，是不会发送后续的数据；</li><li>所以接收方只能等待最大时间 200 ms 后，才回 ACK 报文，发送方收到第一个报文的确认报文后，也才可以发送后续的数据。</li></ul><p>很明显，这两个同时使用会造成额外的时延，这就会使得网络&quot;很慢&quot;的感觉。</p><p>要解决这个问题，只有两个办法：</p><ul><li>要不发送方关闭 Nagle 算法</li><li>要不接收方关闭 TCP 延迟确认</li></ul><hr><p>参考资料：</p><p>[1] Wireshark网络分析的艺术.林沛满.人民邮电出版社.</p><p>[2] Wireshark网络分析就这么简单.林沛满.人民邮电出版社.</p><p>[3] Wireshark数据包分析实战.Chris Sanders .人民邮电出版社.读者问答</p><hr><h2 id="读者问答">读者问答</h2><blockquote><p>读者问：“两个问题，请教一下作者: tcp_retries1 参数，是什么场景下生效？ tcp_retries2是不是只受限于规定的次数，还是受限于次数和时间限制的最小值？”</p></blockquote><p>tcp_retries1和tcp_retries2都是在TCP三次握手之后的场景。</p><ul><li>当重传次数超过tcp_retries1就会指示 IP 层进行 MTU 探测、刷新路由等过程，并不会断开TCP连接，当重传次数超过 tcp_retries2 才会断开TCP流。</li><li>tcp_retries1 和 tcp_retries2 两个重传次数都是受一个 timeout 值限制的，timeout 的值是根据它俩的值计算出来的，当重传时间超过 timeout，就不会继续重传了，即使次数还没到达。</li></ul><blockquote><p>读者问：“tcp_orphan_retries也是控制tcp连接的关闭。这个跟tcp_retries1 tcp_retries2有什么区别吗？”</p></blockquote><p>主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态下，该状态通常应在数十毫秒内转为 FIN_WAIT2。如果迟迟收不到对方返回的 ACK 时，此时，内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制。</p><blockquote><p>读者问：“请问，为什么连续两个报文的seq会是一样的呢，比如三次握手之后的那个报文？还是说，序号相同的是同一个报文，只是拆开显示了？”</p></blockquote><ol><li>三次握手中的前两次，是 seq+1；</li><li>三次握手中的最后一个 ack，实际上是可以携带数据的，由于我文章的例子是没有发送数据的，你可以看到第三次握手的 len=0 ，在数据传输阶段「下一个 seq=seq+len 」，所以第三次握手的 seq 和下一个数据报的 seq 是一样的，因为 len 为 0；</li></ol><hr><h2 id="最后">最后</h2>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 重传、滑动窗口、流量控制、拥塞控制</title>
    <link href="/2021/05/11/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/02.TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
    <url>/2021/05/11/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/02.TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1>TCP 重传、滑动窗口、流量控制、拥塞控制</h1><p>TCP <strong>巨复杂</strong>，它为了保证可靠性，用了巨多的机制来保证，真是个「伟大」的协议，写着写着发现这水太深了。。。</p><p>本文的全部图片都是小林绘画的，非常的辛苦且累，不废话了，直接进入正文，Go！</p><p>相信大家都知道 TCP 是一个可靠传输的协议，那它是如何保证可靠的呢？</p><p>为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。</p><p>那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。</p><p>今天，将重点介绍 TCP 的<strong>重传机制、滑动窗口、流量控制、拥塞控制。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/3.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img"></p><hr><h2 id="重传机制">重传机制</h2><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。</p><p>在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/4.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="正常的数据传输"></p><p>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？</p><p>所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决。</p><p>接下来说说常见的重传机制：</p><ul><li>超时重传</li><li>快速重传</li><li>SACK</li><li>D-SACK</li></ul><h3 id="超时重传">超时重传</h3><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong>。</p><p>TCP 会在以下两种情况发生超时重传：</p><ul><li>数据包丢失</li><li>确认应答丢失</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/5.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="超时重传的两种情况"></p><blockquote><p>超时时间应该设置为多少呢？</p></blockquote><p>我们先来了解一下什么是 <code>RTT</code>（Round-Trip Time 往返时延），从下图我们就可以知道：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/6.jpg?" alt="RTT"></p><p><code>RTT</code> 指的是<strong>数据发送时刻到接收到确认的时刻的差值</strong>，也就是包的往返时间。</p><p>超时重传时间是以 <code>RTO</code> （Retransmission Timeout 超时重传时间）表示。</p><p>假设在重传的情况下，超时时间 <code>RTO</code> 「较长或较短」时，会发生什么事情呢？</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/7.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="超时时间较长与较短"></p><p>上图中有两种超时时间不同的情况：</p><ul><li>当超时时间 <strong>RTO 较大</strong>时，重发就慢，丢了老半天才重发，没有效率，性能差；</li><li>当超时时间 <strong>RTO 较小</strong>时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li></ul><p>精确的测量超时时间 <code>RTO</code> 的值是非常重要的，这可让我们的重传机制更高效。</p><p>根据上述的两种情况，我们可以得知，<strong>超时重传时间 RTO 的值应该略大于报文往返 RTT 的值</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/8.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="RTO 应略大于 RTT"></p><p>至此，可能大家觉得超时重传时间 <code>RTO</code> 的值计算，也不是很复杂嘛。</p><p>好像就是在发送端发包时记下 <code>t0</code> ，然后接收端再把这个 <code>ack</code> 回来时再记一个 <code>t1</code>，于是 <code>RTT = t1 – t0</code>。没那么简单，<strong>这只是一个采样，不能代表普遍情况</strong>。</p><p>实际上「报文往返 RTT 的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」 是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个<strong>动态变化的值</strong>。</p><p>我们来看看 Linux 是如何计算 <code>RTO</code> 的呢？</p><p>估计往返时间，通常需要采样以下两个：</p><ul><li>需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。</li><li>除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。</li></ul><p>RFC6289 建议使用以下的公式计算 RTO：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/9.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="RFC6289 建议的 RTO 计算 "></p><p>其中 <code>SRTT</code> 是计算平滑的RTT ，<code>DevRTR</code> 是计算平滑的RTT 与 最新 RTT 的差距。</p><p>在 Linux 下，<strong>α = 0.125，β = 0.25， μ = 1，∂ = 4</strong>。别问怎么来的，问就是大量实验中调出来的。</p><p>如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是<strong>超时间隔加倍。</strong></p><p>也就是<strong>每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</strong></p><p>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？</p><p>于是就可以用「快速重传」机制来解决超时重发的时间等待。</p><h3 id="快速重传">快速重传</h3><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><p>快速重传机制，是如何工作的呢？其实很简单，一图胜千言。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/10.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传机制"></p><p>在上图，发送方发出了 1，2，3，4，5 份数据：</p><ul><li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li><li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li><li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li><li><strong>发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</strong></li><li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li></ul><p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<strong>重传的时候，是重传一个，还是重传所有的问题。</strong></p><p>举个例子，假设发送方发了 6 个数据，编号的顺序是 Seq1 ~ Seq6 ，但是 Seq2、Seq3 都丢失了，那么接收方在收到 Seq4、Seq5、Seq6 时，都是回复 ACK2 给发送方，但是发送方并不清楚这连续的 ACK2 是接收方收到哪个报文而回复的， 那是选择重传 Seq2 一个报文，还是重传 Seq2 之后已发送的所有报文呢（Seq2、Seq3、 Seq4、Seq5、 Seq6） 呢？</p><ul><li>如果只选择重传 Seq2 一个报文，那么重传的效率很低。因为对于丢失的 Seq3 报文，还得在后续收到三个重复的 ACK3 才能触发重传。</li><li>如果选择重传 Seq2 之后已发送的所有报文，虽然能同时重传已丢失的 Seq2 和 Seq3 报文，但是 Seq4、Seq5、Seq6 的报文是已经被接收过了，对于重传 Seq4 ～Seq6 折部分数据相当于做了一次无用功，浪费资源。</li></ul><p>可以看到，不管是重传一个报文，还是重传已发送的报文，都存在问题。</p><p>为了解决不知道该重传哪些 TCP 报文，于是就有 <code>SACK</code> 方法。</p><h3 id="SACK-方法">SACK 方法</h3><p>还有一种实现重传机制的方式叫：<code>SACK</code>（ Selective Acknowledgment）， <strong>选择性确认</strong>。</p><p>这种方式需要在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，它<strong>可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p><p>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 <code>SACK</code> 信息发现只有 <code>200~299</code> 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/11.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="选择性确认"></p><p>如果要支持 <code>SACK</code>，必须双方都要支持。在 Linux 下，可以通过 <code>net.ipv4.tcp_sack</code> 参数打开这个功能（Linux 2.4 后默认打开）。</p><h3 id="Duplicate-SACK">Duplicate SACK</h3><p>Duplicate SACK 又称 <code>D-SACK</code>，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p><p>下面举例两个栗子，来说明 <code>D-SACK</code> 的作用。</p><p><em>栗子一号：ACK 丢包</em></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="ACK 丢包"></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><em>栗子二号：网络延时</em></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/13.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="网络延时"></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li><li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul><p>可见，<code>D-SACK</code> 有这么几个好处：</p><ol><li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li><li>可以知道是不是「发送方」的数据包被网络延迟了;</li><li>可以知道网络中是不是把「发送方」的数据包给复制了;</li></ol><p>在 Linux 下可以通过 <code>net.ipv4.tcp_dsack</code> 参数开启/关闭这个功能（Linux 2.4 后默认打开）。</p><hr><h2 id="滑动窗口">滑动窗口</h2><blockquote><p>引入窗口概念的原因</p></blockquote><p>我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。</p><p>这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。</p><p>如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/14.jpg?" alt="按数据包进行确认应答"></p><p>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。</p><p>为解决这个问题，TCP 引入了<strong>窗口</strong>这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。</p><p>那么有了窗口，就可以指定窗口大小，窗口大小就是指<strong>无需等待确认应答，而可以继续发送数据的最大值</strong>。</p><p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p><p>假设窗口大小为 <code>3</code> 个 TCP 段，那么发送方就可以「连续发送」 <code>3</code> 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/15.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="用滑动窗口方式并行处理"></p><p>图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫<strong>累计确认</strong>或者<strong>累计应答</strong>。</p><blockquote><p>窗口大小由哪一方决定？</p></blockquote><p>TCP 头里有一个字段叫 <code>Window</code>，也就是窗口大小。</p><p><strong>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</strong></p><p>所以，通常窗口的大小是由接收方的窗口大小来决定的。</p><p>发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</p><blockquote><p>发送方的滑动窗口</p></blockquote><p>我们先来看看发送方的窗口，下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/16.jpg?" alt="img"></p><ul><li>#1 是已发送并收到 ACK确认的数据：1~31 字节</li><li>#2 是已发送但未收到 ACK确认的数据：32~45 字节</li><li>#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节</li><li>#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后</li></ul><p>在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/17.jpg?" alt="可用窗口耗尽"></p><p>在下图，当收到之前发送的数据 <code>32~36</code> 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则<strong>滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认</strong>，接下来 <code>52~56</code> 字节又变成了可用窗口，那么后续也就可以发送 <code>52~56</code> 这 5 个字节的数据了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/18.jpg" alt="32 ~ 36 字节已确认"></p><blockquote><p>程序是如何表示发送方的四个部分的呢？</p></blockquote><p>TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="SND.WND、SND.UN、SND.NXT"></p><ul><li><code>SND.WND</code>：表示发送窗口的大小（大小是由接收方指定的）；</li><li><code>SND.UNA</code>（<em>Send Unacknoleged</em>）：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。</li><li><code>SND.NXT</code>：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。</li><li>指向 #4 的第一个字节是个相对指针，它需要 <code>SND.UNA</code> 指针加上 <code>SND.WND</code> 大小的偏移量，就可以指向 #4 的第一个字节了。</li></ul><p>那么可用窗口大小的计算就可以是：</p><p><strong>可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）</strong></p><blockquote><p>接收方的滑动窗口</p></blockquote><p>接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：</p><ul><li>#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；</li><li>#3 是未收到数据但可以接收的数据；</li><li>#4 未收到数据并不可以接收的数据；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg" alt="接收窗口"></p><p>其中三个接收部分，使用两个指针进行划分:</p><ul><li><code>RCV.WND</code>：表示接收窗口的大小，它会通告给发送方。</li><li><code>RCV.NXT</code>：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。</li><li>指向 #4 的第一个字节是个相对指针，它需要 <code>RCV.NXT</code> 指针加上 <code>RCV.WND</code> 大小的偏移量，就可以指向 #4 的第一个字节了。</li></ul><blockquote><p>接收窗口和发送窗口的大小是相等的吗？</p></blockquote><p>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。</p><p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p><hr><h2 id="流量控制">流量控制</h2><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p><p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p><p>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong></p><p>下面举个栗子，为了简单起见，假设以下场景：</p><ul><li>客户端是接收方，服务端是发送方</li><li>假设接收窗口和发送窗口相同，都为 <code>200</code></li><li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/21.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="流量控制"></p><p>根据上图的流量控制，说明下每个过程：</p><ol><li>客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。</li><li>服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 <code>Usable</code> 减少为 120 字节，同时 <code>SND.NXT</code> 指针也向右偏移 80 字节后，指向 321，<strong>这意味着下次发送数据的时候，序列号是 321。</strong></li><li>客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，<code>RCV.NXT</code> 也就指向 321，<strong>这意味着客户端期望的下一个报文的序列号是 321</strong>，接着发送确认报文给服务端。</li><li>服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。</li><li>客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，<code>RCV.NXT</code> 也就指向 441，接着发送确认报文给服务端。</li><li>服务端收到对 80 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 321，于是可用窗口 <code>Usable</code> 增大到 80。</li><li>服务端收到对 120 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 441，于是可用窗口 <code>Usable</code> 增大到 200。</li><li>服务端可以继续发送了，于是发送了 160 字节的数据后，<code>SND.NXT</code> 指向 601，于是可用窗口 <code>Usable</code> 减少到 40。</li><li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，<code>RCV.NXT</code> 也就是指向了 601，接着发送确认报文给服务端。</li><li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 <code>SND.UNA</code> 指针偏移了 160 后指向 601，可用窗口 <code>Usable</code> 也就增大至了 200。</li></ol><h3 id="操作系统缓冲区与滑动窗口的关系">操作系统缓冲区与滑动窗口的关系</h3><p>前面的流量控制例子，我们假定了发送窗口和接收窗口是不变的，但是实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会<strong>被操作系统调整</strong>。</p><p>当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。</p><blockquote><p>那操作系统的缓冲区，是如何影响发送窗口和接收窗口的呢？</p></blockquote><p><em>我们先来看看第一个例子。</em></p><p>当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化。</p><p>考虑以下场景：</p><ul><li>客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为 <code>360</code>；</li><li>服务端非常的繁忙，当收到客户端的数据时，应用层不能及时读取数据。</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/22.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img"></p><p>根据上图的流量控制，说明下每个过程：</p><ol><li>客户端发送 140 字节数据后，可用窗口变为 220 （360 - 140）。</li><li>服务端收到 140 字节数据，<strong>但是服务端非常繁忙，应用进程只读取了 40 个字节，还有 100 字节占用着缓冲区，于是接收窗口收缩到了 260 （360 - 100）</strong>，最后发送确认信息时，将窗口大小通告给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 260。</li><li>客户端发送 180 字节数据，此时可用窗口减少到 80。</li><li>服务端收到 180 字节数据，<strong>但是应用程序没有读取任何数据，这 180 字节直接就留在了缓冲区，于是接收窗口收缩到了 80 （260 - 180）</strong>，并在发送确认信息时，通过窗口大小给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 80。</li><li>客户端发送 80 字节数据后，可用窗口耗尽。</li><li>服务端收到 80 字节数据，<strong>但是应用程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗口收缩到了 0</strong>，并在发送确认信息时，通过窗口大小给客户端。</li><li>客户端收到确认和窗口通告报文后，发送窗口减少为 0。</li></ol><p>可见最后窗口都收缩为 0 了，也就是发生了窗口关闭。当发送方可用窗口变为 0 时，发送方实际上会定时发送窗口探测报文，以便知道接收方的窗口是否发生了改变，这个内容后面会说，这里先简单提一下。</p><p><em>我们先来看看第二个例子。</em></p><p>当服务端系统资源非常紧张的时候，操作系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/23.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="img"></p><p>说明下每个过程：</p><ol><li>客户端发送 140 字节的数据，于是可用窗口减少到了 220。</li><li><strong>服务端因为现在非常的繁忙，操作系统于是就把接收缓存减少了 120 字节，当收到 140 字节数据后，又因为应用程序没有读取任何数据，所以 140 字节留在了缓冲区中，于是接收窗口大小从 360 收缩成了 100</strong>，最后发送确认信息时，通告窗口大小给对方。</li><li>此时客户端因为还没有收到服务端的通告窗口报文，所以不知道此时接收窗口收缩成了 100，客户端只会看自己的可用窗口还有 220，所以客户端就发送了 180 字节数据，于是可用窗口减少到 40。</li><li>服务端收到了 180 字节数据时，<strong>发现数据大小超过了接收窗口的大小，于是就把数据包丢失了。</strong></li><li>客户端收到第 2 步时，服务端发送的确认报文和通告窗口报文，尝试减少发送窗口到 100，把窗口的右端向左收缩了 80，此时可用窗口的大小就会出现诡异的负值。</li></ol><p>所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。</p><p><strong>为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。</strong></p><h3 id="窗口关闭">窗口关闭</h3><p>在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。</p><p><strong>如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。</strong></p><blockquote><p>窗口关闭潜在的危险</p></blockquote><p>接收方向发送方通告窗口大小时，是通过 <code>ACK</code> 报文来通告的。</p><p>那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/24.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口关闭潜在的危险"></p><p>这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</p><blockquote><p>TCP 是如何解决窗口关闭时，潜在的死锁现象呢？</p></blockquote><p>为了解决这个问题，TCP 为每个连接设有一个持续定时器，<strong>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</strong></p><p>如果持续计时器超时，就会发送<strong>窗口探测 ( Window probe ) 报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/25.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口探测"></p><ul><li>如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；</li><li>如果接收窗口不是 0，那么死锁的局面就可以被打破了。</li></ul><p>窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 <code>RST</code> 报文来中断连接。</p><h3 id="糊涂窗口综合症">糊涂窗口综合症</h3><p>如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。</p><p>到最后，<strong>如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症</strong>。</p><p>要知道，我们的 <code>TCP + IP</code> 头有 <code>40</code> 个字节，为了传输那几个字节的数据，要搭上这么大的开销，这太不经济了。</p><p>就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家里有矿的大巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。</p><p>现举个糊涂窗口综合症的栗子，考虑以下场景：</p><p>接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下：</p><ul><li>接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据；</li><li>在下一个发送方的 TCP 段到达之前，应用程序还从缓冲区中读取了 40 个额外的字节；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/26.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="糊涂窗口综合症"></p><p>每个过程的窗口大小的变化，在图中都描述的很清楚了，可以发现窗口不断减少了，并且发送的数据都是比较小的了。</p><p>所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：</p><ul><li>接收方可以通告一个小的窗口</li><li>而发送方可以发送小数据</li></ul><p>于是，要解决糊涂窗口综合症，就要同时解决上面两个问题就可以了：</p><ul><li>让接收方不通告小窗口给发送方</li><li>让发送方避免发送小数据</li></ul><blockquote><p>怎么让接收方不通告小窗口呢？</p></blockquote><p>接收方通常的策略如下:</p><p>当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 <code>0</code>，也就阻止了发送方再发数据过来。</p><p>等到接收方处理了一些数据后，窗口大小 &gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。</p><blockquote><p>怎么让发送方避免发送小数据呢？</p></blockquote><p>发送方通常的策略如下:</p><p>使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：</p><ul><li>条件一：要等到窗口大小 &gt;= <code>MSS</code> 并且 数据大小 &gt;= <code>MSS</code>；</li><li>条件二：收到之前发送数据的 <code>ack</code> 回包；</li></ul><p>只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。</p><p>Nagle 伪代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span> 有数据要发送 &#123;<br>    <span class="hljs-keyword">if</span> 可用窗口大小 &gt;= MSS <span class="hljs-keyword">and</span> 可发送的数据 &gt;= MSS &#123;<br>    立刻发送MSS大小的数据<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">if</span> 有未确认的数据 &#123;<br>            将数据放入缓存等待接收ACK<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            立刻发送数据<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>注意，如果接收方不能满足「不通告小窗口给发送方」，那么即使开了 Nagle 算法，也无法避免糊涂窗口综合症，因为如果对端 ACK 回复很快的话（达到 Nagle 算法的条件二），Nagle 算法就不会拼接太多的数据包，这种情况下依然会有小数据包的传输，网络总体的利用率依然很低。</p><p>所以，<strong>接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症</strong>。</p><p>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。</p><p>可以在 Socket 设置 <code>TCP_NODELAY</code> 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (<span class="hljs-keyword">char</span> *)&amp;value, <span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">int</span>));<br></code></pre></td></tr></table></figure><hr><h2 id="拥塞控制">拥塞控制</h2><blockquote><p>为什么要有拥塞控制呀，不是有流量控制了吗？</p></blockquote><p>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。</p><p>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。</p><p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大…</strong></p><p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p><blockquote><p>什么是拥塞窗口？和发送窗口有什么关系呢？</p></blockquote><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p><p>拥塞窗口 <code>cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li><li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li></ul><blockquote><p>那么怎么知道当前网络是否出现了拥塞呢？</p></blockquote><p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p><blockquote><p>拥塞控制有哪些控制算法？</p></blockquote><p>拥塞控制主要是四个算法：</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复</li></ul><h3 id="慢启动">慢启动</h3><p>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？</p><p>慢启动的算法记住一个规则就行：<strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><p>这里假定拥塞窗口 <code>cwnd</code> 和发送窗口 <code>swnd</code> 相等，下面举个栗子：</p><ul><li>连接建立完成后，一开始初始化 <code>cwnd = 1</code>，表示可以传一个 <code>MSS</code> 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p>慢启动算法的变化过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/27.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="慢启动算法"></p><p>可以看出慢启动算法，发包的个数是<strong>指数性的增长</strong>。</p><blockquote><p>那慢启动涨到什么时候是个头呢？</p></blockquote><p>有一个叫慢启动门限 <code>ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code>cwnd</code> &lt; <code>ssthresh</code> 时，使用慢启动算法。</li><li>当 <code>cwnd</code> &gt;= <code>ssthresh</code> 时，就会使用「拥塞避免算法」。</li></ul><h3 id="拥塞避免算法">拥塞避免算法</h3><p>前面说道，当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。</p><p>一般来说 <code>ssthresh</code> 的大小是 <code>65535</code> 字节。</p><p>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1/cwnd。</strong></p><p>接上前面的慢启动的栗子，现假定 <code>ssthresh</code> 为 <code>8</code>：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code>MSS</code> 大小的数据，变成了<strong>线性增长。</strong></li></ul><p>拥塞避免算法的变化过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/28.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞避免"></p><p>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p><p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p><p>当触发了重传机制，也就进入了「拥塞发生算法」。</p><h3 id="拥塞发生">拥塞发生</h3><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。</p><blockquote><p>发生超时重传的拥塞发生算法</p></blockquote><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code>ssthresh</code> 设为 <code>cwnd/2</code>，</li><li><code>cwnd</code> 重置为 <code>1</code> （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）</li></ul><blockquote><p>怎么查看系统的 cwnd 初始化值？</p></blockquote><p>Linux 针对每一个 TCP 连接的 cwnd 初始化值是 10，也就是 10 个 MSS，我们可以用 ss -nli 命令查看每一个 TCP 连接的 cwnd 初始化值，如下图</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/cwnd.png" alt="img"></p><p>拥塞发生算法的变化如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞发送 —— 超时重传"></p><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p><p>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。</p><blockquote><p>发生快速重传的拥塞发生算法</p></blockquote><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p><p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 <code>ssthresh</code> 和 <code>cwnd</code> 变化如下：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li><li>进入快速恢复算法</li></ul><h3 id="快速恢复">快速恢复</h3><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> 超时那么强烈。</p><p>正如前面所说，进入快速恢复之前，<code>cwnd</code> 和 <code>ssthresh</code> 已被更新了：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 <code>cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><p>快速恢复算法的变化过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复"></p><p>也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。</p><p>TIP</p><p>很多人问题，快速恢复算法过程中，为什么收到新的数据后，cwnd 设置回了 ssthresh ？</p><p>我在评论区看到@<a href="https://github.com/muum641651">muum641651 (opens new window)</a>回答的不错，这里贴出来给大家。</p><p>我的理解是：</p><ol><li>在快速恢复的过程中，首先 ssthresh = cwnd/2，然后 cwnd = ssthresh + 3，表示网络可能出现了阻塞，所以需要减小 cwnd 以避免，加 3 代表快速重传时已经确认接收到了 3 个重复的数据包；</li><li>随后继续重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1。加 1 代表每个收到的重复的 ACK 包，都已经离开了网络。这个过程的目的是尽快将丢失的数据包发给目标。</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，恢复过程结束。</li></ol><p><strong>首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变。</strong></p><p><strong>其次，过程2（cwnd逐渐加1）的存在是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题（三次相同的 ACK 导致的快速重传），所以这一过程中 cwnd 反而是逐渐增大的。</strong></p><hr><p>参考资料：</p><p>[1] 趣谈网络协议专栏.刘超.极客时间</p><p>[2] Web协议详解与抓包实战专栏.陶辉.极客时间</p><p>[3] TCP/IP详解 卷1：协议.范建华 译.机械工业出版社</p><p>[4] 图解TCP/IP.竹下隆史.人民邮电出版社</p><p>[5] The TCP/IP Guide.Charles M. Kozierok.</p><p>[6] TCP那些事（上）.陈皓.酷壳博客. <a href="https://coolshell.cn/articles/11564.html">https://coolshell.cn/articles/11564.html</a></p><p>[7] TCP那些事（下）.陈皓.酷壳博客.<a href="https://coolshell.cn/articles/11609.html">https://coolshell.cn/articles/11609.html</a></p><hr><h2 id="读者问答">读者问答</h2><blockquote><p>读者问：“整个看完收获很大，下面是我的一些疑问（稍后 会去确认）： 1.拥塞避免这一段，蓝色字体：每当收到一个 ACK时，cwnd增加1/cwnd。是否应该是 1/ssthresh?否则不符合线性增长。 2.快速重传的拥塞发生算法，步骤一和步骤2是 否写反了？否则快速恢复算法中最后一步【如果 收到新数据的ACK后，设置cwnd为 ssthresh,接看就进入了拥塞避免算法】没什么 意义。 3.对ssthresh的变化介绍的比较含糊。”</p></blockquote><ol><li>是 1/cwnd，你可以在 RFC2581 第 3 页找到答案</li><li>没有写反，同样你可以在 RFC2581 第 5 页找到答案</li><li>ssthresh 就是慢启动门限，我觉得 ssthresh 我已经说的很清楚了，当然你可以找其他资料补充你的疑惑</li></ol>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 三次握手与四次挥手面试题</title>
    <link href="/2021/05/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/01.TCP%20%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8E%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2021/05/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/02.TCP/01.TCP%20%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8E%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1>TCP 三次握手与四次挥手面试题</h1><p><img src="https://cdn.xiaolincoding.com//mysql/other/1310bf5ed78e4c8186481c47719e0793.png" alt="img"></p><blockquote><p>PS：本次文章不涉及 TCP 流量控制、拥塞控制、可靠性传输等方面知识，这些知识在这篇：<a href="https://mp.weixin.qq.com/s/Tc09ovdNacOtnMOMeRc_uA">你还在为 TCP 重传、滑动窗口、流量控制、拥塞控制发愁吗？看完图解就不愁了</a></p></blockquote><hr><h2 id="TCP-基本认识">TCP 基本认识</h2><h3 id="TCP-头格式有哪些？">TCP 头格式有哪些？</h3><p>我们先来看看 TCP 头的格式，标注颜色的表示与本文关联比较大的字段，其他字段不做详细阐述。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png" alt="TCP 头格式"></p><p><strong>序列号</strong>：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。<strong>用来解决网络包乱序问题。</strong></p><p><strong>确认应答号</strong>：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。<strong>用来解决丢包的问题。</strong></p><p><strong>控制位：</strong></p><ul><li><em>ACK</em>：该位为 <code>1</code> 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 <code>SYN</code> 包之外该位必须设置为 <code>1</code> 。</li><li><em>RST</em>：该位为 <code>1</code> 时，表示 TCP 连接中出现异常必须强制断开连接。</li><li><em>SYN</em>：该位为 <code>1</code> 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。</li><li><em>FIN</em>：该位为 <code>1</code> 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 <code>FIN</code> 位为 1 的 TCP 段。</li></ul><h3 id="为什么需要-TCP-协议？-TCP-工作在哪一层？">为什么需要 TCP 协议？ TCP 工作在哪一层？</h3><p><code>IP</code> 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230419839.png" alt="OSI 参考模型与 TCP/IP 的关系"></p><p>如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 <code>TCP</code> 协议来负责。</p><p>因为 TCP 是一个工作在<strong>传输层</strong>的<strong>可靠</strong>数据传输的服务，它能确保接收端接收的网络包是<strong>无损坏、无间隔、非冗余和按序的。</strong></p><h3 id="什么是-TCP-？">什么是 TCP ？</h3><p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230424714.png" alt="img"></p><ul><li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</li><li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；</li><li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</li></ul><h3 id="什么是-TCP-连接？">什么是 TCP 连接？</h3><p>我们来看看 RFC 793 是如何定义「连接」的：</p><p><em>Connections: The reliability and flow control mechanisms described above require that TCPs initialize and maintain certain status information for each data stream. The combination of this information, including sockets, sequence numbers, and window sizes, is called a connection.</em></p><p>简单来说就是，<strong>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230428466.png" alt="img"></p><p>所以我们可以知道，建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。</p><ul><li><strong>Socket</strong>：由 IP 地址和端口号组成</li><li><strong>序列号</strong>：用来解决乱序问题等</li><li><strong>窗口大小</strong>：用来做流量控制</li></ul><h3 id="如何唯一确定一个-TCP-连接呢？">如何唯一确定一个 TCP 连接呢？</h3><p>TCP 四元组可以唯一的确定一个连接，四元组包括如下：</p><ul><li>源地址</li><li>源端口</li><li>目的地址</li><li>目的端口</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230433082.png" alt="TCP 四元组"></p><p>源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。</p><p>源端口和目的端口的字段（16 位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。</p><blockquote><p>有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？</p></blockquote><p>服务端通常固定在某个本地端口上监听，等待客户端的连接请求。</p><p>因此，客户端 IP 和端口是可变的，其理论值计算公式如下:</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230436594.png" alt="img"></p><p>对 IPv4，客户端的 IP 数最多为 <code>2</code> 的 <code>32</code> 次方，客户端的端口数最多为 <code>2</code> 的 <code>16</code> 次方，也就是服务端单机最大 TCP 连接数，约为 <code>2</code> 的 <code>48</code> 次方。</p><p>当然，服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：</p><ul><li><p>文件描述符限制</p><p>，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：</p><ul><li><strong>系统级</strong>：当前系统可打开的最大数量，通过 <code>cat /proc/sys/fs/file-max</code> 查看；</li><li><strong>用户级</strong>：指定用户可打开的最大数量，通过 <code>cat /etc/security/limits.conf</code> 查看；</li><li><strong>进程级</strong>：单个进程可打开的最大数量，通过 <code>cat /proc/sys/fs/nr_open</code> 查看；</li></ul></li><li><p><strong>内存限制</strong>，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</p></li></ul><h3 id="UDP-和-TCP-有什么区别呢？分别的应用场景是？">UDP 和 TCP 有什么区别呢？分别的应用场景是？</h3><p>UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。</p><p>UDP 协议真的非常简，头部只有 <code>8</code> 个字节（64 位），UDP 的头部格式如下：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230439961.png" alt="UDP 头部格式"></p><ul><li>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。</li><li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。</li><li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP 包。</li></ul><p><strong>TCP 和 UDP 区别：</strong></p><p><em>1. 连接</em></p><ul><li>TCP 是面向连接的传输层协议，传输数据前先要建立连接。</li><li>UDP 是不需要连接，即刻传输数据。</li></ul><p><em>2. 服务对象</em></p><ul><li>TCP 是一对一的两点服务，即一条连接只有两个端点。</li><li>UDP 支持一对一、一对多、多对多的交互通信</li></ul><p><em>3. 可靠性</em></p><ul><li>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。</li><li>UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/quic.html">如何基于 UDP 协议实现可靠传输？</a></li></ul><p><em>4. 拥塞控制、流量控制</em></p><ul><li>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。</li><li>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</li></ul><p><em>5. 首部开销</em></p><ul><li>TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 <code>20</code> 个字节，如果使用了「选项」字段则会变长的。</li><li>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</li></ul><p><em>6. 传输方式</em></p><ul><li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li><li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li></ul><p><em>7. 分片不同</em></p><ul><li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li><li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li></ul><p><strong>TCP 和 UDP 应用场景：</strong></p><p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li><code>FTP</code> 文件传输；</li><li>HTTP / HTTPS；</li></ul><p>由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；</li><li>视频、音频等多媒体通信；</li><li>广播通信；</li></ul><blockquote><p>为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？</p></blockquote><p>原因是 TCP 有<strong>可变长</strong>的「选项」字段，而 UDP 头部长度则是<strong>不会变化</strong>的，无需多一个字段去记录 UDP 的首部长度。</p><blockquote><p>为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？</p></blockquote><p>先说说 TCP 是如何计算负载数据长度：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230445811.png" alt="img"></p><p>其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。</p><p>大家这时就奇怪了问：“UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算呀？ 为何还要有「包长度」呢？”</p><p>这么一问，确实感觉 UDP 的「包长度」是冗余的。</p><p>我查阅了很多资料，我觉得有两个比较靠谱的说法：</p><ul><li>第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 <code>4</code> 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 <code>4</code> 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 <code>4</code> 字节的整数倍，才补充了「包长度」字段。</li><li>第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。</li></ul><h3 id="TCP-和-UDP-可以使用同一个端口吗？">TCP 和 UDP 可以使用同一个端口吗？</h3><p>答案：<strong>可以的</strong>。</p><p>在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。</p><p>所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。</p><p>传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。</p><p>当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/port/tcp%E5%92%8Cudp%E6%A8%A1%E5%9D%97.jpeg" alt="img"></p><p>因此，TCP/UDP 各自的端口号也相互独立，如 TCP 有一个 80 号端口，UDP 也可以有一个 80 号端口，二者并不冲突。</p><p>关于端口的知识点，还是挺多可以讲的，比如还可以牵扯到这几个问题：</p><ul><li>多个 TCP 服务进程可以同时绑定同一个端口吗？</li><li>重启 TCP 服务进程时，为什么会出现“Address in use”的报错信息？又该怎么避免？</li><li>客户端的端口可以重复使用吗？</li><li>客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？</li></ul><p>上面这些问题，可以看这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/port.html">TCP 和 UDP 可以使用同一个端口吗？</a></p><h2 id="TCP-连接建立">TCP 连接建立</h2><h3 id="TCP-三次握手过程是怎样的？">TCP 三次握手过程是怎样的？</h3><p>TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而<strong>建立连接是通过三次握手来进行的</strong>。三次握手的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手"></p><ul><li>一开始，客户端和服务端都处于 <code>CLOSE</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230500953.png" alt="第一个报文 —— SYN 报文"></p><ul><li>客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code>，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230504118.png" alt="第二个报文 —— SYN + ACK 报文"></p><ul><li>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230508297.png" alt="第三个报文 —— ACK 报文"></p><ul><li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。</li><li>服务端收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态。</li></ul><p>从上面的过程可以发现<strong>第三次握手是可以携带数据的，前两次握手是不可以携带数据的</strong>，这也是面试常问的题。</p><p>一旦完成三次握手，双方都处于 <code>ESTABLISHED</code> 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。</p><h3 id="如何在-Linux-系统中查看-TCP-状态？">如何在 Linux 系统中查看 TCP 状态？</h3><p>TCP 的连接状态查看，在 Linux 可以通过 <code>netstat -napt</code> 命令查看。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230520683.png" alt="TCP 连接状态查看"></p><h3 id="为什么是三次握手？不是两次、四次？">为什么是三次握手？不是两次、四次？</h3><p>相信大家比较常回答的是：“因为三次握手才能保证双方具有接收和发送的能力。”</p><p>这回答是没问题，但这回答是片面的，并没有说出主要的原因。</p><p>在前面我们知道了什么是 <strong>TCP 连接</strong>：</p><ul><li>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 <strong>Socket、序列号和窗口大小</strong>称为连接。</li></ul><p>所以，重要的是<strong>为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接。</strong></p><p>接下来，以三个方面分析三次握手的原因：</p><ul><li>三次握手才可以阻止重复历史连接的初始化（主要原因）</li><li>三次握手才可以同步双方的初始序列号</li><li>三次握手才可以避免资源浪费</li></ul><p><em>原因一：避免历史连接</em></p><p>我们来看看 RFC 793 指出的 TCP 连接使用三次握手的<strong>首要原因</strong>：</p><p><em>The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.</em></p><p>简单来说，三次握手的<strong>首要原因是为了防止旧的重复连接初始化造成混乱。</strong></p><p>我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（<em>注意！不是重传 SYN，重传的 SYN 的序列号是一样的</em>）。</p><p>看看三次握手是如何阻止历史连接的：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230525514.png" alt="三次握手避免历史连接"></p><p>客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在<strong>网络拥堵</strong>情况下：</p><ul><li>一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 <code>SYN + ACK</code> 报文给客户端，此报文中的确认号是 91（90+1）。</li><li>客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。</li><li>服务端收到 RST 报文后，就会释放连接。</li><li>后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。</li></ul><p>上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的<strong>最主要原因就是防止「历史连接」初始化了连接</strong>。</p><p>TIP</p><p>有很多人问，如果服务端在收到 RST 报文之前，先收到了「新 SYN 报文」，也就是服务端收到客户端报文的顺序是：「旧 SYN 报文」-&gt;「新 SYN 报文」，此时会发生什么?</p><p>当服务端第一次收到 SYN 报文，也就是收到 「旧 SYN 报文」时，就会回复 <code>SYN + ACK</code> 报文给客户端，此报文中的确认号是 91（90+1）。</p><p>然后这时再收到「新 SYN 报文」时，就会回 <a href="https://xiaolincoding.com/network/3_tcp/challenge_ack.html">Challenge Ack </a>报文给客户端，<strong>这个 ack 报文并不是确认收到「新 SYN 报文」的，而是上一次的 ack 确认号</strong>，也就是91（90+1）。所以客户端收到此 ACK 报文时，发现自己期望收到的确认号应该是 101，而不是 91，于是就会回 RST 报文。</p><p><strong>如果是两次握手连接，就无法阻止历史连接</strong>，那为什么 TCP 两次握手为什么无法阻止历史连接呢？</p><p>我先直接说结论，主要是因为<strong>在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费</strong>。</p><p>你想想，在两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态，假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/fe898053d2e93abac950b1637645943f.png" alt="两次握手无法阻止历史连接"></p><p>可以看到，如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。</p><p>因此，<strong>要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手</strong>。</p><p>所以，<strong>TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。</strong></p><p>TIP</p><p>有人问：客户端发送三次握手（ack 报文）后就可以发送数据了，而被动方此时还是 syn_received 状态，如果 ack 丢了，那客户端发的数据是不是也白白浪费了？</p><p>不是的，即使服务端还是在 syn_received 状态，收到了客户端发送的数据，还是可以建立连接的，并且还可以正常收到这个数据包。这是因为数据报文中是有 ack 标识位，也有确认号，这个确认号就是确认收到了第二次握手。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%9B%B8%E5%90%8Cack.png" alt="img"></p><p>所以，服务端收到这个数据报文，是可以正常建立连接的，然后就可以正常接收这个数据包了。</p><p><em>原因二：同步双方初始序列号</em></p><p>TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：</p><ul><li>接收方可以去除重复的数据；</li><li>接收方可以根据数据包的序列号按序接收；</li><li>可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；</li></ul><p>可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 <code>SYN</code> 报文的时候，需要服务端回一个 <code>ACK</code> 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，<strong>这样一来一回，才能确保双方的初始序列号能被可靠的同步。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230639121.png" alt="四次握手与三次握手"></p><p>四次握手其实也能够可靠的同步双方的初始化序号，但由于<strong>第二步和第三步可以优化成一步</strong>，所以就成了「三次握手」。</p><p>而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p><p><em>原因三：避免资源浪费</em></p><p>如果只有「两次握手」，当客户端发生的 <code>SYN</code> 报文在网络中阻塞，客户端没有接收到 <code>ACK</code> 报文，就会重新发送 <code>SYN</code> ，<strong>由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 <code>ACK</code> 报文，所以服务端每收到一个 <code>SYN</code> 就只能先主动建立一个连接</strong>，这会造成什么情况呢？</p><p>如果客户端发送的 <code>SYN</code> 报文在网络中阻塞了，重复发送多次 <code>SYN</code> 报文，那么服务端在收到请求后就会<strong>建立多个冗余的无效链接，造成不必要的资源浪费。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230636571.png" alt="两次握手会造成资源浪费"></p><p>即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 <code>SYN</code> 报文，而造成重复分配资源。</p><p>TIP</p><p>很多人问，两次握手不是也可以根据上下文信息丢弃 syn 历史报文吗？</p><p>我这里两次握手是假设「由于没有第三次握手，服务端不清楚客户端是否收到了自己发送的建立连接的 <code>ACK</code> 确认报文，所以每收到一个 <code>SYN</code> 就只能先主动建立一个连接」这个场景。</p><p>当然你要实现成类似三次握手那样，根据上下文丢弃 syn 历史报文也是可以的，两次握手没有具体的实现，怎么假设都行。</p><p><em>小结</em></p><p>TCP 建立连接时，通过三次握手<strong>能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号</strong>。序列号能够保证数据包不重复、不丢弃和按序传输。</p><p>不使用「两次握手」和「四次握手」的原因：</p><ul><li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</li><li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。</li></ul><h3 id="为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？">为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</h3><p>主要原因有两个方面：</p><ul><li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</li><li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li></ul><p>接下来，详细说说第一点。</p><p>假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E7%9B%B8%E5%90%8C.png" alt="img"></p><p>过程如下：</p><ul><li>客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。</li><li>紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；</li><li>在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</li></ul><p>可以看到，<strong>如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题</strong>。</p><p>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文，比如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/isn%E4%B8%8D%E7%9B%B8%E5%90%8C.png" alt="img"></p><p>相反，如果每次建立连接客户端和服务端的初始化序列号都「一样」，就有大概率遇到历史报文的序列号刚「好在」对方的接收窗口内，从而导致历史报文被新连接成功接收。</p><p>所以，每次初始化序列号不一样很大程度上能够避免历史报文被下一个相同四元组的连接接收，注意是很大程度上，并不是完全避免了（因为序列号会有回绕的问题，所以需要用时间戳的机制来判断历史报文，详细看篇：<a href="https://xiaolincoding.com/network/3_tcp/isn_deff.html">TCP 是如何避免历史报文的？ </a>）。</p><h3 id="初始序列号-ISN-是如何随机产生的？">初始序列号 ISN 是如何随机产生的？</h3><p>起始 <code>ISN</code> 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。</p><p>RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。</p><ul><li><code>M</code> 是一个计时器，这个计时器每隔 4 微秒加 1。</li><li><code>F</code> 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。</li></ul><p>可以看到，随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。</p><h3 id="既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？">既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</h3><p>我们先来认识下 MTU 和 MSS</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230633447.png" alt="MTU 与 MSS"></p><ul><li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节；</li><li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</li></ul><p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？</p><p>当 IP 层有一个超过 <code>MTU</code> 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。</p><p>这看起来井然有序，但这存在隐患的，<strong>那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传</strong>。</p><p>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</p><p>当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。</p><p>因此，可以得知由 IP 层进行分片传输，是非常没有效率的。</p><p>所以，为了达到最佳的传输效能 TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230628926.png" alt="握手阶段协商 MSS"></p><p>经过 TCP 层分片后，如果一个 TCP 分片丢失后，<strong>进行重发时也是以 MSS 为单位</strong>，而不用重传所有的分片，大大增加了重传的效率。</p><h3 id="第一次握手丢失了，会发生什么？">第一次握手丢失了，会发生什么？</h3><p>当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 <code>SYN_SENT</code> 状态。</p><p>在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且<strong>重传的 SYN 报文的序列号都是一样的</strong>。</p><p>不同版本的操作系统可能超时时间不同，有的 1 秒的，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。</p><p>当客户端在 1 秒后没收到服务端的 SYN-ACK 报文后，客户端就会重发 SYN 报文，那到底重发几次呢？</p><p>在 Linux 里，客户端的 SYN 报文最大重传次数由 <code>tcp_syn_retries</code>内核参数控制，这个参数是可以自定义的，默认值一般是 5。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> cat /proc/sys/net/ipv4/tcp_syn_retries</span><br>5<br></code></pre></td></tr></table></figure><p>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，<strong>每次超时的时间是上一次的 2 倍</strong>。</p><p>当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。</p><p>所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。</p><p>举个例子，假设 tcp_syn_retries 参数值为 3，那么当客户端的 SYN 报文一直在网络中丢失时，会发生下图的过程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC1%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%A2%E5%A4%B1.png" alt="img"></p><p>具体过程：</p><ul><li>当客户端超时重传 3 次 SYN 报文后，由于 tcp_syn_retries 为 3，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。</li></ul><h3 id="第二次握手丢失了，会发生什么？">第二次握手丢失了，会发生什么？</h3><p>当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 <code>SYN_RCVD</code> 状态。</p><p>第二次握手的 <code>SYN-ACK</code> 报文其实有两个目的 ：</p><ul><li>第二次握手里的 ACK， 是对第一次握手的确认报文；</li><li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</li></ul><p>所以，如果第二次握手丢了，就会发生比较有意思的事情，具体会怎么样呢？</p><p>因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是<strong>客户端就会触发超时重传机制，重传 SYN 报文</strong>。</p><p>然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。</p><p>那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是<strong>服务端这边会触发超时重传机制，重传 SYN-ACK 报文</strong>。</p><p>在 Linux 下，SYN-ACK 报文的最大重传次数由 <code>tcp_synack_retries</code>内核参数决定，默认值是 5。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> cat /proc/sys/net/ipv4/tcp_synack_retries</span><br>5<br></code></pre></td></tr></table></figure><p>因此，当第二次握手丢失了，客户端和服务端都会重传：</p><ul><li>客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 <code>tcp_syn_retries</code>内核参数决定；</li><li>服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 <code>tcp_synack_retries</code> 内核参数决定。</li></ul><p>举个例子，假设 tcp_syn_retries 参数值为 1，tcp_synack_retries 参数值为 2，那么当第二次握手一直丢失时，发生的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC2%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%A2%E5%A4%B1.png" alt="img"></p><p>具体过程：</p><ul><li>当客户端超时重传 1 次 SYN 报文后，由于 tcp_syn_retries 为 1，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。</li><li>当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。</li></ul><h3 id="第三次握手丢失了，会发生什么？">第三次握手丢失了，会发生什么？</h3><p>客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 <code>ESTABLISH</code> 状态。</p><p>因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。</p><p>注意，<strong>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</strong>。</p><p>举个例子，假设 tcp_synack_retries 参数值为 2，那么当第三次握手一直丢失时，发生的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%A2%E5%A4%B1.drawio.png" alt="img"></p><p>具体过程：</p><ul><li>当服务端超时重传 2 次 SYN-ACK 报文后，由于 tcp_synack_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第三次握手（ACK 报文），那么服务端就会断开连接。</li></ul><h3 id="什么是-SYN-攻击？如何避免-SYN-攻击？">什么是 SYN 攻击？如何避免 SYN 攻击？</h3><p>我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 <code>SYN</code> 报文，服务端每接收到一个 <code>SYN</code> 报文，就进入<code>SYN_RCVD</code> 状态，但服务端发送出去的 <code>ACK + SYN</code> 报文，无法得到未知 IP 主机的 <code>ACK</code> 应答，久而久之就会<strong>占满服务端的半连接队列</strong>，使得服务端不能为正常用户服务。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230625853.png" alt="SYN 攻击"></p><p>先跟大家说一下，什么是 TCP 半连接和全连接队列。</p><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accept 队列；</li></ul><p>我们先来看下 Linux 内核的 <code>SYN</code> 队列（半连接队列）与 <code>Accpet</code> 队列（全连接队列）是如何工作的？</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230622886.png" alt="正常流程"></p><p>正常流程：</p><ul><li>当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；</li><li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li><li>服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；</li><li>应用通过调用 <code>accpet()</code> socket 接口，从「 Accept 队列」取出连接对象。</li></ul><p>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。</p><p>SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样<strong>当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃</strong>，导致客户端无法和服务端建立连接。</p><p>避免 SYN 攻击方式，可以有以下四种方法：</p><ul><li>调大 netdev_max_backlog；</li><li>增大 TCP 半连接队列；</li><li>开启 tcp_syncookies；</li><li>减少 SYN+ACK 重传次数</li></ul><blockquote><p>方式一：调大 netdev_max_backlog</p></blockquote><p>当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">net.core.netdev_max_backlog = 10000<br></code></pre></td></tr></table></figure><blockquote><p>方式二：增大 TCP 半连接队列</p></blockquote><p>增大 TCP 半连接队列，要同时增大下面这三个参数：</p><ul><li>增大 net.ipv4.tcp_max_syn_backlog</li><li>增大 listen() 函数中的 backlog</li><li>增大 net.core.somaxconn</li></ul><p>具体为什么是三个参数决定 TCP 半连接队列的大小，可以看这篇：可以看这篇：<a href="https://xiaolincoding.com/network/3_tcp/tcp_queue.html">TCP 半连接队列和全连接队列满了会发生什么？又该如何应对？</a></p><blockquote><p>方式三：开启 net.ipv4.tcp_syncookies</p></blockquote><p>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230618804.png" alt="tcp_syncookies 应对 SYN 攻击"></p><p>具体过程：</p><ul><li>当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 <code>cookie</code> 值；</li><li>将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；</li><li>服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。</li><li>最后应用程序通过调用 <code>accpet()</code> 接口，从「 Accept 队列」取出的连接。</li></ul><p>可以看到，当开启了 tcp_syncookies 了，即使受到 SYN 攻击而导致 SYN 队列满时，也能保证正常的连接成功建立。</p><p>net.ipv4.tcp_syncookies 参数主要有以下三个值：</p><ul><li>0 值，表示关闭该功能；</li><li>1 值，表示仅当 SYN 半连接队列放不下时，再启用它；</li><li>2 值，表示无条件开启功能；</li></ul><p>那么在应对 SYN 攻击时，只需要设置为 1 即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/tcp_syncookies<br></code></pre></td></tr></table></figure><blockquote><p>方式四：减少 SYN+ACK 重传次数</p></blockquote><p>当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。</p><p>那么针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。</p><p>SYN-ACK 报文的最大重传次数由 <code>tcp_synack_retries</code>内核参数决定（默认值是 5 次），比如将 tcp_synack_retries 减少到 2 次：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">echo</span> 2 &gt; /proc/sys/net/ipv4/tcp_synack_retries</span><br></code></pre></td></tr></table></figure><h2 id="TCP-连接断开">TCP 连接断开</h2><h3 id="TCP-四次挥手过程是怎样的？">TCP 四次挥手过程是怎样的？</h3><p>天下没有不散的宴席，对于 TCP 连接也是这样， TCP 断开连接是通过<strong>四次挥手</strong>方式。</p><p>双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230614791.png" alt="客户端主动关闭连接 —— TCP 四次挥手"></p><ul><li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li><li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li><li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li><li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li><li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li><li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li><li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭。</li></ul><p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><h3 id="为什么挥手需要四次？">为什么挥手需要四次？</h3><p>再来回顾下四次挥手双方发 <code>FIN</code> 包的过程，就能理解为什么需要四次了。</p><ul><li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li><li>服务端收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li></ul><p>从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，因此是需要四次挥手。</p><p>但是<strong>在特定情况下，四次挥手是可以变成三次挥手的</strong>，具体情况可以看这篇：<a href="https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html">TCP 四次挥手，可以变成三次吗？</a></p><h3 id="第一次挥手丢失了，会发生什么？">第一次挥手丢失了，会发生什么？</h3><p>当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 <code>FIN_WAIT_1</code> 状态。</p><p>正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 <code>FIN_WAIT2</code>状态。</p><p>如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 <code>tcp_orphan_retries</code> 参数控制。</p><p>当客户端重传 FIN 报文的次数超过 <code>tcp_orphan_retries</code> 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 <code>close</code> 状态。</p><p>举个例子，假设 tcp_orphan_retries 参数值为 3，当第一次挥手一直丢失时，发生的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1.png" alt="img"></p><p>具体过程：</p><ul><li>当客户端超时重传 3 次 FIN 报文后，由于 tcp_orphan_retries 为 3，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK报文），那么客户端就会断开连接。</li></ul><h3 id="第二次挥手丢失了，会发生什么？">第二次挥手丢失了，会发生什么？</h3><p>当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 <code>CLOSE_WAIT</code> 状态。</p><p>在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。</p><p>举个例子，假设 tcp_orphan_retries 参数值为 2，当第二次挥手一直丢失时，发生的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%BA%8C%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1.png" alt="img"></p><p>具体过程：</p><ul><li>当客户端超时重传 2 次 FIN 报文后，由于 tcp_orphan_retries 为 2，已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK 报文），那么客户端就会断开连接。</li></ul><p>这里提一下，当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 <code>FIN_WAIT2</code> 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。</p><p>对于 close 函数关闭的连接，由于无法再发送和接收数据，所以<code>FIN_WAIT2</code> 状态不可以持续太久，而 <code>tcp_fin_timeout</code> 控制了这个状态下连接的持续时长，默认值是 60 秒。</p><p>这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/fin_wait_2.drawio.png" alt="img"></p><p>但是注意，如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。</p><p>此时，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 <code>FIN_WAIT2</code> 状态（<code>tcp_fin_timeout</code> 无法控制 shutdown 关闭的连接）。如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/fin_wait_2%E6%AD%BB%E7%AD%89.drawio.png" alt="img"></p><h3 id="第三次挥手丢失了，会发生什么？">第三次挥手丢失了，会发生什么？</h3><p>当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 <code>CLOSE_WAIT</code> 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p><p>此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。</p><p>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。</p><p>如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 <code>tcp_orphan_retrie</code>s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。</p><p>举个例子，假设 <code>tcp_orphan_retrie</code>s = 3，当第三次挥手一直丢失时，发生的过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1.drawio.png" alt="img"></p><p>具体过程：</p><ul><li>当服务端重传第三次挥手报文的次数达到了 3 次后，由于 tcp_orphan_retries 为 3，达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。</li><li>客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。</li></ul><h3 id="第四次挥手丢失了，会发生什么？">第四次挥手丢失了，会发生什么？</h3><p>当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 <code>TIME_WAIT</code> 状态。</p><p>在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。</p><p>然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。</p><p>如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 <code>tcp_orphan_retries</code> 参数控制。</p><p>举个例子，假设 tcp_orphan_retries 为 2，当第四次挥手一直丢失时，发生的过程如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/tcp/%E7%AC%AC%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E4%B8%A2%E5%A4%B1drawio.drawio.png" alt="img"></p><p>具体过程：</p><ul><li>当服务端重传第三次挥手报文达到 2 时，由于 tcp_orphan_retries 为 2， 达到了最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。</li><li>客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。</li></ul><h3 id="为什么-TIME-WAIT-等待的时间是-2MSL？">为什么 TIME_WAIT 等待的时间是 2MSL？</h3><p><code>MSL</code> 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 <code>TTL</code> 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</p><p>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 <strong>MSL 应该要大于等于 TTL 消耗为 0 的时间</strong>，以确保报文已被自然消亡。</p><p><strong>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong>。</p><p>TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong>。</p><p>比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 <code>FIN</code> 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。</p><p>可以看到 <strong>2MSL时长</strong> 这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。</p><p>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p><p><code>2MSL</code> 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong>。</p><p>在 Linux 系统里 <code>2MSL</code> 默认是 <code>60</code> 秒，那么一个 <code>MSL</code> 也就是 <code>30</code> 秒。<strong>Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒</strong>。</p><p>其定义在 Linux 内核代码里的名称为 TCP_TIMEWAIT_LEN：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> TCP_TIMEWAIT_LEN (60*HZ) <span class="hljs-comment">/* how long to wait to destroy TIME-WAIT </span></span><br><span class="hljs-comment"><span class="hljs-meta">                                    state, about 60 seconds  */</span></span><br></code></pre></td></tr></table></figure><p>如果要修改 TIME_WAIT 的时间长度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux 内核。</p><h3 id="为什么需要-TIME-WAIT-状态？">为什么需要 TIME_WAIT 状态？</h3><p>主动发起关闭连接的一方，才会有 <code>TIME-WAIT</code> 状态。</p><p>需要 TIME-WAIT 状态，主要是两个原因：</p><ul><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li><li>保证「被动关闭连接」的一方，能被正确的关闭；</li></ul><p><em>原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收</em></p><p>为了能更好的理解这个原因，我们先来了解序列号（SEQ）和初始序列号（ISN）。</p><ul><li><strong>序列号</strong>，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。<strong>序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0</strong>。</li><li><strong>初始序列号</strong>，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。<strong>初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时</strong>。</li></ul><p>给大家抓了一个包，下图中的 Seq 就是序列号，其中红色框住的分别是客户端和服务端各自生成的初始序列号。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/c9ea9b844e87bcd4acd3e320403ecab3.png" alt="TCP 抓包图"></p><p>通过前面我们知道，<strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong>。</p><p>假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/6385cc99500b01ba2ef288c27523c1e7-20230309230608128.png" alt="TIME-WAIT 时间过短，收到旧连接的数据报文"></p><p>如上图：</p><ul><li>服务端在关闭连接之前发送的 <code>SEQ = 301</code> 报文，被网络延迟了。</li><li>接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 <code>SEQ = 301</code> 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li></ul><p>为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 <code>2MSL</code> 时长，这个时间<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></p><p><em>原因二：保证「被动关闭连接」的一方，能被正确的关闭</em></p><p>在 RFC 793 指出 TIME-WAIT 另一个重要的作用是：</p><p><em>TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.</em></p><p>也就是说，TIME-WAIT 作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p><p>如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。</p><p>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/3a81c23ce57c27cf63fc2b77e34de0ab-20230309230604522.png" alt="TIME-WAIT 时间过短，没有确保连接正常关闭"></p><p>服务端收到这个 RST 并将其解释为一个错误（Connection reset by peer），这对于一个可靠的协议来说不是一个优雅的终止方式。</p><p>为了防止这种情况出现，客户端必须等待足够长的时间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送一个 FIN，这样一去一来刚好两个 MSL 的时间。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TIME-WAIT%E8%BF%9E%E6%8E%A5%E6%AD%A3%E5%B8%B8%E5%85%B3%E9%97%AD.drawio.png" alt="TIME-WAIT 时间正常，确保了连接正常关闭"></p><p>客户端在收到服务端重传的 FIN 报文时，TIME_WAIT 状态的等待时间，会重置回 2MSL。</p><h3 id="TIME-WAIT-过多有什么危害？">TIME_WAIT 过多有什么危害？</h3><p>过多的 TIME-WAIT 状态主要的危害有两种：</p><ul><li>第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；</li><li>第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 <code>32768～61000</code>，也可以通过 <code>net.ipv4.ip_local_port_range</code>参数指定范围。</li></ul><p>客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。</p><p><strong>如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多</strong>，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。具体可以看我这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/port.html#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%AB%AF%E5%8F%A3%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%A4%8D%E4%BD%BF%E7%94%A8%E5%90%97">客户端的端口可以重复使用吗？</a></p><p>因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务端建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务端建立连接了。</p><p>不过，即使是在这种场景下，只要连接的是不同的服务端，端口是可以重复使用的，所以客户端还是可以向其他服务端发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。</p><p><strong>如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多</strong>，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。</p><h3 id="如何优化-TIME-WAIT？">如何优化 TIME_WAIT？</h3><p>这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：</p><ul><li>打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；</li><li>net.ipv4.tcp_max_tw_buckets</li><li>程序中使用 SO_LINGER ，应用强制使用 RST 关闭。</li></ul><p><em>方式一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps</em></p><p>如下的 Linux 内核参数开启后，则可以<strong>复用处于 TIME_WAIT 的 socket 为新的连接所用</strong>。</p><p>有一点需要注意的是，<strong>tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">net.ipv4.tcp_tw_reuse = 1<br></code></pre></td></tr></table></figure><p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">net.ipv4.tcp_timestamps=1（默认即为 1）<br></code></pre></td></tr></table></figure><p>这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。</p><p>由于引入了时间戳，我们在前面提到的 <code>2MSL</code> 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</p><p><em>方式二：net.ipv4.tcp_max_tw_buckets</em></p><p>这个值默认为 18000，<strong>当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置</strong>，这个方法比较暴力。</p><p><em>方式三：程序中使用 SO_LINGER</em></p><p>我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">linger</span> <span class="hljs-title">so_linger</span>;</span><br>so_linger.l_onoff = <span class="hljs-number">1</span>;<br>so_linger.l_linger = <span class="hljs-number">0</span>;<br>setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,<span class="hljs-keyword">sizeof</span>(so_linger));<br></code></pre></td></tr></table></figure><p>如果<code>l_onoff</code>为非 0， 且<code>l_linger</code>值为 0，那么调用<code>close</code>后，会立该发送一个<code>RST</code>标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了<code>TIME_WAIT</code>状态，直接关闭。</p><p>但这为跨越<code>TIME_WAIT</code>状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。</p><p>前面介绍的方法都是试图越过 <code>TIME_WAIT</code>状态的，这样其实不太好。虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。</p><p>《UNIX网络编程》一书中却说道：<strong>TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它</strong>。</p><p><strong>如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT</strong>。</p><h3 id="服务器出现大量-TIME-WAIT-状态的原因有哪些？">服务器出现大量 TIME_WAIT 状态的原因有哪些？</h3><p>首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。</p><p>问题来了，<strong>什么场景下服务端会主动断开连接呢？</strong></p><ul><li>第一个场景：HTTP 没有使用长连接</li><li>第二个场景：HTTP 长连接超时</li><li>第三个场景：HTTP 长连接的请求数量达到上限</li></ul><p>接下来，分别介绍下。</p><p><em>第一个场景：HTTP 没有使用长连接</em></p><p>我们先来看看 HTTP 长连接（Keep-Alive）机制是怎么开启的。</p><p>在 HTTP/1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的 header 中添加：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Connection: Keep-Alive<br></code></pre></td></tr></table></figure><p>然后当服务器收到请求，作出回应的时候，它也被添加到响应中 header 里：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Connection: Keep-Alive<br></code></pre></td></tr></table></figure><p>这样做，TCP 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个 TCP 连接。这一直继续到客户端或服务器端提出断开连接。</p><p><strong>从 HTTP/1.1 开始， 就默认是开启了 Keep-Alive</strong>，现在大多数浏览器都默认是使用 HTTP/1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。</p><p>如果要关闭 HTTP Keep-Alive，需要在 HTTP 请求或者响应的 header 里添加 <code>Connection:close</code> 信息，也就是说，<strong>只要客户端和服务端任意一方的 HTTP header 中有 <code>Connection:close</code> 信息，那么就无法使用 HTTP 长连接的机制</strong>。</p><p>关闭 HTTP 长连接机制后，每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 <strong>HTTP 短连接</strong>，如下图：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d6f6757c02e3afbf113d1048c937f8ee.png" alt="HTTP 短连接"></p><p>在前面我们知道，只要任意一方的 HTTP header 中有 <code>Connection:close</code> 信息，就无法使用 HTTP 长连接机制，这样在完成一次 HTTP 请求/处理后，就会关闭连接。</p><p>问题来了，<strong>这时候是客户端还是服务端主动关闭连接呢？</strong></p><p>在 RFC 文档中，并没有明确由谁来关闭连接，<strong>请求和响应的双方都可以主动关闭 TCP 连接。</strong></p><p>不过，<strong>根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接</strong>，那么此时服务端上就会出现 TIME_WAIT 状态的连接。</p><blockquote><p>客户端禁用了 HTTP Keep-Alive，服务端开启 HTTP Keep-Alive，谁是主动关闭方？</p></blockquote><p>当客户端禁用了 HTTP Keep-Alive，这时候 HTTP 请求的 header 就会有 <code>Connection:close</code> 信息，这时服务端在发完 HTTP 响应后，就会主动关闭连接。</p><p>为什么要这么设计呢？HTTP 是请求-响应模型，发起方一直是客户端，HTTP Keep-Alive 的初衷是<strong>为客户端后续的请求重用连接</strong>，如果我们<strong>在某次 HTTP 请求-响应模型中，请求的 header 定义了 <code>connection：close</code> 信息，那不再重用这个连接的时机就只有在服务端了</strong>，所以我们在 HTTP 请求-响应这个周期的「末端」关闭连接是合理的。</p><blockquote><p>客户端开启了 HTTP Keep-Alive，服务端禁用了 HTTP Keep-Alive，谁是主动关闭方？</p></blockquote><p>当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。</p><p>为什么要这么设计呢？在服务端主动关闭连接的情况下，只要调用一次 close() 就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次 syscall；如果是要求 客户端关闭，则服务端在写完最后一个 response 之后需要把这个 socket 放入 readable 队列，调用 select / epoll 去等待事件；然后调用一次 read() 才能知道连接已经被关闭，这其中是两次 syscall，多一次用户态程序被激活执行，而且 socket 保持时间也会更长。</p><p>因此，<strong>当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive</strong>，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。</p><p>针对这个场景下，解决的方式也很简单，让客户端和服务端都开启 HTTP Keep-Alive 机制。</p><p><em>第二个场景：HTTP 长连接超时</em></p><p>HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p><p>HTTP 长连接可以在同一个 TCP 连接上接收和发送多个 HTTP 请求/应答，避免了连接建立和释放的开销。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d2b20d1cc03936332adb2a68512eb167.png" alt="img"></p><p>可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？</p><p>对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间，比如 nginx 提供的 keepalive_timeout 参数。</p><p>假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，<strong>如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/7e995ecb2e42941342f97256707496c9.png" alt="HTTP 长连接超时"></p><p>当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。</p><p>可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。</p><p><em>第三个场景：HTTP 长连接的请求数量达到上限</em></p><p>Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。</p><p>比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。<strong>如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接</strong>，那么此时服务端上就会出现 TIME_WAIT 状态的连接。</p><p>keepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。</p><p>但是，<strong>对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态</strong>。</p><p>针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。</p><h3 id="服务器出现大量-CLOSE-WAIT-状态的原因有哪些？">服务器出现大量 CLOSE_WAIT 状态的原因有哪些？</h3><p>CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。</p><p>所以，<strong>当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接</strong>。</p><p>那什么情况会导致服务端的程序没有调用 close 函数关闭连接？这时候通常需要排查代码。</p><p>我们先来分析一个普通的 TCP 服务端的流程：</p><ol><li>创建服务端 socket，bind 绑定端口、listen 监听端口</li><li>将服务端 socket 注册到 epoll</li><li>epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket</li><li>将已连接的 socket 注册到 epoll</li><li>epoll_wait 等待事件发生</li><li>对方连接关闭时，我方调用 close</li></ol><p>可能导致服务端没有调用 close 函数的原因，如下。</p><p><strong>第一个原因</strong>：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。</p><p>不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。</p><p><strong>第二个原因</strong>： 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。</p><p>发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。</p><p><strong>第三个原因</strong>：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。</p><p>发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：<a href="https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&amp;mid=2247486020&amp;idx=1&amp;sn=f7cf41aec28e2e10a46228a64b1c0a5c&amp;scene=21#wechat_redirect">一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析</a></p><p><strong>第四个原因</strong>：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。</p><p>可以发现，<strong>当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close</strong>。</p><h3 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？">如果已经建立了连接，但是客户端突然出现故障了怎么办？</h3><p>客户端出现故障指的是客户端的主机发生了宕机，或者断电的场景。发生这种情况的时候，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 <code>ESTABLISH</code> 状态，占用着系统资源。</p><p>为了避免这种情况，TCP 搞了个<strong>保活机制</strong>。这个机制的原理是这样的：</p><p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p><p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">net.ipv4.tcp_keepalive_time=7200<br>net.ipv4.tcp_keepalive_intvl=75  <br>net.ipv4.tcp_keepalive_probes=9<br></code></pre></td></tr></table></figure><ul><li>tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li><li>tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；</li><li>tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li></ul><p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230552557.png" alt="img"></p><p>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 <code>SO_KEEPALIVE</code> 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p><p>如果开启了 TCP 保活，需要考虑以下几种情况：</p><ul><li>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 <strong>TCP 保活时间会被重置</strong>，等待下一个 TCP 保活时间的到来。</li><li>第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，<strong>会产生一个 RST 报文</strong>，这样很快就会发现 TCP 连接已经被重置。</li><li>第三种，是对端主机宕机（<em>注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机</em>），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，<strong>TCP 会报告该 TCP 连接已经死亡</strong>。</li></ul><p>TCP 保活的这个机制检测的时间是有点长，我们可以自己在应用层实现一个心跳机制。</p><p>比如，web 服务软件一般都会提供 <code>keepalive_timeout</code> 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会<strong>启动一个定时器</strong>，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，<strong>定时器的时间一到，就会触发回调函数来释放该连接。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/2d872f947dedd24800a1867dc4f8b9ce.png" alt="web 服务的 心跳机制"></p><h3 id="如果已经建立了连接，但是服务端的进程崩溃会发生什么？">如果已经建立了连接，但是服务端的进程崩溃会发生什么？</h3><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。</p><p>我自己做了个实验，使用 kill -9 来模拟进程崩溃的情况，发现<strong>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</strong>。</p><p>TIP</p><p>关于进程崩溃和主机宕机的区别，可以参考这篇：<a href="https://xiaolincoding.com/network/3_tcp/tcp_down_and_crash.html">TCP 连接，一端断电和进程崩溃有什么区别？</a></p><p>还有一个类似的问题：「拔掉网线后， 原本的 TCP 连接还存在吗？」，具体可以看这篇：<a href="https://xiaolincoding.com/network/3_tcp/tcp_unplug_the_network_cable.html">拔掉网线后， 原本的 TCP 连接还存在吗？</a></p><hr><h2 id="Socket-编程">Socket 编程</h2><h3 id="针对-TCP-应该如何-Socket-编程？">针对 TCP 应该如何 Socket 编程？</h3><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230545997.png" alt="基于 TCP 协议的客户端和服务端工作"></p><ul><li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li><li>服务端调用 <code>bind</code>，将 socket 绑定在指定的 IP 地址和端口;</li><li>服务端调用 <code>listen</code>，进行监听；</li><li>服务端调用 <code>accept</code>，等待客户端连接；</li><li>客户端调用 <code>connect</code>，向服务端的地址和端口发起连接请求；</li><li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li><li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li><li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li></ul><p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p><p>所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p><p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p><h3 id="listen-时候参数-backlog-的意义？">listen 时候参数 backlog 的意义？</h3><p>Linux内核中会维护两个队列：</p><ul><li>半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；</li><li>全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230542373.png" alt=" SYN 队列 与 Accpet 队列 "></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">listen</span> <span class="hljs-params">(<span class="hljs-keyword">int</span> socketfd, <span class="hljs-keyword">int</span> backlog)</span></span><br></code></pre></td></tr></table></figure><ul><li>参数一 socketfd 为 socketfd 文件描述符</li><li>参数二 backlog，这参数在历史版本有一定的变化</li></ul><p>在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。</p><p>在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，<strong>所以现在通常认为 backlog 是 accept 队列。</strong></p><p><strong>但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。</strong></p><p>想详细了解 TCP 半连接队列和全连接队列，可以看这篇：<a href="https://xiaolincoding.com/network/3_tcp/tcp_queue.html">TCP 半连接队列和全连接队列满了会发生什么？又该如何应对？</a></p><h3 id="accept-发生在三次握手的哪一步？">accept 发生在三次握手的哪一步？</h3><p>我们先看看客户端连接服务端时，发送了什么？</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/socket%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="socket 三次握手"></p><ul><li>客户端的协议栈向服务端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；</li><li>服务端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端进入 SYN_RCVD 状态；</li><li>客户端协议栈收到 ACK 之后，使得应用程序从 <code>connect</code> 调用返回，表示客户端到服务端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端的 SYN 包进行应答，应答数据为 server_isn+1；</li><li>ACK 应答包到达服务端后，服务端的 TCP 连接进入 ESTABLISHED 状态，同时服务端协议栈使得 <code>accept</code> 阻塞调用返回，这个时候服务端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。</li></ul><p>从上面的描述过程，我们可以得知<strong>客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。</strong></p><h3 id="客户端调用-close-了，连接是断开的流程是什么？">客户端调用 close 了，连接是断开的流程是什么？</h3><p>我们看看客户端主动调用了 <code>close</code>，会发生什么？</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230538308.png" alt="客户端调用 close 过程"></p><ul><li>客户端调用 <code>close</code>，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；</li><li>服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 <code>EOF</code> 到接收缓冲区中，应用程序可以通过 <code>read</code> 调用来感知这个 FIN 包。这个 <code>EOF</code> 会被<strong>放在已排队等候的其他已接收的数据之后</strong>，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；</li><li>接着，当处理完数据后，自然就会读到 <code>EOF</code>，于是也调用 <code>close</code> 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；</li><li>客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；</li><li>服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；</li><li>客户端经过 <code>2MSL</code> 时间之后，也进入 CLOSE 状态；</li></ul><h3 id="没有-accept，能建立-TCP-连接吗？">没有 accept，能建立 TCP 连接吗？</h3><p>答案：<strong>可以的</strong>。</p><p>accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" alt="半连接队列与全连接队列"></p><p>更想了解这个问题，可以参考这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/tcp_no_accpet.html">没有 accept，能建立 TCP 连接吗？</a></p><h3 id="没有-listen，能建立-TCP-连接吗？">没有 listen，能建立 TCP 连接吗？</h3><p>答案：<strong>可以的</strong>。</p><p>客户端是可以自己连自己的形成连接（<strong>TCP自连接</strong>），也可以两个客户端同时向对方发出请求建立连接（<strong>TCP同时打开</strong>），这两个情况都有个共同点，就是<strong>没有服务端参与，也就是没有 listen，就能 TCP 建立连接。</strong></p><p>更想了解这个问题，可以参考这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/tcp_no_listen.html">服务端没有 listen，客户端发起连接建立，会发生什么？</a></p><hr><h2 id="唠叨">唠叨</h2>]]></content>
    
    
    <categories>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>既然有 HTTP 协议，为什么还要有 WebSocket？</title>
    <link href="/2021/05/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/09.%E6%97%A2%E7%84%B6%E6%9C%89%20HTTP%20%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89%20WebSocket%EF%BC%9F/"/>
    <url>/2021/05/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/09.%E6%97%A2%E7%84%B6%E6%9C%89%20HTTP%20%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89%20WebSocket%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>既然有 HTTP 协议，为什么还要有 WebSocket？</h1><p>平时我们打开网页，比如购物网站某宝。都是点一下「列表商品」，跳转一下网页就到了「商品详情」。</p><p>从 HTTP 协议的角度来看，就是点一下网页上的某个按钮，<strong>前端发一次 HTTP请 求，网站返回一次 HTTP 响应</strong>。这种由客户端主动请求，服务器响应的方式也满足大部分网页的功能场景。</p><p>但有没有发现，这种情况下，服务器从来就「不会主动」给客户端发一次消息。就像你喜欢的女生从来不会主动找你一样。</p><p>但如果现在，你在刷网页的时候「右下角」突然弹出一个小广告，提示你【一个人在家偷偷才能玩哦】。</p><p><strong>求知，好学，勤奋</strong>，这些刻在你 DNA 里的东西都动起来了。</p><p>你点开后发现。</p><p>长相平平无奇的古某提示你&quot;道士 9 条狗，全服横着走&quot;。</p><p>影帝某辉老师跟你说&quot;系兄弟就来砍我&quot;。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/b8cca4b1291f25235bc8df3dddbb6da3.png" alt="图片"></p><p>来都来了，你就选了个角色进到了游戏界面里。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/95e5b4cee384b182d0e604378c3ca00a.jpeg" alt=""></p><p>这时候，上来就是一个小怪，从远处走来，然后疯狂拿木棒子抽你。</p><p><strong>你全程没点任何一次鼠标</strong>。服务器就自动将怪物的移动数据和攻击数据源源不断发给你了。</p><p>这….太暖心了。</p><p>感动之余，问题就来了，</p><p>像这种<strong>看起来服务器主动发消息给客户端的场景</strong>，是怎么做到的？</p><p>在真正回答这个问题之前，我们先来聊下一些相关的知识背景。</p><h2 id="使用-HTTP-不断轮询">使用 HTTP 不断轮询</h2><p>其实问题的痛点在于，<strong>怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。</strong></p><p>最常见的解决方案是，<strong>网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。</strong></p><p>这其实时一种「<strong>伪</strong>」服务器推的形式。</p><p>它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。</p><p>用这种方式的场景也有很多，最常见的就是<strong>扫码登录</strong>。</p><p>比如，某信公众号平台，登录页面二维码出现之后，<strong>前端</strong>网页根本不知道用户扫没扫，于是不断去向<strong>后端</strong>服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于<strong>等太久</strong>。</p><p>使用HTTP定时轮询</p><p>但这样，会有两个比较明显的问题：</p><ul><li>当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。</li><li>最坏情况下，用户在扫码后，需要等个 1~2 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到<strong>明显的卡顿</strong>。</li></ul><p>使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候<strong>卡顿等个 1~2 秒</strong>，页面才跳转。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/63f9236749344bfdb568495589d9434b.png" alt="在这里插入图片描述"></p><p>那么问题又来了，<strong>有没有更好的解决方案？</strong></p><p>有，而且实现起来成本还非常低。</p><h2 id="长轮询">长轮询</h2><p>我们知道，HTTP 请求发出后，一般会给服务器留一定的时间做响应，比如 3 秒，规定时间内没返回，就认为是超时。</p><p>如果我们的 HTTP 请求<strong>将超时设置的很大</strong>，比如 30 秒，<strong>在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。</strong></p><p>这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/1058a96ba35215c0f30accc3ff5bb824.png" alt="图片"></p><p>比如，某度云网盘就是这么干的。所以你会发现一扫码，手机上点个确认，电脑端网页就<strong>秒跳转</strong>，体验很好。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/10bcbd2ced8e4b5fbc4f8ecb181b3a62.png" alt="在这里插入图片描述"></p><p>像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的<strong>长训轮机制</strong>。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/6173c1d25abc914ef17ee9e534ed6a5f.png" alt="图片"></p><p>像这种，在用户不感知的情况下，服务器将数据推送给浏览器的技术，就是所谓的<strong>服务器推送</strong>技术，它还有个毫不沾边的英文名，<strong>comet</strong> 技术，大家听过就好。</p><p>上面提到的两种解决方案（不断轮询和长轮询），本质上，其实还是客户端主动去取数据。</p><p>对于像扫码登录这样的<strong>简单场景</strong>还能用用。但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。</p><p>这就得说下 <strong>WebSocket</strong> 了。</p><h2 id="WebSocket是什么">WebSocket是什么</h2><p>我们知道 TCP 连接的两端，<strong>同一时间里</strong>，<strong>双方</strong>都可以<strong>主动</strong>向对方发送数据。这就是所谓的<strong>全双工</strong>。</p><p>而现在使用最广泛的<code>HTTP/1.1</code>，也是基于TCP协议的，<strong>同一时间里</strong>，客户端和服务器<strong>只能有一方主动</strong>发数据，这就是所谓的<strong>半双工</strong>。</p><p>也就是说，好好的全双工 TCP，被 HTTP/1.1 用成了半双工。</p><p>为什么？</p><p>这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到<strong>客户端发起请求再由服务器响应</strong>，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。</p><p>所以，为了更好的支持这样的场景，我们需要另外一个<strong>基于TCP的新协议</strong>。</p><p>于是新的应用层协议<strong>WebSocket</strong>就被设计出来了。</p><p>大家别被这个名字给带偏了。虽然名字带了个socket，但其实 <strong>socket 和 WebSocket 之间，就跟雷峰和雷峰塔一样，二者接近毫无关系</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/3bbe4c5db972513f912d30ba8cbddd65.png" alt="图片"></p><h3 id="怎么建立WebSocket连接">怎么建立WebSocket连接</h3><p>我们平时刷网页，一般都是在浏览器上刷的，一会刷刷图文，这时候用的是 <strong>HTTP 协议</strong>，一会打开网页游戏，这时候就得切换成我们新介绍的 <strong>WebSocket 协议</strong>。</p><p>为了兼容这些使用场景。浏览器在 <strong>TCP 三次握手</strong>建立连接之后，都<strong>统一使用 HTTP 协议</strong>先进行一次通信。</p><ul><li>如果此时是<strong>普通的 HTTP 请求</strong>，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。</li><li>如果这时候是<strong>想建立 WebSocket 连接</strong>，就会在 HTTP 请求里带上一些<strong>特殊的header 头</strong>，如下：</li></ul><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs http"><span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Upgrade<br><span class="hljs-attribute">Upgrade</span><span class="hljs-punctuation">: </span>WebSocket<br><span class="hljs-attribute">Sec-WebSocket-Key</span><span class="hljs-punctuation">: </span>T2a6wZlAwhgQNqruZ2YUyg==\r\n<br></code></pre></td></tr></table></figure><p>这些 header 头的意思是，浏览器想<strong>升级协议（Connection: Upgrade）</strong>，并且<strong>想升级成 WebSocket 协议（Upgrade: WebSocket）</strong>。同时带上一段<strong>随机生成的 base64 码（Sec-WebSocket-Key）</strong>，发给服务器。</p><p>如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个<strong>公开的</strong>算法变成另一段字符串，放在 HTTP 响应的 <code>Sec-WebSocket-Accept</code> 头里，同时带上<code>101状态码</code>，发回给浏览器。HTTP 的响应如下：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs http"><span class="hljs-meta">HTTP/1.1</span> <span class="hljs-number">101</span> Switching Protocols\r\n<br><span class="hljs-attribute">Sec-WebSocket-Accept</span><span class="hljs-punctuation">: </span>iBJKv/ALIW2DobfoA4dmr3JHBCY=\r\n<br><span class="hljs-attribute">Upgrade</span><span class="hljs-punctuation">: </span>WebSocket\r\n<br><span class="hljs-attribute">Connection</span><span class="hljs-punctuation">: </span>Upgrade\r\n<br></code></pre></td></tr></table></figure><p>HTTP 状态码=200（正常响应）的情况，大家见得多了。101 确实不常见，它其实是指<strong>协议切换</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/dea71991b336c876cae2e1ebdf03b62d.png" alt="图片"></p><p>之后，浏览器也用同样的<strong>公开算法</strong>将<code>base64码</code>转成另一段字符串，如果这段字符串跟服务器传回来的<strong>字符串一致</strong>，那验证通过。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/117eebe06cc6b35ded3216a95706f080.png" alt="图片"></p><p>就这样经历了一来一回两次 HTTP 握手，WebSocket就建立完成了，后续双方就可以使用 webscoket 的数据格式进行通信了。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f4edd3018914fe6eb38fad6aa3fd2d65.png" alt="图片"></p><h3 id="WebSocket抓包">WebSocket抓包</h3><p>我们可以用wireshark抓个包，实际看下数据包的情况。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f756ca625523f0f9d40a402465179bbe.png" alt="图片"></p><p>上面这张图，注意画了红框的第<code>2445</code>行报文，是WebSocket的<strong>第一次握手</strong>，意思是发起了一次带有<code>特殊Header</code>的HTTP请求。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/82d65f08dad05e6b537ea06b94224a5f.png" alt="图片"></p><p>上面这个图里画了红框的<code>4714</code>行报文，就是服务器在得到第一次握手后，响应的<strong>第二次握手</strong>，可以看到这也是个 HTTP 类型的报文，返回的状态码是 101。同时可以看到返回的报文 header 中也带有各种<code>WebSocket</code>相关的信息，比如<code>Sec-WebSocket-Accept</code>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/382c7699530ea7e7b22f60bb68af21bd.png" alt="图片"></p><p>上面这张图就是全貌了，从截图上的注释可以看出，WebSocket和HTTP一样都是基于TCP的协议。<strong>经历了三次TCP握手之后，利用 HTTP 协议升级为 WebSocket 协议</strong>。</p><p>你在网上可能会看到一种说法：“WebSocket 是基于HTTP的新协议”，<strong>其实这并不对</strong>，因为WebSocket只有在建立连接时才用到了HTTP，<strong>升级完成之后就跟HTTP没有任何关系了</strong>。</p><p>这就好像你喜欢的女生通过你要到了你大学室友的微信，然后他们自己就聊起来了。你能说这个女生是通过你去跟你室友沟通的吗？不能。你跟HTTP一样，都只是个<strong>工具人</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/2e9d4b1652bdfa1e3ae4bb24f70a1b5a.png" alt="图片"></p><p>这就有点&quot;<strong>借壳生蛋</strong>&quot;的那意思。</p><p>HTTP和WebSocket的关系</p><h3 id="WebSocket的消息格式">WebSocket的消息格式</h3><p>上面提到在完成协议升级之后，两端就会用webscoket的数据格式进行通信。</p><p>数据包在WebSocket中被叫做<strong>帧</strong>，我们来看下它的数据格式长什么样子。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/3a63a86e5d7e72a37b9828fc6e65c21f.png" alt="图片"></p><p>这里面字段很多，但我们只需要关注下面这几个。</p><p><strong>opcode字段</strong>：这个是用来标志这是个<strong>什么类型</strong>的数据帧。比如。</p><ul><li>等于 1 ，是指text类型（<code>string</code>）的数据包</li><li>等于 2 ，是二进制数据类型（<code>[]byte</code>）的数据包</li><li>等于 8 ，是关闭连接的信号</li></ul><p><strong>payload字段</strong>：存放的是我们<strong>真正想要传输的数据的长度</strong>，单位是<strong>字节</strong>。比如你要发送的数据是<code>字符串&quot;111&quot;</code>，那它的长度就是<code>3</code>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/437a076935f82be1d36960c9a4785fbd.png" alt="图片"></p><p>另外，可以看到，我们存放** payload 长度的字段有好几个**，我们既可以用最前面的<code>7bit</code>, 也可以用后面的<code>7+16bit 或 7+64bit。</code></p><p>那么问题就来了。</p><p>我们知道，在数据层面，大家都是 01 二进制流。我怎么知道<strong>什么情况下应该读 7 bit，什么情况下应该读7+16bit呢？</strong></p><p>WebSocket会用最开始的7bit做标志位。不管接下来的数据有多大，都<strong>先读最先的7个bit</strong>，根据它的取值决定还要不要再读个 16bit 或 64bit。</p><ul><li>如果<code>最开始的7bit</code>的值是 0~125，那么它就表示了 <strong>payload 全部长度</strong>，只读最开始的<code>7个bit</code>就完事了。</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/690f5a4deda2de50f3a35eddf0be4d75.png" alt="图片"></p><ul><li>如果是<code>126（0x7E）</code>。那它表示payload的长度范围在 <code>126~65535</code> 之间，接下来还需要<strong>再读16bit</strong>。这16bit会包含payload的真实长度。</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/c815c9dabc02fceb42a98c762705af33.png" alt="图片"></p><ul><li>如果是<code>127（0x7F）</code>。那它表示payload的长度范围<code>&gt;=65536</code>，接下来还需要<strong>再读64bit</strong>。这64bit会包含payload的长度。这能放2的64次方byte的数据，换算一下好多个TB，肯定够用了。</li></ul><p><img src="https://cdn.xiaolincoding.com//mysql/other/192b22b4fe46e8dfb7b17549306d5998.png" alt="图片"></p><p><strong>payload data字段</strong>：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。</p><p>大家有没有发现一个小细节，WebSocket的数据格式也是<strong>数据头（内含payload长度） + payload data</strong> 的形式。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d449242f1bf41c6f95a5314ec8311d0d.jpeg" alt="图片"></p><p>这是因为 TCP 协议本身就是全双工，但直接使用<strong>纯裸TCP</strong>去传输数据，会有<strong>粘包</strong>的&quot;问题&quot;。为了解决这个问题，上层协议一般会用<strong>消息头+消息体</strong>的格式去重新包装要发的数据。</p><p>而<strong>消息头</strong>里一般含有<strong>消息体的长度</strong>，通过这个长度可以去截取真正的消息体。</p><p>HTTP 协议和大部分 RPC 协议，以及我们今天介绍的WebSocket协议，都是这样设计的。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/b91fedb1856897c231b8fb5932b7b2d2.png" alt="图片"></p><h3 id="WebSocket的使用场景">WebSocket的使用场景</h3><p>WebSocket完美继承了 TCP 协议的<strong>全双工</strong>能力，并且还贴心的提供了解决粘包的方案。</p><p>它适用于<strong>需要服务器和客户端（浏览器）频繁交互</strong>的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。</p><p>回到文章开头的问题，在使用 WebSocket 协议的网页游戏里，怪物移动以及攻击玩家的行为是<strong>服务器逻辑</strong>产生的，对玩家产生的伤害等数据，都需要由<strong>服务器主动发送给客户端</strong>，客户端获得数据后展示对应的效果。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/31410d2e885aab55c2c588aad754bb5c.png" alt="图片"></p><h2 id="总结">总结</h2><ul><li>TCP 协议本身是<strong>全双工</strong>的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是<strong>半双工</strong>的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。</li><li>在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用<strong>定时轮询或者长轮询</strong>的方式实现<strong>服务器推送</strong>(comet)的效果。</li><li>对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。</li><li>WebSocket 和 socket 几乎没有任何关系，只是叫法相似。</li><li>正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。</li></ul>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>既然有 HTTP 协议，为什么还要有 RPC？</title>
    <link href="/2021/05/09/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/08.%E6%97%A2%E7%84%B6%E6%9C%89%20HTTP%20%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89%20RPC%EF%BC%9F/"/>
    <url>/2021/05/09/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/08.%E6%97%A2%E7%84%B6%E6%9C%89%20HTTP%20%E5%8D%8F%E8%AE%AE%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E6%9C%89%20RPC%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>既然有 HTTP 协议，为什么还要有 RPC？</h1><p>我想起了我刚工作的时候，第一次接触 RPC 协议，当时就很懵，<strong>我 HTTP 协议用的好好的，为什么还要用 RPC 协议？</strong></p><p>于是就到网上去搜。</p><p>不少解释显得非常官方，我相信大家在各种平台上也都看到过，解释了又好像没解释，都在<strong>用一个我们不认识的概念去解释另外一个我们不认识的概念</strong>，懂的人不需要看，不懂的人看了还是不懂。</p><p>这种看了，又好像没看的感觉，云里雾里的很难受，<strong>我懂</strong>。</p><p>为了避免大家有强烈的<strong>审丑疲劳</strong>，今天我们来尝试重新换个方式讲一讲。</p><h2 id="从-TCP-聊起">从 TCP 聊起</h2><p>作为一个程序员，假设我们需要在 A 电脑的进程发一段数据到 B 电脑的进程，我们一般会在代码里使用 Socket 进行编程。</p><p>这时候，我们可选项一般也就 TCP 和 UDP 二选一。TCP 可靠，UDP 不可靠。除非是马总这种神级程序员（早期 QQ 大量使用 UDP），否则，只要稍微对可靠性有些要求，普通人一般无脑选 TCP 就对了。</p><p>类似下面这样。</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">fd = socket(AF_INET,SOCK_STREAM,<span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>其中 <code>SOCK_STREAM</code>，是指使用<strong>字节流</strong>传输数据，说白了就是 <strong>TCP 协议</strong>。</p><p>在定义了 Socket 之后，我们就可以愉快的对这个 Socket 进行操作，比如用 <code>bind()</code> 绑定 IP 端口，用 <code>connect()</code> 发起建连。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/23cc66a7f4cb06afe13842b4b339e28b.gif" alt="握手建立连接流程"></p><p>在连接建立之后，我们就可以使用 <code>send()</code> 发送数据，<code>recv()</code> 接收数据。</p><p>光这样一个纯裸的 TCP 连接，就可以做到收发数据了，那是不是就够了？</p><p>不行，这么用会有问题。</p><h2 id="使用纯裸-TCP-会有什么问题">使用纯裸 TCP 会有什么问题</h2><p>八股文常背，TCP 是有三个特点，<strong>面向连接</strong>、<strong>可靠</strong>、基于<strong>字节流</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/3fcad07ba7ae92299b32224da8583363.png" alt="TCP 是什么"></p><p>这三个特点真的概括的<strong>非常精辟</strong>，这个八股文我们没白背。</p><p>每个特点展开都能聊一篇文章，而今天我们需要关注的是<strong>基于字节流</strong>这一点。</p><p>字节流可以理解为一个双向的通道里流淌的数据，这个<strong>数据</strong>其实就是我们常说的二进制数据，简单来说就是一大堆 <strong>01 串</strong>。纯裸 TCP 收发的这些 01 串之间是<strong>没有任何边界</strong>的，你根本不知道到哪个地方才算一条完整消息。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/254d845f9de05c19536d8343d268595a.png" alt="01 二进制字节流"></p><p>正因为这个没有<strong>任何边界</strong>的特点，所以当我们选择使用 TCP 发送&quot;夏洛&quot;和&quot;特烦恼&quot;的时候，接收端收到的就是&quot;夏洛特烦恼&quot;，这时候接收端没发区分你是想要表达&quot;夏洛&quot;+“特烦恼&quot;还是&quot;夏洛特”+“烦恼”。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/cd7c006cb4180bf751c4afd268ed44f0.png" alt="消息对比"></p><p>这就是所谓的<strong>粘包问题</strong>，之前也写过一篇专门的<a href="https://xiaolincoding.com/network/3_tcp/tcp_stream.html">文章 (opens new window)</a>聊过这个问题。</p><p>说这个的目的是为了告诉大家，纯裸 TCP 是不能直接拿来用的，你需要在这个基础上加入一些<strong>自定义的规则</strong>，用于区分<strong>消息边界</strong>。</p><p>于是我们会把每条要发送的数据都包装一下，比如加入<strong>消息头</strong>，<strong>消息头里写清楚一个完整的包长度是多少</strong>，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的<strong>消息体</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/9428feed1ff22156fc136d17a129527b.png" alt="消息边界长度标志"></p><p>而这里头提到的<strong>消息头</strong>，还可以放各种东西，比如消息体是否被压缩过和消息体格式之类的，只要上下游都约定好了，互相都认就可以了，这就是所谓的<strong>协议。</strong></p><p>每个使用 TCP 的项目都可能会定义一套类似这样的协议解析标准，他们可能<strong>有区别，但原理都类似</strong>。</p><p><strong>于是基于 TCP，就衍生了非常多的协议，比如 HTTP 和 RPC。</strong></p><h2 id="HTTP-和-RPC">HTTP 和 RPC</h2><p>我们回过头来看网络的分层图。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/da970d16a205fb48d6a8bea14498814d.png" alt="四层网络协议"></p><p><strong>TCP 是传输层的协议</strong>，而基于 TCP 造出来的 HTTP 和<strong>各类</strong> RPC 协议，它们都只是定义了不同消息格式的<strong>应用层协议</strong>而已。</p><p><strong>HTTP</strong> 协议（<strong>H</strong>yper <strong>T</strong>ext <strong>T</strong>ransfer <strong>P</strong>rotocol），又叫做<strong>超文本传输协议</strong>。我们用的比较多，平时上网在浏览器上敲个网址就能访问网页，这里用到的就是 HTTP 协议。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/809c33f7090c08b78d494445e39ae1b4.png" alt="HTTP调用"></p><p>而 <strong>RPC</strong>（<strong>R</strong>emote <strong>P</strong>rocedure <strong>C</strong>all），又叫做<strong>远程过程调用</strong>。它本身并不是一个具体的协议，而是一种<strong>调用方式</strong>。</p><p>举个例子，我们平时调用一个<strong>本地方法</strong>就像下面这样。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">res = localFunc(req)<br></code></pre></td></tr></table></figure><p>如果现在这不是个本地方法，而是个<strong>远端服务器</strong>暴露出来的一个方法 <code>remoteFunc</code>，如果我们还能像调用本地方法那样去调用它，这样就可以<strong>屏蔽掉一些网络细节</strong>，用起来更方便，岂不美哉？</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">res = remoteFunc(req)<br></code></pre></td></tr></table></figure><p><img src="https://cdn.xiaolincoding.com//mysql/other/2b2ea6d26af9ded517043e528b032307.png" alt="RPC可以像调用本地方法那样调用远端方法"></p><p>基于这个思路，大佬们造出了非常多款式的 RPC 协议，比如比较有名的<code>gRPC</code>，<code>thrift</code>。</p><p>值得注意的是，虽然大部分 RPC 协议底层使用 TCP，但实际上<strong>它们不一定非得使用 TCP，改用 UDP 或者 HTTP，其实也可以做到类似的功能。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/054e9738bc492a6fb6e9a71737d95fc0.png" alt="基于TCP协议的HTTP和RPC协议"></p><p>到这里，我们回到文章标题的问题。</p><blockquote><p>既然有 HTTP 协议，为什么还要有 RPC？</p></blockquote><p>其实，<code>TCP</code> 是<strong>70年</strong>代出来的协议，而 <code>HTTP</code> 是 <strong>90 年代</strong>才开始流行的。而直接使用裸 TCP 会有问题，可想而知，这中间这么多年有多少自定义的协议，而这里面就有<strong>80年代</strong>出来的 <code>RPC</code>。</p><p>所以我们该问的不是<strong>既然有 HTTP 协议为什么要有 RPC</strong>，而是<strong>为什么有 RPC 还要有 HTTP 协议</strong>。</p><blockquote><p>那既然有 RPC 了，为什么还要有 HTTP 呢？</p></blockquote><p>现在电脑上装的各种<strong>联网</strong>软件，比如 xx管家，xx卫士，它们都作为<strong>客户端（Client）需要跟服务端（Server）建立连接收发消息</strong>，此时都会用到应用层协议，在这种 Client/Server (C/S) 架构下，它们可以使用自家造的 RPC 协议，因为它只管连自己公司的服务器就 ok 了。</p><p>但有个软件不同，<strong>浏览器（Browser）</strong>，不管是 Chrome 还是 IE，它们不仅要能访问自家公司的<strong>服务器（Server）</strong>，还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，不然大家没法交流。于是，HTTP 就是那个时代用于统一 <strong>Browser/Server (B/S)</strong> 的协议。</p><p>也就是说在多年以前，<strong>HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。*<em>很多软件同时支持多端，比如某度云盘，既要支持*<em>网页版</em></em>，还要支持</strong>手机端和 PC 端**，如果通信协议都用 HTTP 的话，那服务器只用同一套就够了。而 RPC 就开始退居幕后，一般用于公司内部集群里，各个微服务之间的通讯。</p><p>那这么说的话，<strong>都用 HTTP 得了，还用什么 RPC？</strong></p><p>仿佛又回到了文章开头的样子，那这就要从它们之间的区别开始说起。</p><h2 id="HTTP-和-RPC-有什么区别">HTTP 和 RPC 有什么区别</h2><p>我们来看看 RPC 和 HTTP 区别比较明显的几个点。</p><h3 id="服务发现">服务发现</h3><p>首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道 <strong>IP 地址和端口</strong>。这个找到服务对应的 IP 端口的过程，其实就是<strong>服务发现</strong>。</p><p>在 <strong>HTTP</strong> 中，你知道服务的域名，就可以通过 <strong>DNS 服务</strong>去解析得到它背后的 IP 地址，默认 80 端口。</p><p>而 <strong>RPC</strong> 的话，就有些区别，一般会有专门的<strong>中间服务</strong>去保存服务名和IP信息，比如 <strong>Consul 或者 Etcd，甚至是 Redis</strong>。想要访问某个服务，就去这些中间服务去获得 IP 和端口信息。由于 DNS 也是服务发现的一种，所以也有基于 DNS 去做服务发现的组件，比如<strong>CoreDNS</strong>。</p><p>可以看出服务发现这一块，两者是有些区别，但不太能分高低。</p><h3 id="底层连接形式">底层连接形式</h3><p>以主流的 <strong>HTTP/1.1</strong> 协议为例，其默认在建立底层 TCP 连接之后会一直保持这个连接（<strong>Keep Alive</strong>），之后的请求和响应都会复用这条连接。</p><p>而 <strong>RPC</strong> 协议，也跟 HTTP 类似，也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个<strong>连接池</strong>，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，<strong>用完放回去，下次再复用</strong>，可以说非常环保。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/ec5c8e28d3ea308c6db2ac991a12ea80.png" alt="connection_pool"></p><p><strong>由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给 HTTP 加个连接池</strong>，比如 <strong>Go</strong> 就是这么干的。</p><p>可以看出这一块两者也没太大区别，所以也不是关键。</p><h3 id="传输的内容">传输的内容</h3><p>基于 TCP 传输的消息，说到底，无非都是<strong>消息头 Header 和消息体 Body。</strong></p><p><strong>Header</strong> 是用于标记一些特殊信息，其中最重要的是<strong>消息体长度</strong>。</p><p><strong>Body</strong> 则是放我们真正需要传输的内容，而这些内容只能是二进制 01 串，毕竟计算机只认识这玩意。所以 TCP 传字符串和数字都问题不大，因为字符串可以转成编码再变成 01 串，而数字本身也能直接转为二进制。但结构体呢，我们得想个办法将它也转为二进制 01 串，这样的方案现在也有很多现成的，比如 <strong>Json，Protobuf。</strong></p><p>这个将结构体转为二进制数组的过程就叫<strong>序列化</strong>，反过来将二进制数组复原成结构体的过程叫<strong>反序列化</strong>。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/dba2bc3af0938d2c087f85acc191fd3f.png" alt="序列化和反序列化"></p><p>对于主流的 HTTP/1.1，虽然它现在叫<strong>超文本</strong>协议，支持音频视频，但 HTTP 设计初是用于做网页<strong>文本</strong>展示的，所以它传的内容以字符串为主。Header 和 Body 都是如此。在 Body 这块，它使用 <strong>Json</strong> 来<strong>序列化</strong>结构体数据。</p><p>我们可以随便截个图直观看下。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/324cbe84c303a3b975e50329f5cdbf8b.png" alt="HTTP 报文"></p><p>可以看到这里面的内容非常多的<strong>冗余</strong>，显得<strong>非常啰嗦</strong>。最明显的，像 <code>Header</code> 里的那些信息，其实如果我们约定好头部的第几位是 Content-Type，就<strong>不需要每次都真的把&quot;Content-Type&quot;这个字段都传过来</strong>，类似的情况其实在 <code>body</code> 的 Json 结构里也特别明显。</p><p>而 RPC，因为它定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为，比如 302 重定向跳转啥的。<strong>因此性能也会更好一些，这也是在公司内部微服务中抛弃 HTTP，选择使用 RPC 的最主要原因。</strong></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/f4cef7331cabcfe56d9d6434f7ef907f.png" alt="HTTP 原理"></p><p><img src="https://cdn.xiaolincoding.com//mysql/other/12244fb0b19b2e61755fcab799198f68.png" alt="RPC 原理"></p><p>当然上面说的 HTTP，其实<strong>特指的是现在主流使用的 HTTP/1.1</strong>，<code>HTTP/2</code> 在前者的基础上做了很多改进，所以<strong>性能可能比很多 RPC 协议还要好</strong>，甚至连 <code>gRPC</code> 底层都直接用的 <code>HTTP/2</code>。</p><blockquote><p>那么问题又来了，为什么既然有了 HTTP/2，还要有 RPC 协议？</p></blockquote><p>这个是由于 HTTP/2 是 2015 年出来的。那时候很多公司内部的 RPC 协议都已经跑了好些年了，基于历史原因，一般也没必要去换了。</p><h2 id="总结">总结</h2><ul><li>纯裸 TCP 是能收发数据，但它是个<strong>无边界</strong>的数据流，上层需要定义<strong>消息格式</strong>用于定义<strong>消息边界</strong>。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。</li><li><strong>RPC 本质上不算是协议，而是一种调用方式</strong>，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，<strong>不一定非得基于 TCP 协议</strong>。</li><li>从发展历史来说，<strong>HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合</strong>。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。</li><li>RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 <strong>性能</strong>要更好，所以大部分公司内部都还在使用 RPC。</li><li><strong>HTTP/2.0</strong> 在 <strong>HTTP/1.1</strong> 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。</li></ul>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP/3 强势来袭</title>
    <link href="/2021/05/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/07.HTTP3%20%E5%BC%BA%E5%8A%BF%E6%9D%A5%E8%A2%AD/"/>
    <url>/2021/05/08/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/07.HTTP3%20%E5%BC%BA%E5%8A%BF%E6%9D%A5%E8%A2%AD/</url>
    
    <content type="html"><![CDATA[<h1>HTTP/3 强势来袭</h1><p>HTTP/3 现在（2022 年 5 月）还没正式推出，不过自 2017 年起，HTTP/3 已经更新到 34 个草案了，基本的特性已经确定下来了，对于包格式可能后续会有变化。</p><p>所以，这次 HTTP/3 介绍不会涉及到包格式，只说它的特性。</p><p><img src="https://camo.githubusercontent.com/3cf6441cfddcc61302d25725bafaa16a5d373dbb4066286e8e9ea8b23079db93/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f48545450332545362538462539302545372542412542322e706e67" alt="img"></p><h2 id="美中不足的-HTTP-2">美中不足的 HTTP/2</h2><p>HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。</p><ul><li>队头阻塞；</li><li>TCP 与 TLS 的握手时延迟；</li><li>网络迁移需要重新连接；</li></ul><h3 id="队头阻塞">队头阻塞</h3><p>HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求。</p><p>比如下图中，Stream 2 有一个 TCP 报文丢失了，那么即使收到了 Stream 3 和 Stream 4 的 TCP 报文，应用层也是无法读取读取的，相当于阻塞了 Stream 3 和 Stream 4 请求。</p><p><img src="https://camo.githubusercontent.com/c0ac72d28a41b36aa7b7ae5a35df35452546e370a84da7936b8862fa6bb208f1/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f717569632f68747470322545392539382542422545352541312539452e6a706567" alt="img"></p><p>因为 TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。</p><p>举个例子，如下图：</p><p><img src="https://camo.githubusercontent.com/a4a7aabef6da85b8797389ebe0e9dca4cd6ceabb26aacb6a179aa52d6f2d26db/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f7463702545392539382539462545352541342542342545392539382542422545352541312539452e676966" alt="img"></p><p>图中发送方发送了很多个 Packet，每个 Packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 Packet 3 在网络中丢失了，即使 Packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 Packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。</p><h3 id="TCP-与-TLS-的握手时延迟">TCP 与 TLS 的握手时延迟</h3><p>发起 HTTP 请求时，需要经过 TCP 三次握手和 TLS 四次握手（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据。</p><p><img src="https://camo.githubusercontent.com/ce1e970a8d3ff52ff895ca2b4200e49e6e4a1d2486d7c198f079ea9eef902fe9/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f544350253242544c532e676966" alt="img"></p><p>另外，TCP 由于具有「拥塞控制」的特性，所以刚建立连接的 TCP 会有个「慢启动」的过程，它会对 TCP 连接产生“减速”效果。</p><h3 id="网络迁移需要重新连接">网络迁移需要重新连接</h3><p>一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WiFi。</p><p>这些问题都是 TCP 协议固有的问题，无论应用层的 HTTP/2 在怎么设计都无法逃脱。要解决这个问题，就必须把<strong>传输层协议替换成 UDP</strong>，这个大胆的决定，HTTP/3 做了！</p><p><img src="https://camo.githubusercontent.com/8fc01fbb786ca5745f6eeeef9c3200223914ba96df7153aada1a166070ad530f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f32372d48545450332e706e67" alt="img"></p><h2 id="QUIC-协议的特点">QUIC 协议的特点</h2><p>我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。</p><p>而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。</p><p>当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 <strong>QUIC 协议</strong>，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。</p><p>QUIC 协议的优点有很多，这里举例几个，比如：</p><ul><li>无队头阻塞；</li><li>更快的连接建立；</li><li>连接迁移；</li></ul><h3 id="无队头阻塞">无队头阻塞</h3><p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p><p>由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。</p><p>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。</p><p>而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p><p><img src="https://camo.githubusercontent.com/721c2108b922e90a2f9b150d9d9a3751fc0a6cba3ff30bfb88d8fead8ae532c2/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f717569632f717569632545362539372541302545392539382542422545352541312539452e6a706567" alt="img"></p><h3 id="更快的连接建立">更快的连接建立</h3><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、OpenSSL 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 <strong>QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果</strong>。</p><p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：</p><p><img src="https://camo.githubusercontent.com/c10cd44d6a90ef3190b4cb138dd18303c8035476eff7b2976bccb336a0797610/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f302d7274742e676966" alt="img"></p><h3 id="连接迁移">连接迁移</h3><p>在前面我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p><p><img src="https://camo.githubusercontent.com/5e889c0db1c5e141545b48ef9301d7e50190ea8eb3044894f7e027456459650f/68747470733a2f2f696d67636f6e766572742e6373646e696d672e636e2f6148523063484d364c79396a5a473475616e4e6b5a577870646e4975626d56304c32646f4c336870595739736157356a6232526c6369394a6257466e5a556876633351794c7956464f435642525356424d5356464e795642525355354e7956464e69553551795643515356464e795643524355354d5356464e7956435169553551793955513141744a5555304a5549344a5467354a5555324a5546444a5545784a5555324a5468474a5545784a5555324a5467354a5468434a5555314a546b794a5468444a5555314a546c434a546c434a5555324a5546444a5545784a5555324a5468444a5545314a5555324a5467354a5468434c7a45774c6d70775a773f782d6f73732d70726f636573733d696d6167652f666f726d61742c706e67" alt="img"></p><p>那么当移动设备的网络从 4G 切换到 WiFi 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接，而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong> 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><h2 id="HTTP-3-协议">HTTP/3 协议</h2><p>了解完 QUIC 协议的特点后，我们再来看看 HTTP/3 协议在 HTTP 这一层做了什么变化。</p><p>HTTP/3 同 HTTP/2 一样采用二进制帧的结构，不同的地方在于 HTTP/2 的二进制帧里需要定义 Stream，而 HTTP/3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP/3 的帧的结构也变简单了。</p><p><img src="https://camo.githubusercontent.com/da7789d070872afc91c65d89c00cb176cd3d1c54241d65b4ac2a3bb72c605412/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f68747470336672616d652e706e67" alt="img"></p><p>从上图可以看到，HTTP/3 帧头只有两个字段：类型和长度。</p><p>根据帧类型的不同，大体上分为数据帧和控制帧两大类，Headers 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。</p><p>HTTP/3 在头部压缩算法这一方面也做了升级，升级成了 <strong>QPACK</strong>。与 HTTP/2 中的 HPACK 编码方式相似，HTTP/3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。</p><p>对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，而 HTTP/3 中的 QPACK 的静态表扩大到 91 项。</p><p>HTTP/2 和 HTTP/3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。</p><p>所谓的动态表，在首次请求-响应后，双方会将未包含在静态表中的 Header 项更新各自的动态表，接着后续传输时仅用 1 个数字表示，然后对方可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，大大提升了编码效率。</p><p>可以看到，<strong>动态表是具有时序性的，如果首次出现的请求发生了丢包，后续的收到请求，对方就无法解码出 HPACK 头部，因为对方还没建立好动态表，因此后续的请求解码会阻塞到首次请求中丢失的数据包重传过来</strong>。</p><p>HTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？</p><p>QUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，双向则指两端都可以发送消息，传输 HTTP 消息时用的是双向流，这两个单向流的用法：</p><ul><li>一个叫 QPACK Encoder Stream，用于将一个字典（Key-Value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；</li><li>一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。</li></ul><p>这两个特殊的单向流是用来<strong>同步双方的动态表</strong>，编码方收到解码方更新确认的通知后，才使用动态表编码 HTTP 头部。</p><h2 id="总结">总结</h2><p>HTTP/2 虽然具有多个流并发传输的能力，但是传输层是 TCP 协议，于是存在以下缺陷：</p><ul><li><strong>队头阻塞</strong>，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；</li><li><strong>TCP 和 TLS 握手时延</strong>，TCP 三次握手和 TLS 四次握手，共有 3-RTT 的时延；</li><li><strong>连接迁移需要重新连接</strong>，移动设备从 4G 网络环境切换到 WiFi 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；</li></ul><p>HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。</p><p>QUIC 协议的特点：</p><ul><li><strong>无队头阻塞</strong>，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；</li><li><strong>建立连接速度快</strong>，因为 QUIC 内部包含 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</li><li><strong>连接迁移</strong>，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；</li></ul><p>另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双方的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。</p><p><strong>期待，HTTP/3 正式推出的那一天！</strong></p>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP/2 牛逼在哪？</title>
    <link href="/2021/05/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/06.HTTP2%20%E7%89%9B%E9%80%BC%E5%9C%A8%E5%93%AA%EF%BC%9F/"/>
    <url>/2021/05/07/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/06.HTTP2%20%E7%89%9B%E9%80%BC%E5%9C%A8%E5%93%AA%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>HTTP/2 牛逼在哪？</h1><p>不多 BB 了，直接发车！</p><p><strong>一起来看看 HTTP/2 牛逼在哪？</strong></p><p><a href="https://camo.githubusercontent.com/900e0816a27df014f952109b5f562e126eab1749cf0b650da6fb1f72d6ce0e09/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f68747470322545362538462539302545372542412542322e706e67"><img src="https://camo.githubusercontent.com/900e0816a27df014f952109b5f562e126eab1749cf0b650da6fb1f72d6ce0e09/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f68747470322545362538462539302545372542412542322e706e67" alt="img"></a></p><hr><h2 id="HTTP-1-1-协议的性能问题">HTTP/1.1 协议的性能问题</h2><p>我们得先要了解下 HTTP/1.1 协议存在的性能问题，因为 HTTP/2 协议就是把这些性能问题逐个攻破了。</p><p>现在的站点相比以前变化太多了，比如：</p><ul><li><em>消息的大小变大了</em>，从几 KB 大小的消息，到几 MB 大小的消息；</li><li><em>页面资源变多了</em>，从每个页面不到 10 个的资源，到每页超 100 多个资源；</li><li><em>内容形式变多样了</em>，从单纯到文本内容，到图片、视频、音频等内容；</li><li><em>实时性要求变高了</em>，对页面的实时性要求的应用越来越多；</li></ul><p>这些变化带来的最大性能问题就是 <strong>HTTP/1.1 的高延迟</strong>，延迟高必然影响的就是用户体验。主要原因如下几个：</p><ul><li><em>延迟难以下降</em>，虽然现在网络的「带宽」相比以前变多了，但是延迟降到一定幅度后，就很难再下降了，说白了就是到达了延迟的下限；</li><li><em>并发连接有限</em>，谷歌浏览器最大并发连接数是 6 个，而且每一个连接都要经过 TCP 和 TLS 握手耗时，以及 TCP 慢启动过程给流量带来的影响；</li><li><em>队头阻塞问题</em>，同一连接只能在完成一个 HTTP 事务（请求和响应）后，才能处理下一个事务；</li><li><em>HTTP 头部巨大且重复</em>，由于 HTTP 协议是无状态的，每一个请求都得携带 HTTP 头部，特别是对于有携带 Cookie 的头部，而 Cookie 的大小通常很大；</li><li><em>不支持服务器推送消息</em>，因此当客户端需要获取通知时，只能通过定时器不断地拉取消息，这无疑浪费大量了带宽和服务器资源。</li></ul><p>为了解决 HTTP/1.1 性能问题，具体的优化手段你可以看这篇文章「<a href="https://xiaolincoding.com/network/2_http/http_optimize.html">HTTP/1.1 如何优化？ </a>」，这里我举例几个常见的优化手段：</p><ul><li>将多张小图合并成一张大图供浏览器 JavaScript 来切割使用，这样可以将多个请求合并成一个请求，但是带来了新的问题，当某张小图片更新了，那么需要重新请求大图片，浪费了大量的网络带宽；</li><li>将图片的二进制数据通过 Base64 编码后，把编码数据嵌入到 HTML 或 CSS 文件中，以此来减少网络请求次数；</li><li>将多个体积较小的 JavaScript 文件使用 Webpack 等工具打包成一个体积更大的 JavaScript 文件，以一个请求替代了很多个请求，但是带来的问题，当某个 js 文件变化了，需要重新请求同一个包里的所有 js 文件；</li><li>将同一个页面的资源分散到不同域名，提升并发连接上限，因为浏览器通常对同一域名的 HTTP 连接最大只能是 6 个；</li></ul><p>尽管对 HTTP/1.1 协议的优化手段如此之多，但是效果还是不尽人意，因为这些手段都是对 HTTP/1.1 协议的“外部”做优化，<strong>而一些关键的地方是没办法优化的，比如请求-响应模型、头部巨大且重复、并发连接耗时、服务器不能主动推送等，要改变这些必须重新设计 HTTP 协议，于是 HTTP/2 就出来了！</strong></p><hr><h2 id="兼容-HTTP-1-1">兼容 HTTP/1.1</h2><p>HTTP/2 出来的目的是为了改善 HTTP 的性能。协议升级有一个很重要的地方，就是要<strong>兼容</strong>老版本的协议，否则新协议推广起来就相当困难，所幸 HTTP/2 做到了兼容 HTTP/1.1。</p><p>那么，HTTP/2 是怎么做的呢？</p><p>第一点，HTTP/2 没有在 URI 里引入新的协议名，仍然用「http://」表示明文协议，用「https://」表示加密协议，于是只需要浏览器和服务器在背后自动升级协议，这样可以让用户意识不到协议的升级，很好的实现了协议的平滑升级。</p><p>第二点，只在应用层做了改变，还是基于 TCP 协议传输，应用层方面为了保持功能上的兼容，HTTP/2 把 HTTP 分解成了「语义」和「语法」两个部分，「语义」层不做改动，与 HTTP/1.1 完全一致，比如请求方法、状态码、头字段等规则保留不变。</p><p>但是，HTTP/2 在「语法」层面做了很多改造，基本改变了 HTTP 报文的传输格式。</p><h2 id="头部压缩">头部压缩</h2><p>HTTP 协议的报文是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使用头字段 「Content-Encoding」指定 Body 的压缩方式，比如用 gzip 压缩，这样可以节约带宽，但报文中的另外一部分 Header，是没有针对它的优化手段。</p><p>HTTP/1.1 报文中 Header 部分存在的问题：</p><ul><li>含很多固定的字段，比如 Cookie、User Agent、Accept 等，这些字段加起来也高达几百字节甚至上千字节，所以有必要<strong>压缩</strong>；</li><li>大量的请求和响应的报文里有很多字段值都是重复的，这样会使得大量带宽被这些冗余的数据占用了，所以有必须要<strong>避免重复性</strong>；</li><li>字段是 ASCII 编码的，虽然易于人类观察，但效率低，所以有必要改成<strong>二进制编码</strong>；</li></ul><p>HTTP/2 对 Header 部分做了大改造，把以上的问题都解决了。</p><p>HTTP/2 没使用常见的 gzip 压缩方式来压缩头部，而是开发了 <strong>HPACK</strong> 算法，HPACK 算法主要包含三个组成部分：</p><ul><li>静态字典；</li><li>动态字典；</li><li>Huffman 编码（压缩算法）；</li></ul><p>客户端和服务器两端都会建立和维护「<strong>字典</strong>」，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，<strong>可达到 50%~90% 的高压缩率</strong>。</p><h3 id="静态表编码">静态表编码</h3><p>HTTP/2 为高频出现在头部的字符串和字段建立了一张<strong>静态表</strong>，它是写入到 HTTP/2 框架里的，不会变化的，静态表里共有 <code>61</code> 组，如下图：</p><p><a href="https://camo.githubusercontent.com/fc9933adbf417e813375a55bad191a445a9ff04166269d75ba084b75823c3991/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545382541312541382e706e67"><img src="https://camo.githubusercontent.com/fc9933adbf417e813375a55bad191a445a9ff04166269d75ba084b75823c3991/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545382541312541382e706e67" alt="img"></a></p><p>表中的 <code>Index</code> 表示索引（Key），<code>Header Value</code> 表示索引对应的 Value，<code>Header Name</code> 表示字段的名字，比如 Index 为 2 代表 GET，Index 为 8 代表状态码 200。</p><p>你可能注意到，表中有的 Index 没有对应的 Header Value，这是因为这些 Value 并不是固定的而是变化的，这些 Value 都会经过 Huffman 编码后，才会发送出去。</p><p>这么说有点抽象，我们来看个具体的例子，下面这个 <code>server</code> 头部字段，在 HTTP/1.1 的形式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">server: nghttpx\r\n<br></code></pre></td></tr></table></figure><p>算上冒号空格和末尾的<code>\r\n</code>，共占用了 17 字节，<strong>而使用了静态表和 Huffman 编码，可以将它压缩成 8 字节，压缩率大概 47%</strong>。</p><p>我抓了个 HTTP/2 协议的网络包，你可以从下图看到，高亮部分就是 <code>server</code> 头部字段，只用了 8 个字节来表示 <code>server</code> 头部数据。</p><p><a href="https://camo.githubusercontent.com/c509e61780a035d9aab87a56f50af01d3bff137af3ff209760484a92ddf08122/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545372542432539362545372541302538312e706e67"><img src="https://camo.githubusercontent.com/c509e61780a035d9aab87a56f50af01d3bff137af3ff209760484a92ddf08122/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545372542432539362545372541302538312e706e67" alt="img"></a></p><p>根据 RFC7541 规范，如果头部字段属于静态表范围，并且 Value 是变化，那么它的 HTTP/2 头部前 2 位固定为 <code>01</code>，所以整个头部格式如下图：</p><p><a href="https://camo.githubusercontent.com/73609ea619387f567250bb5b99344ac81575fd8003f2f3741870b25970b69412/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545352541342542342545392538332541382e706e67"><img src="https://camo.githubusercontent.com/73609ea619387f567250bb5b99344ac81575fd8003f2f3741870b25970b69412/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545392539442539392545362538302538312545352541342542342545392538332541382e706e67" alt="img"></a></p><p>HTTP/2 头部由于基于<strong>二进制编码</strong>，就不需要冒号空格和末尾的\r\n作为分隔符，于是改用表示字符串长度（Value Length）来分割 Index 和 Value。</p><p>接下来，根据这个头部格式来分析上面抓包的 <code>server</code> 头部的二进制数据。</p><p>首先，从静态表中能查到 <code>server</code> 头部字段的 Index 为 54，二进制为 110110，再加上固定 01，头部格式第 1 个字节就是 <code>01110110</code>，这正是上面抓包标注的红色部分的二进制数据。</p><p>然后，第二个字节的首个比特位表示 Value 是否经过 Huffman 编码，剩余的 7 位表示 Value 的长度，比如这次例子的第二个字节为 <code>10000110</code>，首位比特位为 1 就代表 Value 字符串是经过 Huffman 编码的，经过 Huffman 编码的 Value 长度为 6。</p><p>最后，字符串 <code>nghttpx</code> 经过 Huffman 编码后压缩成了 6 个字节，Huffman 编码的原理是将高频出现的信息用「较短」的编码表示，从而缩减字符串长度。</p><p>于是，在统计大量的 HTTP 头部后，HTTP/2 根据出现频率将 ASCII 码编码为了 Huffman 编码表，可以在 RFC7541 文档找到这张<strong>静态 Huffman 表</strong>，我就不把表的全部内容列出来了，我只列出字符串 <code>nghttpx</code> 中每个字符对应的 Huffman 编码，如下图：</p><p><a href="https://camo.githubusercontent.com/66f54143bf0f8d4fa96b649bcffe64f8df59bf042f3772d079d47d5496040f96/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6e6768747470782e706e67"><img src="https://camo.githubusercontent.com/66f54143bf0f8d4fa96b649bcffe64f8df59bf042f3772d079d47d5496040f96/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6e6768747470782e706e67" alt="img"></a></p><p>通过查表后，字符串 <code>nghttpx</code> 的 Huffman 编码在下图看到，共 6 个字节，每一个字符的 Huffman 编码，我用相同的颜色将他们对应起来了，最后的 7 位是补位的。</p><p><a href="https://camo.githubusercontent.com/9c5e780a7feecc81973d9c7ded0db985df9cb9691c7e55f30f077476a82e776f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6e676874747078322e706e67"><img src="https://camo.githubusercontent.com/9c5e780a7feecc81973d9c7ded0db985df9cb9691c7e55f30f077476a82e776f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6e676874747078322e706e67" alt="img"></a></p><p>最终，<code>server</code> 头部的二进制数据对应的静态头部格式如下：</p><p><a href="https://camo.githubusercontent.com/f2461428f4180b488af4b04d9fcb9f3af8451ec5a2e773567dc5144c37872fcd/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f254539253944253939254536253830253831254535254134254234254539253833254138322e706e67"><img src="https://camo.githubusercontent.com/f2461428f4180b488af4b04d9fcb9f3af8451ec5a2e773567dc5144c37872fcd/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f254539253944253939254536253830253831254535254134254234254539253833254138322e706e67" alt="img"></a></p><h3 id="动态表编码">动态表编码</h3><p>静态表只包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建<strong>动态表</strong>，它的 Index 从 <code>62</code> 起步，会在编码解码的时候随时更新。</p><p>比如，第一次发送时头部中的「<code>User-Agent</code> 」字段数据有上百个字节，经过 Huffman 编码发送出去后，客户端和服务器双方都会更新自己的动态表，添加一个新的 Index 号 62。<strong>那么在下一次发送的时候，就不用重复发这个字段的数据了，只用发 1 个字节的 Index 号就好了，因为双方都可以根据自己的动态表获取到字段的数据</strong>。</p><p>所以，使得动态表生效有一个前提：<strong>必须同一个连接上，重复传输完全相同的 HTTP 头部</strong>。如果消息字段在 1 个连接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。</p><p>因此，随着在同一 HTTP/2 连接上发送的报文越来越多，客户端和服务器双方的「字典」积累的越来越多，理论上最终每个头部字段都会变成 1 个字节的 Index，这样便避免了大量的冗余数据的传输，大大节约了带宽。</p><p>理想很美好，现实很骨感。动态表越大，占用的内存也就越大，如果占用了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类似 <code>http2_max_requests</code> 的配置，用于限制一个连接上能够传输的请求数量，避免动态表无限增大，请求数量到达上限后，就会关闭 HTTP/2 连接来释放内存。</p><p>综上，HTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。</p><p><a href="https://camo.githubusercontent.com/70960859f8efdc1f4f20113842a7b1175a359fbc1774e1803271a90cec97f8da/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352541342542342545392538332541382545372542432539362545372541302538312e706e67"><img src="https://camo.githubusercontent.com/70960859f8efdc1f4f20113842a7b1175a359fbc1774e1803271a90cec97f8da/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352541342542342545392538332541382545372542432539362545372541302538312e706e67" alt="img"></a></p><hr><h2 id="二进制帧">二进制帧</h2><p>HTTP/2 厉害的地方在于将 HTTP/1 的文本格式改成二进制格式传输数据，极大提高了 HTTP 传输效率，而且二进制数据使用位运算能高效解析。</p><p>你可以从下图看到，HTTP/1.1 的响应和 HTTP/2 的区别：</p><p><a href="https://camo.githubusercontent.com/1c35c3b57d9e16e9a44a4a63b83971a1e2f85344b94d45a2b42ed8b3ea3a00c0/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545342542412538432545382542462539422545352538382542362545352542382541372e706e67"><img src="https://camo.githubusercontent.com/1c35c3b57d9e16e9a44a4a63b83971a1e2f85344b94d45a2b42ed8b3ea3a00c0/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545342542412538432545382542462539422545352538382542362545352542382541372e706e67" alt="img"></a></p><p>HTTP/2 把响应报文划分成了两类<strong>帧（*Frame*）</strong>，图中的 HEADERS（首部）和 DATA（消息负载） 是帧的类型，也就是说一条 HTTP 响应，划分成了两类帧来传输，并且采用二进制来编码。</p><p>比如状态码 200 ，在 HTTP/1.1 是用 ‘2’‘0’‘0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节，如下图</p><p><a href="https://camo.githubusercontent.com/78e918cfe0abcd0ddc68ac0f1fbc39c4c9d2bd1d295d5e16637e560d4532a843/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f68747470312e706e67"><img src="https://camo.githubusercontent.com/78e918cfe0abcd0ddc68ac0f1fbc39c4c9d2bd1d295d5e16637e560d4532a843/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f68747470312e706e67" alt="img"></a></p><p>在 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节，如下图：</p><p><a href="https://camo.githubusercontent.com/1b1c3d619520c83b8f8bfe1d5f5d99760db554599edcfebed7d4ad39492884cc/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6832632e706e67"><img src="https://camo.githubusercontent.com/1b1c3d619520c83b8f8bfe1d5f5d99760db554599edcfebed7d4ad39492884cc/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f6832632e706e67" alt="img"></a></p><p>Header: :status: 200 OK 的编码内容为：1000 1000，那么表达的含义是什么呢？</p><p><a href="https://camo.githubusercontent.com/0fe7d5b992d7dd2a5a1720185653d5ba7d946efd749cfdbe441d72aef12e0737/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f696e6465782e706e67"><img src="https://camo.githubusercontent.com/0fe7d5b992d7dd2a5a1720185653d5ba7d946efd749cfdbe441d72aef12e0737/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f696e6465782e706e67" alt="img"></a></p><ol><li>最前面的 1 标识该 Header 是静态表中已经存在的 KV。</li><li>我们再回顾一下之前的静态表内容，“:status: 200 OK”其静态表编码是 8，即 1000。</li></ol><p>因此，整体加起来就是 1000 1000。</p><p>HTTP/2 <strong>二进制帧</strong>的结构如下图：</p><p><a href="https://camo.githubusercontent.com/66ea435b7b3d6426bb30bec91500f4519664fd70386e4dad88f2083f75345e04/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352542382541372545362541302542432545352542432538462e706e67"><img src="https://camo.githubusercontent.com/66ea435b7b3d6426bb30bec91500f4519664fd70386e4dad88f2083f75345e04/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352542382541372545362541302542432545352542432538462e706e67" alt="img"></a></p><p>帧头（Frame Header）很小，只有 9 个字节，帧开头的前 3 个字节表示帧数据（Frame Playload）的<strong>长度</strong>。</p><p>帧长度后面的一个字节是表示<strong>帧的类型</strong>，HTTP/2 总共定义了 10 种类型的帧，一般分为<strong>数据帧</strong>和<strong>控制帧</strong>两类，如下表格：</p><p><a href="https://camo.githubusercontent.com/e8f362b07067ff98b717e6477468eca69876a44dd2eb9010a7e785ccf57899a0/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352542382541372545372542312542422545352539452538422e706e67"><img src="https://camo.githubusercontent.com/e8f362b07067ff98b717e6477468eca69876a44dd2eb9010a7e785ccf57899a0/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f2545352542382541372545372542312542422545352539452538422e706e67" alt="img"></a></p><p>帧类型后面的一个字节是<strong>标志位</strong>，可以保存 8 个标志位，用于携带简单的控制信息，比如：</p><ul><li><strong>END_HEADERS</strong> 表示头数据结束标志，相当于 HTTP/1 里头后的空行（“\r\n”）；</li><li><strong>END_Stream</strong> 表示单方向数据发送结束，后续不会再有数据帧。</li><li><strong>PRIORITY</strong> 表示流的优先级；</li></ul><p>帧头的最后 4 个字节是<strong>流标识符</strong>（Stream ID），但最高位被保留不用，只有 31 位可以使用，因此流标识符的最大值是 2^31，大约是 21 亿，它的作用是用来标识该 Frame 属于哪个 Stream，接收方可以根据这个信息从乱序的帧里找到相同 Stream ID 的帧，从而有序组装信息。</p><p>最后面就是<strong>帧数据</strong>了，它存放的是通过 <strong>HPACK 算法</strong>压缩过的 HTTP 头部和包体。</p><hr><h2 id="并发传输">并发传输</h2><p>知道了 HTTP/2 的帧结构后，我们再来看看它是如何实现<strong>并发传输</strong>的。</p><p>我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了<strong>队头阻塞</strong>的问题。</p><p>而 HTTP/2 就很牛逼了，通过 Stream 这个设计，<strong>多个 Stream 复用一条 TCP 连接，达到并发的效果</strong>，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。</p><p>为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。</p><p><a href="https://camo.githubusercontent.com/eac74b0353c82f43301e48df402dceba83c7cfc652cc1160e62cba22b08042df/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f73747265616d2e706e67"><img src="https://camo.githubusercontent.com/eac74b0353c82f43301e48df402dceba83c7cfc652cc1160e62cba22b08042df/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f73747265616d2e706e67" alt="img"></a></p><p>你可以从上图中看到：</p><ul><li>1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；</li><li>Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；</li><li>Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；</li></ul><p>因此，我们可以得出个结论：多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。</p><p><a href="https://camo.githubusercontent.com/128362dd941849f0b1f34f32e80d8ca2c4c1fdb2cb454be65adc99da2c94470b/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f73747265616d322e706e67"><img src="https://camo.githubusercontent.com/128362dd941849f0b1f34f32e80d8ca2c4c1fdb2cb454be65adc99da2c94470b/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f73747265616d322e706e67" alt="img"></a></p><p>在 HTTP/2 连接上，<strong>不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）</strong>，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而<strong>同一 Stream 内部的帧必须是严格有序的</strong>。</p><p>比如下图，服务端<strong>并行交错地</strong>发送了两个响应： Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息。</p><p><a href="https://camo.githubusercontent.com/27096f135de66a7d4a2f71c3eedba56437cbdb066a1b2b76c5ecf86db236541e/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f68747470322545352541342539412545382542372541462545352541342538442545372539342541382e6a706567"><img src="https://camo.githubusercontent.com/27096f135de66a7d4a2f71c3eedba56437cbdb066a1b2b76c5ecf86db236541e/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f6e6574776f726b2f687474702f68747470322545352541342539412545382542372541462545352541342538442545372539342541382e6a706567" alt="img"></a></p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>，因为服务端可以主动推送资源给客户端， 客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><p>比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字 1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和 4）。</p><p><a href="https://camo.githubusercontent.com/dbc0b26395aeefa91d48c1e7dc38d2497096e62e2e6e2e816e9a5caba039c5f6/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f38333434353538316461666534303964386366643263353733623237383161632e706e67"><img src="https://camo.githubusercontent.com/dbc0b26395aeefa91d48c1e7dc38d2497096e62e2e6e2e816e9a5caba039c5f6/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f38333434353538316461666534303964386366643263353733623237383161632e706e67" alt="img"></a></p><p>同一个连接中的 Stream ID 是不能复用的，只能顺序递增，所以当 Stream ID 耗尽时，需要发一个控制帧 <code>GOAWAY</code>，用来关闭 TCP 连接。</p><p>在 Nginx 中，可以通过 <code>http2_max_concurrent_Streams</code> 配置来设置 Stream 的上限，默认是 128 个。</p><p>HTTP/2 通过 Stream 实现的并发，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，<strong>因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过 TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。</strong></p><p>HTTP/2 还可以对每个 Stream 设置不同<strong>优先级</strong>，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS 和图片资源时，希望服务器先传递 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来实现，以此提高用户体验。</p><h2 id="服务器主动推送资源">服务器主动推送资源</h2><p>HTTP/1.1 不支持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资源。</p><p>比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：</p><p><a href="https://camo.githubusercontent.com/96422ef88f8ec2e5f74197e309314dfb773ff344e3c17eacec88a258970e688a/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f707573682e706e67"><img src="https://camo.githubusercontent.com/96422ef88f8ec2e5f74197e309314dfb773ff344e3c17eacec88a258970e688a/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f707573682e706e67" alt="img"></a></p><p>如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。</p><p>在 Nginx 中，如果你希望客户端访问 /test.html 时，服务器直接推送 /test.css，那么可以这么配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">location /test.html &#123; <br>  http2_push /test.css; <br>&#125;<br></code></pre></td></tr></table></figure><p>那 HTTP/2 的推送是怎么实现的？</p><p>客户端发起的请求，必须使用的是奇数号 Stream，服务器主动的推送，使用的是偶数号 Stream。服务器在推送资源时，会通过 <code>PUSH_PROMISE</code> 帧传输 HTTP 头部，并通过帧中的 <code>Promised Stream ID</code> 字段告知客户端，接下来会在哪个偶数号 Stream 中发送包体。</p><p><a href="https://camo.githubusercontent.com/0c97615e843d3d76e7b1c152848d479b39927c79d983fdb0610980bdcf0632fb/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f70757368322e706e67"><img src="https://camo.githubusercontent.com/0c97615e843d3d76e7b1c152848d479b39927c79d983fdb0610980bdcf0632fb/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470322f70757368322e706e67" alt="img"></a></p><p>如上图，在 Stream 1 中通知客户端 CSS 资源即将到来，然后在 Stream 2 中发送 CSS 资源，注意 Stream 1 和 2 是可以<strong>并发</strong>的。</p><hr><h2 id="总结">总结</h2><p>HTTP/2 协议其实还有很多内容，比如流控制、流状态、依赖关系等等。</p><p>这次主要介绍了关于 HTTP/2 是如何提升性能的几个方向，它相比 HTTP/1 大大提高了传输效率、吞吐能力。</p><p>第一点，对于常见的 HTTP 头部通过<strong>静态表和 Huffman 编码</strong>的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立<strong>动态表</strong>，将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。</p><p>不过，动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，因此服务器需要限制 HTTP/2 连接时长或者请求次数。</p><p>第二点，<strong>HTTP/2 实现了 Stream 并发</strong>，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 可以并发，即使乱序发送帧也没问题，比如发送 A 请求帧 1 -&gt; B 请求帧 1 -&gt; A 请求帧 2 -&gt; B 请求帧2，但是同一个 Stream 里的帧必须严格有序。</p><p>另外，可以根据资源的渲染顺序来设置 Stream 的<strong>优先级</strong>，从而提高用户体验。</p><p>第三点，<strong>服务器支持主动推送资源</strong>，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。</p><p>HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。</p><p><strong>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</strong></p><p>有没有什么解决方案呢？既然是 TCP 协议自身的问题，那干脆放弃 TCP 协议，转而使用 UDP 协议作为传输层协议，这个大胆的决定，HTTP/3 协议做了！</p><p><a href="https://camo.githubusercontent.com/8fc01fbb786ca5745f6eeeef9c3200223914ba96df7153aada1a166070ad530f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f32372d48545450332e706e67"><img src="https://camo.githubusercontent.com/8fc01fbb786ca5745f6eeeef9c3200223914ba96df7153aada1a166070ad530f/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f485454502f32372d48545450332e706e67" alt="img"></a></p>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTPS 如何优化？</title>
    <link href="/2021/05/06/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/05.HTTPS%20%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F/"/>
    <url>/2021/05/06/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/05.HTTPS%20%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<p>由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应用数据套了个「保护伞」，提高安全性的同时也带来了性能消耗。</p><p>因为 HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，<strong>目的是为了通过非对称加密握手协商或者交换出对称加密密钥</strong>，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密/解密。</p><p>为了数据的安全性，我们不得不使用 HTTPS 协议，至今大部分网址都已从 HTTP 迁移至 HTTPS 协议，因此针对 HTTPS 的优化是非常重要的。</p><p>这次，就从多个角度来优化 HTTPS。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/%E4%BC%98%E5%8C%96https%E6%8F%90%E7%BA%B2.png" alt="img"></p><hr><h2 id="分析性能损耗">分析性能损耗</h2><p>既然要对 HTTPS 优化，那得清楚哪些步骤会产生性能消耗，再对症下药。</p><p>产生性能消耗的两个环节：</p><ul><li>第一个环节， TLS 协议握手过程；</li><li>第二个环节，握手后的对称加密报文传输。</li></ul><p>对于第二环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说非常地小。</p><p>而第一个环节，TLS 协议握手过程不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：</p><ul><li>对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；</li><li>客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；</li><li>双方计算 Pre-Master，也就是对称加密密钥；</li></ul><p>为了大家更清楚这些步骤在 TLS 协议握手的哪一个阶段，我画出了这幅图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls%E6%80%A7%E8%83%BD%E6%8D%9F%E8%80%97.png" alt="img"></p><hr><h2 id="硬件优化">硬件优化</h2><p>玩游戏时，如果我们怎么都战胜不了对方，那么有一个最有效、最快的方式来变强，那就是「充钱」，如果还是不行，那说明你充的钱还不够多。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/%E5%85%85%E9%92%B1.jpg" alt="img"></p><p>对于计算机里也是一样，软件都是跑在物理硬件上，硬件越牛逼，软件跑的也越快，所以如果要优化 HTTPS 优化，最直接的方式就是花钱买性能参数更牛逼的硬件。</p><p>但是花钱也要花对方向，<strong>HTTPS 协议是计算密集型，而不是 I/O 密集型</strong>，所以不能把钱花在网卡、硬盘等地方，应该花在 CPU 上。</p><p>一个好的 CPU，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速 TLS 握手过程。</p><p>另外，如果可以，应该选择可以<strong>支持 AES-NI 特性的 CPU</strong>，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。</p><p>如果你的服务器是 Linux 系统，那么你可以使用下面这行命令查看 CPU 是否支持 AES-NI 指令集：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/aesni_intel.png" alt="img"></p><p>如果我们的 CPU 支持 AES-NI 特性，那么对于对称加密的算法应该选择 AES 算法。否则可以选择 ChaCha20 对称加密算法，因为 ChaCha20 算法的运算指令相比 AES 算法会对 CPU 更友好一点。</p><hr><h2 id="软件优化">软件优化</h2><p>如果公司预算充足对于新的服务器是可以考虑购买更好的 CPU，但是对于已经在使用的服务器，硬件优化的方式可能就不太适合了，于是就要从软件的方向来优化了。</p><p>软件的优化方向可以分层两种，一个是<strong>软件升级</strong>，一个是<strong>协议优化</strong>。</p><p>先说第一个软件升级，软件升级就是将正在使用的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。比如：</p><ul><li>将 Linux 内核从 2.x 升级到 4.x；</li><li>将 OpenSSL 从 1.0.1 升级到 1.1.1；</li><li>…</li></ul><p>看似简单的软件升级，对于有成百上千服务器的公司来说，软件升级也跟硬件升级同样是一个棘手的问题，因为要实行软件升级，会花费时间和人力，同时也存在一定的风险，也可能会影响正常的线上服务。</p><p>既然如此，我们把目光放到协议优化，也就是在现有的环节下，通过较小的改动，来进行优化。</p><hr><h2 id="协议优化">协议优化</h2><p>协议的优化就是对「密钥交换过程」进行优化。</p><h3 id="密钥交换算法优化">密钥交换算法优化</h3><p>TLS 1.2 版本如果使用的是 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 2 RTT，才可以进行应用数据的传输，而且 RSA 密钥交换算法不具备前向安全性。</p><p>总之使用 <strong>RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高</strong>。</p><p>因此如果可以，尽量<strong>选用 ECDHE 密钥交换</strong>算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 <strong>TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性</strong>。</p><p>ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量<strong>选择 x25519 曲线</strong>，该曲线是目前最快的椭圆曲线。</p><p>比如在 Nginx 上，可以使用 ssl_ecdh_curve 指令配置想使用的椭圆曲线，把优先使用的放在前面：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ssl_ecdh_curve.png" alt="img"></p><p>对于对称加密算法方面，如果对安全性不是特别高的要求，可以<strong>选用 AES_128_GCM</strong>，它比 AES_256_GCM 快一些，因为密钥的长度短一些。</p><p>比如在 Nginx 上，可以使用 ssl_ciphers 指令配置想使用的非对称加密算法和对称加密算法，也就是密钥套件，而且把性能最快最安全的算法放在最前面：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ssl_ciphers.png" alt="img"></p><h3 id="TLS-升级">TLS 升级</h3><p>当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，<strong>完成 TLS 握手只要 1 RTT</strong>，而且安全性更高。</p><p>在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握手过程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png" alt="img"></p><p>上图的右边部分就是 TLS 1.3 的握手过程，可以发现 <strong>TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手</strong>。</p><p>怎么合并的呢？具体的做法是，客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。</p><p>服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。</p><p>而且，TLS1.3 对密码套件进行“减肥”了， <strong>对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法</strong>。</p><p>对于对称加密和签名算法，只支持目前最安全的几个密码套件，比如 openssl 中仅支持下面 5 种密码套件：</p><ul><li>TLS_AES_256_GCM_SHA384</li><li>TLS_CHACHA20_POLY1305_SHA256</li><li>TLS_AES_128_GCM_SHA256</li><li>TLS_AES_128_CCM_8_SHA256</li><li>TLS_AES_128_CCM_SHA256</li></ul><p>之所以 TLS1.3 仅支持这么少的密码套件，是因为 TLS1.2 由于支持各种古老且不安全的密码套件，中间人可以利用降级攻击，伪造客户端的 Client Hello 消息，替换客户端支持的密码套件为一些不安全的密码套件，使得服务器被迫使用这个密码套件进行 HTTPS 连接，从而破解密文。</p><hr><h2 id="证书优化">证书优化</h2><p>为了验证的服务器的身份，服务器会在 TLS 握手过程中，把自己的证书发给客户端，以此证明自己身份是可信的。</p><p>对于证书的优化，可以有两个方向：</p><ul><li>一个是<strong>证书传输</strong>，</li><li>一个是<strong>证书验证</strong>；</li></ul><h3 id="证书传输优化">证书传输优化</h3><p>要让证书更便于传输，那必然是减少证书的大小，这样可以节约带宽，也能减少客户端的运算量。所以，<strong>对于服务器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥长度比 RSA 短的多</strong>。</p><h3 id="证书验证优化">证书验证优化</h3><p>客户端在验证证书时，是个复杂的过程，会走证书链逐级验证，验证的过程不仅需要「用 CA 公钥解密证书」以及「用签名算法验证证书的完整性」，而且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL 或者 OCSP 数据，以此确认证书的有效性。</p><p>这个访问过程是 HTTP 访问，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。</p><h4 id="CRL">CRL</h4><p>CRL 称为证书吊销列表（<em>Certificate Revocation List</em>），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/crl.png" alt="img"></p><p>但是 CRL 存在两个问题：</p><ul><li>第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，<strong>实时性较差</strong>；</li><li>第二个问题，<strong>随着吊销证书的增多，列表会越来越大，下载的速度就会越慢</strong>，下载完客户端还得遍历这么大的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 HTTPS 连接。</li></ul><h4 id="OCSP">OCSP</h4><p>因此，现在基本都是使用 OCSP ，名为在线证书状态协议（<em>Online Certificate Status Protocol</em>）来查询证书的有效性，它的工作方式是<strong>向 CA 发送查询请求，让 CA 返回证书的有效状态</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ocsp.png" alt="img"></p><p>不必像 CRL 方式客户端需要下载大大的列表，还要从列表查询，同时因为可以实时查询每一张证书的有效性，解决了 CRL 的实时性问题。</p><p>OCSP 需要向 CA 查询，因此也是要发生网络请求，而且还得看 CA 服务器的“脸色”，如果网络状态不好，或者 CA 服务器繁忙，也会导致客户端在校验证书这一环节的延时变大。</p><h4 id="OCSP-Stapling">OCSP Stapling</h4><p>于是为了解决这一个网络开销，就出现了 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/opscp-stapling.png" alt="img"></p><p>当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握手过程中发给客户端。由于有签名的存在，服务器无法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。</p><hr><h2 id="会话复用">会话复用</h2><p>TLS 握手的目的就是为了协商出会话密钥，也就是对称加密密钥，那我们如果我们把首次 TLS 握手协商的对称加密密钥缓存起来，待下次需要建立 HTTPS 连接时，直接「复用」这个密钥，不就减少 TLS 握手的性能损耗了吗？</p><p>这种方式就是<strong>会话复用</strong>（<em>TLS session resumption</em>），会话复用分两种：</p><ul><li>第一种叫 Session ID；</li><li>第二种叫 Session Ticket；</li></ul><h3 id="Session-ID">Session ID</h3><p>Session ID 的工作原理是，<strong>客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识</strong>，Session ID 和会话密钥相当于 key-value 的关系。</p><p>当客户端再次连接时，hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然为了安全性，内存中的会话密钥会定期失效。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/sessionid.png" alt="img"></p><p>但是它有两个缺点：</p><ul><li>服务器必须保持每一个客户端的会话密钥，随着客户端的增多，<strong>服务器的内存压力也会越大</strong>。</li><li>现在网站服务一般是由多台服务器通过负载均衡提供服务的，<strong>客户端再次连接不一定会命中上次访问过的服务器</strong>，于是还要走完整的 TLS 握手过程；</li></ul><h3 id="Session-Ticket">Session Ticket</h3><p>为了解决 Session ID 的问题，就出现了 Session Ticket，<strong>服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端</strong>，类似于 HTTP 的 Cookie。</p><p>客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。</p><p>客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ticket.png" alt="img"></p><p>对于集群服务器的话，<strong>要确保每台服务器加密 「会话密钥」的密钥是一致的</strong>，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。</p><p>Session ID 和 Session Ticket <strong>都不具备前向安全性</strong>，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。</p><p>同时应对<strong>重放攻击</strong>也很困难，这里简单介绍下重放攻击工作的原理。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB.png" alt="img"></p><p>假设 Alice 想向 Bob 证明自己的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。</p><p>交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后一个会话中读取的 Alice 的密码（或哈希），从而授予 Eve 访问权限。</p><p>重放攻击的危险之处在于，如果中间人截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报文，而一般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数据库的数据被中间人改变了，而客户是不知情的。</p><p>避免重放攻击的方式就是需要<strong>对会话密钥设定一个合理的过期时间</strong>。</p><h3 id="Pre-shared-Key">Pre-shared Key</h3><p>前面的 Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。</p><p>而 TLS1.3 更为牛逼，对于重连 TLS1.3 只需要 <strong>0 RTT</strong>，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 <strong>Pre-shared Key</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/0-RTT.png" alt="img"></p><p>同样的，Pre-shared Key 也有重放攻击的危险。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/0-rtt-attack.png" alt="img"></p><p>如上图，假设中间人通过某种方式，截获了客户端使用会话重用技术的 POST 请求，通常 POST 请求是会改变数据库的数据，然后中间人就可以把截获的这个报文发送给服务器，服务器收到后，也认为是合法的，于是就恢复会话，致使数据库的数据又被更改，但是此时用户是不知情的。</p><p>所以，应对重放攻击可以给会话密钥设定一个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使用会话重用。</p><hr><h2 id="总结">总结</h2><p>对于硬件优化的方向，因为 HTTPS 是属于计算密集型，应该选择计算力更强的 CPU，而且最好选择<strong>支持 AES-NI 特性的 CPU</strong>，这个特性可以在硬件级别优化 AES 对称加密算法，加快应用数据的加解密。</p><p>对于软件优化的方向，如果可以，把软件升级成较新的版本，比如将 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1 升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。</p><p>对于协议优化的方向：</p><ul><li>密钥交换算法应该选择 <strong>ECDHE 算法</strong>，而不用 RSA 算法，因为 ECDHE 算法具备前向安全性，而且客户端可以在第三次握手之后，就发送加密应用数据，节省了 1 RTT。</li><li>将 TLS1.2 升级 <strong>TLS1.3</strong>，因为 TLS1.3 的握手过程只需要 1 RTT，而且安全性更强。</li></ul><p>对于证书优化的方向：</p><ul><li>服务器应该选用 <strong>ECDSA 证书</strong>，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率；</li><li>服务器应该开启 <strong>OCSP Stapling</strong> 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；</li></ul><p>对于重连 HTTPS 时，我们可以使用一些技术让客户端和服务端使用上一次 HTTPS 连接使用的会话密钥，直接恢复会话，而不用再重新走完整的 TLS 握手过程。</p><p>常见的<strong>会话重用</strong>技术有 Session ID 和 Session Ticket，用了会话重用技术，当再次重连 HTTPS 时，只需要 1 RTT 就可以恢复会话。对于 TLS1.3 使用 Pre-shared Key 会话重用技术，只需要 0 RTT 就可以恢复会话。</p><p>这些会话重用技术虽然好用，但是存在一定的安全风险，它们不仅不具备前向安全，而且有重放攻击的风险，所以应当对会话密钥设定一个合理的过期时间。</p>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTPS ECDHE 握手解析</title>
    <link href="/2021/05/05/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/04.HTTPS%20ECDHE%20%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90/"/>
    <url>/2021/05/05/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/04.HTTPS%20ECDHE%20%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1>HTTPS ECDHE 握手解析</h1><p>HTTPS 常用的密钥交换算法有两种，分别是 RSA 和 ECDHE 算法。</p><p>其中，RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法具有前向安全，所以被广泛使用。</p><p>我在上一篇已经介绍了 <a href="https://mp.weixin.qq.com/s/U9SRLE7jZTB6lUZ6c8gTKg">RSA 握手的过程 (opens new window)</a>，今天这一篇就「从理论再到实战抓包」介绍 <strong>ECDHE 算法</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ecdhe%E6%8F%90%E7%BA%B2.png" alt="img"></p><hr><h2 id="离散对数">离散对数</h2><p>ECDHE 密钥协商算法是 DH 算法演进过来的，所以我们先从 DH 算法说起。</p><p>DH 算法是非对称加密算法， 因此它可以用于密钥交换，该算法的核心数学思想是<strong>离散对数</strong>。</p><p>是不是听到这个数学概念就怂了？不怕，这次不会说离散对数推导的过程，只简单提一下它的数学公式。</p><p>离散对数是「离散 + 对数」的两个数学概念的组合，所以我们先来复习一遍对数。</p><p>要说起对数，必然要说指数，因为它们是互为反函数，指数就是幂运算，对数是指数的逆运算。</p><p>举个栗子，如果以 2 作为底数，那么指数和对数运算公式，如下图所示：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E6%8C%87%E6%95%B0%E4%B8%8E%E5%AF%B9%E6%95%B0.png" alt="img"></p><p>那么对于底数为 2 的时候， 32 的对数是 5，64 的对数是 6，计算过程如下：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E6%B1%82%E5%AF%B9%E6%95%B0.png" alt="img"></p><p>对数运算的取值是可以连续的，而离散对数的取值是不能连续的，因此也以「离散」得名，</p><p>离散对数是在对数运算的基础上加了「模运算」，也就说取余数，对应编程语言的操作符是「%」，也可以用 mod 表示。离散对数的概念如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0.png" alt="img"></p><p>上图的，底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。</p><p><strong>特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。</strong></p><hr><h2 id="DH-算法">DH 算法</h2><p>认识了离散对数，我们来看看 DH 算法是如何密钥交换的。</p><p>现假设小红和小明约定使用 DH 算法来交换密钥，那么基于离散对数，小红和小明需要先确定模数和底数作为算法的参数，这两个参数是公开的，用 P 和 G 来代称。</p><p>然后小红和小明各自生成一个随机整数作为<strong>私钥</strong>，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称。</p><p>现在小红和小明双方都有了 P 和 G 以及各自的私钥，于是就可以计算出<strong>公钥</strong>：</p><ul><li>小红的公钥记作 A，A = G ^ a ( mod P )；</li><li>小明的公钥记作 B，B = G ^ b ( mod P )；</li></ul><p>A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有计算机的计算能力是无法破解的，如果量子计算机出来了，那就有可能被破解，当然如果量子计算机真的出来了，那么密钥协商算法就要做大的升级了。</p><p>双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。</p><p>然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/dh%E7%AE%97%E6%B3%95.png" alt="img"></p><p>这个 K 就是小红和小明之间用的<strong>对称加密密钥</strong>，可以作为会话密钥使用。</p><p>可以看到，整个密钥协商过程中，小红和小明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B 是公钥，而 a、b 是双方各自保管的私钥，黑客无法获取这 2 个私钥，因此黑客只能从公开的 P、G、A、B 入手，计算出离散对数（私钥）。</p><p>前面也多次强调， 根据离散对数的原理，如果 P 是一个大数，在现有的计算机的计算能力是很难破解出 私钥 a、b 的，破解不出私钥，也就无法计算出会话密钥，因此 DH 密钥交换是安全的。</p><hr><h2 id="DHE-算法">DHE 算法</h2><p>根据私钥生成的方式，DH 算法分为两种实现：</p><ul><li>static DH 算法，这个是已经被废弃了；</li><li>DHE 算法，现在常用的；</li></ul><p>static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。</p><p>于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 <strong>static DH 算法不具备前向安全性</strong>。</p><p>既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。</p><p>所以，即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为<strong>每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」</strong>。</p><hr><h2 id="ECDHE-算法">ECDHE 算法</h2><p>DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— <strong>ECDHE 算法</strong>。</p><p>ECDHE 算法是在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。</p><p>小红和小明使用 ECDHE 密钥交换算法的过程：</p><ul><li>双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；</li><li>双方各自随机生成一个随机数作为<strong>私钥d</strong>，并与基点 G相乘得到<strong>公钥Q</strong>（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；</li><li>双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此<strong>双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥</strong>。</li></ul><p>这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。</p><hr><h2 id="ECDHE-握手过程">ECDHE 握手过程</h2><p>知道了 ECDHE 算法基本原理后，我们就结合实际的情况来看看。</p><p>我用 Wireshark 工具抓了用 ECDHE 密钥协商算法的 TSL 握手过程，可以看到是四次握手：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_tls%E6%8F%A1%E6%89%8B.png" alt="img"></p><p>细心的小伙伴应该发现了，<strong>使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据</strong>，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。</p><p>所以，<strong>ECDHE 相比 RSA 握手过程省去了一个消息往返的时间</strong>，这个有点「抢跑」的意思，它被称为是「<em>TLS False Start</em>」，跟「<em>TCP Fast Open</em>」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。</p><p>接下来，分析每一个 ECDHE 握手过程。</p><h3 id="TLS-第一次握手">TLS 第一次握手</h3><p>客户端首先会发一个「<strong>Client Hello</strong>」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（*Client Random*）</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_clinethello.png" alt="img"></p><h3 id="TLS-第二次握手">TLS 第二次握手</h3><p>服务端收到客户端的「打招呼」，同样也要回礼，会返回「<strong>Server Hello</strong>」消息，消息面有服务器确认的 TLS 版本号，也给出了一个<strong>随机数（*Server Random*）</strong>，然后从客户端的密码套件列表选择了一个合适的密码套件。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_serverhello.png" alt="img"></p><p>不过，这次选择的密码套件就和 RSA 不一样了，我们来分析一下这次的密码套件的意思。</p><p>「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」</p><ul><li>密钥协商算法使用 ECDHE；</li><li>签名算法使用 RSA；</li><li>握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM；</li><li>摘要算法使用 SHA384；</li></ul><p>接着，服务端为了证明自己的身份，发送「<strong>Certificate</strong>」消息，会把证书也发给客户端。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_certificate.png" alt="img"></p><p>这一步就和 RSA 握手过程有很大的区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「<strong>Server Key Exchange</strong>」消息。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_serverkey.png" alt="img"></p><p>这个过程服务器做了三件事：</p><ul><li>选择了<strong>名为 x25519 的椭圆曲线</strong>，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；</li><li>生成随机数作为服务端椭圆曲线的私钥，保留到本地；</li><li>根据基点 G 和私钥计算出<strong>服务端的椭圆曲线公钥</strong>，这个会公开给客户端。</li></ul><p>为了保证这个椭圆曲线的公钥不被第三方篡改，服务端会用 RSA 签名算法给服务端的椭圆曲线公钥做个签名。</p><p>随后，就是「<strong>Server Hello Done</strong>」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_serverhellodone.png" alt="img"></p><p>至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息：<strong>Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥</strong>，这几个信息很重要，是后续生成会话密钥的材料。</p><h3 id="TLS-第三次握手">TLS 第三次握手</h3><p>客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。</p><p>客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成<strong>客户端的椭圆曲线公钥</strong>，然后用「<strong>Client Key Exchange</strong>」消息发给服务端。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_clientkeyexchange.png" alt="img"></p><p>至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，<strong>但实际应用中，x 还不是最终的会话密钥</strong>。</p><p>还记得 TLS 握手阶段，客户端和服务端都会生成了一个随机数传递给对方吗？</p><p><strong>最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的</strong>。</p><p>之所以这么麻烦，是因为 TLS 设计者不信任客户端或服务器「伪随机数」的可靠性，为了保证真正的完全随机，把三个不可靠的随机数混合起来，那么「随机」的程度就非常高了，足够让黑客计算不出最终的会话密钥，安全性更高。</p><p>算好会话密钥后，客户端会发一个「<strong>Change Cipher Spec</strong>」消息，告诉服务端后续改用对称算法加密通信。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_schangecipherspec.png" alt="img"></p><p>接着，客户端会发「<strong>Encrypted Handshake Message</strong>」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/ech_encryptedhandshakemessage.png" alt="img"></p><h3 id="TLS-第四次握手">TLS 第四次握手</h3><p>最后，服务端也会有一个同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。</p><hr><h2 id="总结">总结</h2><p>RSA 和 ECDHE 握手过程的区别：</p><ul><li>RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；</li><li>使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）；</li><li>使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息；</li></ul>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP1.1如何优化</title>
    <link href="/2021/05/04/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/02.HTTP1.1%20%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F/"/>
    <url>/2021/05/04/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/02.HTTP1.1%20%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1>HTTP1.1如何优化</h1><p>问你一句：「<strong>你知道 HTTP/1.1 该如何优化吗？</strong>」</p><p>我们可以从下面这三种优化思路来优化 HTTP/1.1 协议：</p><ul><li><em>尽量避免发送 HTTP 请求</em>；</li><li><em>在需要发送 HTTP 请求时，考虑如何减少请求次数</em>；</li><li><em>减少服务器的 HTTP 响应的数据大小</em>；</li></ul><p>下面，就针对这三种思路具体看看有哪些优化方法。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E4%BC%98%E5%8C%96http1.1%E6%8F%90%E7%BA%B2.png" alt="img"></p><hr><h2 id="如何避免发送-HTTP-请求？">如何避免发送 HTTP 请求？</h2><p>这个思路你看到是不是觉得很奇怪，不发送 HTTP 请求，那客户端还怎么和服务器交互数据？小林你这不是耍流氓嘛？</p><p>冷静冷静，你说的没错，客户端当然要向服务器发送请求的。</p><p>但是，对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</p><p>所以，避免发送 HTTP 请求的方法就是通过<strong>缓存技术</strong>，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。</p><p>那缓存是如何做到的呢？</p><p>客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系。</p><p>这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本地磁盘的速度肯定比网络请求快得多，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E7%BC%93%E5%AD%98%E8%AE%BF%E9%97%AE.png" alt="img"></p><p>聪明的你可能想到了，万一缓存的响应不是最新的，而客户端并不知情，那么该怎么办呢？</p><p>放心，这个问题 HTTP 设计者早已考虑到。</p><p>所以，服务器在发送 HTTP 响应时，会估算一个过期的时间，并把这个信息放到响应头部中，这样客户端在查看响应头部的信息时，一旦发现缓存的响应是过期的，则就会重新发送网络请求。</p><p>如果客户端从第一次请求得到的响应头部中发现该响应过期了，客户端重新发送请求，假设服务器上的资源并没有变更，还是老样子，那么你觉得还要在服务器的响应带上这个资源吗？</p><p>很显然不带的话，可以提高 HTTP 协议的性能，那具体如何做到呢？</p><p>只需要客户端在重新发送请求时，在请求的 <code>Etag</code> 头部带上第一次请求的响应头部中的摘要，这个摘要是唯一标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要做个比较。</p><p>如果不同，那么说明客户端的缓存已经没有价值，服务器在响应中带上最新的资源。</p><p>如果相同，说明客户端的缓存还是可以继续使用的，那么服务器<strong>仅返回不含有包体的 <code>304 Not Modified</code> 响应</strong>，告诉客户端仍然有效，这样就可以减少响应资源在网络中传输的延时，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E7%BC%93%E5%AD%98etag.png" alt="img"></p><p>缓存真的是性能优化的一把万能钥匙，小到 CPU Cache、Page Cache、Redis Cache，大到 HTTP 协议的缓存。</p><hr><h2 id="如何减少-HTTP-请求次数？">如何减少 HTTP 请求次数？</h2><p>减少 HTTP 请求次数自然也就提升了 HTTP 性能，可以从这 3 个方面入手：</p><ul><li><em>减少重定向请求次数</em>；</li><li><em>合并请求</em>；</li><li><em>延迟发送请求</em>；</li></ul><h3 id="减少重定向请求次数">减少重定向请求次数</h3><p>我们先来看看什么是<strong>重定向请求</strong>？</p><p>服务器上的一个资源可能由于迁移、维护等原因从 url1 移至 url2 后，而客户端不知情，它还是继续请求 url1，这时服务器不能粗暴地返回错误，而是通过 <code>302</code> 响应码和 <code>Location</code> 头部，告诉客户端该资源已经迁移至 url2 了，于是客户端需要再发送 url2 请求以获得服务器的资源。</p><p>那么，如果重定向请求越多，那么客户端就要多次发起 HTTP 请求，每一次的 HTTP 请求都得经过网络，这无疑会越降低网络性能。</p><p>另外，服务端这一方往往不只有一台服务器，比如源服务器上一级是代理服务器，然后代理服务器才与客户端通信，这时客户端重定向就会导致客户端与代理服务器之间需要 2 次消息传递，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%87%8D%E5%AE%9A%E5%90%91.png" alt="img"></p><p>如果<strong>重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了</strong>，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E5%AE%9A%E5%90%91.png" alt="img"></p><p>而且当代理服务器知晓了重定向规则后，可以进一步减少消息传递次数，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E5%AE%9A%E5%90%912.png" alt="img"></p><p>除了 <code>302</code> 重定向响应码，还有其他一些重定向的响应码，你可以从下图看到：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E9%87%8D%E5%AE%9A%E5%90%91%E5%93%8D%E5%BA%94%E7%A0%81.png" alt="img"></p><p>其中，<code>301</code> 和 <code>308</code> 响应码是告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就自动用 url2 替代 url1 访问服务器的资源。</p><h3 id="合并请求">合并请求</h3><p>如果把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着<strong>减少了重复发送的 HTTP 头部</strong>。</p><p>另外由于 HTTP/1.1 是请求响应模型，如果第一个发送的请求，未收到对应的响应，那么后续的请求就不会发送（PS：HTTP/1.1 管道模式是默认不使用的，所以讨论 HTTP/1.1 的队头阻塞问题，是不考虑管道模式的），于是为了防止单个请求的阻塞，所以<strong>一般浏览器会同时发起 5-6 个请求，每一个请求都是不同的 TCP 连接</strong>，那么如果合并了请求，也就会<strong>减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间</strong>。</p><p>接下来，具体看看合并请求的几种方式。</p><p>有的网页会含有很多小图片、小图标，有多少个小图片，客户端就要发起多少次请求。那么对于这些小图片，我们可以考虑使用 <code>CSS Image Sprites</code> 技术把它们合成一个大图片，这样浏览器就可以用一次请求获得一个大图片，然后再根据 CSS 数据把大图片切割成多张小图片。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/css%E7%B2%BE%E7%81%B5.png" alt="图来源于：墨染枫林的CSDN"></p><p>这种方式就是<strong>通过将多个小图片合并成一个大图片来减少 HTTP 请求的次数，以减少 HTTP 请求的次数，从而减少网络的开销</strong>。</p><p>除了将小图片合并成大图片的方式，还有服务端使用 <code>webpack</code> 等打包工具将 js、css 等资源合并打包成大文件，也是能达到类似的效果。</p><p>另外，还可以将图片的二进制数据用 <code>base64</code> 编码后，以 URL 的形式嵌入到 HTML 文件，跟随 HTML 文件一并发送.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;image src=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPoAAAFKCAIAAAC7M9WrAAAACXBIWXMAA ... /&gt;<br></code></pre></td></tr></table></figure><p>这样客户端收到 HTML 后，就可以直接解码出数据，然后直接显示图片，就不用再发起图片相关的请求，这样便减少了请求的次数。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/base64%E5%9B%BE%E7%89%87.png" alt="图来源于：陈健平的CSDN "></p><p>可以看到，<strong>合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求</strong>。</p><p>但是这样的合并请求会带来新的问题，<strong>当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件</strong>，这显然带来了额外的网络消耗。</p><h3 id="延迟发送请求">延迟发送请求</h3><p>不要一口气吃成大胖子，一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「<strong>按需获取</strong>」的方式，来减少第一时间的 HTTP 请求次数。</p><p>请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。</p><hr><h2 id="如何减少-HTTP-响应的数据大小？">如何减少 HTTP 响应的数据大小？</h2><p>对于 HTTP 的请求和响应，通常 HTTP 的响应的数据大小会比较大，也就是服务器返回的资源会比较大。</p><p>于是，我们可以考虑对响应的资源进行<strong>压缩</strong>，这样就可以减少响应的数据大小，从而提高网络传输的效率。</p><p>压缩的方式一般分为 2 种，分别是：</p><ul><li><em>无损压缩</em>；</li><li><em>有损压缩</em>；</li></ul><h3 id="无损压缩">无损压缩</h3><p>无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。</p><p>首先，我们针对代码的语法规则进行压缩，因为通常代码文件都有很多换行符或者空格，这些是为了帮助程序员更好的阅读，但是机器执行时并不要这些符，把这些多余的符号给去除掉。</p><p>接下来，就是无损压缩了，需要对原始资源建立统计模型，利用这个统计模型，将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较长的二进制比特序列表示，生成二进制比特序列一般是「霍夫曼编码」算法。</p><p>gzip 就是比较常见的无损压缩。客户端支持的压缩算法，会在 HTTP 请求中通过头部中的 <code>Accept-Encoding</code> 字段告诉服务器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Accept-Encoding: gzip, deflate, br<br></code></pre></td></tr></table></figure><p>服务器收到后，会从中选择一个服务器支持的或者合适的压缩算法，然后使用此压缩算法对响应资源进行压缩，最后通过响应头部中的 <code>Content-Encoding</code> 字段告诉客户端该资源使用的压缩算法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Content-Encoding: gzip<br></code></pre></td></tr></table></figure><p>gzip 的压缩效率相比 Google 推出的 Brotli 算法还是差点意思，也就是上文中的 br，所以如果可以，服务器应该选择压缩效率更高的 br 压缩算法。</p><h3 id="有损压缩">有损压缩</h3><p>与无损压缩相对的就是有损压缩，经过此方法压缩，解压的数据会与原始数据不同但是非常接近。</p><p>有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。</p><p>可以通过 HTTP 请求头部中的 <code>Accept</code> 字段里的「 q 质量因子」，告诉服务器期望的资源质量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Accept: audio/*; q=0.2, audio/basic<br></code></pre></td></tr></table></figure><p>关于图片的压缩，目前压缩比较高的是 Google 推出的 <strong>WebP 格式</strong>，它与常见的 Png 格式图片的压缩比例对比如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/webp%E4%B8%8Epng.png" alt="来源于：https://isparta.github.io/compare-webp/index.html"></p><p>可以发现，相同图片质量下，WebP 格式的图片大小都比 Png 格式的图片小，所以对于大量图片的网站，可以考虑使用 WebP 格式的图片，这将大幅度提升网络传输的性能。</p><p>关于音视频的压缩，音视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很小的。</p><p>比如，一个在看书的视频，画面通常只有人物的手和书桌上的书是会有变化的，而其他地方通常都是静态的，于是只需要在一个静态的关键帧，使用<strong>增量数据</strong>来表达后续的帧，这样便减少了很多数据，提高了网络传输的性能。对于视频常见的编码格式有 H264、H265 等，音频常见的编码格式有 AAC、AC3。</p><hr><h2 id="总结">总结</h2><p>这次主要从 3 个方面介绍了优化 HTTP/1.1 协议的思路。</p><p>第一个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。</p><p>第二个思路是，减少 HTTP 请求的次数，有以下的方法：</p><ol><li>将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；</li><li>将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；</li><li>按需访问资源，只访问当前用户看得到/用得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同一时间的 HTTP 请求次数。</li></ol><p>第三思路是，通过压缩响应资源，降低传输资源的大小，从而提高传输效率，所以应当选择更优秀的压缩算法。</p><p>不管怎么优化 HTTP/1.1 协议都是有限的，不然也不会出现 HTTP/2 和 HTTP/3 协议，后续我们再来介绍 HTTP/2 和 HTTP/3 协议。</p>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP1.1如何优化</title>
    <link href="/2021/05/04/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/03.HTTPS%20RSA%20%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90/"/>
    <url>/2021/05/04/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/03.HTTPS%20RSA%20%E6%8F%A1%E6%89%8B%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1>HTTPS RSA 握手解析</h1><p>我前面讲，简单给大家介绍了的 HTTPS 握手过程，但是还不够细！</p><p>只讲了比较基础的部分，所以这次我们再来深入一下 HTTPS，用<strong>实战抓包</strong>的方式，带大家再来窥探一次 HTTPS。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/https%E6%8F%90%E7%BA%B2.png" alt="img"></p><p>对于还不知道对称加密和非对称加密的同学，你先复习我以前的这篇文章<a href="https://mp.weixin.qq.com/s/bUy220-ect00N4gnO0697A">「硬核！30 张图解 HTTP 常见的面试题」， (opens new window)</a>本篇文章默认大家已经具备了这些知识。</p><hr><h2 id="TLS-握手过程">TLS 握手过程</h2><p>HTTP 由于是明文传输，所谓的明文，就是说客户端与服务端通信的信息都是肉眼可见的，随意使用一个抓包工具都可以截获通信的内容。</p><p>所以安全上存在以下三个风险：</p><ul><li><em>窃听风险</em>，比如通信链路上可以获取通信内容，用户号容易没。</li><li><em>篡改风险</em>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li><li><em>冒充风险</em>，比如冒充淘宝网站，用户钱容易没。</li></ul><p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 TLS 协议，来解决上述的风险。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/19-HTTPS%E4%B8%8EHTTP.png" alt="img"></p><p>TLS 协议是如何解决 HTTP 的风险的呢？</p><ul><li><em>信息加密</em>： HTTP 交互信息是被加密的，第三方就无法被窃取；</li><li><em>校验机制</em>：校验信息传输过程中是否有被第三方篡改过，如果被篡改过，则会有警告提示；</li><li><em>身份证书</em>：证明淘宝是真的淘宝网；</li></ul><p>可见，有了 TLS 协议，能保证 HTTP 通信是安全的了，那么在进行 HTTP 通信前，需要先进行 TLS 握手。TLS 的握手过程，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/tls%E6%8F%A1%E6%89%8B.png" alt="img"></p><p>上图简要概述了 TLS 的握手过程，其中每一个「框」都是一个记录（<em>record</em>），记录是 TLS 收发数据的基本单位，类似于 TCP 里的 segment。多个记录可以组合成一个 TCP 包发送，所以<strong>通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延</strong>，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。</p><p>所以可以发现，HTTPS 是应用层协议，需要先完成 TCP 连接建立，然后走 TLS 握手过程后，才能建立通信安全的连接。</p><p>事实上，不同的密钥交换算法，TLS 的握手过程可能会有一些区别。</p><p>这里先简单介绍下密钥交换算法，因为考虑到性能的问题，所以双方在加密应用信息时使用的是对称加密密钥，而对称加密密钥是不能被泄漏的，为了保证对称加密密钥的安全性，所以使用非对称加密的方式来保护对称加密密钥的协商，这个工作就是密钥交换算法负责的。</p><p>接下来，我们就以最简单的 <code>RSA</code> 密钥交换算法，来看看它的 TLS 握手过程。</p><hr><h2 id="RSA-握手过程">RSA 握手过程</h2><p>传统的 TLS 握手基本都是使用 RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书文件其实就是服务端的公钥，会在 TLS 握手阶段传递给客户端，而服务端的私钥则一直留在服务端，一定要确保私钥不能被窃取。</p><p>在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。</p><p>我用 Wireshark 工具抓了用 RSA 密钥交换的 TLS 握手过程，你可以从下面看到，一共经历了四次握手：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/tls%E5%9B%9B%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt="img"></p><p>对应 Wireshark 的抓包，我也画了一幅图，你可以从下图很清晰地看到该过程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/https_rsa.png" alt="img"></p><p>那么，接下来针对每一个 TLS 握手做进一步的介绍。</p><h3 id="TLS-第一次握手">TLS 第一次握手</h3><p>客户端首先会发一个「<strong>Client Hello</strong>」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/clienthello.png" alt="img"></p><p>消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的<strong>随机数（*Client Random*）</strong>，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。</p><h3 id="TLS-第二次握手">TLS 第二次握手</h3><p>当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成<strong>随机数（*Server Random*）</strong>。</p><p>接着，返回「<strong>Server Hello</strong>」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/serverhello.png" alt="img"></p><p>可以看到，服务端选择的密码套件是 “Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256”。</p><p>这个密码套件看起来真让人头晕，好一大串，但是其实它是有固定格式和规范的。基本的形式是「<strong>密钥交换算法 + 签名算法 + 对称加密算法 + 摘要算法</strong>」， 一般 WITH 单词前面有两个单词，第一个单词是约定密钥交换的算法，第二个单词是约定证书的验证算法。比如刚才的密码套件的意思就是：</p><ul><li>由于 WITH 单词只有一个 RSA，则说明握手时密钥交换算法和签名算法都是使用 RSA；</li><li>握手后的通信使用 AES 对称算法，密钥长度 128 位，分组模式是 GCM；</li><li>摘要算法 SHA256 用于消息认证和产生随机数；</li></ul><p>就前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 TLS 版本和使用的密码套件，而且你可能发现客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方。</p><p>那这个随机数有啥用呢？其实这两个随机数是后续作为生成「会话密钥」的条件，所谓的会话密钥就是数据传输时，所使用的对称加密密钥。</p><p>然后，服务端为了证明自己的身份，会发送「<strong>Server Certificate</strong>」给客户端，这个消息里含有数字证书。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/certificate.png" alt="img"></p><p>随后，服务端发了「<strong>Server Hello Done</strong>」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/serverhellodone.png" alt="img"></p><h3 id="客户端验证证书">客户端验证证书</h3><p>在这里刹个车，客户端拿到了服务端的数字证书后，要怎么校验该数字证书是真实有效的呢？</p><h4 id="数字证书和-CA-机构">数字证书和 CA 机构</h4><p>在说校验数字证书是否可信的过程前，我们先来看看数字证书是什么，一个数字证书通常包含了：</p><ul><li>公钥；</li><li>持有者信息；</li><li>证书认证机构（CA）的信息；</li><li>CA 对这份文件的数字签名及使用的算法；</li><li>证书有效期；</li><li>还有一些其他额外信息；</li></ul><p>那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。</p><p>我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？</p><p>为了让服务端的公钥被大家信任，服务端的证书都是由 CA （<em>Certificate Authority</em>，证书认证机构）签名的，CA 就是网络世界里的公安局、公证中心，具有极高的可信度，所以由它来给各个公钥签名，信任的一方签发的证书，那必然证书也是被信任的。</p><p>之所以要签名，是因为签名的作用可以避免中间人在获取证书时对证书内容的篡改。</p><h4 id="数字证书签发和验证流程">数字证书签发和验证流程</h4><p>如下图图所示，为数字证书签发和验证流程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" alt="img"></p><p>CA 签发证书的过程，如上图左边部分：</p><ul><li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li><li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li><li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li></ul><p>客户端校验服务端的数字证书的过程，如上图右边部分：</p><ul><li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li><li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li><li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li></ul><h4 id="证书链">证书链</h4><p>但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/baidu%E8%AF%81%E4%B9%A6.png" alt="img"></p><p>对于这种三级层级关系的证书的验证过程如下：</p><ul><li>客户端收到 <a href="http://baidu.com">baidu.com</a> 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 <a href="http://baidu.com">baidu.com</a> 证书是否可信。于是，客户端根据 <a href="http://baidu.com">baidu.com</a> 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。</li><li>请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。</li><li>“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 <a href="http://baidu.com">baidu.com</a> 证书的可信性，如果验证通过，就可以信任 <a href="http://baidu.com">baidu.com</a> 证书。</li></ul><p>在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 <a href="http://baidu.com">baidu.com</a> 证书，于是客户端也信任 <a href="http://baidu.com">baidu.com</a> 证书。</p><p>总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 <a href="http://baidu.com">baidu.com</a> 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%94%A8%E6%88%B7%E4%BF%A1%E4%BB%BB.png" alt="img"></p><p>操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%B3%BB%E7%BB%9F%E6%A0%B9%E8%AF%81%E4%B9%A6.png" alt="img"></p><p>这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E9%93%BE.png" alt="img"></p><p>最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？</p><p>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</p><h3 id="TLS-第三次握手">TLS 第三次握手</h3><p>客户端验证完证书后，认为可信则继续往下走。</p><p>接着，客户端就会生成一个新的<strong>随机数 (*pre-master*)</strong>，用服务器的 RSA 公钥加密该随机数，通过「<strong>Client Key Exchange</strong>」消息传给服务端。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/clietnkeyexchange.png" alt="img"></p><p>服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。</p><p>至此，<strong>客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master</strong>。</p><p>于是，双方根据已经得到的三个随机数，生成<strong>会话密钥（Master Secret）</strong>，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。</p><p>生成完「会话密钥」后，然后客户端发一个「<strong>Change Cipher Spec</strong>」，告诉服务端开始使用加密方式发送消息。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/cipherspecmessage.png" alt="img"></p><p>然后，客户端再发一个「<strong>Encrypted Handshake Message（Finishd）</strong>」消息，把之前所有发送的数据做个<strong>摘要</strong>，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/encryptd.png" alt="img"></p><p>可以发现，「Change Cipher Spec」之前传输的 TLS 握手数据都是明文，之后都是对称密钥加密的密文。</p><h3 id="TLS-第四次握手">TLS 第四次握手</h3><p>服务器也是同样的操作，发「<strong>Change Cipher Spec</strong>」和「<strong>Encrypted Handshake Message</strong>」消息，如果双方都验证加密和解密没问题，那么握手正式完成。</p><p>最后，就用「会话密钥」加解密 HTTP 请求和响应了。</p><hr><h2 id="RSA-算法的缺陷">RSA 算法的缺陷</h2><p><strong>使用 RSA 密钥协商算法的最大问题是不支持前向保密</strong>。</p><p>因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。</p><p>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法，关于 ECDHE 握手的过程，将在下一篇揭晓。</p>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP常见面试题</title>
    <link href="/2021/05/03/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/01.HTTP%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2021/05/03/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/04.%E7%BD%91%E7%BB%9C/01.HTTP/01.HTTP%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1>HTTP常见面试题</h1><p>在面试过程中，HTTP 被提问的概率还是比较高的。</p><p>我搜集了 6 大类 HTTP 面试常问的题目，同时这 6 大类题跟 <strong>HTTP 的发展和演变</strong>关联性是比较大的，通过<strong>问答 + 图解</strong>的形式<strong>由浅入深</strong>的方式帮助大家进一步的学习和理解 HTTP。</p><ol><li>HTTP 基本概念</li><li>Get 与 Post</li><li>HTTP 特性</li><li>HTTP 缓存技术</li><li>HTTPS 与 HTTP</li><li>HTTP/1.1、HTTP/2、HTTP/3 演变</li></ol><p><img src="https://cdn.xiaolincoding.com//mysql/other/6b9bfd38d2684b3f9843ebabf8771212.png" alt="提纲"></p><h2 id="HTTP-基本概念">HTTP 基本概念</h2><h3 id="HTTP-是什么？">HTTP 是什么？</h3><p>HTTP 是超文本传输协议，也就是<strong>H</strong>yperText <strong>T</strong>ransfer <strong>P</strong>rotocol。</p><blockquote><p>能否详细解释「超文本传输协议」？</p></blockquote><p>HTTP 的名字「超文本协议传输」，它可以拆成三个部分：</p><ul><li>超文本</li><li>传输</li><li>协议</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/3-HTTP%E4%B8%89%E9%83%A8%E5%88%86.png" alt="三个部分"></p><p><em>1. 「协议」</em></p><p>在生活中，我们也能随处可见「协议」，例如：</p><ul><li>刚毕业时会签一个「三方协议」；</li><li>找房子时会签一个「租房协议」；</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/4-%E7%A7%9F%E6%88%BF%E5%92%8C%E4%B8%89%E6%96%B9%E5%8D%8F%E8%AE%AE.png" alt="三方协议和租房协议"></p><p>生活中的协议，本质上与计算机中的协议是相同的，协议的特点:</p><ul><li>「<strong>协</strong>」字，代表的意思是必须有<strong>两个以上的参与者</strong>。例如三方协议里的参与者有三个：你、公司、学校三个；租房协议里的参与者有两个：你和房东。</li><li>「<strong>议</strong>」字，代表的意思是对参与者的一种<strong>行为约定和规范</strong>。例如三方协议里规定试用期期限、毁约金等；租房协议里规定租期期限、每月租金金额、违约如何处理等。</li></ul><p>针对 HTTP <strong>协议</strong>，我们可以这么理解。</p><p>HTTP 是一个用在计算机世界里的<strong>协议</strong>。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（<strong>两个以上的参与者</strong>），以及相关的各种控制和错误处理方式（<strong>行为约定和规范</strong>）。</p><p><em>2. 「传输」</em></p><p>所谓的「传输」，很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点 搬到 A 点。</p><p>别轻视了这个简单的动作，它至少包含两项重要的信息。</p><p>HTTP 协议是一个<strong>双向协议</strong>。</p><p>我们在上网冲浪时，浏览器是请求方 A，百度网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把请求数据发送给网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片、视频了。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/5-%E8%AF%B7%E6%B1%82%E5%BA%94%E7%AD%94.png" alt="请求 - 应答"></p><p>数据虽然是在 A 和 B 之间传输，但允许中间有<strong>中转或接力</strong>。</p><p>就好像第一排的同学想传递纸条给最后一排的同学，那么传递的过程中就需要经过好多个同学（中间人），这样的传输方式就从「A &lt; — &gt; B」，变成了「A &lt;-&gt; N &lt;-&gt; M &lt;-&gt; B」。</p><p>而在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。</p><p>针对<strong>传输</strong>，我们可以进一步理解了 HTTP。</p><p>HTTP 是一个在计算机世界里专门用来在<strong>两点之间传输数据</strong>的约定和规范。</p><p><em>3. 「超文本」</em></p><p>HTTP 传输的内容是「超文本」。</p><p>我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。</p><p>再来理解「超文本」，它就是<strong>超越了普通文本的文本</strong>，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。</p><p>HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。</p><p>OK，经过了对 HTTP 里这三个名词的详细解释，就可以给出比「超文本传输协议」这七个字更准确更有技术含量的答案：</p><p><strong>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</strong></p><blockquote><p>那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议」，这种说法正确吗？</p></blockquote><p>这种说法是<strong>不正确</strong>的。因为也可以是「服务器&lt; – &gt;服务器」，所以采用<strong>两点之间</strong>的描述会更准确。</p><h3 id="HTTP-常见的状态码有哪些？">HTTP 常见的状态码有哪些？</h3><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 "></p><p><code>1xx</code> 类状态码属于<strong>提示信息</strong>，是协议处理中的一种中间状态，实际用到的比较少。</p><p><code>2xx</code> 类状态码表示服务器<strong>成功</strong>处理了客户端的请求，也是我们最愿意看到的状态。</p><ul><li>「<strong>200 OK</strong>」是最常见的成功状态码，表示一切正常。如果是非 <code>HEAD</code> 请求，服务器返回的响应头都会有 body 数据。</li><li>「<strong>204 No Content</strong>」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li><li>「<strong>206 Partial Content</strong>」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li></ul><p><code>3xx</code> 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是<strong>重定向</strong>。</p><ul><li>「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li><li>「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。</li></ul><p>301 和 302 都会在响应头里使用字段 <code>Location</code>，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</p><ul><li>「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li></ul><p><code>4xx</code> 类状态码表示客户端发送的<strong>报文有误</strong>，服务器无法处理，也就是错误码的含义。</p><ul><li>「<strong>400 Bad Request</strong>」表示客户端请求的报文有错误，但只是个笼统的错误。</li><li>「<strong>403 Forbidden</strong>」表示服务器禁止访问资源，并不是客户端的请求出错。</li><li>「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li></ul><p><code>5xx</code> 类状态码表示客户端请求报文正确，但是<strong>服务器处理时内部发生了错误</strong>，属于服务器端的错误码。</p><ul><li>「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li><li>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li><li>「<strong>502 Bad Gateway</strong>」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li><li>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。</li></ul><h3 id="HTTP-常见字段有哪些？">HTTP 常见字段有哪些？</h3><p><em>Host</em> 字段</p><p>客户端发送请求时，用来指定服务器的域名。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/7-HOST%E5%AD%97%E6%AE%B5.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Host: www.A.com<br></code></pre></td></tr></table></figure><p>有了 <code>Host</code> 字段，就可以将请求发往「同一台」服务器上的不同网站。</p><p><em>Content-Length 字段</em></p><p>服务器在返回数据时，会有 <code>Content-Length</code> 字段，表明本次回应的数据长度。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/8-content-length%E5%AD%97%E6%AE%B5.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Content-Length: 1000<br></code></pre></td></tr></table></figure><p>如上面则是告诉浏览器，本次服务器回应的数据长度是 1000 个字节，后面的字节就属于下一个回应了。</p><p>大家应该都知道 HTTP 是基于 TCP 传输协议进行通信的，而使用了 TCP 传输协议，就会存在一个“粘包”的问题，<strong>HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题</strong>。具体什么是 TCP 粘包，可以看这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/tcp_stream.html">如何理解是 TCP 面向字节流协议？(opens new window)</a></p><p><em>Connection 字段</em></p><p><code>Connection</code> 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/9-connection%E5%AD%97%E6%AE%B5.png" alt="img"></p><p>HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/d2b20d1cc03936332adb2a68512eb167-20230309231005893.png" alt="HTTP 长连接"></p><p>HTTP/1.1 版本的默认连接都是长连接，但为了兼容老版本的 HTTP，需要指定 <code>Connection</code> 首部字段的值为 <code>Keep-Alive</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Connection: Keep-Alive<br></code></pre></td></tr></table></figure><p>开启了 HTTP Keep-Alive 机制后， 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。</p><p>PS：大家不要把 HTTP Keep-Alive 和 TCP Keepalive 搞混了，这两个虽然长的像，但是不是一个东西，具体可以看我这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/tcp_http_keepalive.html">TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？(opens new window)</a></p><p><em>Content-Type 字段</em></p><p><code>Content-Type</code> 字段用于服务器回应时，告诉客户端，本次数据是什么格式。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/10-content-type%E5%AD%97%E6%AE%B5.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Content-Type: text/html; Charset=utf-8<br></code></pre></td></tr></table></figure><p>上面的类型表明，发送的是网页，而且编码是UTF-8。</p><p>客户端请求的时候，可以使用 <code>Accept</code> 字段声明自己可以接受哪些数据格式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Accept: */*<br></code></pre></td></tr></table></figure><p>上面代码中，客户端声明自己可以接受任何格式的数据。</p><p><em>Content-Encoding 字段</em></p><p><code>Content-Encoding</code> 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/11-content-encoding%E5%AD%97%E6%AE%B5.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Content-Encoding: gzip<br></code></pre></td></tr></table></figure><p>上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。</p><p>客户端在请求时，用 <code>Accept-Encoding</code> 字段说明自己可以接受哪些压缩方法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">Accept-Encoding: gzip, deflate<br></code></pre></td></tr></table></figure><hr><h2 id="GET-与-POST">GET 与 POST</h2><h3 id="GET-和-POST-有什么区别？">GET 和 POST 有什么区别？</h3><p>根据 RFC 规范，<strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。</p><p>比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/12-Get%E8%AF%B7%E6%B1%82.png" alt="GET 请求"></p><p>根据 RFC 规范，<strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p><p>比如，你在我文章底部，敲入了留言后点击「提交」（<strong>暗示你们留言</strong>），浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/13-Post%E8%AF%B7%E6%B1%82.png" alt="POST 请求"></p><h3 id="GET-和-POST-方法都是安全和幂等的吗？">GET 和 POST 方法都是安全和幂等的吗？</h3><p>先说明下安全和幂等的概念：</p><ul><li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</li><li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li></ul><p>如果从 RFC 规范定义的语义来看：</p><ul><li><strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，<strong>可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签</strong>。</li><li><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。所以，<strong>浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签</strong>。</li></ul><p>做个简要的小结。</p><p>GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。</p><p>POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。</p><p>注意， 上面是从 RFC 规范定义的语义来分析的。</p><p>但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：</p><ul><li>可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。</li><li>可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。</li></ul><p>曾经有个笑话，有人写了个博客，删除博客用的是 GET 请求，他觉得没人访问就连鉴权都没做。然后 Google 服务器爬虫爬了一遍，他所有博文就没了。。。</p><p>如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。</p><p>因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了。</p><p>所以，要避免传输过程中数据被窃取，就要使用 HTTPS 协议，这样所有 HTTP 的数据都会被加密传输。</p><blockquote><p>GET 请求可以带 body 吗？</p></blockquote><p>RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。</p><p>另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。</p><h2 id="HTTP-缓存技术">HTTP 缓存技术</h2><h3 id="HTTP-缓存有哪些实现方式？">HTTP 缓存有哪些实现方式？</h3><p>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</p><p>所以，避免发送 HTTP 请求的方法就是通过<strong>缓存技术</strong>，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。</p><p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p><h3 id="什么是强制缓存？">什么是强制缓存？</h3><p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><p>如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/1cb6bc37597e4af8adfef412bfc57a42.png" alt="img"></p><p>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p><ul><li><code>Cache-Control</code>， 是一个相对时间；</li><li><code>Expires</code>，是一个绝对时间；</li></ul><p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control 的优先级高于 Expires</strong> 。</p><p>Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：</p><ul><li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li><li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</li><li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</li></ul><h3 id="什么是协商缓存？">什么是协商缓存？</h3><p>当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 <code>304</code>，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E7%BC%93%E5%AD%98etag.png" alt="img"></p><p>上图就是一个协商缓存的过程，所以<strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p><p>协商缓存可以基于两种头部来实现。</p><p>第一种：请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的 <code>Last-Modified</code> 字段实现，这两个字段的意思是：</p><ul><li>响应头部中的 <code>Last-Modified</code>：标示这个响应资源的最后修改时间；</li><li>请求头部中的 <code>If-Modified-Since</code>：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li></ul><p>第二种：请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段，这两个字段的意思是：</p><ul><li>响应头部中 <code>Etag</code>：唯一标识响应资源；</li><li>请求头部中的 <code>If-None-Match</code>：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。</li></ul><p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。</p><p>如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，<strong>这时 Etag 的优先级更高</strong>，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。</p><p>**为什么 ETag 的优先级更高？**这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：</p><ol><li>在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求；</li><li>可能有些文件是在秒级以内修改的，<code>If-Modified-Since</code> 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；</li><li>有些服务器不能精确获取文件的最后修改时间。</li></ol><p>注意，<strong>协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</strong>。</p><p>下图是强制缓存和协商缓存的工作流程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http%E7%BC%93%E5%AD%98.png" alt="img"></p><p>当使用 ETag 字段实现的协商缓存的过程：</p><ul><li><p>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；</p></li><li><p>当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：</p><ul><li>如果没有过期，则直接使用本地缓存；</li><li>如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；</li></ul></li><li><p>服务器再次收到请求后，</p><p>会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较</p><p>：</p><ul><li><strong>如果值相等，则返回 304 Not Modified，不会返回资源</strong>；</li><li>如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；</li></ul></li><li><p>如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。</p></li></ul><h2 id="HTTP-特性">HTTP 特性</h2><p>到目前为止，HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。</p><p>这里先用 HTTP/1.1 版本给大家介绍，其他版本的后续也会介绍。</p><h3 id="HTTP-1-1-的优点有哪些？">HTTP/1.1 的优点有哪些？</h3><p>HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。</p><p><em>1. 简单</em></p><p>HTTP 基本的报文格式就是 <code>header + body</code>，头部信息也是 <code>key-value</code> 简单文本的形式，<strong>易于理解</strong>，降低了学习和使用的门槛。</p><p><em>2. 灵活和易于扩展</em></p><p>HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员<strong>自定义和扩充</strong>。</p><p>同时 HTTP 由于是工作在应用层（ <code>OSI</code> 第七层），则它<strong>下层可以随意变化</strong>，比如：</p><ul><li>HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；</li><li>HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。</li></ul><p><em>3. 应用广泛和跨平台</em></p><p>互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有<strong>跨平台</strong>的优越性。</p><h3 id="HTTP-1-1-的缺点有哪些？">HTTP/1.1 的缺点有哪些？</h3><p>HTTP 协议里有优缺点一体的<strong>双刃剑</strong>，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。</p><p><em>1. 无状态双刃剑</em></p><p>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。</p><p>无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。</p><p>例如登录-&gt;添加购物车-&gt;下单-&gt;结算-&gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。</p><p>这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是<strong>酸爽</strong>！</p><p>对于无状态的问题，解法方案有很多种，其中比较简单的方式用 <strong>Cookie</strong> 技术。</p><p><code>Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。</p><p>相当于，<strong>在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了</strong>，</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/14-cookie%E6%8A%80%E6%9C%AF.png" alt="Cookie 技术"></p><p><em>2. 明文传输双刃剑</em></p><p>明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。</p><p>但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于<strong>信息裸奔</strong>。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那<strong>你号没了</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/15-%E4%BD%A0%E5%8F%B7%E6%B2%A1%E4%BA%86.png" alt="img"></p><p><em>3. 不安全</em></p><p>HTTP 比较严重的缺点就是不安全：</p><ul><li>通信使用明文（不加密），内容可能会被窃听。比如，<strong>账号信息容易泄漏，那你号没了。</strong></li><li>不验证通信方的身份，因此有可能遭遇伪装。比如，<strong>访问假的淘宝、拼多多，那你钱没了。</strong></li><li>无法证明报文的完整性，所以有可能已遭篡改。比如，<strong>网页上植入垃圾广告，视觉污染，眼没了。</strong></li></ul><p>HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。</p><h3 id="HTTP-1-1-的性能如何？">HTTP/1.1 的性能如何？</h3><p>HTTP 协议是基于 <strong>TCP/IP</strong>，并且使用了「<strong>请求 - 应答</strong>」的通信模式，所以性能的关键就在这<strong>两点</strong>里。</p><p><em>1. 长连接</em></p><p>早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。</p><p>为了解决上述 TCP 连接问题，HTTP/1.1 提出了<strong>长连接</strong>的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。</p><p>持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/16-%E7%9F%AD%E8%BF%9E%E6%8E%A5%E4%B8%8E%E9%95%BF%E8%BF%9E%E6%8E%A5.png" alt="短连接与长连接"></p><p>当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。</p><p><em>2. 管道网络传输</em></p><p>HTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。</p><p>即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以<strong>减少整体的响应时间。</strong></p><p>举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/17-%E7%AE%A1%E9%81%93%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93.png" alt="管道网络传输"></p><p>但是<strong>服务器必须按照接收请求的顺序发送对这些管道化请求的响应</strong>。</p><p>如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。</p><p>所以，<strong>HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞</strong>。</p><p>TIP</p><p><strong>注意!!!</strong></p><p>实际上 HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持，所以<strong>后面所有文章讨论 HTTP/1.1 都是建立在没有使用管道化的前提</strong>。大家知道有这个功能，但是没有被使用就行了。</p><p><em>3. 队头阻塞</em></p><p>「请求 - 应答」的模式会造成 HTTP 的性能问题。为什么呢？</p><p>因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「<strong>队头阻塞</strong>」，好比上班的路上塞车。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/18-%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.png" alt="队头阻塞"></p><p>总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。</p><h2 id="HTTP-与-HTTPS">HTTP 与 HTTPS</h2><h3 id="HTTP-与-HTTPS-有哪些区别？">HTTP 与 HTTPS 有哪些区别？</h3><ul><li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。</li><li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。</li><li>两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。</li><li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li></ul><h3 id="HTTPS-解决了-HTTP-的哪些问题？">HTTPS 解决了 HTTP 的哪些问题？</h3><p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p><ul><li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li><li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li><li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li></ul><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/19-HTTPS%E4%B8%8EHTTP.png" alt="HTTP 与 HTTPS 网络层"></p><p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 <code>SSL/TLS</code> 协议，可以很好的解决了上述的风险：</p><ul><li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li><li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li><li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li></ul><p>可见，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。</p><blockquote><p>HTTPS 是如何解决上面的三个风险的？</p></blockquote><ul><li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li><li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li><li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li></ul><p><em>1. 混合加密</em></p><p>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/20-%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86.png" alt="混合加密"></p><p>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p><ul><li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li></ul><p>采用「混合加密」的方式的原因：</p><ul><li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li><li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li></ul><p><em>2. 摘要算法 + 数字签名</em></p><p>为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。</p><p>对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。</p><p>那么，在计算机里会<strong>用摘要算法（哈希函数）来计算出内容的哈希值</strong>，也就是内容的「指纹」，这个<strong>哈希值是唯一的，且无法通过哈希值推导出内容</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95.png" alt="img"></p><p>通过哈希算法可以确保内容不会被篡改，<strong>但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明</strong>。</p><p>举个例子，你想向老师请假，一般来说是要求由家长写一份请假理由并签名，老师才能允许你请假。</p><p>但是你有模仿你爸爸字迹的能力，你用你爸爸的字迹写了一份请假理由然后签上你爸爸的名字，老师一看到这个请假条，查看字迹和签名，就误以为是你爸爸写的，就会允许你请假。</p><p>那作为老师，要如何避免这种情况发生呢？现实生活中的，可以通过电话或视频来确认是否是由父母发出的请假，但是计算机里可没有这种操作。</p><p>那为了避免这种情况，计算机里会用<strong>非对称加密算法</strong>来解决，共有两个密钥：</p><ul><li>一个是公钥，这个是可以公开给所有人的；</li><li>一个是私钥，这个必须由本人管理，不可泄露。</li></ul><p>这两个密钥可以<strong>双向加解密</strong>的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。</p><p>流程的不同，意味着目的也不相同：</p><ul><li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；</li><li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</li></ul><p>一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。</p><p>所以非对称加密的用途主要在于<strong>通过「私钥加密，公钥解密」的方式，来确认消息的身份</strong>，我们常说的<strong>数字签名算法</strong>，就是用的是这种方式，不过私钥加密内容不是内容本身，而是<strong>对内容的哈希值加密</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png" alt="img"></p><p>私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。</p><p>引入了数字签名算法后，你就无法模仿你爸爸的字迹来请假了，你爸爸手上持有着私钥，你老师持有着公钥。</p><p>这样只有用你爸爸手上的私钥才对请假条进行「签名」，老师通过公钥看能不能解出这个「签名」，如果能解出并且确认内容的完整性，就能证明是由你爸爸发起的请假条，这样老师才允许你请假，否则老师就不认。</p><p><em>3. 数字证书</em></p><p>前面我们知道：</p><ul><li>可以通过哈希算法来保证消息的完整性；</li><li>可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；</li></ul><p>但是这还远远不够，<strong>还缺少身份验证的环节</strong>，万一公钥是被伪造的呢？</p><p>还是拿请假的例子，虽然你爸爸持有私钥，老师通过是否能用公钥解密来确认这个请假条是不是来源你父亲的。</p><p>但是我们还可以自己伪造出一对公私钥啊！</p><p>你找了个夜晚，偷偷把老师桌面上和你爸爸配对的公钥，换成了你的公钥，那么下次你在请假的时候，你继续模仿你爸爸的字迹写了个请假条，然后用你的私钥做个了「数字签名」。</p><p>但是老师并不知道自己的公钥被你替换过了，所以他还是按照往常一样用公钥解密，由于这个公钥和你的私钥是配对的，老师当然能用这个被替换的公钥解密出来，并且确认了内容的完整性，于是老师就会以为是你父亲写的请假条，又允许你请假了。</p><p>好家伙，为了一个请假，真的是斗智斗勇。</p><p>后面你的老师和父亲发现了你伪造公私钥的事情后，决定重新商量一个对策来应对你这个臭家伙。</p><p>正所谓魔高一丈，道高一尺。</p><p>既然伪造公私钥那么随意，所以你爸把他的公钥注册到<strong>警察局</strong>，警察局用他们自己的私钥对你父亲的公钥做了个数字签名，然后把你爸爸的「个人信息 + 公钥 + 数字签名」打包成一个<strong>数字证书，也就是说这个数字证书包含你爸爸的公钥。</strong></p><p>这样，你爸爸如果因为家里确实有事要向老师帮你请假的时候，不仅会用自己的私钥对内容进行签名，还会把数字证书给到老师。</p><p>老师拿到了数字证书后，<strong>首先会去警察局验证这个数字证书是否合法</strong>，因为数字证书里有警察局的数字签名，警察局要验证证书合法性的时候，用自己的公钥解密，如果能解密成功，就说明这个数字证书是在警察局注册过的，就认为该数字证书是合法的，然后就会把数字证书里头的公钥（你爸爸的）给到老师。</p><p><strong>由于通过警察局验证了数字证书是合法的，那么就能证明这个公钥就是你父亲的</strong>，于是老师就可以安心的用这个公钥解密出请假条，如果能解密出，就证明是你爸爸写的请假条。</p><p>正是通过了一个权威的机构来证明你爸爸的身份，所以你的伪造公私钥这个小伎俩就没用了。</p><p>在计算机里，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><p>数字证书的工作流程，我也画了一张图，方便大家理解：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="数子证书工作流程"></p><p>通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。</p><h3 id="HTTPS-是如何建立连接的？其间交互了什么？">HTTPS 是如何建立连接的？其间交互了什么？</h3><p>SSL/TLS 协议基本流程：</p><ul><li>客户端向服务器索要并验证服务器的公钥。</li><li>双方协商生产「会话秘钥」。</li><li>双方采用「会话秘钥」进行加密通信。</li></ul><p>前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。</p><p>TLS 的「握手阶段」涉及<strong>四次</strong>通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：<a href="https://xiaolincoding.com/network/2_http/https_rsa.html">RSA 算法 (opens new window)</a>和 <a href="https://xiaolincoding.com/network/2_http/https_ecdhe.html">ECDHE 算法 (opens new window)</a>。</p><p>基于 RSA 算法的 TLS 握手过程比较容易理解，所以这里先用这个给大家展示 TLS 握手过程，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="HTTPS 连接建立过程"></p><p>TLS 协议建立的详细流程：</p><p><em>1. ClientHello</em></p><p>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。</p><p>在这一步，客户端主要向服务器发送以下信息：</p><p>（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。</p><p>（2）客户端生产的随机数（<code>Client Random</code>），后面用于生成「会话秘钥」条件之一。</p><p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p><p><em>2. SeverHello</em></p><p>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：</p><p>（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p><p>（2）服务器生产的随机数（<code>Server Random</code>），也是后面用于生产「会话秘钥」条件之一。</p><p>（3）确认的密码套件列表，如 RSA 加密算法。</p><p>（4）服务器的数字证书。</p><p><em>3.客户端回应</em></p><p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：</p><p>（1）一个随机数（<code>pre-master key</code>）。该随机数会被服务器公钥加密。</p><p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p><p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p><p><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。</p><p><em>4. 服务器的最后回应</em></p><p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p><p>然后，向客户端发送最后的信息：</p><p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p><p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p><p>至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p><p>TIP</p><p>如果想深入学习基于 RSA 算法的 HTTPS 握手过程，可以看这篇，我通过抓包的方式，逐步分析每一个过程：<a href="https://xiaolincoding.com/network/2_http/https_rsa.html">HTTPS RSA 握手解析(opens new window)</a></p><p>不过，基于 RSA 算法的 HTTPS 存在「前向安全」的问题：如果服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。</p><p>为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法，关于 ECDHE 握手的过程可以看这篇文章：<a href="https://xiaolincoding.com/network/2_http/https_ecdhe.html#%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0">HTTPS ECDHE 握手解析(opens new window)</a></p><blockquote><p>客户端校验数字证书的流程是怎样的？</p></blockquote><p>接下来，详细说一下实际中数字证书签发和验证流程。</p><p>如下图图所示，为数字证书签发和验证流程：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" alt="img"></p><p>CA 签发证书的过程，如上图左边部分：</p><ul><li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li><li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li><li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li></ul><p>客户端校验服务端的数字证书的过程，如上图右边部分：</p><ul><li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li><li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li><li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li></ul><p>但事实上，证书的验证过程中<strong>还存在一个证书信任链的问题</strong>，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/baidu%E8%AF%81%E4%B9%A6.png" alt="img"></p><p>对于这种三级层级关系的证书的验证过程如下：</p><ul><li>客户端收到 <a href="http://baidu.com">baidu.com</a> 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 <a href="http://baidu.com">baidu.com</a> 证书是否可信。于是，客户端根据 <a href="http://baidu.com">baidu.com</a> 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。</li><li>请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。</li><li>“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 <a href="http://baidu.com">baidu.com</a> 证书的可信性，如果验证通过，就可以信任 <a href="http://baidu.com">baidu.com</a> 证书。</li></ul><p>在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 <a href="http://baidu.com">baidu.com</a> 证书，于是客户端也信任 <a href="http://baidu.com">baidu.com</a> 证书。</p><p>总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 <a href="http://baidu.com">baidu.com</a> 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%94%A8%E6%88%B7%E4%BF%A1%E4%BB%BB.png" alt="img"></p><p>操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%B3%BB%E7%BB%9F%E6%A0%B9%E8%AF%81%E4%B9%A6.png" alt="img"></p><p>这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E9%93%BE.png" alt="img"></p><p>最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？</p><p><strong>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</strong></p><h3 id="HTTPS-的应用数据是如何保证完整性的？">HTTPS 的应用数据是如何保证完整性的？</h3><p>TLS 在实现上分为<strong>握手协议</strong>和<strong>记录协议</strong>两层：</p><ul><li>TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；</li><li>TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；</li></ul><p>TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E8%AE%B0%E5%BD%95%E5%8D%8F%E8%AE%AE.png" alt="img"></p><p>具体过程如下：</p><ul><li>首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。</li><li>接下来，经过压缩的片段会被<strong>加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证</strong>。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。</li><li>再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。</li><li>最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。</li></ul><p>记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。</p><p>如果你想详细了解记录协议是如何分片、压缩、计算 MAC 值、分组加密，可以看这篇：<a href="https://blog.csdn.net/zhanyiwp/article/details/105627799">理解SSL/TLS系列 (四) 记录协议(opens new window)</a></p><h3 id="HTTPS-一定安全可靠吗？">HTTPS 一定安全可靠吗？</h3><p>之前有读者在字节面试的时候，被问到：<strong>HTTPS 一定安全可靠吗？</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/%E6%8F%90%E9%97%AE.jpeg" alt="img"></p><p>这个问题的场景是这样的：客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/https%E4%B8%AD%E9%97%B4%E4%BA%BA.drawio.png" alt="img"></p><p>具体过程如下：</p><ul><li>客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手；</li><li>在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，<strong>客户端验证证书的真伪</strong>，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。</li><li>在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。</li><li>后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。</li></ul><p>从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。</p><p>但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。</p><p>中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/%E8%AF%81%E4%B9%A6%E5%AE%89%E5%85%A8%E6%8F%90%E7%A4%BA.png" alt="img"></p><p>如果用户执意点击「继续浏览此网站」，相当于用户接受了中间人伪造的证书，那么后续整个 HTTPS 通信都能被中间人监听了。</p><p>所以，这其实并不能说 HTTPS 不够安全，毕竟浏览器都已经提示证书有问题了，如果用户坚决要访问，那不能怪 HTTPS ，得怪自己手贱。</p><p>另外，如果你的电脑中毒了，被恶意导入了中间人的根证书，那么在验证中间人的证书的时候，由于你操作系统信任了中间人的根证书，那么等同于中间人的证书是合法的，这种情况下，浏览器是不会弹出证书存在问题的风险提醒的。</p><p>这其实也不关 HTTPS 的事情，是你电脑中毒了才导致 HTTPS 数据被中间人劫持的。</p><p>所以，<strong>HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全</strong>。</p><blockquote><p>为什么抓包工具能截取 HTTPS 数据？</p></blockquote><p>很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。</p><p>对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理:</p><ol><li>中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；</li><li>中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；</li></ol><p>中间人要拿到私钥只能通过如下方式：</p><ol><li>去网站服务端拿到私钥；</li><li>去CA处拿域名签发私钥；</li><li>自己签发证书，切要被浏览器信任；</li></ol><p>不用解释，抓包工具只能使用第三种方式取得中间人的身份。</p><p>使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。</p><p>抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。</p><blockquote><p>如何避免被中间人抓取数据？</p></blockquote><p>我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。</p><p>当然，我们还可以通过 <strong>HTTPS 双向认证</strong>来避免这种问题。</p><p>一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/%E5%8F%8C%E5%90%91%E8%AE%A4%E8%AF%81.png" alt="img"></p><p>如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。</p><h2 id="HTTP-1-1、HTTP-2、HTTP-3-演变">HTTP/1.1、HTTP/2、HTTP/3 演变</h2><h3 id="HTTP-1-1-相比-HTTP-1-0-提高了什么性能？">HTTP/1.1 相比 HTTP/1.0 提高了什么性能？</h3><p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p><ul><li>使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。</li><li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>但 HTTP/1.1 还是有性能瓶颈：</p><ul><li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li><li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li><li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li><li>没有请求优先级控制；</li><li>请求只能从客户端开始，服务器只能被动响应。</li></ul><h3 id="HTTP-2-做了什么优化？">HTTP/2 做了什么优化？</h3><p>HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/25-HTTP2.png" alt="HTT/1 ~ HTTP/2"></p><p>那 HTTP/2 相比 HTTP/1.1 性能上的改进：</p><ul><li>头部压缩</li><li>二进制格式</li><li>并发传输</li><li>服务器主动推送资源</li></ul><p><em>1. 头部压缩</em></p><p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。</p><p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p><p><em>2. 二进制格式</em></p><p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%B8%A7.png" alt="HTTP/1 与 HTTP/2 "></p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p><p>比如状态码 200 ，在 HTTP/1.1 是用 ‘2’‘0’‘0’ 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节，如下图</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/http1.png" alt="img"></p><p>在 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/h2c.png" alt="img"></p><p>Header: :status: 200 OK 的编码内容为：1000 1000，那么表达的含义是什么呢？</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/index.png" alt="img"></p><ol><li>最前面的 1 标识该 Header 是静态表中已经存在的 KV。（至于什么是静态表，可以看这篇：<a href="https://xiaolincoding.com/network/2_http/http2.html">HTTP/2 牛逼在哪？ (opens new window)</a>）</li><li>在静态表里，“:status: 200 ok” 静态表编码是 8，二进制即是 1000。</li></ol><p>因此，整体加起来就是 1000 1000。</p><p><em>3. 并发传输</em></p><p>我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了<strong>队头阻塞</strong>的问题。</p><p>而 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/stream.png" alt="img"></p><p>从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。</p><p><strong>针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应</strong>。</p><p>比如下图，服务端<strong>并行交错地</strong>发送了两个响应： Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.jpeg" alt="img"></p><p><em>4、服务器推送</em></p><p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。</p><p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p><p>比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字 1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和 4）。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/83445581dafe409d8cfd2c573b2781ac.png" alt="img"></p><p>再比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/push.png" alt="img"></p><p>如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。</p><blockquote><p>HTTP/2 有什么缺陷？</p></blockquote><p>HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。</p><p><strong>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/http2%E9%98%BB%E5%A1%9E.jpeg" alt="img"></p><p>举个例子，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif" alt="img"></p><p>图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。</p><p>所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><p>TIP</p><p>如果想更进一步了解 HTTP/2 协议，可以看我这篇文章：<a href="https://xiaolincoding.com/network/2_http/http2.html">HTTP/2 牛逼在哪？(opens new window)</a></p><h3 id="HTTP-3-做了哪些优化？">HTTP/3 做了哪些优化？</h3><p>前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：</p><ul><li>HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。</li><li>HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 TCP 层队头阻塞。</li></ul><p>HTTP/2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png" alt="HTTP/1 ~ HTTP/3"></p><p>UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><p>QUIC 有以下 3 个特点。</p><ul><li>无队头阻塞</li><li>更快的连接建立</li><li>连接迁移</li></ul><p><em>1、无队头阻塞</em></p><p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p><p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" alt="img"></p><p><em>2、更快的连接建立</em></p><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.png" alt="TCP HTTPS（TLS/1.3） 和 QUIC HTTPS "></p><p>甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p><p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/4cad213f5125432693e0e2a512c2d1a1-20230309231022316.png" alt="img"></p><p><em>3、连接迁移</em></p><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p><p><img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309231026577.png" alt="TCP 四元组"></p><p>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong> 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP/2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。</p><p>HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p><hr><h2 id="读者问答">读者问答</h2><blockquote><p>读者问：“https 和 http 相比，就是传输的内容多了对称加密，可以这么理解吗？”</p></blockquote><ol><li>建立连接时候：https 比 http多了 TLS 的握手过程；</li><li>传输内容的时候：https 会把数据进行加密，通常是对称加密数据；</li></ol><blockquote><p>读者问：“ 我看文中 TLS 和 SSL 没有做区分，这两个需要区分吗？”</p></blockquote><p>这两实际上是一个东西。</p><p>SSL 是洋文 “<em>Secure Sockets Layer</em>” 的缩写，中文叫做「安全套接层」。它是在上世纪 90 年代中期，由网景公司设计的。</p><p>到了1999年，SSL 因为应用广泛，已经成为互联网上的事实标准。IETF 就在那年把 SSL 标准化。标准化之后的名称改为 TLS（是 “<em>Transport Layer Security</em>” 的缩写），中文叫做 「传输层安全协议」。</p><p>很多相关的文章都把这两者并列称呼（SSL/TLS），因为这两者可以视作同一个东西的不同阶段。</p><blockquote><p>读者问：“为啥 SSL 的握手是 4 次？”</p></blockquote><p>SSL/TLS 1.2 需要 4 握手，需要 2 个 RTT 的时延，我文中的图是把每个交互分开画了，实际上把他们合在一起发送，就是 4 次握手：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/29-TLS1.2-%E5%9B%9B%E6%AC%A1%E6%8F%A1%E6%89%8B.png" alt="img"></p><p>另外， SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握手：</p><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/30-TLS1.3.png" alt="T"></p><hr>]]></content>
    
    
    <categories>
      
      <category>HTTP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HTTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>minIO</title>
    <link href="/2021/03/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/03.%E7%BB%84%E4%BB%B6/01.minIO/"/>
    <url>/2021/03/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/03.%E7%BB%84%E4%BB%B6/01.minIO/</url>
    
    <content type="html"><![CDATA[<h1>一、简介</h1><p>minIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。minIO 是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。</p><span id="more"></span><h1>二、特点</h1><ul><li>高性能：作为高性能对象存储，在标准硬件条件下它能达到55GB/s的读、35GG/s的写速率。</li><li>可扩容：不同MinIO集群可以组成联邦，并形成一个全局的命名空间，并跨越多个数据中心。</li><li>云原生：容器化、基于K8S的编排、多租户支持。</li><li>Amazon S3兼容：Minio使用Amazon S3 v2 / v4 API。可以使用Minio SDK，Minio Client，AWS SDK和AWS CLI访问Minio服务器。</li><li>可对接后端存储: 除了Minio自己的文件系统，还支持DAS、 JBODs、NAS、Google云存储和Azure Blob存储。</li><li>SDK支持: 基于Minio轻量的特点，它得到类似Java、Python或Go等语言的sdk支持。</li><li>Lambda计算: Minio服务器通过其兼容AWS SNS / SQS的事件通知服务触发Lambda功能。支持的目标是消息队列，如Kafka，NATS，AMQP，MQTT，Webhooks以及Elasticsearch，Redis，Postgres和MySQL等数据库。</li><li>有操作页面</li><li>功能简单: 这一设计原则让MinIO不容易出错、更快启动。</li><li>支持纠删码：MinIO使用纠删码、Checksum来防止硬件错误和静默数据污染。在最高冗余度配置下，即使丢失1/2的磁盘也能恢复数据。</li></ul><h1>三、存储机制</h1><h2 id="1-校验和">1. <strong>校验和</strong></h2><p>保护数据免受硬件故障和无声数据损坏</p><h2 id="2-纠删码">2. <strong>纠删码</strong></h2><p>纠删码是一种恢复丢失和损坏数据的数学算法，目前，纠删码技术在分布式存储系统中的应用主要有三类，阵列纠删码（Array Code: RAID5、RAID6等）、RS(Reed-Solomon)里德-所罗门类纠删码和LDPC(LowDensity Parity Check Code)低密度奇偶校验纠删码。Erasure Code是一种编码技术，它可以将n份原始数据，增加m份数据，并能通过n+m份中的任意n份数据，还原为原始数据。即如果有任意小于等于m份的数据失效，仍然能通过剩下的数据还原出来。Minio采用Reed-Solomon code将对象拆分成N/2数据和N/2 奇偶校验块。 这就意味着如果是12块盘，一个对象会被分成6个数据块、6个奇偶校验块，可以丢失任意6块盘（不管其是存放的数据块还是奇偶校验块），仍可以从剩下的盘中的数据进行恢复。</p><h2 id="3-RS-code编码数据恢复原理">3.<strong>RS code编码数据恢复原理</strong></h2><p>RS编码以word为编码和解码单位，大的数据块拆分到字长为w（取值一般为8或者16位）的word，然后对word进行编解码。 数据块的编码原理与word编码原理相同，后文中以word为例说明，变量Di, Ci将代表一个word。把输入数据视为向量D=(D1，D2，…, Dn）, 编码后数据视为向量（D1, D2,…, Dn, C1, C2,…, Cm)，RS编码可视为如下（图1）所示矩阵运算。<br>图1最左边是编码矩阵（或称为生成矩阵、分布矩阵，Distribution Matrix），编码矩阵需要满足任意n*n子矩阵可逆。为方便数据存储，编码矩阵上部是单位阵（n行n列），下部是m行n列矩阵。下部矩阵可以选择范德蒙德矩阵或柯西矩阵。</p><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5C189732-918cf64c1a46a102.png" alt="189732-918cf64c1a46a102"></p><p>RS最多能容忍m个数据块被删除。 数据恢复的过程如下：<br>（1）假设D1、D4、C2丢失，从编码矩阵中删掉丢失的数据块/编码块对应的行。（图2、3）<br>（2）由于B’ 是可逆的，记B’的逆矩阵为 (B’^-1)，则B’ * (B’^-1) = I 单位矩阵。两边左乘B’ 逆矩阵。 （图4、5）<br>（3)得到如下原始数据D的计算公式 。</p><p><img src="D:%5Cworkspace%5Cgithub%5Chexo_blog%5Csource%5Cimage%5C189732-5d1a7bdb324b0e33.png" alt="189732-5d1a7bdb324b0e33"></p><p>（4）对D重新编码，可得到丢失的编码</p><h1>四、部署时遇到的问题</h1><h2 id="1-WARNING-Published-ports-are-discarded-f-using-host-network-mode">1. WARNING: Published ports are discarded f using host network mode</h2><p><img src="....%5Cimage%5Cimage-20230309101022659.png" alt="image-20230309101022659"></p><p>使用了–net=host，这个容器使用的实际上是宿主机的ip和端口。</p><h2 id="2-本机可以访问9090端口，其他机器不行">2.本机可以访问9090端口，其他机器不行</h2><p>1.关闭防火墙 2.执行<code>iptables -F</code>清空防火墙规则</p>]]></content>
    
    
    <categories>
      
      <category>minIO</category>
      
    </categories>
    
    
    <tags>
      
      <tag>minIO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>秒杀场景</title>
    <link href="/2021/02/27/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E9%AB%98%E5%B9%B6%E5%8F%91/01.%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    <url>/2021/02/27/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E9%AB%98%E5%B9%B6%E5%8F%91/01.%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1>高并发场景</h1><p>一般在秒杀时间点（比如：12点）前几分钟，用户并发量才真正突增，达到秒杀时间点时，并发量会达到顶峰。但由于这类活动是大量用户抢少量商品的场景，必定会出现狼多肉少的情况，所以其实绝大部分用户秒杀会失败，只有极少部分用户能够成功。正常情况下，大部分用户会收到商品已经抢完的提醒，收到该提醒后，他们大概率不会在那个活动页面停留了，如此一来，用户并发量又会急剧下降。所以这个峰值持续的时间其实是非常短的，这样就会出现瞬时高并发的情况。</p><p><img src="https://picx.zhimg.com/50/v2-b0b3c8187b13765d9c140cbc2efdd49b_720w.jpg?source=1940ef5c" alt="img"></p><p>像这种瞬时高并发的场景，传统的系统很难应对，我们需要设计一套全新的系统。可以从以下几个方面入手：</p><ol><li>页面静态化</li><li>CDN加速</li><li>缓存</li><li>mq异步处理</li><li>限流</li><li>分布式锁</li></ol><h2 id="一、页面静态化">一、页面静态化</h2><p>活动页面是用户流量的第一入口，所以是并发量最大的地方。如果这些流量都能直接访问服务端，恐怕服务端会因为承受不住这么大的压力，而直接挂掉。</p><p>活动页面绝大多数内容是固定的，比如：商品名称、商品描述、图片等。为了减少不必要的服务端请求，通常情况下，会对活动页面做静态化处理。用户浏览商品等常规操作，并不会请求到服务端。只有到了秒杀时间点，并且用户主动点了秒杀按钮才允许访问服务端。</p><p>这样能过滤大部分无效请求。</p><p>但只做页面静态化还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，网速各不相同。</p><p>如何才能让用户最快访问到活动页面呢？</p><h2 id="二、CDN">二、CDN</h2><p>这就需要使用CDN，它的全称是Content Delivery Network，即<a href="https://www.zhihu.com/search?q=%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">内容分发网络</a>。</p><p>使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。</p><h2 id="三、秒杀按钮">三、秒杀按钮</h2><p>大部分用户怕错过秒杀时间点，一般会提前进入活动页面。此时看到的秒杀按钮是置灰，不可点击的。只有到了秒杀时间点那一时刻，秒杀按钮才会自动点亮，变成可点击的。</p><p>但此时很多用户已经迫不及待了，通过不停刷新页面，争取在第一时间看到秒杀按钮的点亮。</p><p>从前面得知，该活动页面是静态的。那么我们在静态页面中如何控制秒杀按钮，只在秒杀时间点时才点亮呢？</p><p>没错，使用<a href="https://www.zhihu.com/search?q=js%E6%96%87%E4%BB%B6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">js文件</a>控制。</p><p>为了性能考虑，一般会将css、js和图片等静态资源文件提前缓存到CDN上，让用户能够就近访问秒杀页面。</p><p>看到这里，有些聪明的小伙伴，可能会问：CDN上的js文件是如何更新的？</p><p>秒杀开始之前，js标志为false，还有另外一个随机参数。</p><p><img src="https://pica.zhimg.com/50/v2-a95fc3dd1f7d6860150cf69482a22e5d_720w.jpg?source=1940ef5c" alt="img"></p><p>当秒杀开始的时候系统会生成一个新的js文件，此时标志为true，并且随机参数生成一个新值，然后同步给CDN。由于有了这个随机参数，CDN不会缓存数据，每次都能从CDN中获取最新的js代码。</p><p><img src="https://picx.zhimg.com/50/v2-9c8c5a039b815b68ce30f5d450e36a2f_720w.jpg?source=1940ef5c" alt="img"></p><p>此外，前端还可以加一个定时器，控制比如：10秒之内，只允许发起一次请求。如果用户点击了一次秒杀按钮，则在10秒之内置灰，不允许再次点击，等到过了时间限制，又允许重新点击该按钮。</p><h2 id="四、读多写少">四、读多写少</h2><p>在秒杀的过程中，系统一般会先查一下库存是否足够，如果足够才允许下单，写数据库。如果不够，则直接返回该商品已经抢完。</p><p>由于大量用户抢少量商品，只有极少部分用户能够抢成功，所以绝大部分用户在秒杀时，库存其实是不足的，系统会直接返回该商品已经抢完。</p><p>这是非常典型的：读多写少 的场景。</p><p><img src="https://pic1.zhimg.com/50/v2-5ea5db9ea70e6e6f105624d041eec611_720w.jpg?source=1940ef5c" alt="img"></p><p>如果有数十万的请求过来，同时通过数据库查缓存是否足够，此时数据库可能会挂掉。因为数据库的连接资源非常有限，比如：mysql，无法同时支持这么多的连接。</p><p>而应该改用缓存，比如：redis。</p><p>即便用了redis，也需要部署多个节点。</p><p><img src="https://pic1.zhimg.com/50/v2-be759a8adf8e46740ded8560c6ebefb0_720w.jpg?source=1940ef5c" alt="img"></p><h2 id="五、缓存问题">五、缓存问题</h2><p>通常情况下，我们需要在redis中保存商品信息，里面包含：商品id、商品名称、规格属性、库存等信息，同时数据库中也要有相关信息，毕竟缓存并不完全可靠。</p><p>用户在点击秒杀按钮，请求秒杀接口的过程中，需要传入的商品id参数，然后服务端需要校验该商品是否合法。</p><p>大致流程如下图所示：</p><p><img src="https://pic1.zhimg.com/50/v2-289ab91d8390caaf29362452a4c7ceac_720w.jpg?source=1940ef5c" alt="img"></p><p>根据商品id，先从缓存中查询商品，如果商品存在，则参与秒杀。如果不存在，则需要从数据库中查询商品，如果存在，则将商品信息放入缓存，然后参与秒杀。如果商品不存在，则直接提示失败。</p><p>这个过程表面上看起来是OK的，但是如果深入分析一下会发现一些问题。</p><h3 id="5-1-缓存击穿">5.1 缓存击穿</h3><p>比如商品A第一次秒杀时，缓存中是没有数据的，但数据库中有。虽说上面有如果从数据库中查到数据，则放入缓存的逻辑。</p><p>然而，在高并发下，同一时刻会有大量的请求，都在秒杀同一件商品，这些请求同时去查缓存中没有数据，然后又同时访问数据库。结果悲剧了，数据库可能扛不住压力，直接挂掉。</p><p>如何解决这个问题呢？</p><p>这就需要加锁，最好使用分布式锁。</p><p><img src="https://picx.zhimg.com/50/v2-5a3e62d649dd8ccc5f33585c8e225824_720w.jpg?source=1940ef5c" alt="img"></p><p>当然，针对这种情况，最好在项目启动之前，先把缓存进行预热。即事先把所有的商品，同步到缓存中，这样商品基本都能直接从缓存中获取到，就不会出现缓存击穿的问题了。</p><p>是不是上面加锁这一步可以不需要了？</p><p>表面上看起来，确实可以不需要。但如果缓存中设置的过期时间不对，缓存提前过期了，或者缓存被不小心删除了，如果不加速同样可能出现缓存击穿。</p><p>其实这里加锁，相当于买了一份保险。</p><p>比如商品A第一次秒杀时，缓存中是没有数据的，但数据库中有。虽说上面有如果从数据库中查到数据，则放入缓存的逻辑。</p><p>然而，在高并发下，同一时刻会有大量的请求，都在秒杀同一件商品，这些请求同时去查缓存中没有数据，然后又同时访问数据库。结果悲剧了，数据库可能扛不住压力，直接挂掉。</p><p>如何解决这个问题呢？</p><p>这就需要加锁，最好使用分布式锁。</p><p><img src="https://picx.zhimg.com/50/v2-5a3e62d649dd8ccc5f33585c8e225824_720w.jpg?source=1940ef5c" alt="img"></p><p>当然，针对这种情况，最好在项目启动之前，先把缓存进行预热。即事先把所有的商品，同步到缓存中，这样商品基本都能直接从缓存中获取到，就不会出现缓存击穿的问题了。</p><p>是不是上面加锁这一步可以不需要了？</p><p>表面上看起来，确实可以不需要。但如果缓存中设置的过期时间不对，缓存提前过期了，或者缓存被不小心删除了，如果不加速同样可能出现缓存击穿。</p><p>其实这里加锁，相当于买了一份保险。</p><h3 id="5-2-缓存穿透">5.2 缓存穿透</h3><p>如果有大量的请求传入的商品id，在缓存中和数据库中都不存在，这些请求不就每次都会穿透过缓存，而直接访问数据库了。</p><p>由于前面已经加了锁，所以即使这里的并发量很大，也不会导致数据库直接挂掉。</p><p>但很显然这些请求的处理性能并不好，有没有更好的解决方案？</p><p>这时可以想到布隆过滤器。</p><p><img src="https://pic1.zhimg.com/50/v2-80e67ce476c20c25e61e24b548efe6ed_720w.jpg?source=1940ef5c" alt="img"></p><p>系统根据商品id，先从<a href="https://www.zhihu.com/search?q=%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">布隆过滤器</a>中查询该id是否存在，如果存在则允许从缓存中查询数据，如果不存在，则直接返回失败。</p><p>虽说该方案可以解决缓存穿透问题，但是又会引出另外一个问题：布隆过滤器中的数据如何更缓存中的数据保持一致？</p><p>这就要求，如果缓存中数据有更新，则要及时同步到布隆过滤器中。如果数据同步失败了，还需要增加<a href="https://www.zhihu.com/search?q=%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">重试机制</a>，而且跨数据源，能保证数据的实时一致性吗？</p><p>显然是不行的。</p><p>所以布隆过滤器绝大部分使用在缓存数据更新很少的场景中。</p><p>如果缓存数据更新非常频繁，又该如何处理呢？</p><p>这时，就需要把不存在的商品id也缓存起来。</p><p><img src="https://pic1.zhimg.com/50/v2-78149e5bad987589cfdbe37a3c9bd5de_720w.jpg?source=1940ef5c" alt="img"></p><p>下次，再有该商品id的请求过来，则也能从缓存中查到数据，只不过该数据比较特殊，表示商品不存在。需要特别注意的是，这种特殊缓存设置的超时时间应该尽量短一点。</p><p>作者：苏三说技术<br>链接：<a href="https://www.zhihu.com/question/356916763/answer/2488511352">https://www.zhihu.com/question/356916763/answer/2488511352</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h2 id="六、库存问题">六、库存问题</h2><p>对于库存问题看似简单，实则里面还是有些东西。</p><p>真正的秒杀商品的场景，不是说扣完库存，就完事了，如果用户在一段时间内，还没完成支付，扣减的库存是要加回去的。</p><p>所以，在这里引出了一个<a href="https://www.zhihu.com/search?q=%E9%A2%84%E6%89%A3%E5%BA%93%E5%AD%98&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">预扣库存</a>的概念，预扣库存的主要流程如下：</p><p><img src="https://pica.zhimg.com/50/v2-d4e329d9b219c4c5a12de7db7b2f6560_720w.jpg?source=1940ef5c" alt="img"></p><p>扣减库存中除了上面说到的预扣库存和回退库存之外，还需要特别注意的是库存不足和库存超卖问题。</p><h3 id="6-1-数据库扣减库存">6.1 <a href="https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A3%E5%87%8F&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">数据库扣减</a>库存</h3><p>使用数据库扣减库存，是最简单的实现方案了，假设扣减库存的sql如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">update product <span class="hljs-keyword">set</span> stock<span class="hljs-operator">=</span>stock<span class="hljs-number">-1</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span><span class="hljs-number">123</span>;<br></code></pre></td></tr></table></figure><p>这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？</p><p>这就需要在update之前，先查一下库存是否足够了。</p><p>伪代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">int</span> stock = mapper.getStockById(<span class="hljs-number">123</span>);<br><span class="hljs-keyword">if</span>(stock &gt; <span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">int</span> count = mapper.updateStock(<span class="hljs-number">123</span>);<br>  <span class="hljs-keyword">if</span>(count &gt; <span class="hljs-number">0</span>) &#123;<br>    addOrder(<span class="hljs-number">123</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>大家有没有发现这段代码的问题？</p><p>没错，查询操作和更新操作不是原子性的，会导致在并发的场景下，出现库存超卖的情况。</p><p>有人可能会说，这样好办，加把锁，不就搞定了，比如使用synchronized关键字。</p><p>确实，可以，但是性能不够好。</p><p>还有更优雅的处理方案，即基于数据库的乐观锁，这样会少一次数据库查询，而且能够天然的保证数据操作的原子性。</p><p>只需将上面的sql稍微调整一下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">update product <span class="hljs-keyword">set</span> stock<span class="hljs-operator">=</span>stock<span class="hljs-number">-1</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span>product <span class="hljs-keyword">and</span> stock <span class="hljs-operator">&gt;</span> <span class="hljs-number">0</span>;<br></code></pre></td></tr></table></figure><p>在sql最后加上：stock &gt; 0，就能保证不会出现超卖的情况。</p><p>但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。</p><h3 id="6-2-redis扣减库存">6.2 redis扣减库存</h3><p>redis的incr方法是原子性的，可以用该方法扣减库存。伪代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"> boolean exist = redisClient.query(productId,userId);<br>  <span class="hljs-keyword">if</span>(exist) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>  &#125;<br>  <span class="hljs-keyword">int</span> stock = redisClient.queryStock(productId);<br>  <span class="hljs-keyword">if</span>(stock &lt;=<span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>  &#125;<br>  redisClient.incrby(productId, <span class="hljs-number">-1</span>);<br>  redisClient.add(productId,userId);<br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>代码流程如下：</p><ol><li>先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。</li><li>查询库存，如果库存小于等于0，则直接返回0，表示库存不足。</li><li>如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。</li></ol><p>估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。</p><p>有什么问题呢？</p><p>如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即库存超卖。</p><p>当然有人可能会说，加个synchronized不就解决问题？</p><p>调整后代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go">   boolean exist = redisClient.query(productId,userId);<br>   <span class="hljs-keyword">if</span>(exist) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>   &#125;<br>   synchronized(this) &#123;<br>       <span class="hljs-keyword">int</span> stock = redisClient.queryStock(productId);<br>       <span class="hljs-keyword">if</span>(stock &lt;=<span class="hljs-number">0</span>) &#123;<br>         <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>       &#125;<br>       redisClient.incrby(productId, <span class="hljs-number">-1</span>);<br>       redisClient.add(productId,userId);<br>   &#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>加synchronized确实能解决库存为负数问题，但是这样会导致接口性能急剧下降，每次查询都需要竞争同一把锁，显然不太合理。</p><p>为了解决上面的问题，代码优化如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go">boolean exist = redisClient.query(productId,userId);<br><span class="hljs-keyword">if</span>(exist) &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>&#125;<br><span class="hljs-keyword">if</span>(redisClient.incrby(productId, <span class="hljs-number">-1</span>)&lt;<span class="hljs-number">0</span>) &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br>redisClient.add(productId,userId);<br><span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>该代码主要流程如下：</p><ol><li>先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。</li><li>扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。</li><li>如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。</li></ol><p>该方案咋一看，好像没问题。</p><p>但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。</p><p>虽说，库存出现负数，不会出现超卖的问题。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。</p><h2 id="七、分布式锁">七、分布式锁</h2><p>之前我提到过，在秒杀的时候，需要先从缓存中查商品是否存在，如果不存在，则会从数据库中查商品。如果数据库中，则将该商品放入缓存中，然后返回。如果数据库中没有，则直接返回失败。</p><p>大家试想一下，如果在高并发下，有大量的请求都去查一个缓存中不存在的商品，这些请求都会直接打到数据库。数据库由于承受不住压力，而直接挂掉。</p><p>那么如何解决这个问题呢？</p><p>这就需要用redis分布式锁了。</p><h3 id="7-1-setNx加锁">7.1 setNx加锁</h3><p>使用redis的分布式锁，首先想到的是setNx命令。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">if</span> (jedis.setnx(lockKey, val) == <span class="hljs-number">1</span>) &#123;<br>   jedis.expire(lockKey, timeout);<br>&#125;<br></code></pre></td></tr></table></figure><p>用该命令其实可以加锁，但和后面的设置超时时间是分开的，并非原子操作。</p><p>假如加锁成功了，但是设置超时时间失败了，该lockKey就变成永不失效的了。在高并发场景中，该问题会导致非常严重的后果。</p><p>那么，有没有保证原子性的加锁命令呢？</p><h3 id="7-2-set加锁">7.2 set加锁</h3><p>使用redis的set命令，它可以指定多个参数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go">String result = jedis.set(lockKey, requestId, <span class="hljs-string">&quot;NX&quot;</span>, <span class="hljs-string">&quot;PX&quot;</span>, expireTime);<br><span class="hljs-keyword">if</span> (<span class="hljs-string">&quot;OK&quot;</span>.equals(result)) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure><p>其中：</p><ul><li>lockKey：锁的标识</li><li>requestId：请求id</li><li>NX：只在键不存在时，才对键进行设置操作。</li><li>PX：设置键的过期时间为 millisecond 毫秒。</li><li>expireTime：过期时间</li></ul><p>由于该命令只有一步，所以它是原子操作。</p><h3 id="7-3-释放锁">7.3 释放锁</h3><p>接下来，有些朋友可能会问：在加锁时，既然已经有了lockKey锁标识，为什么要需要记录requestId呢？</p><p>答：requestId是在释放锁的时候用的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">if (jedis.get(lockKey).equals(requestId)) &#123;<br>    jedis.del(lockKey);<br>    return true;<br>&#125;<br>return false;<br></code></pre></td></tr></table></figure><p>在释放锁的时候，只能释放自己加的锁，不允许释放别人加的锁。</p><p>这里为什么要用requestId，用userId不行吗？</p><p>答：如果用userId的话，假设本次请求流程走完了，准备删除锁。此时，巧合锁到了过期时间失效了。而另外一个请求，巧合使用的相同userId加锁，会成功。而本次请求删除锁的时候，删除的其实是别人的锁了。</p><p>当然使用lua脚本也能避免该问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then <br> return redis.call(&#x27;del&#x27;, KEYS[1]) <br>else <br>  return 0 <br>end<br></code></pre></td></tr></table></figure><p>它能保证查询锁是否存在和删除锁是原子操作。</p><h3 id="7-4-自旋锁">7.4 <a href="https://www.zhihu.com/search?q=%E8%87%AA%E6%97%8B%E9%94%81&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">自旋锁</a></h3><p>上面的加锁方法看起来好像没有问题，但如果你仔细想想，如果有1万的请求同时去竞争那把锁，可能只有一个请求是成功的，其余的9999个请求都会失败。</p><p>在秒杀场景下，会有什么问题？</p><p>答：每1万个请求，有1个成功。再1万个请求，有1个成功。如此下去，直到库存不足。这就变成均匀分布的秒杀了，跟我们想象中的不一样。</p><p>如何解决这个问题呢？</p><p>答：使用自旋锁。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs text">try &#123;<br>  Long start = System.currentTimeMillis();<br>  while(true) &#123;<br>      String result = jedis.set(lockKey, requestId, &quot;NX&quot;, &quot;PX&quot;, expireTime);<br>     if (&quot;OK&quot;.equals(result)) &#123;<br>        return true;<br>     &#125;<br>     <br>     long time = System.currentTimeMillis() - start;<br>      if (time&gt;=timeout) &#123;<br>          return false;<br>      &#125;<br>      try &#123;<br>          Thread.sleep(50);<br>      &#125; catch (InterruptedException e) &#123;<br>          e.printStackTrace();<br>      &#125;<br>  &#125;<br> <br>&#125; finally&#123;<br>    unlock(lockKey,requestId);<br>&#125;  <br>return false;<br></code></pre></td></tr></table></figure><p>在规定的时间，比如500毫秒内，自旋不断尝试加锁，如果成功则直接返回。如果失败，则休眠50毫秒，再发起新一轮的尝试。如果到了超时时间，还未加锁成功，则直接返回失败。</p><h3 id="7-5-redisson">7.5 redisson</h3><p>除了上面的问题之外，使用redis分布式锁，还有锁竞争问题、续期问题、锁重入问题、多个redis实例加锁问题等。</p><p>这些问题使用redisson可以解决，由于篇幅的原因，在这里先保留一点悬念，有疑问的私聊给我。后面会出一个专题介绍分布式锁，敬请期待。</p><p>作者：苏三说技术<br>链接：<a href="https://www.zhihu.com/question/356916763/answer/2488511352">https://www.zhihu.com/question/356916763/answer/2488511352</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h2 id="八、mq异步处理">八、mq异步处理</h2><p>我们都知道在真实的秒杀场景中，有三个核心流程：</p><p><img src="https://pica.zhimg.com/50/v2-a5011587873070a13725f99c5d9a0603_720w.jpg?source=1940ef5c" alt="img"></p><p>而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能要做成mq异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。</p><p>于是，秒杀后下单的流程变成如下：</p><p><img src="https://picx.zhimg.com/50/v2-7e651a864d76d87ffecedd204d89540f_720w.jpg?source=1940ef5c" alt="img"></p><p>如果使用mq，需要关注以下几个问题：</p><h3 id="8-1-消息丢失问题">8.1 消息丢失问题</h3><p>秒杀成功了，往mq发送下单消息的时候，有可能会失败。原因有很多，比如：网络问题、broker挂了、mq服务端磁盘问题等。这些情况，都可能会造成消息丢失。</p><p>那么，如何防止消息丢失呢？</p><p>答：加一张消息发送表。</p><p><img src="https://picx.zhimg.com/50/v2-441957d6ee6fb1fe545312c13adeac78_720w.jpg?source=1940ef5c" alt="img"></p><p>在生产者发送mq消息之前，先把该条消息写入消息发送表，初始状态是待处理，然后再发送mq消息。消费者消费消息时，处理完业务逻辑之后，再回调生产者的一个接口，修改消息状态为已处理。</p><p>如果生产者把消息写入消息发送表之后，再发送mq消息到mq服务端的过程中失败了，造成了消息丢失。</p><p>这时候，要如何处理呢？</p><p>答：使用job，增加重试机制。</p><p><img src="https://pic1.zhimg.com/50/v2-79a3a4e3ae1c10b3240e1b687f7bc1ce_720w.jpg?source=1940ef5c" alt="img"></p><p>用job每隔一段时间去查询消息发送表中状态为待处理的数据，然后重新发送mq消息。</p><h3 id="8-2-重复消费问题">8.2 重复消费问题</h3><p>本来消费者消费消息时，在ack应答的时候，如果网络超时，本身就可能会消费重复的消息。但由于消息发送者增加了重试机制，会导致消费者重复消息的概率增大。</p><p>那么，如何解决重复消息问题呢？</p><p>答：加一张消息处理表。</p><p><img src="https://picx.zhimg.com/50/v2-14693f27d2ed657bd9c027bd1f79eb44_720w.jpg?source=1940ef5c" alt="img"></p><p>消费者读到消息之后，先判断一下消息处理表，是否存在该消息，如果存在，表示是重复消费，则直接返回。如果不存在，则进行下单操作，接着将该消息写入消息处理表中，再返回。</p><p>有个比较关键的点是：下单和写消息处理表，要放在同一个事务中，保证原子操作。</p><h3 id="8-3-垃圾消息问题">8.3 垃圾消息问题</h3><p>这套方案表面上看起来没有问题，但如果出现了消息消费失败的情况。比如：由于某些原因，消息消费者下单一直失败，一直不能回调状态变更接口，这样job会不停的重试发消息。最后，会产生大量的垃圾消息。</p><p>那么，如何解决这个问题呢？</p><p><img src="https://picx.zhimg.com/50/v2-a22df75b85cb518ae528d181431825e8_720w.jpg?source=1940ef5c" alt="img"></p><p>每次在job重试时，需要先判断一下消息发送表中该消息的发送次数是否达到最大限制，如果达到了，则直接返回。如果没有达到，则将次数加1，然后发送消息。</p><p>这样如果出现异常，只会产生少量的垃圾消息，不会影响到正常的业务。</p><h3 id="8-4-延迟消费问题">8.4 延迟消费问题</h3><p>通常情况下，如果用户秒杀成功了，下单之后，在15分钟之内还未完成支付的话，该订单会被自动取消，回退库存。</p><p>那么，在15分钟内未完成支付，订单被自动取消的功能，要如何实现呢？</p><p>我们首先想到的可能是job，因为它比较简单。</p><p>但job有个问题，需要每隔一段时间处理一次，实时性不太好。</p><p>还有更好的方案？</p><p>答：使用<a href="https://www.zhihu.com/search?q=%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2488511352%7D">延迟队列</a>。</p><p>我们都知道rocketmq，自带了延迟队列的功能。</p><p><img src="https://pic1.zhimg.com/50/v2-39934c1b3c74dfdf48a5a1b41c2d511e_720w.jpg?source=1940ef5c" alt="img"></p><p>下单时消息生产者会先生成订单，此时状态为待支付，然后会向延迟队列中发一条消息。达到了延迟时间，消息消费者读取消息之后，会查询该订单的状态是否为待支付。如果是待支付状态，则会更新订单状态为取消状态。如果不是待支付状态，说明该订单已经支付过了，则直接返回。</p><p>还有个关键点，用户完成支付之后，会修改订单状态为已支付。</p><p><img src="https://pica.zhimg.com/50/v2-57e23fae445dc707d7f6c74ae11664b7_720w.jpg?source=1940ef5c" alt="img"></p><h2 id="9-如何限流？">9 如何限流？</h2><p>通过秒杀活动，如果我们运气爆棚，可能会用非常低的价格买到不错的商品（这种概率堪比买福利彩票中大奖）。</p><p>但有些高手，并不会像我们一样老老实实，通过秒杀页面点击秒杀按钮，抢购商品。他们可能在自己的服务器上，模拟正常用户登录系统，跳过秒杀页面，直接调用秒杀接口。</p><p>如果是我们手动操作，一般情况下，一秒钟只能点击一次秒杀按钮。</p><p><img src="https://pica.zhimg.com/50/v2-989096eb0642aad5cb479667cb36327c_720w.jpg?source=1940ef5c" alt="img"></p><p>但是如果是服务器，一秒钟可以请求成上千接口。</p><p><img src="https://picx.zhimg.com/50/v2-6e96a20df41c62fbdc0042eda3c801b0_720w.jpg?source=1940ef5c" alt="img"></p><p>这种差距实在太明显了，如果不做任何限制，绝大部分商品可能是被机器抢到，而非正常的用户，有点不太公平。</p><p>所以，我们有必要识别这些非法请求，做一些限制。那么，我们该如何现在这些非法请求呢？</p><p>目前有两种常用的限流方式：</p><ol><li>基于nginx限流</li><li>基于redis限流</li></ol><h3 id="9-1-对同一用户限流">9.1 对同一用户限流</h3><p>为了防止某个用户，请求接口次数过于频繁，可以只针对该用户做限制。</p><p><img src="https://picx.zhimg.com/50/v2-091313947f9197ecdfea67c06d794545_720w.jpg?source=1940ef5c" alt="img"></p><p>限制同一个用户id，比如每分钟只能请求5次接口。</p><h3 id="9-2-对同一ip限流">9.2 对同一ip限流</h3><p>有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这种nginx就没法识别了。</p><p>这时需要加同一ip限流功能。</p><p><img src="https://picx.zhimg.com/50/v2-242cd513037a1f7741b7445a85548649_720w.jpg?source=1940ef5c" alt="img"></p><p>限制同一个ip，比如每分钟只能请求5次接口。</p><p>但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。</p><h3 id="9-3-对接口限流">9.3 对接口限流</h3><p>别以为限制了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。</p><p>这时可以限制请求的接口总次数。</p><p><img src="https://pic1.zhimg.com/50/v2-4cdb6ba94125a0a08cbac9ff92da8314_720w.jpg?source=1940ef5c" alt="img"></p><p>在高并发场景下，这种限制对于系统的稳定性是非常有必要的。但可能由于有些非法请求次数太多，达到了该接口的请求上限，而影响其他的正常用户访问该接口。看起来有点得不偿失。</p><h3 id="9-4-加验证码">9.4 加验证码</h3><p>相对于上面三种方式，加验证码的方式可能更精准一些，同样能限制用户的访问频次，但好处是不会存在误杀的情况。</p><p><img src="https://pic1.zhimg.com/50/v2-666551c0ec3eba04a8a9188fcbcc239e_720w.jpg?source=1940ef5c" alt="img"></p><p>通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。</p><p>此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。</p><p>普通验证码，由于生成的数字或者图案比较简单，可能会被破解。优点是生成速度比较快，缺点是有安全隐患。</p><p>还有一个验证码叫做：移动滑块，它生成速度比较慢，但比较安全，是目前各大互联网公司的首选。</p><p>最近无意间获得一份BAT大厂大佬写的刷题笔记，一下子打通了我的任督二脉，越来越觉得算法没有想象中那么难了。</p><p><a href="%5B%E8%BF%99%E4%BD%8DBAT%E5%A4%A7%E4%BD%AC%E5%86%99%E7%9A%84Leetcode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0%EF%BC%8C%E8%AE%A9%E6%88%91offer%E6%8B%BF%E5%88%B0%E6%89%8B%E8%BD%AF%5D(https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/tq4HYlL5A4qL5Aka3jFNqw)">BAT大佬写的刷题笔记，让我offer拿到手软</a></p><h3 id="9-5-提高业务门槛">9.5 提高业务门槛</h3><p>上面说的加验证码虽然可以限制非法用户请求，但是有些影响用户体验。用户点击秒杀按钮前，还要先输入验证码，流程显得有点繁琐，秒杀功能的流程不是应该越简单越好吗？</p><p>其实，有时候达到某个目的，不一定非要通过技术手段，通过业务手段也一样。</p><p>12306刚开始的时候，全国人民都在同一时刻抢火车票，由于并发量太大，系统经常挂。后来，重构优化之后，将购买周期放长了，可以提前20天购买火车票，并且可以在9点、10、11点、12点等整点购买火车票。调整业务之后（当然技术也有很多调整），将之前集中的请求，分散开了，一下子降低了用户并发量。</p><p>回到这里，我们通过提高业务门槛，比如只有会员才能参与秒杀活动，普通注册用户没有权限。或者，只有等级到达3级以上的普通用户，才有资格参加该活动。</p><p>这样简单的提高一点门槛，即使是黄牛党也束手无策，他们总不可能为了参加一次秒杀活动，还另外花钱充值会员吧？</p>]]></content>
    
    
    <categories>
      
      <category>高并发</category>
      
      <category>秒杀场景</category>
      
    </categories>
    
    
    <tags>
      
      <tag>高并发</tag>
      
      <tag>秒杀场景</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo</title>
    <link href="/2021/02/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/hexo/hexo/"/>
    <url>/2021/02/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/hexo/hexo/</url>
    
    <content type="html"><![CDATA[<h2 id="部署">部署</h2><h3 id="安装前提">安装前提</h3><ul><li><p><a href="https://nodejs.org/zh-cn/download/releases/">Node.js</a> (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本)</p><p>镜像下载链接：<a href="https://nodejs.org/download/release/v12.20.1/node-v12.20.1-x64.msi">https://nodejs.org/download/release/v12.20.1/node-v12.20.1-x64.msi</a></p></li><li><p><a href="http://git-scm.com/">Git</a></p><p>镜像下载链接：<a href="https://cdn.npmmirror.com/binaries/git-for-windows/v2.39.1.windows.1/Git-2.39.1-64-bit.exe">https://cdn.npmmirror.com/binaries/git-for-windows/v2.39.1.windows.1/Git-2.39.1-64-bit.exe</a></p><h4 id="问题">问题</h4><p><strong>安装后可能没有npm命令：</strong></p><p>重启shell终端</p></li></ul><h3 id="安装">安装</h3><p>所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">npm install -g hexo-cli<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes</title>
    <link href="/2021/01/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%AE%B9%E5%99%A8/01.K8S/"/>
    <url>/2021/01/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%AE%B9%E5%99%A8/01.K8S/</url>
    
    <content type="html"><![CDATA[<p>情况一、如果面试官问的是使用kubectl run命令创建的pod，可以这样说：<br>#注意：kubectl run 在旧版本中创建的是deployment，但在新的版本中创建的是pod则其创建过程不涉及deployment<br>如果是单独的创建一个pod，则其创建过程是这样的：<br>1、首先，用户通过kubectl或其他api客户端工具提交需要创建的pod信息给apiserver；<br>2、apiserver验证客户端的用户权限信息，验证通过开始处理创建请求生成pod对象信息，并将信息存入etcd，然后返回确认信息给客户端；<br>3、apiserver开始反馈etcd中pod对象的变化，其他组件使用watch机制跟踪apiserver上的变动；<br>4、scheduler发现有新的pod对象要创建，开始调用内部算法机制为pod分配最佳的主机，并将结果信息更新至apiserver；<br>5、node节点上的kubelet通过watch机制跟踪apiserver发现有pod调度到本节点，尝试调用docker启动容器，并将结果反馈apiserver；<br>6、apiserver将收到的pod状态信息存入etcd中。<br>至此，整个pod创建完毕。</p><p>情况二、如果面试官说的是使用deployment来创建pod，则可以这样回答：<br>1、首先，用户使用kubectl create命令或者kubectl apply命令提交了要创建一个deployment资源请求；<br>2、api-server收到创建资源的请求后，会对客户端操作进行身份认证，在客户端的~/.kube文件夹下，已经设置好了相关的用户认证信息，这样api-server会知道我是哪个用户，并对此用户进行鉴权，当api-server确定客户端的请求合法后，就会接受本次操作，并把相关的信息保存到etcd中，然后返回确认信息给客户端。<br>3、apiserver开始反馈etcd中过程创建的对象的变化，其他组件使用watch机制跟踪apiserver上的变动。<br>4、controller-manager组件会监听api-server的信息，controller-manager是有多个类型的，比如Deployment Controller, 它的作用就是负责监听Deployment，此时Deployment Controller发现有新的deployment要创建，那么它就会去创建一个ReplicaSet，一个ReplicaSet的产生，又被另一个叫做ReplicaSet Controller监听到了，紧接着它就会去分析ReplicaSet的语义，它了解到是要依照ReplicaSet的template去创建Pod, 它一看这个Pod并不存在，那么就新建此Pod，当Pod刚被创建时，它的nodeName属性值为空，代表着此Pod未被调度。<br>5、调度器Scheduler组件开始介入工作，Scheduler也是通过watch机制跟踪apiserver上的变动，发现有未调度的Pod，则根据内部算法、节点资源情况，pod定义的亲和性反亲和性等等，调度器会综合的选出一批候选节点，在候选节点中选择一个最优的节点，然后将pod绑定该该节点，将信息反馈给api-server。<br>6、kubelet组件布署于Node之上，它也是通过watch机制跟踪apiserver上的变动，监听到有一个Pod应该要被调度到自身所在Node上来，kubelet首先判断本地是否在此Pod，如果不存在，则会进入创建Pod流程，创建Pod有分为几种情况，第一种是容器不需要挂载外部存储，则相当于直接docker run把容器启动，但不会直接挂载docker网络，而是通过CNI调用网络插件配置容器网络，如果需要挂载外部存储，则还要调用CSI来挂载存储。kubelet创建完pod，将信息反馈给api-server，api-servier将pod信息写入etcd。<br>7、Pod建立成功后，ReplicaSet Controller会对其持续进行关注，如果Pod因意外或被我们手动退出，ReplicaSet Controller会知道，并创建新的Pod，以保持replicas数量期望值。</p><p>以上即使pod的调度过程。</p><ol><li>提交创建命令</li><li>api-server 会对客户端进行身份认证，在~./kube文件夹下，设置好了相关的用户认证信息，确定请求合法之后，会把相关信息存到etcd中。</li><li>api-server开始反馈etcd中的创建的对象的变化，其他组件使用watch机制跟踪apiserver上的变动。</li><li>controller-manager组件会监听api-server的信息，如果deploy controller发现有新的deployment要创建，那么它就回去新建一个replicaSet，之后又被另一个replicatset controller 监听到了，紧接着它就会去分析replicaset的语义，了解到是要依照replicaset的template 去创建Pod，他看到pod并不存在就会去新建一个pod，当pod刚被创建时，他的node name属性值为空，代表着此pod还未调度。</li><li>调度器schedule开始介入工作，通过watch机制跟踪apiserver上的变动，发现有未调度的pod，根据内部算法和资源情况，选出最优节点，然后绑定到这个节点。</li><li>kubelet判断本地是否存在这个pod，如果不存在就创建，不需要挂载外部存储，直接docker run启动，但是不会直接挂载docker网络，而是通过CNI调用网络插件配置容器网络，如果需要挂载存储，则还要调用CSI来挂载存储，创建完之后会把信息反馈给api-server，返回将pod的信息写入etcd。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL组成原理</title>
    <link href="/2020/03/28/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/02.MySQL/1.MySQL%E6%9E%B6%E6%9E%84/"/>
    <url>/2020/03/28/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/02.MySQL/1.MySQL%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h1>一、架构</h1><p>MySQL架构分两层：server层和存储引擎层</p><h2 id="server层">server层</h2><p>负责建立连接、执行和分析SQL。<br><strong>1. connectors</strong></p><p>与其他编程语言中的sql 语句进行交互，如php、java等。</p><p><strong>2. Management Serveices &amp; Utilities</strong></p><p>系统管理和控制工具</p><p><strong>3. Connection Pool (连接池)</strong></p><p>管理缓冲用户连接，线程处理等需要缓存的需求</p><p><strong>4. SQL Interface (SQL接口)</strong></p><p>接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface</p><p><strong>5. Parser （解析器）</strong></p><p>SQL命令传递到解析器的时候会被解析器验证和解析。</p><p>主要功能：</p><p>a . 将SQL语句分解成数据结构，并将这个结构传递到后续步骤，后面SQL语句的传递和处理就是基于这个结构的</p><p>b. 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的，语句将不会继续执行下去</p><p><strong>6. Optimizer (查询优化器)</strong></p><p>SQL语句在查询之前会使用查询优化器对查询进行优化(产生多种执行计划,最终数据库会选择最优化的方案去执行,尽快返会结果) 他使用的是“选取-投影-联接”策略进行查询。</p><p>用一个例子就可以理解：select uid,name from user where gender = 1;</p><p>这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤</p><p>这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤</p><p>将这两个查询条件联接起来生成最终查询结果.</p><p><strong>7. Cache和Buffer (查询缓存)</strong></p><p>如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。</p><p>这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等</p><p><strong>8.Engine (存储引擎)</strong></p><p>存储引擎是MySql中具体的与文件打交道的子系统。也是Mysql最具有特色的一个地方。</p><p>Mysql的存储引擎是插件式的。它根据MySql AB公司提供的文件访问层的一个抽象接口来定制一种文件访问机制（这种访问机制就叫存储引擎）</p><p><strong>9.文件和日志</strong></p><h1>二、<strong>SQL 语句执行过程</strong></h1><p>数据库通常不会被直接使用，而是由其他编程语言通过SQL语句调用mysql，由mysql处理并返回执行结果。那么Mysql接受到SQL语句后，又是如何处理</p><p>首先程序的请求会通过mysql的connectors与其进行交互，请求到处后，会暂时存放在连接池（connection pool)中并由处理器（Management Serveices &amp; Utilities）管理。当该请求从等待队列进入到处理队列，管理器会将该请求丢给SQL接口（SQL Interface）。SQL接口接收到请求后，它会将请求进行hash处理并与缓存中的结果进行对比，如果完全匹配则通过缓存直接返回处理结果；否则，需要完整的走一趟流程：</p><p>(1)由SQL接口丢给后面的解释器（Parser），解释器会判断SQL语句正确与否，若正确则将其转化为数据结构。</p><p>(2)解释器处理完，便来到后面的优化器（Optimizer），它会产生多种执行计划,最终数据库会选择最优化的方案去执行,尽快返会结果。</p><p>(3)确定最优执行计划后，SQL语句此时便可以交由存储引擎（Engine）处理，存储引擎将会到后端的存储设备中取得相应的数据，并原路返回给程序。</p><p><strong>(1)如何缓存查询数据</strong></p><p>存储引擎处理完数据，并将其返回给程序的同时，它还会将一份数据保留在缓存中，以便更快速的处理下一次相同的请求。具体情况是，mysql会将查询的语句、执行结果等进行hash，并保留在cache中，等待下次查询。</p><p><strong>(2)buffer与cache的区别</strong></p><p>从mysql原理图可以看到，缓存那里实际上有buffer和cache两个，那它们之间的区别：简单的说就是，buffer是写缓存，cache是读缓存。</p><p><strong>(3)如何判断缓存中是否已缓存需要的数据</strong></p><p>这里可能有一个误区，觉得处理SQL语句的时候，为了判断是否已缓存查询结果，会将整个流程走一遍，取得执行结果后再与需要的进行对比，看看是否命中，并以此说，既然不管缓存中有没有缓存到查询内容，都要整个流程走一遍，那缓存的优势在哪？</p><p>其实并不是这样，在第一次查询后，mysql便将查询语句以及查询结果进行hash处理并保留在缓存中，SQL查询到达之后，对其进行同样的hash处理后，将两个hash值进行对照，如果一样，则命中，从缓存中返回查询结果；否则，需要整个流程走一遍。</p><p>当数据库中有多个操作需要修改同一数据时，不可避免的会产生数据的脏读。这时就需要数据库具有良好的并发控制能力，这一切在MySQL中都是由服务器和存储引擎来实现的。</p><p>解决并发问题最有效的方案是引入了锁的机制，锁在功能上分为共享锁(shared lock)和排它锁(exclusive lock)即通常说的读锁和写锁。当一个select语句在执行时可以施加读锁，这样就可以允许其它的select操作进行，因为在这个过程中数据信息是不会被改变的这样就能够提高数据库的运行效率。当需要对数据更新时，就需要施加写锁了，不在允许其它的操作进行，以免产生数据的脏读和幻读。锁同样有粒度大小，有表级锁(table lock)和行级锁(row lock)，分别在数据操作的过程中完成行的锁定和表的锁定。这些根据不同的存储引擎所具有的特性也是不一样的。</p><p>MySQL大多数事务型的存储引擎都不是简单的行级锁，基于性能的考虑，他们一般都同时实现了多版本并发控制(MVCC)。这一方案也被Oracle等主流的关系数据库采用。它是通过保存数据中某个时间点的快照来实现的，这样就保证了每个事务看到的数据都是一致的。</p><h1>三、事务</h1><p>简单的说事务就是一组原子性的SQL语句。可以将这组语句理解成一个工作单元，要么全部执行要么都不执行。</p><h2 id="3-1-特性">3.1 特性</h2><p>原子性(atomicity):事务中的所有操作要么全部提交成功，要么全部失败回滚。<br>一致性(consistency):数据库总是从一个一致性状态转换到另一个一致性状态。<br>隔离性(isolation):一个事务所做的修改在提交之前对其它事务是不可见的。<br>持久性(durability):一旦事务提交，其所做的修改便会永久保存在数据库中。</p><h2 id="3-2-隔离级别">3.2 隔离级别</h2><h4 id="3-2-1-READ-UNCOMMITTED-读未提交">3.2.1 READ UNCOMMITTED(读未提交)</h4><p>在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。</p><h4 id="3-2-2-READ-COMMITTED-读已提交">3.2.2 READ COMMITTED(读已提交)</h4><p>一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。</p><h4 id="3-2-3-REPEATABLE-READ-可重复读">3.2.3 REPEATABLE READ(可重复读)</h4><p>这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。</p><h4 id="3-2-4-SERIALIZABLE-串行化">3.2.4 SERIALIZABLE(串行化)</h4><p>这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</p><h2 id="3-3-多版本并发控制（MVCC-）">3.3 多版本并发控制（MVCC ）</h2><p>是通过保存数据在某个时间点的快照来实现并发控制的。也就是说，不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。</p><p>简单来说， <strong>多版本并发控制</strong>的思想就是保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制。这样我们就可以通过比较版本号决定数据是否显示出来，读取数据的时候不需要加锁也可以保证事务的隔离效果。</p><h4 id="3-3-1-当前读和快照读">3.3.1 当前读和快照读</h4><h2 id="3-4-死锁">3.4 死锁</h2><p>两个或多个事务在同一资源上相互占用并请求锁定对方占用的资源，从而导致恶性循环的现象。MySQL的部分存储引擎能够检测到死锁的循环依赖并产生相应的错误。InnoDB引擎解决死锁的方案是将持有最少排它锁的事务进行回滚。</p><h1>四、Mysql 与 磁盘交互的过程</h1><h2 id="1、Mysql-交互模型（站在OS的角度）">1、Mysql 交互模型（站在OS的角度）</h2><p>核心理念说在最前面，Mysql 对数据所做的所有访问，无论是查询，还是增删改，都是在内存中进行的！</p><h3 id="1-Mysql-从磁盘读数据">(1) Mysql 从磁盘读数据</h3><p>早在Mysql 启动的时候，Mysql 就会向内存申请一块空间（下面统称“缓存池”）。</p><p>每次查询的时候，会预先从磁盘读取一部分相关数据到缓存池。（至于读取多少，详见“Mysql和磁盘交互的基本单位”）</p><p>每次增删改的时候，如果缓存池里存在对应的记录，那就直接在已有的记录上改；如果不存在，那就先从磁盘读取到缓存池，然后再改。</p><h3 id="2-Mysql-向磁盘写数据">(2) Mysql 向磁盘写数据</h3><p>所有的增删改查都在内存中进行，每次执行sql的时候都会在缓存池中先把数据调整好，然后再刷新到内核缓冲区。内核有自己刷新策略，会定期把数据从内核缓冲区刷新到磁盘。</p><p>从缓存池 ==》内核缓冲区的刷新策略有以下三种选择：</p><p>有脏数据就立马刷新（脏数据是内存操作完毕以后的数据）<br>定期刷新<br>达到一定的数据量再刷新<br>从内核缓冲区 ==》磁盘的刷新则是定期刷新。如果想要手动刷新内核缓冲区，可以参考系统调用接口 syncfs 。</p><h2 id="2、Mysql-交互的基本单位">2、Mysql 交互的基本单位</h2><h3 id="1-交互的基本单位（每次IO的数据量）">(1) 交互的基本单位（每次IO的数据量）</h3><p>上面提到，查询时，Mysql 会读取一部分数据到缓存池，那么问题来了，每次到底读取多少呢？</p><p>Mysql和外设交互的基本单位是16KB，即一次IO的数据量就是16KB，站在Mysql的角度，这16KB就是一个page。读数据时，将以page为单位，把相关数据从磁盘读取到内存；写数据也是同理。</p><h3 id="2-为什么IO交互要以page为基本单位？">(2) 为什么IO交互要以page为基本单位？</h3><p>假设每次查询都只读取一条记录，多次查询的时候，就要频繁跟数据库（简单理解为磁盘）交互。系统和磁盘的IO是比较费时的，为了提升效率，一般我们要尽量减少系统和磁盘IO的次数。</p><p>如果每次查询，我们以page（16KB）读取数据，那就相当于我们可以一次读取几百条记录到缓存池中，即便我们后续要频繁查询数据库，只要是在这个 page 里的内容，我们便无需和磁盘IO。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>channel</title>
    <link href="/2019/12/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/03.%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    <url>/2019/12/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/03.%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1>一、channel</h1><h2 id="1-前言">1. 前言</h2><p>channel是Golang在语言层面提供的goroutine间的通信方式，比Unix管道更易用也更轻便。channel主要用于进程内各goroutine间通信，如果需要跨进程通信，建议使用分布式系统的方法来解决。</p><h2 id="2-分类">2.分类</h2><h3 id="2-1-带缓冲">2.1 带缓冲</h3><p>带缓冲的channel，只有等缓冲区满了后才会阻塞；</p><p>读取一个关闭的channel，会读取到空值；</p><p>写入一个已经关闭的channel，会导致死锁；</p><h3 id="2-2-不带缓冲">2.2 不带缓冲</h3><p>读取/写入一个为nil的channel，会导致阻塞；</p><p>读取一个关闭的channel，会读取到空值；</p><p>写入一个已经关闭的channel，会导致死锁；</p><h2 id="3-数据结构">3. 数据结构</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs awk">type hchan struct &#123;<br>qcount   uint           <span class="hljs-regexp">//</span> 当前队列的剩余元素数量<br>dataqsiz uint           <span class="hljs-regexp">//</span> 环形队列长度，即可存放的元素个数<br>buf      unsafe.Pointer <span class="hljs-regexp">//</span> 环形队列指针<br>elemsize uint16         <span class="hljs-regexp">//</span> 每个元素大小<br>closed   uint32         <span class="hljs-regexp">//</span> 关闭状态标识<br>elemtype *_type         <span class="hljs-regexp">//</span> 元素类型<br>sendx    uint           <span class="hljs-regexp">//</span> 队列下标，指示元素写入时存放到队列中的位置<br>recvx    uint           <span class="hljs-regexp">//</span> 队列下标，指示元素从队列的该位置读出<br>recvq    waitq          <span class="hljs-regexp">//</span> 等待读消息的goroutine队列<br>sendq    waitq          <span class="hljs-regexp">//</span> 等待写消息的goroutine队列<br>  lock     mutex          <span class="hljs-regexp">//</span> 互斥锁，chan不允许并发读写<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-1-环形队列">3.1 环形队列</h3><p>chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。</p><h3 id="3-2-等待队列">3.2 等待队列</h3><h3 id="3-3-实现原理和特性">3.3 实现原理和特性</h3><h4 id="3-3-1-全局锁">3.3.1. 全局锁</h4><h4 id="3-3-2-移入、移除元素">3.3.2. 移入、移除元素</h4><h1>二、select</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">select</span> &#123;<br><span class="hljs-keyword">case</span> &lt;-signals1:<br><br><span class="hljs-keyword">case</span> &lt;-signals2:<br><br>&#125;<br></code></pre></td></tr></table></figure><p>注意如果signals1和signals2的信号过来，case的执行顺序是随机的。</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进程</title>
    <link href="/2019/11/13/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/02.%E8%BF%9B%E7%A8%8B/"/>
    <url>/2019/11/13/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/02.%E8%BF%9B%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="进程定义">进程定义</h2><p>进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位</p><h2 id="进程的组成">进程的组成</h2><p>进程由程序段、数据段、PCB三部分组成</p><h3 id="程序段">程序段</h3><p>存放要执行的代码</p><h3 id="数据段">数据段</h3><p>存放程序运行过程中处理的各种数据</p><h3 id="PCB">PCB</h3><p>进程的描述信息：进程标识符PID、用户标识符UID<br>进程控制和管理信息：进程当前状态、进程优先级<br>资源分配清单：程序段指针、数据段指针、键盘、鼠标<br>处理机相关信息：各种寄存器的值</p><h2 id="进程的组织方式">进程的组织方式</h2><h3 id="链接方式">链接方式</h3><p>按照进程状态指向对应的PCB，通常优先级高的放在队列</p><h3 id="索引方式">索引方式</h3><p>按照进程状态，建立几张索引表，操作系统拥有指向索引表的指针</p><h2 id="特征">特征</h2><ul><li>动态性</li><li>并发性</li><li>独立性</li><li>异步性</li><li>结构性</li></ul>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
      <category>进程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>操作系统</tag>
      
      <tag>进程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基础概念</title>
    <link href="/2019/11/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/01.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    <url>/2019/11/02/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/01.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<h2 id="概念">概念</h2><p>操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织和调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境，它是计算机系统中最基本的系统软件。</p><span id="more"></span><h2 id="功能和目标">功能和目标</h2><p><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.png" alt="avatar"></p><h3 id="作为系统资源的管理者">作为系统资源的管理者</h3><ol><li>处理机管理</li><li>存储器管理</li><li>文件管理</li><li>设备管理</li><li>安全、高效</li></ol><h3 id="作为用户和计算机硬件之间的接口">作为用户和计算机硬件之间的接口</h3><ul><li>命令接口：联机接口、脱机接口</li><li>程序接口</li><li>GUI（Graphical User Interface）</li></ul><h2 id="特征">特征</h2><p><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%89%B9%E5%BE%81.jpg" alt="avatar"></p><h3 id="并发">并发</h3><p>指多个时间在同一个时间间隔内发生，这些时间宏观上是一些发生的，微观上是交替发生的。</p><h3 id="共享">共享</h3><p>系统中的资源可供内存中多个并发执行的进程共同使用。</p><p>两种共享方式：</p><ul><li>互斥共享方式：一个时间段只允许一个进程访问</li><li>同时共享方式：一个时间段允许多个进程访问</li></ul><h3 id="虚拟">虚拟</h3><p>把一个是指把一个物理上的实体变为若干个逻辑上的对应物。</p><p>虚拟技术:</p><ul><li>空分复用技术</li><li>时分复用技术</li></ul><h3 id="异步">异步</h3><p>多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。</p><h2 id="发展和分类">发展和分类</h2><h2 id="特征-2">特征</h2><p><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%8F%91%E5%B1%95%E5%92%8C%E5%88%86%E7%B1%BB.jpg" alt="avatar"></p><h3 id="手工操作阶段">手工操作阶段</h3><p>缺点：用户独占全机、人机速度矛盾导致资源利用率极低</p><h3 id="单道批处理系统">单道批处理系统</h3><p>优点：缓解了一定的人机速度矛盾，资源利用有所提升<br>缺点：内存中只有一道程序运行，只有该程序运行结束之后才能调入下一道程序。CPU有大量时间实在空闲等待I/O完成。资源利用率依然很低。</p><h3 id="多道批处理系统">多道批处理系统</h3><p>优点：多道程序并发运行，共享计算机资源，资源利用率大幅提升。<br>缺点：用户响应时间长，没有人机交互功能。</p><h3 id="分时操作系统">分时操作系统</h3><p>计算机以时间片为单位轮流为各个用户/作业服务，各个用户可通过终端与计算机交互。<br>优点：用户请求能够被及时响应，解决了人机交互问题。<br>缺点：不能处理紧急任务。</p><h3 id="实时操作系统">实时操作系统</h3><p>优点：能够优先响应一些紧急任务，某些紧急任务不需时间片排队。</p><h2 id="运行机制和体系结构">运行机制和体系结构</h2><p><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.jpg" alt="avatar"></p><h3 id="指令">指令</h3><p>CPU能识别、处理的最基础的命令</p><ul><li>特权指令：不允许程序使用</li><li>非特权指令</li></ul><p>当CPU处于用户态，只能使用非特权指令，当处于核心态的时候，两种指令都能实现。所以将程序也分为内核程序和应用程序。</p><h3 id="内核">内核</h3><p>内核是计算机上配置的底层软件，是操作系统最基本、最核心的部分。<br>包括进程管理、存储器管理、设备管理等功能，时钟管理、中断处理，原语。</p><h2 id="中断和异常">中断和异常</h2><p><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8.jpg" alt="avatar"></p><ol><li>当中断发生后，CPU立即进入核心态</li><li>当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进行处理</li><li>对于不同的中断信号，会进行不用的处理</li></ol><p>分类：</p><ul><li>内中断：陷入（trap）、故障（fault）、终止（abort）</li><li>外中断：I/O中断请求、人工干预</li></ul><h2 id="系统调用">系统调用</h2><p>操作系统提供给应用程序使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务。<br><img src="/source/image/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8.jpg" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go基础</title>
    <link href="/2019/09/03/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/02.%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/"/>
    <url>/2019/09/03/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/02.%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/</url>
    
    <content type="html"><![CDATA[<h1>1. 数组</h1><p>语法：[cap]type</p><ol><li>初始化要指定长度</li><li>直接初始化</li><li>arr[i]的形式访问元素</li><li>len和cap计算数组长度</li></ol><h1>2. 切片</h1><p>语法：[]type</p><p>不需要声明容量</p><ol><li>直接初始化</li><li>使用<code>make</code>初始化</li><li>长度和容量不一定相等</li><li>使用append追加元素，如果超过了容量限制，就会进行扩容，当容量小于1024，双倍扩容，当容量大于1024，扩容1/4大小。</li><li>len获取元素数量，cap获取切片容量</li></ol><p>子切片：</p><ol><li>arr[start:end] ,获得[start,end)之间的元素</li><li>arr[start:] ,获得(start,len(arr)]之间的元素</li><li>arr[:end] ,获得[0,end)之间的元素</li></ol><p>只有append操作，切片支持子切片，和原本切片是共享数组，看他们的结构有没有发生变化，看切片有没有扩容。</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go基础</title>
    <link href="/2019/09/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/01.go%E5%9F%BA%E7%A1%80/"/>
    <url>/2019/09/01/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/01.Go/01.%E5%9F%BA%E7%A1%80/01.go%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1>一、环境</h1><h2 id="1-安装go">1.安装go</h2><p>下载go的安装包，go安装包<a href="https://studygolang.com/dl">下载链接</a></p><h2 id="2-配置环境变量">2.配置环境变量</h2><p>配置GOROOT</p><h2 id="3-配置Go-env">3.配置Go env</h2><p>GO111MODULE:是否启用go mod</p><p>GOROOT：安装路径</p><p>GOPATH：关键，设置为自己的golang的项目放置路径</p><p>GOPROXY：推荐https://goproxy.cn</p><h1>二、新建项目</h1><p>goland 点击 file-&gt;new-&gt;project</p><p>新建main.go文件，注意package为main</p><h1>三、基础语法</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;hello go!&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="1-包">1. 包</h2><p>package 包名</p><ul><li>字母和下划线的组合</li><li>文件夹下的包名保持一致</li></ul><p>import 注意匿名引用</p><h2 id="2-基础类型">2. 基础类型</h2><h3 id="2-1-string">2.1 string</h3><p>长度特殊：</p><p>字节长度：和编码无关，使用<code>len(string)</code>输出字符长度</p><p>字节数量：和编码有关，用编码库来计算</p><p><code>strings</code>包是处理<code>string</code>的方法集</p><h3 id="2-2-rune">2.2 rune</h3><p>直观理解，就是字符，不是byte，本质是int32，一个rune四个字节</p><h3 id="2-3-bool-int-unit-float">2.3 bool,int,unit,float</h3><p>bool:ture,false</p><p>int8,int16,int32,int64,int</p><p>uint8,uint16,uint32,uint64,uint</p><p>float32, float64</p><h3 id="2-4-byte">2.4 byte</h3><p>字节，本质是int8</p><p>相关的包是<code>bytes</code></p><h2 id="3-变量命名">3. 变量命名</h2><p>首字母大写控制了作用域</p><p>不会做任何隐式转换</p><p>局部变量声明</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">a := <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>易错点：</p><p>声明没使用</p><p>类型不匹配</p><p>同作用域下，变量只能声明一次</p><h2 id="4-方法声明">4. 方法声明</h2><p>格式：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">funeName</span><span class="hljs-params">(name <span class="hljs-keyword">string</span>)</span><span class="hljs-params">(err error)</span></span>&#123;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>特性：支持多返回值，通过首字母大小写控制了作用域</p><h2 id="5-控制语句">5. 控制语句</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">for</span> &#123;<br><br>&#125;<br><br><span class="hljs-keyword">for</span> index, value := <span class="hljs-keyword">range</span> arr &#123;<br>    <br>&#125;<br><br><span class="hljs-keyword">switch</span> a &#123;<br><span class="hljs-keyword">case</span> <span class="hljs-string">&quot;a&quot;</span>:<br>    <span class="hljs-built_in">print</span><br><span class="hljs-keyword">case</span> <span class="hljs-string">&quot;b&quot;</span>:<br>    <span class="hljs-built_in">print</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="6-type定义">6. type定义</h2><h4 id="type-名字-interface">type 名字 interface{}</h4><p>里面只能有方法</p><p>是一组行为的抽象</p><p>尽量用接口，已面向接口编程</p><h4 id="type-名字-struct">type 名字 struct{}</h4><p>可以嵌套</p><p>结构体里面，自己引用自己，只能用指针</p><p>接收器：</p><p>结构体接收器 修改不了自身的状态，如果是func就用这种</p><p>指针接收器 可以修改自身的状态，struct用这种</p><p>type 名字 别的类型</p><p>type 别名 = 别的类型</p><h2 id="7-实现接口">7. 实现接口</h2><p>需要实现对应结构的所有方法，才能实现接口。</p><h2 id="8-抽象思维">8. 抽象思维</h2><p>可以逻辑中一些可以抽象出来的逻辑，把入参构建结构体后，再把逻辑绑定到结构体上，尽量把生成的结构体由自己控制。</p><p>尽量把公共方法抽象成接口。</p>]]></content>
    
    
    <categories>
      
      <category>Go</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PAAS和SAAS</title>
    <link href="/2019/08/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/4.PAAS%E3%80%81SAAS/"/>
    <url>/2019/08/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/4.PAAS%E3%80%81SAAS/</url>
    
    <content type="html"><![CDATA[<h1>一、什么是IAAS，PAAS和SAAS</h1><p>要理解什么是PAAS和SAAS，需要理解什么是云服务。云服务是指互联网提供动态易扩展的虚拟资源整合服务，云服务的主体架构，主要有基础设施服务、平台服务、软件服务。</p><h2 id="1-IaaS">1. IaaS</h2><p>基础设施即服务。有了laaS，企业在开发APP时，只需在公有云平台上注册一个账号，花点钱，配置各种云服务器，各种大小的存储，各种带宽的网络，都配齐，不用操心诸如机房选址、设备采购、实体服务器、存储、网络等问题，只要一个账号，便解决了。</p><p>而作为程序员，只需在服务器上安装各类runtime，中间件，数据库等等以及开发这款APP的前端与后台，测试，上线，再迭代，再更新的操作，如果没有IaaS，前期我们的工作还有很多。</p><h2 id="2-PaaS">2. PaaS</h2><p>平台即服务。PaaS是在IaaS的基础之上，解决了操作系统、数据库、运行时环境runtime、中间件、各种框架的搭建操作问题，有了PaaS，程序员只需要专心的开发自己的APP就行了。</p><h2 id="3-SaaS">3. SaaS</h2><p>软件即服务。SaaS就是现成的了，根本用不着开发，商家只需要专注在自己的业务上就行了，别的写代码、维护等各种事情都交给SaaS厂商就行了。用户只需要一个续费账号，所有问题都解决了。</p>]]></content>
    
    
    <categories>
      
      <category>PAAS</category>
      
      <category>SAAS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PAAS</tag>
      
      <tag>SAAS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>微服务</title>
    <link href="/2019/08/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/1.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A6%82%E8%A7%88/"/>
    <url>/2019/08/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/1.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A6%82%E8%A7%88/</url>
    
    <content type="html"><![CDATA[<h2 id="一、概念">一、概念</h2><p>微服务，又名微服务架构，是一种架构风格，它将应用程序构建为以业务领域建模的小型自治服务的集合。在微服务架构中，每个服务都是自包含的，并且实现了单一的业务能力。</p><p>可以把微服务看作是SOA的一种最佳实践。</p><h3 id="1-1-传统架构与微服务的区别">1.1 传统架构与微服务的区别</h3><p>对于单体应用，所有功能最初都在共享单个数据库的单个实例下。但是，对于微服务，每个特性都被分配了一个不同的微服务，处理它们自己的数据，并执行不同的功能。</p><h3 id="1-2-微服务架构">1.2 微服务架构</h3><ul><li>来自不同设备的不同客户端尝试使用不同的服务，例如搜索、构建、配置和其他管理功能。</li><li>所有服务都根据其域和功能进行分离，并进一步分配给各个微服务。</li><li>这些微服务有自己的负载均衡器和执行环境来执行它们的功能，同时在自己的数据库中捕获数据。</li><li>所有微服务都通过无状态服务器（REST 或消息总线）相互通信。</li><li>微服务借助服务发现了解其通信路径，并执行自动化、监控等操作功能。</li><li>然后，微服务执行的所有功能都通过 API 网关与客户端通信。</li><li>所有内部点都从 API 网关连接。因此，任何连接到 API 网关的人都会自动连接到整个系统。</li></ul><h3 id="1-3-微服务功能">1.3 微服务功能</h3><ul><li>解耦——系统内的服务在很大程度上是解耦的。因此，整个应用程序可以轻松构建、更改和扩展。</li><li>组件化——微服务被视为可以轻松更换和升级的独立组件。</li><li>业务能力——微服务非常简单，专注于单一能力。</li><li>自治——开发人员和团队可以彼此独立工作，从而提高速度。</li><li>持续交付——通过软件创建、测试和批准的系统自动化，允许频繁发布软件。</li><li>责任——微服务不关注应用程序作为项目。相反，他们将应用程序视为他们负责的产品。</li><li>去中心化治理——重点是为正确的工作使用正确的工具。这意味着没有标准化的模式或任何技术模式。开发人员可以自由选择最有用的工具来解决他们的问题。</li><li>敏捷性——微服务支持敏捷开发。任何新功能都可以快速开发并再次丢弃。</li></ul><h3 id="1-4-微服务的优势">1.4 微服务的优势</h3><ul><li>独立开发——所有微服务都可以根据各自的功能轻松开发</li><li>独立部署——根据他们的服务，他们可以单独部署在任何应用程序中</li><li>故障隔离——即使应用程序的一项服务不工作，系统仍然继续运行</li><li>混合技术栈——不同的语言和技术可用于构建同一应用程序的不同服务</li><li>粒度缩放——单个组件可以根据需要进行缩放，无需将所有组件一起缩放</li></ul><h1>二、实现一个微服务</h1><h2 id="2-1-组件服务化">2.1 组件服务化</h2><p>我们用go实现一个微服务：</p><ul><li><p>kit：一个微服务的基础库（框架）</p></li><li><p>service：业务代码+kit依赖+第三方依赖组成的业务微服务</p></li><li><p>RPC+message queue：轻量级通讯</p></li></ul><p>多个微服务compose成一个usecase</p><h2 id="2-2-按业务组织服务">2.2 按业务组织服务</h2><p>服务提供的能力和业务功能对应，开发团队对软件在生产环境负全部责任</p><h2 id="2-3-去中心化">2.3 去中心化</h2><p>每个服务面对的场景不同，可以针对性的选择合适的技术解决方案。数据、治理、技术去中心化。所有的资源都是隔离的。</p><h2 id="2-4-基础设施自动化">2.4 基础设施自动化</h2><p>自动化包括测试和部署</p><p>CICD：gitlab+gitlab hooks +kubernetes</p><p>testing: 测试环境、单元测试、API自动化测试</p><p>在线运行时：K8S，已经一系列Prometheus、ELK、conrtol panle</p><h3 id="2-5-可用性-兼容性设计">2.5 可用性&amp;兼容性设计</h3><p>著名的Design For Failure思想，微服务架构采用粗粒度的进程间通信，引入了额外的复杂性和需要处理的新问题，如网络延迟、消息格式、负载均衡和容错。</p><p>在服务需要变更时需要特别小心，服务提供者的变更可能引发服务消费者的兼容性破坏。发送时要保守，接收性要开放。最小化的传送必要的信息，要最大限度的容忍冗余数据，保证兼容性。</p>]]></content>
    
    
    <categories>
      
      <category>微服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>微服务设计</title>
    <link href="/2019/08/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/2.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/"/>
    <url>/2019/08/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E5%BE%AE%E6%9C%8D%E5%8A%A1/2.%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1>一、API Gateway</h1><h2 id="1-踩过的坑">1. 踩过的坑</h2><p>按照垂直功能进行了拆分，对外暴露了一批微服务，缺乏统一的出口。</p><ul><li>客户端到微服务直接通信，强耦合，微服务老的接口下不了</li><li>需要多次请求，客户端聚合数据，工作量巨大，延迟高，会延迟发布速度</li><li>协议不利于统一，各个部门有差异，需要端来兼容</li><li>面向端的API适配，耦合到了内部服务</li><li>多终端兼容逻辑复杂，每个服务都需要处理</li><li>统一逻辑无法收敛，比如安全认证、限流。</li></ul><h2 id="2-新增app-interface">2. 新增app-interface</h2><p>用于统一的协议出口，在服务内进行大量的dataset join，按照业务场景来设计粗粒度的API。</p><p>轻量交互：协议精简、聚合。</p><p>差异服务：数据裁剪以及聚合，针对终端定制化API。</p><p>动态升级：原有系统兼容升级，更新服务而非协议。</p><p>沟通效率提升，协作模式演进为移动服务+网关小组。</p><p>最致命的问题是整个app-interface数据single point of failure，严重代码缺陷或者流量洪峰可能引发集群宕机。</p><p>按照重要性和业务拆分。</p><p>跨横切面逻辑，比如安全认证，日志监控，限流熔断等，随着时间推移，代码变得越来越复杂。</p><p>跨横切面的功能，需要协调更新框架升级发版（路由，认证，限流，安全），因此全部上沉，引入了API Gateway，把业务集成度很高的BFF层和通用功能服务层API gateway进行了分层处理。</p><h1>二、领域驱动设计</h1><h2 id="2-1-基础概念">2.1 基础概念</h2><h3 id="2-1-1-领域和子域">2.1.1 领域和子域</h3><p>在研究和解决业务问题时，DDD 会按照一定的规则将业务领域进行细分，当领域细分到一定的程度后，DDD 会将问题范围限定在特定的边界内，在这个边界内建立领域模型，进而用代码实现该领域模型，解决相应的业务问题。简言之，DDD 的领域就是这个边界内要解决的业务问题域。</p><p>在研究和解决业务问题时，DDD 会按照一定的规则将业务领域进行细分，当领域细分到一定的程度后，DDD 会将问题范围限定在特定的边界内，在这个边界内建立领域模型，进而用代码实现该领域模型，解决相应的业务问题。简言之，DDD 的领域就是这个边界内要解决的业务问题域。</p><p>领域的核心思想就是将问题域逐级细分，来降低业务理解和系统实现的复杂度。通过领域细分，逐步缩小服务需要解决的问题域，构建合适的领域模型。</p><h3 id="2-1-2-核心域、通用域和支撑域">2.1.2 核心域、通用域和支撑域</h3><p>子域可以根据重要程度和功能属性划分为如下：</p><ul><li>核心域：决定产品和公司核心竞争力的子域，它是业务成功的主要因素和公司的核心竞争力。</li><li>通用域：没有太多个性化的诉求，同时被多个子域使用的通用功能的子域。</li><li>支撑域：但既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域。</li></ul><p>核心域、支撑域和通用域的主要目标是：通过领域划分，区分不同子域在公司内的不同功能属性和重要性，从而公司可对不同子域采取不同的资源投入和建设策略，其关注度也会不一样。</p><p>很多公司的业务，表面看上去相似，但商业模式和战略方向是存在很大差异的，因此公司的关注点会不一样，在划分核心域、通用域和支撑域时，其结果也会出现非常大的差异。</p><p>比如同样都是电商平台的淘宝、天猫、京东和苏宁易购，他们的商业模式是不同的。淘宝是 C2C 网站，个人卖家对个人买家，而天猫、京东和苏宁易购则是 B2C 网站，是公司卖家对个人买家。即便是苏宁易购与京东都是 B2C 的模式，苏宁易购是典型的传统线下卖场转型成为电商，京东则是直营加部分平台模式。因此，在公司建立领域模型时，我们就要结合公司战略重点和商业模式，重点关注核心域。</p><h4 id="通用语言和限界上下文">通用语言和限界上下文</h4><ul><li>通用语言：就是能够简单、清晰、准确描述业务涵义和规则的语言。</li><li>限界上下文：用来封装通用语言和领域对象，提供上下文环境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。</li></ul><h5 id="通用语言">通用语言</h5><p>通用语言是团队统一的语言，不管你在团队中承担什么角色，在同一个领域的软件生命周期里都使用统一的语言进行交流。那么，通用语言的价值也就很明了，它可以解决交流障碍这个问题，使领域专家和开发人员能够协同合作，从而确保业务需求的正确表达。</p><p>这个通用语言到场景落地，大家可能还很模糊，其实就是把领域对象、属性、代码模型对象等，通过代码和文字建立映射关系，可以通过Excel记录这个关系，这样研发可以通过代码知道这个含义，产品或者业务方可以通过文字知道这个含义，沟通起来就不会有歧义，说的简单一点，其实就是统一产品和研发的话术。</p><h5 id="限界上下文">限界上下文</h5><p>通用语言也有它的上下文环境，为了避免同样的概念或语义在不同的上下文环境中产生歧义，DDD 在战略设计上提出了“限界上下文”这个概念，用来确定语义所在的领域边界。</p><p>限界上下文是一个显式的语义和语境上的边界，领域模型便存在于边界之内。边界内，通用语言中的所有术语和词组都有特定的含义。把限界上下文拆解开看，限界就是领域的边界，而上下文则是语义环境。通过领域的限界上下文，我们就可以在统一的领域边界内用统一的语言进行交流。</p><h4 id="实体和值对象">实体和值对象</h4><h5 id="实体">实体</h5><p>DDD中要求实体是唯一的且可持续变化的。意思是说在实体的生命周期内，无论其如何变化，其仍旧是同一个实体。唯一性由唯一的身份标识来决定的。可变性也正反映了实体本身的状态和行为。</p><p>实体以 DO（领域对象）的形式存在，每个实体对象都有唯一的 ID。我们可以对一个实体对象进行多次修改，修改后的数据和原来的数据可能会大不相同。但是，由于它们拥有相同的 ID，它们依然是同一个实体。比如商品是商品上下文的一个实体，通过唯一的商品 ID 来标识，不管这个商品的数据如何变化，商品的 ID 一直保持不变，它始终是同一个商品。</p><h5 id="值对象">值对象</h5><p>当你只关心某个对象的属性时，该对象便可作为一个值对象。 我们需要将值对象看成不变对象，不要给它任何身份标识，还应该尽量避免像实体对象一样的复杂性。</p><p>还是举个订单的例子，订单是一个实体，里面包含地址，这个地址可以只通过属性嵌入的方式形成的订单实体对象，也可以将地址通过JSON序列化一个string类型的数据，存到DB的一个字段中，那么这个JSON串就是一个值对象</p><h4 id="聚合和聚合根">聚合和聚合根</h4><h5 id="聚合">聚合</h5><p>聚合：我们把一些关联性极强、生命周期一致的实体、值对象放到一个聚合里。聚合是领域对象的显式分组，旨在支持领域模型的行为和不变性，同时充当一致性和事务性边界。</p><p>聚合有一个聚合根和上下文边界，这个边界根据业务单一职责和高内聚原则，定义了聚合内部应该包含哪些实体和值对象，而聚合之间的边界是松耦合的。按照这种方式设计出来的服务很自然就是“高内聚、低耦合”的。</p><p>聚合在 DDD 分层架构里属于领域层，领域层包含了多个聚合，共同实现核心业务逻辑。跨多个实体的业务逻辑通过领域服务来实现，跨多个聚合的业务逻辑通过应用服务来实现。比如有的业务场景需要同一个聚合的 A 和 B 两个实体来共同完成，我们就可以将这段业务逻辑用领域服务来实现；而有的业务逻辑需要聚合 C 和聚合 D 中的两个服务共同完成，这时你就可以用应用服务来组合这两个服务。</p><h5 id="聚合根">聚合根</h5><p>如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者。</p><ul><li>首先它作为实体本身，拥有实体的属性和业务行为，实现自身的业务逻辑。</li><li>其次它作为聚合的管理者，在聚合内部负责协调实体和值对象按照固定的业务规则协同完成共同的业务逻辑。</li><li>最后在聚合之间，它还是聚合对外的接口人，以聚合根 ID 关联的方式接受外部任务和请求，在上下文内实现聚合之间的业务协同。也就是说，聚合之间通过聚合根 ID 关联引用，如果需要访问其它聚合的实体，就要先访问聚合根，再导航到聚合内部实体，外部对象不能直接访问聚合内实体。</li></ul><p>​</p><h4 id="领域服务和应用服务">领域服务和应用服务</h4><h5 id="领域服务">领域服务</h5><p>当一些逻辑不属于某个实体时，可以把这些逻辑单独拿出来放到领域服务中，理想的情况是没有领域服务，如果领域服务使用不恰当，慢慢又演化回了以前逻辑都在service层的局面。</p><p>可以使用领域服务的情况：</p><ul><li>执行一个显著的业务操作</li><li>对领域对象进行转换</li><li>以多个领域对象作为输入参数进行计算，结果产生一个值对象</li></ul><h5 id="应用服务">应用服务</h5><p>应用层作为展现层与领域层的桥梁，是用来表达用例和用户故事的主要手段。</p><p>应用层通过应用服务接口来暴露系统的全部功能。在应用服务的实现中，它负责编排和转发，它将要实现的功能委托给一个或多个领域对象来实现，它本身只负责处理业务用例的执行顺序以及结果的拼装。通过这样一种方式，它隐藏了领域层的复杂性及其内部实现机制。</p><p>应用层相对来说是较“薄”的一层，除了定义应用服务之外，在该层我们可以进行安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知，另外还可以用于创建邮件以发送给客户等。</p><h4 id="领域事件">领域事件</h4><p>领域事件 = 事件发布 + 事件存储 + 事件分发 + 事件处理。</p><p>领域事件是一个领域模型中极其重要的部分，用来表示领域中发生的事件。忽略不相关的领域活动，同时明确领域专家要跟踪或希望被通知的事情，或与其他模型对象中的状态更改相关联，下面简单说明领域事件：</p><ul><li>事件发布：构建一个事件，需要唯一标识，然后发布；</li><li>事件存储：发布事件前需要存储，因为接收后的事建也会存储，可用于重试或对账等；</li><li>事件分发：服务内直接发布给订阅者，服务外需要借助消息中间件，比如Kafka，RabbitMQ等；</li><li>事件处理：先将事件存储，然后再处理。</li></ul><p>比如下订单后，给用户增长积分与赠送优惠券的需求。如果使用瀑布流的方式写代码。一个个逻辑调用，那么不同用户，赠送的东西不同，逻辑就会变得又臭又长。这里的比较好的方式是，用户下订单成功后，发布领域事件，积分聚合与优惠券聚合监听订单发布的领域事件进行处理。</p><h4 id="资源库【仓储】">资源库【仓储】</h4><p>仓储介于领域模型和数据模型之间，主要用于聚合的持久化和检索。它隔离了领域模型和数据模型，以便我们关注于领域模型而不需要考虑如何进行持久化。</p><p>我们将暂时不使用的领域对象从内存中持久化存储到磁盘中。当日后需要再次使用这个领域对象时，根据 key 值到数据库查找到这条记录，然后将其恢复成领域对象，应用程序就可以继续使用它了，这就是领域对象持久化存储的设计思想。</p><h1>三、Mircoservice划分</h1><p>通常采用两种不同的方式划分服务边界：通过业务职能或者DDD的界限上下文。</p><h2 id="业务职能">业务职能</h2><p>由公司内部的不同部门提供的职能划分。</p><h2 id="限界上下文-2">限界上下文</h2><p>限界上下文市DDD中用来划分不同业务边界的元素，这里业务边界的含义是解决不同的业务问题的问题域和对应的解决方案域，为了解决的某种类型的业务问题，贴近领域知识，也就是业务。</p><p>合久必分，分久必合。</p><h1>四、微服务的安全</h1><p>对于外网的请求来说，我们通常在APi Gateway进行统一的认证拦截，一旦认证成功，我们会使用header的方式通过RPC元数据传递的方式带到BFF层，BFF获取后把身份信息注入到应用的Context层，BFF到其他下游的微服务，建议是直接在RPC Request中带入用户身份的请求服务。</p><p>对于服务内部更重要的知道谁来调你，一个是认证，一个授权。</p><p>主要分为三种</p><p>Full Trust 全信任</p><p>Half Trust 做认证</p><p>Zero Trust 零信任，最简单的方式就是发放token，基于证书会复杂一些。</p>]]></content>
    
    
    <categories>
      
      <category>微服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>树</title>
    <link href="/2019/04/23/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%A0%91/"/>
    <url>/2019/04/23/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%A0%91/</url>
    
    <content type="html"><![CDATA[<h1>一、树</h1><p>什么是树？</p><p>N个结点构成的有限集合。 树中有一个称为”根(Root)”的特殊结点，其余结点可分为若干个互不相交的树，称为原来结点的”子树”。</p><p><img src="https://static001.geekbang.org/resource/image/b7/29/b7043bf29a253bb36221eaec62b2e129.jpg?wh=800*600" alt="img"></p><h1>二、常用概念</h1><p>高度：从叶结点开始自底向上逐层累加的。</p><p>深度：从根节点开始自上向下逐层累加的。</p><p>层数：</p><p>完全二叉树</p><p>定义：如果一个树，除去最后一层为满二叉树，而且最后一层节点依次从左至右分布，则为完全二叉树<br>特性：对于一个完全二叉树从左至右按层次编号为1至n，有以下特性</p><ol><li>对于 i &gt; 1 ，它的父节点为 i / 2；</li><li>如果 2 * i &gt; n，那么i肯定没有左节点，否则左节点应该是 2 * i</li><li>如果 2*i+1 &gt; n，那么i肯定没有右节点</li></ol><p>例子：堆排序算法</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>散列表</title>
    <link href="/2019/04/20/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%95%A3%E5%88%97%E8%A1%A8/"/>
    <url>/2019/04/20/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%95%A3%E5%88%97%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="概念">概念</h2><p>散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><span id="more"></span><h2 id="散列函数">散列函数</h2><p>散列函数计算得到的散列值是一个非负整数；<br>如果 key1 = key2，那 hash(key1) == hash(key2)；<br>如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。</p><h2 id="散列冲突">散列冲突</h2><h3 id="开放寻址法">开放寻址法</h3><p>开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。<br>探测方法：</p><ol><li><p>线性探测<br>当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。<br>在散列表中查找元素的过程有点儿类似插入过程。我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。<br>散列表跟数组一样，不仅支持插入、查找操作，还支持删除操作。对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别。将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。</p></li><li><p>二次探测<br>所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+1<sup>2，hash(key)+2</sup>2……</p></li><li><p>双重散列<br>不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。</p></li></ol><h4 id="装载因子">装载因子</h4><p>表示空位的多少，装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。</p><figure class="highlight fix"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fix"><span class="hljs-attr">散列表的装载因子</span>=<span class="hljs-string">填入表中的元素个数/散列表的长度</span><br></code></pre></td></tr></table></figure><h3 id="链表法">链表法</h3><p>链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。</p><h2 id="如何设计散列函数？">如何设计散列函数？</h2><p>散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接地影响到散列表的性能。其次，散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。</p><h2 id="装载因子过大了怎么办？">装载因子过大了怎么办？</h2><p>针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。假设每次扩容我们都申请一个原来散列表大小两倍的空间。如果原来散列表的装载因子是 0.8，那经过扩容之后，新散列表的装载因子就下降为原来的一半，变成了 0.4。</p><h2 id="如何选择冲突解决方法？">如何选择冲突解决方法？</h2><p>当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。<br>基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>散列表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>散列表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>跳表</title>
    <link href="/2019/04/19/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E8%B7%B3%E8%A1%A8/"/>
    <url>/2019/04/19/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E8%B7%B3%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="概念">概念</h2><p>在单链表的基础上，增加多级索引，每级索引都是下一级索引的1/2大小。</p><h2 id="查找速度">查找速度</h2><p>第 k 级索引的结点个数是第 k-1 级索引的结点个数的 1/2，那第 k级索引结点的个数就是 n/(2k)。<br>设索引有 h 级，最高级的索引有 2 个结点。通过上面的公式，我们可以得到 n/(2h)=2，从而求得 h=log2n-1。如果包含原始链表这一层，整个跳表的高度就是 log2n。我们在跳表中查询某个数据的时候，如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。<br>跳表中查询任意数据的时间复杂度就是 O(logn)。</p><h2 id="高效的动态插入和删除">高效的动态插入和删除</h2><p>跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 O(logn)。<br>对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是，对于跳表来说，我们讲过查找某个结点的时间复杂度是 O(logn)，所以这里查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 O(logn)。<br>删除时，如果这个结点在索引中也有出现，我们除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果我们用的是双向链表，就不需要考虑这个问题了。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>跳表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>跳表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二分查找法</title>
    <link href="/2019/04/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    <url>/2019/04/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
    
    <content type="html"><![CDATA[<h2 id="概念">概念</h2><p>二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。</p><h2 id="查找速度">查找速度</h2><p>时间复杂度也是 O(logn)</p><h2 id="二分查找的递归与非递归实现">二分查找的递归与非递归实现</h2><h3 id="非递归">非递归</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Bsearch</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, n, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>low := <span class="hljs-number">0</span><br>high := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> low &lt;= high &#123;<br>mid := low + (high-low)&gt;&gt;<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> arr[mid] == value &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt; value &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>high = mid - <span class="hljs-number">1</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="递归">递归</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BsearchRecursion</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, low, high, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br><span class="hljs-keyword">if</span> low &gt; high &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br>mid := low + ((high - low) &gt;&gt; <span class="hljs-number">1</span>) <span class="hljs-comment">// + 的优先级高于 &gt;&gt;</span><br><span class="hljs-keyword">if</span> arr[mid] == value &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt; value &#123;<br><span class="hljs-keyword">return</span> BsearchRecursion(arr, mid+<span class="hljs-number">1</span>, high, value)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">return</span> BsearchRecursion(arr, low, mid<span class="hljs-number">-1</span>, value)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="应用场景的局限性">应用场景的局限性</h2><ol><li>二分查找只能用在数据是通过顺序表来存储的数据结构上。如果你的数据是通过其他数据结构存储的，则无法应用二分查找</li><li>二分查找对这一点的要求比较苛刻，数据必须是有序的。</li><li>如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。</li><li>分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。</li></ol><h2 id="二分查找变体">二分查找变体</h2><h3 id="变体一：查找第一个值等于给定值的元素">变体一：查找第一个值等于给定值的元素</h3><p>有序数据集合中存在重复的数据，我们希望找到第一个值等于给定值的数据</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Bsearch2</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, n, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>low := <span class="hljs-number">0</span><br>high := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> low &lt;= high &#123;<br>mid := low + (high-low)&gt;&gt;<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> arr[mid] &gt; value &#123;<br>high = mid - <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt; value &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> (mid == <span class="hljs-number">0</span>) || (arr[mid<span class="hljs-number">-1</span>] != value) &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>high = mid - <span class="hljs-number">1</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="变体二：查找最后一个值等于给定值的元素">变体二：查找最后一个值等于给定值的元素</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Bsearch3</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, n, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>low := <span class="hljs-number">0</span><br>high := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> low &lt;= high &#123;<br>mid := low + (high-low)&gt;&gt;<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> arr[mid] &gt; value &#123;<br>high = mid - <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt; value &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> (mid == n<span class="hljs-number">-1</span>) || (arr[mid+<span class="hljs-number">1</span>] != value) &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="变体三：查找第一个大于等于给定值的元素">变体三：查找第一个大于等于给定值的元素</h3><p>a[mid]小于要查找的值 value，那要查找的值肯定在[mid+1, high]之间，所以，我们更新 low=mid+1。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Bsearch4</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, n, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>low := <span class="hljs-number">0</span><br>high := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> low &lt;= high &#123;<br>mid := low + (high-low)&gt;&gt;<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> arr[mid] &gt;= value &#123;<br><span class="hljs-keyword">if</span> (mid == <span class="hljs-number">0</span>) || (arr[mid<span class="hljs-number">-1</span>] &lt; value) &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>high = mid - <span class="hljs-number">1</span><br>&#125;<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt; value &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="变体四：查找最后一个小于等于给定值的元素">变体四：查找最后一个小于等于给定值的元素</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Bsearch5</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, n, value <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>low := <span class="hljs-number">0</span><br>high := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> low &lt;= high &#123;<br>mid := low + (high-low)&gt;&gt;<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> arr[mid] &gt; value &#123;<br>high = mid - <span class="hljs-number">1</span><br><br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> arr[mid] &lt;= value &#123;<br><span class="hljs-keyword">if</span> (mid == n<span class="hljs-number">-1</span>) || (arr[mid+<span class="hljs-number">1</span>] &gt; value) &#123;<br><span class="hljs-keyword">return</span> mid<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>low = mid + <span class="hljs-number">1</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>十大排序算法</title>
    <link href="/2019/04/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    <url>/2019/04/18/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="排序算法的执行效率">排序算法的执行效率</h2><ol><li>最好情况、最坏情况、平均情况时间复杂度</li><li>时间复杂度的系数、常数 、低阶</li><li>比较次数和交换（或移动）次数</li></ol><span id="more"></span><h2 id="排序算法的内存消耗">排序算法的内存消耗</h2><p>原地排序（Sorted in place）。原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。我们今天讲的三种排序算法，都是原地排序算法。</p><h2 id="排序算法的稳定性">排序算法的稳定性</h2><p>如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。在真正软件开发中，我们要排序的往往不是单纯的整数，而是一组对象。</p><h2 id="1-冒泡排序">1.冒泡排序</h2><p>重复扫描需要排序的序列，比较相邻的两个元素，如果他们顺序错误就把他们交换位置，最大的时间复杂度为O(n^2)，空间复杂度为O(1)，是稳定的排序算法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// BubbleSort 冒牌排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BubbleSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br><span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> ary &#123;<br><span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; <span class="hljs-built_in">len</span>(ary)<span class="hljs-number">-1</span>-i; j++ &#123;<br><span class="hljs-keyword">if</span> ary[j] &gt; ary[j+<span class="hljs-number">1</span>] &#123;<br>ary[j], ary[j+<span class="hljs-number">1</span>] = ary[j+<span class="hljs-number">1</span>], ary[j]<br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> ary<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-选择排序">2.选择排序</h2><p>冒泡升级版，旨在把数组中最大（最小）一一选择出来放在前面，时间复杂度为O(n^2)，空间复杂度为O(1)，不稳定的排序</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// SelectSort 选择排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">SelectSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>length := <span class="hljs-built_in">len</span>(ary)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; length; i++ &#123;<br>index := i<br><span class="hljs-keyword">for</span> j := i; j &lt; length; j++ &#123;<br><span class="hljs-keyword">if</span> ary[j] &lt; ary[index] &#123;<br>index = j<br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span> index != i &#123;<br>ary[index], ary[i] = ary[i], ary[index]<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> ary<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-插入排序">3.插入排序</h2><p>构建有序序列，对于未排序序列，在已排序序列中从后往前扫描，找到相应的位置并插入，时间复杂度为O(n^2)，空间复杂度为O(1)，是稳定的排序算法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// InsertionSort 插入排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">InsertionSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt; <span class="hljs-built_in">len</span>(ary); i++ &#123;<br>temp := ary[i]<br>index := i<br><span class="hljs-keyword">for</span> index &gt; <span class="hljs-number">0</span> &amp;&amp; temp &lt; ary[index<span class="hljs-number">-1</span>] &#123;<br>ary[index], ary[index<span class="hljs-number">-1</span>] = ary[index<span class="hljs-number">-1</span>], ary[index]<br>index--<br>&#125;<br>ary[index] = temp<br>&#125;<br><span class="hljs-keyword">return</span> ary<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="4-希尔排序">4.希尔排序</h2><p>把记录按下表的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止，时间复杂度O(nlogn)，空间复杂度O(1)</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// ShellSort 希尔排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ShellSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>length := <span class="hljs-built_in">len</span>(ary)<br>temp, gap := <span class="hljs-number">0</span>, length/<span class="hljs-number">2</span><br><span class="hljs-keyword">for</span> gap &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">for</span> i := gap; i &lt; length; i++ &#123;<br>temp = ary[i]<br>j := i - gap<br><span class="hljs-keyword">for</span> j &gt;= <span class="hljs-number">0</span> &amp;&amp; ary[j] &gt; temp &#123;<br>ary[j+gap] = ary[j]<br>j = j - gap<br>&#125;<br>ary[j+gap] = temp<br>&#125;<br>gap /= <span class="hljs-number">2</span><br>&#125;<br><span class="hljs-keyword">return</span> ary<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="5-快速排序">5.快速排序</h2><p>选定一个基准值，把一个序列分成两部分，其中一部分均比另一部分小，然后通过递归的方式分别对两个部分进行相同方式的排序，直到整个序列有序，时间复杂度O(nlogn)，空间复杂度O(nlogn)，不稳定排序</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// QuickSort 快速排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">QuickSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>qSort(ary, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(ary)<span class="hljs-number">-1</span>)<br><span class="hljs-keyword">return</span> ary<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">qSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>, low, high <span class="hljs-keyword">int</span>)</span></span> &#123;<br><span class="hljs-keyword">if</span> low &gt; high &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br>pivot := partition(ary, low, high)<br>qSort(ary, low, pivot<span class="hljs-number">-1</span>)<br>qSort(ary, pivot+<span class="hljs-number">1</span>, high)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">partition</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>, low, high <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;<br>pivot := ary[low]<br><span class="hljs-keyword">for</span> low &lt; high &#123;<br><span class="hljs-keyword">for</span> low &lt; high &amp;&amp; ary[high] &gt;= pivot &#123;<br>high--<br>&#125;<br>ary[low] = ary[high]<br><span class="hljs-keyword">for</span> low &lt; high &amp;&amp; ary[low] &lt;= pivot &#123;<br>low++<br>&#125;<br>ary[high] = ary[low]<br>&#125;<br>ary[low] = pivot<br><span class="hljs-keyword">return</span> low<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="6-归并排序">6.归并排序</h2><p>如果要排序一个数组，可以把项目分成前后两个部分，分别对两个部分进行排序，再把两个合并在一起，再使用递归的思想去执行，时间复杂度O(nlogn)，空间复杂度O(n)，是稳定的算法</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">MergeSort</span><span class="hljs-params">(ary []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>length := <span class="hljs-built_in">len</span>(ary)<br><span class="hljs-keyword">if</span> length &lt; <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">return</span> ary<br>&#125;<br>middle := length / <span class="hljs-number">2</span><br>left := ary[<span class="hljs-number">0</span>:middle]<br>right := ary[middle:]<br><span class="hljs-keyword">return</span> merge(MergeSort(left), MergeSort(right))<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="7-桶排序">7.桶排序</h2><p>类似计数排序，手动设置一个桶，把在这个桶区间的值放入桶中，再对这个桶进行排序，时间复杂度O(n+k)，空间复杂度O(n+k)<br>桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// BucketSort 桶排序</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BucketSort</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, bucketSize <span class="hljs-keyword">int</span>)</span> <span class="hljs-params">(resultArr []<span class="hljs-keyword">int</span>)</span></span> &#123;<br><span class="hljs-keyword">if</span> arr == <span class="hljs-literal">nil</span> || <span class="hljs-built_in">len</span>(arr) &lt; <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">return</span> arr<br>&#125;<br>max, min := arr[<span class="hljs-number">0</span>], arr[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> arr &#123;<br><span class="hljs-keyword">if</span> v &gt; max &#123;<br>max = v<br>&#125;<br><span class="hljs-keyword">if</span> v &lt; min &#123;<br>min = v<br>&#125;<br>&#125;<br>bucketCount := (max-min)/bucketSize + <span class="hljs-number">1</span><br>bucketArr := <span class="hljs-built_in">make</span>([][]<span class="hljs-keyword">int</span>, bucketCount)<br><span class="hljs-keyword">for</span> i := <span class="hljs-keyword">range</span> arr &#123;<br>bucketArr[(arr[i]-min)/bucketSize] = <span class="hljs-built_in">append</span>(bucketArr[(arr[i]-min)/bucketSize], arr[i])<br>&#125;<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; bucketCount; i++ &#123;<br><span class="hljs-keyword">if</span> bucketCount == <span class="hljs-number">1</span> &#123;<br>bucketSize--<br>&#125;<br>temp := InsertionSort(bucketArr[i])<br><span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; <span class="hljs-built_in">len</span>(temp); j++ &#123;<br>resultArr = <span class="hljs-built_in">append</span>(resultArr, temp[j])<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> resultArr<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="8-计数排序">8. 计数排序</h2><p>// CountingSort 计数排序，利用数组下标进行计数，时间复杂度O(n + k)，空间复杂度O(k)</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">CountingSort</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, maxValue <span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>bucketLen := maxValue + <span class="hljs-number">1</span><br>bucket := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">int</span>, bucketLen) <span class="hljs-comment">// 初始为0的数组</span><br><br>sortedIndex := <span class="hljs-number">0</span><br>length := <span class="hljs-built_in">len</span>(arr)<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; length; i++ &#123;<br>bucket[arr[i]] += <span class="hljs-number">1</span><br>&#125;<br><br><span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; bucketLen; j++ &#123;<br><span class="hljs-keyword">for</span> bucket[j] &gt; <span class="hljs-number">0</span> &#123;<br>arr[sortedIndex] = j<br>sortedIndex += <span class="hljs-number">1</span><br>bucket[j] -= <span class="hljs-number">1</span><br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> arr<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="9-堆排序">9.堆排序</h2><p>利用完全二叉树的思想特性进行排序，时间复杂度O(nlogn)，空间复杂度O(1)</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">HeapSort</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>)</span> []<span class="hljs-title">int</span></span> &#123;<br>arrLen := <span class="hljs-built_in">len</span>(arr)<br>buildMaxHeap(arr, arrLen)<br><span class="hljs-keyword">return</span> arr<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">buildMaxHeap</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, arrLen <span class="hljs-keyword">int</span>)</span></span> &#123;<br><span class="hljs-keyword">for</span> i := arrLen / <span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">0</span>; i-- &#123;<br>heapify(arr, i, arrLen)<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">heapify</span><span class="hljs-params">(arr []<span class="hljs-keyword">int</span>, i, arrLen <span class="hljs-keyword">int</span>)</span></span> &#123;<br>left := <span class="hljs-number">2</span>*i + <span class="hljs-number">1</span><br>right := <span class="hljs-number">2</span>*i + <span class="hljs-number">2</span><br>largest := i<br><span class="hljs-keyword">if</span> left &lt; arrLen &amp;&amp; arr[left] &gt; arr[largest] &#123;<br>largest = left<br>&#125;<br><span class="hljs-keyword">if</span> right &lt; arrLen &amp;&amp; arr[right] &gt; arr[largest] &#123;<br>largest = right<br>&#125;<br><span class="hljs-keyword">if</span> largest != i &#123;<br>arr[i], arr[largest] = arr[largest], arr[i]<br>heapify(arr, largest, arrLen)<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="基数排序">基数排序</h2><p>先按照最后一位来排序，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。这样整体就有序了</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>递归</title>
    <link href="/2019/04/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92/"/>
    <url>/2019/04/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%80%92%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h2 id="递归">递归</h2><p>重复将问题分解为同类的子问题而解决问题的办法，表现为函数调用函数本身。</p><h2 id="需要满足的三个条件">需要满足的三个条件</h2><ol><li>一个问题可以分解为几个子问题的解</li><li>这个问题和子问题除了数据规模，求解思路完全一样</li><li>存在递归终止条件</li></ol><h2 id="如何编写递归代码？">如何编写递归代码？</h2><p>写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。<br>如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。因此，编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。</p><h2 id="递归代码要警惕堆栈溢出">递归代码要警惕堆栈溢出</h2><p>函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><h2 id="递归代码要警惕重复计算">递归代码要警惕重复计算</h2><p>当前问题下的子问题，可能在其他问题下的子问题下也进行了计算，这样就导致重复计算。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>递归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>递归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>队列</title>
    <link href="/2019/04/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%98%9F%E5%88%97/"/>
    <url>/2019/04/15/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E9%98%9F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h2 id="队列">队列</h2><p>先进者先出，后进者后出，这就是典型的“队列”</p><span id="more"></span><h2 id="顺序队列">顺序队列</h2><p>队列可以用数组来实现，也可以用链表来实现。用数组实现的栈叫作顺序栈，用链表实现的栈叫作链式栈。同样，用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。</p><p>队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。随着不停地进行入队、出队操作，head 和 tail 都会持续往后移动。当 tail 移动到最右边，即使数组中还有空闲空间，也无法继续往队列中添加数据了。如果没有空闲空间了，我们只需要在入队时，再集中触发一次数据的搬移操作。</p><h2 id="链式队列">链式队列</h2><p>基于链表的实现，我们同样需要两个指针：head 指针和 tail 指针。它们分别指向链表的第一个结点和最后一个结点。如图所示，入队时，tail-&gt;next= new_node, tail = tail-&gt;next；出队时，head = head-&gt;next。</p><h2 id="循环队列">循环队列</h2><p>循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在把首尾相连，扳成了一个环。<br>环形队列的关键在于确定好队空和队满的判定条件。假定头指针为head，尾指针为tail，队列为空的判断条件是 head == tail，队列满时，需要牺牲一个空间完成，当队满时，(tail+1)%n=head，此时tail指向的指针是没有存储数据。</p><h2 id="阻塞队列">阻塞队列</h2><p>阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。</p><h2 id="并发队列">并发队列</h2><p>线程安全的队列，简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>队列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>栈</title>
    <link href="/2019/04/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%A0%88/"/>
    <url>/2019/04/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%A0%88/</url>
    
    <content type="html"><![CDATA[<h2 id="栈">栈</h2><p>后进者先出，先进者后出，这就是典型的“栈”结构，是一种“操作受限”的线性表，只允许在一端插入和删除数据</p><span id="more"></span><h2 id="如何实现一个“栈”">如何实现一个“栈”</h2><p>栈主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Stack <span class="hljs-keyword">struct</span> &#123;<br>Items []<span class="hljs-keyword">string</span><br>Count <span class="hljs-keyword">int</span><br>Size  <span class="hljs-keyword">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(stack *Stack)</span> <span class="hljs-title">NewStack</span><span class="hljs-params">(n <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">Stack</span></span> &#123;<br><span class="hljs-keyword">return</span> Stack&#123;<br>Items: <span class="hljs-literal">nil</span>,<br>Count: <span class="hljs-number">0</span>,<br>Size:  n,<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(stack *Stack)</span> <span class="hljs-title">push</span><span class="hljs-params">(in <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">bool</span></span> &#123;<br><span class="hljs-keyword">if</span> stack.Count == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>stack.Items[stack.Count] = in<br>stack.Count++<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(stack *Stack)</span> <span class="hljs-title">pop</span><span class="hljs-params">(in <span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<br><span class="hljs-keyword">if</span> stack.Count == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span><br>&#125;<br>temp := stack.Items[stack.Count<span class="hljs-number">-1</span>]<br>stack.Count--<br><span class="hljs-keyword">return</span> temp<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="栈在函数调用中的应用">栈在函数调用中的应用</h2><p>操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><h2 id="栈在表达式求值中的应用">栈在表达式求值中的应用</h2><p>编译器是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>栈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数组</title>
    <link href="/2019/04/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/"/>
    <url>/2019/04/10/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E6%95%B0%E7%BB%84/</url>
    
    <content type="html"><![CDATA[<h2 id="定义">定义</h2><p>数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。</p><ol><li>线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。</li><li>连续的内存空间和相同类型的数据。</li></ol><span id="more"></span><h2 id="低效的“插入”和“删除”">低效的“插入”和“删除”</h2><p>数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效，复杂度为O(n)</p><h2 id="警惕数组的访问越界问题">警惕数组的访问越界问题</h2><p>在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">int</span>[] a = <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[<span class="hljs-number">3</span>];<br>a[<span class="hljs-number">3</span>] = <span class="hljs-number">10</span>;<br></code></pre></td></tr></table></figure><h2 id="为什么大多数编程语言中，数组要从-0-开始编号，而不是从-1-开始呢？">为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？</h2><p>从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C">a[k]_address = base_address + k * type_size<br></code></pre></td></tr></table></figure><p>但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：</p><pre><code class="language-C">a[k]_address = base_address + (k-1)*type_size</code></pre><p>从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>复杂度计算</title>
    <link href="/2019/04/09/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AE%A1%E7%AE%97/"/>
    <url>/2019/04/09/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法</p><span id="more"></span><h2 id="时间复杂度">时间复杂度</h2><p>时间复杂度代表代码执行时间随数据规模增长的变化趋势，所有代码的执行时间 T(n) 与每行代码的执行次数 f(n) 成正比，所以<code>T(n) = O(f(n))</code></p><h3 id="分析方法">分析方法</h3><ol><li>只关注循环执行次数最多的一段代码</li><li>加法法则：总复杂度等于量级最大的那段代码的复杂度</li><li>乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积</li></ol><h2 id="几种常见时间复杂度实例分析">几种常见时间复杂度实例分析</h2><h3 id="O-1">O(1)</h3><p>一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)</p><h3 id="O-logn-、O-nlogn">O(logn)、O(nlogn)</h3><p>如代码，i = i * 2执行后的结果为 2^k &gt; n， 所以代码会执行k次，通过数学计算，k=log2n，通常情况下底数可以省略，所以复杂度为O(logn)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs JAVA">i=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span> (i &lt;= n)  &#123;<br>  i = i * <span class="hljs-number">2</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="O-m-n-、O-m-n">O(m+n)、O(m*n)</h3><p>代码的复杂度由两个数据的规模来决定</p><h2 id="空间复杂度">空间复杂度</h2><p>算法的存储空间与数据规模之间的增长关系</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>食谱</title>
    <link href="/2018/11/02/05.%E9%9A%8F%E7%AC%94/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    <url>/2018/11/02/05.%E9%9A%8F%E7%AC%94/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1>一、学习路线</h1><p>现在学习的目的主要是为了找工作，所以学习路线应该精简且有用。</p><ol><li>go runtime并发编程</li><li>go面试题</li><li>Mysql 原理篇主从复制</li><li>kafka应用及原理</li><li>Redis原理</li><li>beego、gin、krotos的官方文档看一遍，并且梳理一下源码</li><li>gRPC，protobuf</li><li>nginx + keepalive 部署方法，以及可能遇到的问题</li><li>云原生技术 K8S，docker，监控</li><li>ELK日志搜集</li></ol><h1>二、学习方法</h1><ol><li>效率要高，看过一遍之后一定要重新梳理一遍。</li><li>不要看那些没用的话。</li><li>总结一些实战场景，发散性的考虑可能遇到的问题。</li></ol>]]></content>
    
    
    <categories>
      
      <category>食谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>食谱</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JavaScript基础</title>
    <link href="/2018/03/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/JavaScript/"/>
    <url>/2018/03/22/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/JavaScript/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><p>概述：JavaScript 是属于 HTML 和 Web 的编程语言，编程令计算机完成您需要它们做的工作，脱胎于Java</p><span id="more"></span><h2 id="一、JavaScript值">一、JavaScript值</h2><ol><li>字面量<br>写数值有无小数点均可，字符串是文本，由双引号或单引号包围</li><li>变量<br>变量用于存储数据值</li><li>运算符<br>JavaScript 使用算数运算符（+ - * /）来计算值</li><li>表达式<br>表达式是值、变量和运算符的组合，计算结果是值</li><li>关键词<br>用于标识被执行的动作</li><li>数据类型<ul><li>字符串值</li><li>数值</li><li>布尔值</li><li>数组</li><li>对象</li></ul></li><li>let和const<br>提供了块作用域（Block Scope）变量（和常量）,let 能重新赋值，但是const不能重新赋值</li></ol><h2 id="二、函数">二、函数</h2><p>函数是被设计为执行特定任务的代码块，会在某代码调用它时被执行</p><h2 id="三、对象">三、对象</h2><p>和Java对象概念一样<br>包含属性和方法</p><h2 id="四、事件">四、事件</h2><p>事件是发生在 HTML 元素上的“事情”。当在 HTML 页面中使用 JavaScript 时，JavaScript 能够“应对”这些事件。<br>HTML 事件可以是浏览器或用户做的某些事情。</p><p>下面是 HTML 事件的一些例子：<br>HTML 网页完成加载<br>HTML 输入字段被修改<br>HTML 按钮被点击<br>通常，当事件发生时，用户会希望做某件事。<br>JavaScript 允许您在事件被侦测到时执行代码。</p><p>常见事件：</p><table><thead><tr><th>事件</th><th>描述</th></tr></thead><tbody><tr><td>onchange</td><td>HTML 元素已被改变</td></tr><tr><td>onclick</td><td>用户点击了 HTML 元素</td></tr><tr><td>onmouseover</td><td>用户把鼠标移动到 HTML 元素上</td></tr><tr><td>onmouseout</td><td>用户把鼠标移开 HTML 元素</td></tr><tr><td>onkeydown</td><td>用户按下键盘按键</td></tr><tr><td>onload</td><td>浏览器已经完成页面加载</td></tr></tbody></table><h2 id="五、字符串">五、字符串</h2><p>字符串用于存储和操作文本<br>内建属性 length 可返回字符串的长度<br>indexOf() 方法返回字符串中指定文本首次出现的索引（位置）<br>lastIndexOf() 方法返回指定文本在字符串中最后一次出现的索引<br>search()</p><h2 id="六、数组">六、数组</h2><p>toString() 把数组转换为数组值（逗号分隔）的字符串。<br>join() 方法也可将所有数组元素结合为一个字符串。<br>pop() 方法从数组中删除最后一个元素<br>push() 方法（在数组结尾处）向数组添加一个新的元素<br>shift() 方法会删除首个数组元素，并把所有其他元素“位移”到更低的索引<br>unshift() 方法（在开头）向数组添加新元素，并“反向位移”旧元素<br>splice() 方法可用于向数组添加新项<br>concat() 方法通过合并（连接）现有数组来创建一个新数组<br>sort() 方法以字母顺序对数组进行排序<br>reverse() 方法反转数组中的元素</p>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>JavaScript</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSS基础</title>
    <link href="/2018/03/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/CSS/"/>
    <url>/2018/03/17/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/CSS/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><p>概述：CSS 是一种描述 HTML 文档样式的语言，描述应该如何显示 HTML 元素</p><span id="more"></span><h2 id="一、选择器">一、选择器</h2><ol><li>简单选择器</li></ol><ul><li>元素选择器</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-selector-tag">p</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>id 选择器</li></ul> <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-selector-id">#para1</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>类选择器</li></ul> <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-selector-class">.center</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>通用选择器</li></ul> <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs CSS">* &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: blue;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>分组选择器</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-selector-tag">h1</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br><br><span class="hljs-selector-tag">h2</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br><br><span class="hljs-selector-tag">p</span> &#123;<br>  <span class="hljs-attribute">text-align</span>: center;<br>  <span class="hljs-attribute">color</span>: red;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="二、背景">二、背景</h2><ul><li>background-color 属性指定元素的背景色</li><li>background-image 属性指定用作元素背景的图像。</li><li>background-repeat 默认情况下，background-image 属性在水平和垂直方向上都重复图像。</li><li>background-attachment 属性指定背景图像是应该滚动还是固定的（不会随页面的其余部分一起滚动）：</li><li>background-position background-position 属性用于指定背景图像的位置。</li><li>opacity 属性指定元素的不透明度/透明度。取值范围为 0.0 - 1.0。值越低，越透明</li></ul><h2 id="三、边框">三、边框</h2><ol><li>边框属性 border</li><li>边框样式 border-style</li><li>边框宽度 border-width 属性指定四个边框的宽度</li><li>边框颜色 border-color 属性用于设置四个边框的颜色</li><li>单独边</li><li>圆角边框 border-radius 属性用于向元素添加圆角边框</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs CSS"><span class="hljs-selector-tag">p</span> &#123;<br>  <span class="hljs-attribute">border-top-style</span>: dotted;<br>  <span class="hljs-attribute">border-right-style</span>: solid;<br>  <span class="hljs-attribute">border-bottom-style</span>: dotted;<br>  <span class="hljs-attribute">border-left-style</span>: solid;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="四、边距">四、边距</h2><p>margin 属性用于在任何定义的边框之外，为元素周围创建空间并<br>当两个垂直外边距相遇时，它们将形成一个外边距，合并后的外边距的高度等于两个发生合并的外边距的高度中的较大者</p><p>padding 属性用于在任何定义的边界内的元素内容周围生成空间</p><p>轮廓是在元素周围绘制的一条线，在边框之外，以凸显元素。</p><h2 id="五、文本">五、文本</h2><p>color 属性用于设置文本的颜色<br>text-align 属性用于设置文本的水平对齐方式<br>text-decoration 属性用于设置或删除文本装饰</p><h2 id="六、布局">六、布局</h2><p>display 属性规定是否/如何显示元素<br>position 属性规定应用于元素的定位方法的类型<br>float 属性规定元素如何浮动<br>clear 属性规定哪些元素可以在清除的元素旁边以及在哪一侧浮动</p>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSS</tag>
      
      <tag>前端</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTML基础</title>
    <link href="/2018/03/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/HTML/"/>
    <url>/2018/03/12/01.%E7%9F%A5%E8%AF%86%E6%9E%B6%E6%9E%84/front/HTML/</url>
    
    <content type="html"><![CDATA[<h1>前言</h1><p>概述：HTML由标签组成，在学习HTML的时候，记录一些基础常用标签</p><span id="more"></span><h2 id="一、标签">一、标签</h2><h3 id="1-标题">1.标题</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">h1</span>&gt;</span>This is a heading<span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h2</span>&gt;</span>This is a heading<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h3</span>&gt;</span>This is a heading<span class="hljs-tag">&lt;/<span class="hljs-name">h3</span>&gt;</span><br>```  <br><br>### 2.段落<br><br>``` HTML<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span>This is a paragraph.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="3-链接">3.链接</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;http://www.baidu.com&quot;</span>&gt;</span>This is a link<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="4-图像">4.图像</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;&quot;</span> <span class="hljs-attr">width</span>=<span class="hljs-string">&quot;&quot;</span> <span class="hljs-attr">height</span>=<span class="hljs-string">&quot;&quot;</span> /&gt;</span><br></code></pre></td></tr></table></figure><h3 id="5-水平线">5.水平线</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">hr</span> /&gt;</span><br></code></pre></td></tr></table></figure><h3 id="6-注释">6.注释</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-comment">&lt;!-- This is a comment --&gt;</span><br></code></pre></td></tr></table></figure><h3 id="7-折行">7.折行</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">br</span> /&gt;</span><br></code></pre></td></tr></table></figure><h3 id="8-表格">8.表格</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">border</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">tr</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>row 1, cell 1<span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>row 1, cell 2<span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">tr</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">tr</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>row 2, cell 1<span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span>row 2, cell 2<span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">tr</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="9-无序列表">9.无序列表</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">ul</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">li</span>&gt;</span>Coffee<span class="hljs-tag">&lt;/<span class="hljs-name">li</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">li</span>&gt;</span>Milk<span class="hljs-tag">&lt;/<span class="hljs-name">li</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">ul</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="10-有序列表">10.有序列表</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">ol</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">li</span>&gt;</span>Coffee<span class="hljs-tag">&lt;/<span class="hljs-name">li</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">li</span>&gt;</span>Milk<span class="hljs-tag">&lt;/<span class="hljs-name">li</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">ol</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="11-块元素">11.块元素</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">div</span>&gt;</span> 定义文档中的分区或节（division/section）。<br><span class="hljs-tag">&lt;<span class="hljs-name">span</span>&gt;</span> 定义 span，用来组合文档中的行内元素。<br></code></pre></td></tr></table></figure><h2 id="二、属性">二、属性</h2><p>HTML 标签可以拥有属性。属性提供了有关 HTML 元素的更多的信息。<br>属性总是以名称/值对的形式出现，比如：name=“value”。<br>属性总是在 HTML 元素的开始标签中规定。</p><p>例：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;http://www.baidu.com&quot;</span>&gt;</span>This is a link<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="1-style-属性用于改变-HTML-元素的样式">1. style 属性用于改变 HTML 元素的样式</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h1</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;font-family:verdana&quot;</span>&gt;</span>A heading<span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;font-family:arial;color:red;font-size:20px;&quot;</span>&gt;</span>A paragraph.<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="2-id-属性">2. id 属性</h3><p>id 属性指定 HTML 元素的唯一 ID。 id 属性的值在 HTML 文档中必须是唯一的。<br>id 属性用于指向样式表中的特定样式声明。JavaScript 也可使用它来访问和操作拥有特定 ID 的元素。<br>id 的语法是：写一个井号 (#)，后跟一个 id 名称。然后，在花括号 {} 中定义 CSS 属性。</p><h2 id="三、类">三、类</h2><p>对 HTML 进行分类（设置类），使我们能够为元素的类定义 CSS 样式。<br>为相同的类设置相同的样式，或者为不同的类设置不同的样式。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-meta-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">style</span>&gt;</span><span class="css"></span><br><span class="css"><span class="hljs-selector-class">.cities</span> &#123;</span><br><span class="css">    <span class="hljs-attribute">background-color</span>:black;</span><br><span class="css">    <span class="hljs-attribute">color</span>:white;</span><br><span class="css">    <span class="hljs-attribute">margin</span>:<span class="hljs-number">20px</span>;</span><br><span class="css">    <span class="hljs-attribute">padding</span>:<span class="hljs-number">20px</span>;</span><br><span class="css">&#125; </span><br><span class="css"></span><span class="hljs-tag">&lt;/<span class="hljs-name">style</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;cities&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h2</span>&gt;</span>London<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><br>London is the capital city of England. <br>It is the most populous city in the United Kingdom, <br>with a metropolitan area of over 13 million inhabitants.<br><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span> <br><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br></code></pre></td></tr></table></figure><h2 id="四、header-头部">四、header 头部</h2><h3 id="1-head-元素">1. <code>&lt;head&gt;</code> 元素</h3><p><code>&lt;head&gt;</code> 元素是所有头部元素的容器。<code>&lt;head&gt;</code> 内的元素可包含脚本，指示浏览器在何处可以找到样式表，提供元信息，等等。</p><h3 id="2-title-元素">2. <code>&lt;title&gt;</code> 元素</h3><p><code>&lt;title&gt;</code> 标签定义文档的标题。</p><h3 id="3-base-元素">3. <code>&lt;base&gt;</code> 元素</h3><p><code>&lt;base&gt;</code> 标签为页面上的所有链接规定默认地址或默认目标</p><h3 id="4-link-元素">4. <code>&lt;link&gt;</code> 元素</h3><p><code>&lt;link&gt;</code> 标签定义文档与外部资源之间的关系</p><h3 id="5-style-元素">5. <code>&lt;style&gt;</code> 元素</h3><p><code>&lt;style&gt;</code> 标签用于为 HTML 文档定义样式信息</p><h3 id="6-meta-元素">6. <code>&lt;meta&gt;</code> 元素</h3><p>元数据（metadata）是关于数据的信息。<br><code>&lt;meta&gt;</code> 标签提供关于 HTML 文档的元数据。元数据不会显示在页面上，但是对于机器是可读的</p><h3 id="7-script-元素">7. <code>&lt;script&gt;</code> 元素</h3><p><code>&lt;script&gt;</code> 标签用于定义客户端脚本，比如 JavaScript</p>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>前端</tag>
      
      <tag>HTML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>offer选择</title>
    <link href="/2018/03/08/04.%E9%9D%A2%E8%AF%95/offer%E9%80%89%E6%8B%A9/"/>
    <url>/2018/03/08/04.%E9%9D%A2%E8%AF%95/offer%E9%80%89%E6%8B%A9/</url>
    
    <content type="html"><![CDATA[<p><strong>1.工资、福利</strong></p><p>工资=基本工资+绩效奖金+各项补贴，问清楚offer上的薪资是底薪还是综合薪资，绩效奖金是如何考核的，平时有没有额外的福利补贴。</p><p>有的求职者面试时被告知薪资是10k，入职之后才发现是6k底薪+4k绩效，实际到手的薪资差了一大截。</p><p><strong>2.五险一金</strong></p><p>提前问清楚是不是入职之后就提供五险一金，当月还是次月，公积金缴存的比例是多少，基数是否是按照实际工资来。</p><p>五险一金和我们买房、医疗等息息相关，一定要问清楚了。</p><p><strong>3.试用期</strong></p><p>问清合同期限、试用期的时间、试用期薪资是否打折，以及问清转正的考核方式。</p><p>**劳动合同法规定：**合同期限3个月以上不满1年的，试用期应小于1个月；合同期限1年以上不满3年的，试用期应小于2个月；合同期限3年以及以上无固定期限的劳动合同，试用期应小于6个月。劳动者在试用期的工资不得低于本单位相同岗位最低档工资或者劳动合同约定工资的 80％，并不得低于用人单位所在地的最低工资标准。</p><p><strong>4.工作时间</strong></p><p>公司是单休、双休还是大小周，工作时间是几点到几点，加班费的计算方法。</p><p>有的朋友跳槽的时候只注意薪资，没注意实际工作时间，薪资涨了不到30%，工作强度却翻了一倍，时薪反而降低了。</p><p><strong>5.培训晋升机制</strong></p><p>入职后有没有培训？晋升机制如何？这些与自己今后在公司的成长跟发展空间有密切的关系。</p>]]></content>
    
    
    <categories>
      
      <category>offer</category>
      
    </categories>
    
    
    <tags>
      
      <tag>offer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面试经验</title>
    <link href="/2018/03/08/04.%E9%9D%A2%E8%AF%95/%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/"/>
    <url>/2018/03/08/04.%E9%9D%A2%E8%AF%95/%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<h2 id="回答问题">回答问题</h2><ol><li>抓住问题的知识考核点，如果不理解，甚至可以反问。</li><li>针对问题有条理的背诵即可。</li><li>提前备好常见的问题。</li><li>分析简历上会问到的问题。</li></ol><h2 id="自我介绍">自我介绍</h2><p>擅长技能、最深入研究的知识领域、个性中最积极的部分、做过最成功的事等，所以可以着重描述跟面试岗位相关的经历——项目、职责和能力，并且突出积极的个性和做事的能力。<br>面试官，您好。我叫曾政雄，来自长沙，毕业于湖南农业大学，主修电子信息工程专业。之前在中软国际、四方精创等公司担任golang开发职位，有4年的go开发工作经验。任职期间，主要负责架构设计，微服务划分落地，在高并发场景下的性能调优工作，上线项目中，拥有百万并发经历。</p><h2 id="修改思路">修改思路</h2><p>背景、工作、解决了什么问题、成果</p><p>负责…，使用…技术，解决了…问题。</p><h2 id="技术亮点">技术亮点</h2><p>每一个相关的组件技术，都准备一个难点问题。</p><h2 id="面经">面经</h2><p>自己可以总结面经，同时可以多看看其他人的面经，通过常问的题目发散出来</p><h2 id="其他人的经验">其他人的经验</h2><p>1、工作经验。系统性总结你工作的几方面，尽量显得你很专业又有一定经验能胜任投递的岗位，就算没做过也要吹自己（别硬吹就行）；</p><p>2、自信，自我介绍或问你问题的时候一定要从容自信，别扭扭捏捏有话不敢说，别显得你工作的时候都是混日子，让人觉得你既上进又努力那种。</p><p>3、谈工资的时候工资上调你期望值的20%，这样就好谈价了，别你要1w就跟人说要1w，说你要1.2或1.1，这样hr给出9-10的价的时候你就可以装不情愿但看在你们诚心要我的份上同意了的效果。 1.4 * 1.2 = 1.7k</p><h2 id="学习web框架">学习web框架</h2><p>不建议一开始就阅读源码，要学习设计者怎么去设计的，比如orm框架，一个select语句，输入一个语句，查询出一个结构集，转换成对应的对象。始终要把自己带入一个设计者的角色！！！然后遇到问题，我要怎么处理，然后看别人怎么去处理。</p><h2 id="刷简历的方式">刷简历的方式</h2><p>找开源项目，提供自己的贡献</p><h2 id="线上事故">线上事故</h2><ol><li><p>协程泄漏</p></li><li><p>内存溢出</p></li><li><p>runtime</p></li><li><p>context优化</p></li></ol><h2 id="架构设计的思路">架构设计的思路</h2>]]></content>
    
    
    <categories>
      
      <category>面试经验</category>
      
    </categories>
    
    
    <tags>
      
      <tag>面试经验</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
